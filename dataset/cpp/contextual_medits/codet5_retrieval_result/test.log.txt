10/04/2023 08:42:41 - INFO - __main__ -   Namespace(ECMG_type='shared_encoders', adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=False, base_model_type='codet5', beam_size=10, cache_path='cache/codesum/java', config_name='', data_num=-1, debug=False, dev_filename='../data/commit_msg/java/contextual_medits/valid.jsonl', dev_retireved_filename='../data/commit_msg/java/contextual_medits/valid.jsonl', diff_type='contextual-medit', do_eval=False, do_eval_bleu=False, do_lower_case=False, do_retrieval=True, do_test=False, do_train=False, eval_batch_size=6, eval_frequency=1, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, is_cosine_space=True, lang='java', learning_rate=5e-05, load_finetuned_model_path=None, load_model_path='saved_model/codet5/cpp/checkpoint-best-bleu/pytorch_model.bin', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=30, model_name_or_path='Salesforce/codet5-base', model_type='codet5', n_debug_samples=100, no_cuda=False, num_train_epochs=10, output_dir='../saved_model/commit_msg_generation/java/tmp', patience=5, retrieval_filename='dataset/cpp/contextual_medits/test.jsonl', retrieval_result_dir='dataset/cpp/contextual_medits/codet5_retrieval_result', retrieval_result_filename='test.jsonl', run_codet5=True, save_last_checkpoints=False, save_steps=-1, seed=3407, start_epoch=0, summary_dir='saved_model/codesum/tmp', task='summarize', test_filename='../data/commit_msg/java/contextual_medits/test.jsonl', test_retireved_filename='../data/commit_msg/java/contextual_medits/test.jsonl', tokenizer_name='Salesforce/codet5-small', train_batch_size=6, train_filename='dataset/cpp/contextual_medits/train.jsonl', train_retireved_filename='../data/commit_msg/java/contextual_medits/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
10/04/2023 08:42:41 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, cpu count: 8
10/04/2023 08:42:50 - INFO - __main__ -   adding new token {'additional_special_tokens': ['<REPLACE>', '<REPLACE_OLD>', '<REPLACE_NEW>', '<REPLACE_END>', '<INSERT>', '<INSERT_OLD>', '<INSERT_NEW>', '<INSERT_END>', '<DELETE>', '<DELETE_END>', '<KEEP>', '<KEEP_END>']}
10/04/2023 08:42:50 - INFO - __main__ -   Reload model from saved_model/codet5/cpp/checkpoint-best-bleu/pytorch_model.bin
10/04/2023 08:42:57 - INFO - __main__ -     ***** retrievaling *****
10/04/2023 08:42:57 - INFO - __main__ -     Batch size = 6
10/04/2023 08:43:50 - INFO - util -   Read 23172 examples, avg src len: 210, avg trg len: 7, max src len: 3907, max trg len: 15
10/04/2023 08:43:50 - INFO - util -   [TOKENIZE] avg src len: 237, avg trg len: 14, max src len: 4465, max trg len: 71
10/04/2023 08:43:50 - INFO - util -   Create cache data into cache/codesum/java/train_all.pt
  0%|          | 0/23172 [00:00<?, ?it/s]  3%|▎         | 725/23172 [00:00<00:04, 4580.77it/s]  6%|▋         | 1450/23172 [00:00<00:03, 5517.73it/s]  9%|▉         | 2175/23172 [00:00<00:03, 5895.99it/s] 13%|█▎        | 2900/23172 [00:00<00:03, 6077.57it/s] 16%|█▌        | 3625/23172 [00:00<00:03, 6153.55it/s] 19%|█▉        | 4350/23172 [00:00<00:03, 6235.05it/s] 22%|██▏       | 5075/23172 [00:00<00:02, 6233.20it/s] 25%|██▌       | 5800/23172 [00:00<00:02, 6247.45it/s] 28%|██▊       | 6525/23172 [00:02<00:12, 1358.39it/s] 31%|███▏      | 7250/23172 [00:02<00:10, 1546.11it/s] 34%|███▍      | 7975/23172 [00:02<00:07, 1975.36it/s] 38%|███▊      | 8700/23172 [00:02<00:05, 2512.42it/s] 41%|████      | 9425/23172 [00:03<00:04, 3027.30it/s] 44%|████▍     | 10150/23172 [00:03<00:03, 3594.36it/s] 47%|████▋     | 10875/23172 [00:03<00:02, 4169.23it/s] 50%|█████     | 11600/23172 [00:03<00:02, 4103.66it/s] 53%|█████▎    | 12325/23172 [00:04<00:06, 1623.11it/s] 56%|█████▋    | 13050/23172 [00:04<00:06, 1674.91it/s] 59%|█████▉    | 13775/23172 [00:05<00:04, 2116.54it/s] 63%|██████▎   | 14500/23172 [00:05<00:03, 2652.55it/s] 66%|██████▌   | 15225/23172 [00:05<00:02, 3123.62it/s] 69%|██████▉   | 15950/23172 [00:05<00:02, 3425.02it/s] 72%|███████▏  | 16675/23172 [00:05<00:01, 4021.84it/s] 75%|███████▌  | 17400/23172 [00:05<00:01, 4135.15it/s] 78%|███████▊  | 18125/23172 [00:06<00:03, 1532.06it/s] 81%|████████▏ | 18850/23172 [00:07<00:02, 1517.21it/s] 84%|████████▍ | 19575/23172 [00:07<00:01, 1937.56it/s] 88%|████████▊ | 20300/23172 [00:07<00:01, 2376.09it/s] 91%|█████████ | 21025/23172 [00:07<00:00, 2829.85it/s] 94%|█████████▍| 21750/23172 [00:07<00:00, 3455.17it/s] 97%|█████████▋| 22475/23172 [00:08<00:00, 3962.14it/s]100%|██████████| 23172/23172 [00:08<00:00, 2860.55it/s]
10/04/2023 08:44:15 - INFO - util -   Read 6151 examples, avg src len: 215, avg trg len: 7, max src len: 2799, max trg len: 15
10/04/2023 08:44:15 - INFO - util -   [TOKENIZE] avg src len: 245, avg trg len: 14, max src len: 2959, max trg len: 43
10/04/2023 08:44:15 - INFO - util -   Create cache data into cache/codesum/java/train_src_all.pt
  0%|          | 0/6151 [00:00<?, ?it/s]  6%|▋         | 386/6151 [00:00<00:02, 2135.09it/s] 13%|█▎        | 772/6151 [00:00<00:02, 2142.33it/s] 19%|█▉        | 1158/6151 [00:00<00:02, 2190.62it/s] 25%|██▌       | 1544/6151 [00:00<00:02, 2126.10it/s] 29%|██▊       | 1757/6151 [00:00<00:02, 2030.46it/s] 32%|███▏      | 1958/6151 [00:00<00:02, 1957.48it/s] 35%|███▍      | 2150/6151 [00:01<00:02, 1905.00it/s] 38%|███▊      | 2337/6151 [00:01<00:02, 1891.83it/s] 44%|████▍     | 2702/6151 [00:01<00:01, 1895.97it/s] 47%|████▋     | 2895/6151 [00:01<00:01, 1903.88it/s] 53%|█████▎    | 3281/6151 [00:01<00:01, 1900.95it/s] 56%|█████▋    | 3474/6151 [00:01<00:01, 1875.42it/s] 60%|█████▉    | 3667/6151 [00:01<00:01, 1849.35it/s] 63%|██████▎   | 3860/6151 [00:02<00:01, 1763.75it/s] 66%|██████▌   | 4053/6151 [00:02<00:01, 1770.08it/s] 69%|██████▉   | 4246/6151 [00:02<00:01, 1765.75it/s] 75%|███████▌  | 4632/6151 [00:02<00:00, 1858.30it/s] 82%|████████▏ | 5018/6151 [00:02<00:00, 1900.07it/s] 85%|████████▍ | 5211/6151 [00:02<00:00, 1858.34it/s] 91%|█████████ | 5597/6151 [00:02<00:00, 1889.12it/s] 97%|█████████▋| 5983/6151 [00:03<00:00, 1925.99it/s]100%|██████████| 6151/6151 [00:03<00:00, 1974.99it/s]
10/04/2023 08:44:19 - INFO - __main__ -     Num examples of Corpus = 23172
10/04/2023 08:46:15 - INFO - __main__ -     Num examples to retrieve = 6151
10/04/2023 08:47:05 - INFO - __main__ -   ranked list [ 2154  2513 12380  1371  2266  3021  8717  1710   439 10800  7832  1349
  6485  6666  6387  2966  2200  3626  5133 10707  1710  7207  4816  4246
  5417  6018  1400  7882 11854  1860]
Total: 6151
10/04/2023 08:47:07 - INFO - __main__ -     codenn_bleu = 9.42 
10/04/2023 08:47:07 - INFO - __main__ -    save predict result in dataset/cpp/contextual_medits/codet5_retrieval_result/test.jsonl.retireval.output
10/04/2023 08:47:07 - INFO - __main__ -   Finish and take 4m
saved dataset in dataset/cpp/contextual_medits/codet5_retrieval_result/test.jsonl
