10/04/2023 08:31:13 - INFO - __main__ -   Namespace(ECMG_type='shared_encoders', adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=False, base_model_type='codet5', beam_size=10, cache_path='cache/codesum/java', config_name='', data_num=-1, debug=False, dev_filename='../data/commit_msg/java/contextual_medits/valid.jsonl', dev_retireved_filename='../data/commit_msg/java/contextual_medits/valid.jsonl', diff_type='contextual-medit', do_eval=False, do_eval_bleu=False, do_lower_case=False, do_retrieval=True, do_test=False, do_train=False, eval_batch_size=6, eval_frequency=1, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, is_cosine_space=True, lang='java', learning_rate=5e-05, load_finetuned_model_path=None, load_model_path='saved_model/codet5/cpp/checkpoint-best-bleu/pytorch_model.bin', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=30, model_name_or_path='Salesforce/codet5-base', model_type='codet5', n_debug_samples=100, no_cuda=False, num_train_epochs=10, output_dir='../saved_model/commit_msg_generation/java/tmp', patience=5, retrieval_filename='dataset/cpp/contextual_medits/train.jsonl', retrieval_result_dir='dataset/cpp/contextual_medits/codet5_retrieval_result', retrieval_result_filename='train.jsonl', run_codet5=True, save_last_checkpoints=False, save_steps=-1, seed=3407, start_epoch=0, summary_dir='saved_model/codesum/tmp', task='summarize', test_filename='../data/commit_msg/java/contextual_medits/test.jsonl', test_retireved_filename='../data/commit_msg/java/contextual_medits/test.jsonl', tokenizer_name='Salesforce/codet5-small', train_batch_size=6, train_filename='dataset/cpp/contextual_medits/train.jsonl', train_retireved_filename='../data/commit_msg/java/contextual_medits/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
10/04/2023 08:31:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, cpu count: 8
10/04/2023 08:31:23 - INFO - __main__ -   adding new token {'additional_special_tokens': ['<REPLACE>', '<REPLACE_OLD>', '<REPLACE_NEW>', '<REPLACE_END>', '<INSERT>', '<INSERT_OLD>', '<INSERT_NEW>', '<INSERT_END>', '<DELETE>', '<DELETE_END>', '<KEEP>', '<KEEP_END>']}
10/04/2023 08:31:23 - INFO - __main__ -   Reload model from saved_model/codet5/cpp/checkpoint-best-bleu/pytorch_model.bin
10/04/2023 08:31:30 - INFO - __main__ -     ***** retrievaling *****
10/04/2023 08:31:30 - INFO - __main__ -     Batch size = 6
10/04/2023 08:32:23 - INFO - util -   Read 23172 examples, avg src len: 210, avg trg len: 7, max src len: 3907, max trg len: 15
10/04/2023 08:32:23 - INFO - util -   [TOKENIZE] avg src len: 237, avg trg len: 14, max src len: 4465, max trg len: 71
10/04/2023 08:32:23 - INFO - util -   Create cache data into cache/codesum/java/train_all.pt
  0%|          | 0/23172 [00:00<?, ?it/s]  3%|▎         | 725/23172 [00:00<00:04, 4597.23it/s]  6%|▋         | 1450/23172 [00:00<00:03, 5538.95it/s]  9%|▉         | 2175/23172 [00:00<00:03, 5938.33it/s] 13%|█▎        | 2900/23172 [00:00<00:03, 6134.32it/s] 16%|█▌        | 3625/23172 [00:00<00:03, 6289.79it/s] 19%|█▉        | 4350/23172 [00:00<00:02, 6351.94it/s] 22%|██▏       | 5075/23172 [00:00<00:02, 6558.31it/s] 25%|██▌       | 5800/23172 [00:00<00:02, 6183.70it/s] 28%|██▊       | 6525/23172 [00:02<00:12, 1313.25it/s] 31%|███▏      | 7250/23172 [00:02<00:10, 1464.41it/s] 34%|███▍      | 7975/23172 [00:02<00:08, 1896.66it/s] 38%|███▊      | 8700/23172 [00:03<00:05, 2430.49it/s] 41%|████      | 9425/23172 [00:03<00:04, 2981.32it/s] 44%|████▍     | 10150/23172 [00:03<00:03, 3394.99it/s] 47%|████▋     | 10875/23172 [00:03<00:03, 3903.99it/s] 53%|█████▎    | 12325/23172 [00:04<00:05, 1871.92it/s] 56%|█████▋    | 13050/23172 [00:05<00:05, 1925.67it/s] 59%|█████▉    | 13775/23172 [00:05<00:04, 2128.09it/s] 66%|██████▌   | 15225/23172 [00:05<00:02, 3066.83it/s] 69%|██████▉   | 15950/23172 [00:05<00:02, 3354.59it/s] 75%|███████▌  | 17400/23172 [00:05<00:01, 4015.57it/s] 78%|███████▊  | 18125/23172 [00:07<00:03, 1525.45it/s] 81%|████████▏ | 18850/23172 [00:07<00:02, 1816.03it/s] 84%|████████▍ | 19575/23172 [00:07<00:01, 1954.21it/s] 88%|████████▊ | 20300/23172 [00:07<00:01, 2364.95it/s] 91%|█████████ | 21025/23172 [00:08<00:00, 2814.51it/s] 94%|█████████▍| 21750/23172 [00:08<00:00, 3341.49it/s] 97%|█████████▋| 22475/23172 [00:08<00:00, 3879.37it/s]100%|██████████| 23172/23172 [00:08<00:00, 2789.11it/s]
10/04/2023 08:33:23 - INFO - util -   Read 23172 examples, avg src len: 210, avg trg len: 7, max src len: 3907, max trg len: 15
10/04/2023 08:33:23 - INFO - util -   [TOKENIZE] avg src len: 237, avg trg len: 14, max src len: 4465, max trg len: 71
10/04/2023 08:33:23 - INFO - util -   Create cache data into cache/codesum/java/train_src_all.pt
  0%|          | 0/23172 [00:00<?, ?it/s]  6%|▋         | 1450/23172 [00:00<00:02, 8538.89it/s] 13%|█▎        | 2900/23172 [00:00<00:02, 8680.21it/s] 19%|█▉        | 4350/23172 [00:00<00:02, 8658.21it/s] 25%|██▌       | 5800/23172 [00:00<00:02, 8248.49it/s] 29%|██▊       | 6628/23172 [00:02<00:09, 1719.13it/s] 31%|███▏      | 7250/23172 [00:02<00:09, 1757.79it/s] 38%|███▊      | 8700/23172 [00:02<00:05, 2551.55it/s] 41%|████      | 9425/23172 [00:02<00:04, 2961.80it/s] 44%|████▍     | 10150/23172 [00:03<00:03, 3375.18it/s] 47%|████▋     | 10875/23172 [00:03<00:03, 3678.14it/s] 50%|█████     | 11600/23172 [00:03<00:02, 3916.71it/s] 53%|█████▎    | 12325/23172 [00:04<00:06, 1641.95it/s] 56%|█████▋    | 13050/23172 [00:04<00:05, 1746.36it/s] 59%|█████▉    | 13775/23172 [00:05<00:04, 1981.52it/s] 63%|██████▎   | 14500/23172 [00:05<00:03, 2469.60it/s] 69%|██████▉   | 15950/23172 [00:05<00:02, 3348.64it/s] 72%|███████▏  | 16675/23172 [00:05<00:01, 3854.14it/s] 75%|███████▌  | 17400/23172 [00:05<00:01, 3746.86it/s] 78%|███████▊  | 18125/23172 [00:06<00:03, 1581.50it/s] 81%|████████▏ | 18850/23172 [00:07<00:02, 1641.26it/s] 84%|████████▍ | 19575/23172 [00:07<00:01, 1908.80it/s] 88%|████████▊ | 20300/23172 [00:07<00:01, 2274.65it/s] 91%|█████████ | 21025/23172 [00:07<00:00, 2837.17it/s] 94%|█████████▍| 21750/23172 [00:07<00:00, 3295.30it/s] 97%|█████████▋| 22475/23172 [00:08<00:00, 3923.65it/s]100%|██████████| 23172/23172 [00:08<00:00, 2864.95it/s]
10/04/2023 08:33:34 - INFO - __main__ -     Num examples of Corpus = 23172
10/04/2023 08:35:30 - INFO - __main__ -     Num examples to retrieve = 23172
10/04/2023 08:38:47 - INFO - __main__ -   return 2nd ranked result
10/04/2023 08:38:47 - INFO - __main__ -   ranked list [11639   863 12486   412  7341     6     5  1419    17 21373  8822  2597
 13871   113  8923 13652 10968 10941 11857 18926  8083  7886 12234 13242
  1523  7875    29  9850 18933 10128]
Total: 23172
10/04/2023 08:38:55 - INFO - __main__ -     codenn_bleu = 13.39 
10/04/2023 08:38:55 - INFO - __main__ -    save predict result in dataset/cpp/contextual_medits/codet5_retrieval_result/train.jsonl.retireval.output
10/04/2023 08:38:57 - INFO - __main__ -   Finish and take 7m
saved dataset in dataset/cpp/contextual_medits/codet5_retrieval_result/train.jsonl
