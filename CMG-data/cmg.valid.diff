mmm sound / pci / ice1712 / ice1724 . c <nl> ppp sound / pci / ice1712 / ice1724 . c <nl> static int __devinit snd_vt1724_read_eeprom ( struct snd_ice1712 * ice , <nl> static void __devinit snd_vt1724_chip_reset ( struct snd_ice1712 * ice ) <nl> { <nl> outb ( VT1724_RESET , ICEREG1724 ( ice , CONTROL )); <nl> + inb ( ICEREG1724 ( ice , CONTROL )); /* pci posting flush */ <nl> msleep ( 10 ); <nl> outb ( 0 , ICEREG1724 ( ice , CONTROL )); <nl> + inb ( ICEREG1724 ( ice , CONTROL )); /* pci posting flush */ <nl> msleep ( 10 ); <nl> } <nl> 
mmm drivers / vhost / net . c <nl> ppp drivers / vhost / net . c <nl> static int get_rx_bufs ( struct vhost_virtqueue * vq , <nl> * iovcount = seg ; <nl> if ( unlikely ( log )) <nl> * log_num = nlogs ; <nl> + <nl> + /* Detect overrun */ <nl> + if ( unlikely ( datalen > 0 )) { <nl> + r = UIO_MAXIOV + 1 ; <nl> + goto err ; <nl> + } <nl> return headcount ; <nl> err : <nl> vhost_discard_vq_desc ( vq , headcount ); <nl> static void handle_rx ( struct vhost_net * net ) <nl> /* On error , stop handling until the next kick . */ <nl> if ( unlikely ( headcount < 0 )) <nl> break ; <nl> + /* On overrun , truncate and discard */ <nl> + if ( unlikely ( headcount > UIO_MAXIOV )) { <nl> + msg . msg_iovlen = 1 ; <nl> + err = sock -> ops -> recvmsg ( NULL , sock , & msg , <nl> + 1 , MSG_DONTWAIT | MSG_TRUNC ); <nl> + pr_debug (" Discarded rx packet : len % zd \ n ", sock_len ); <nl> + continue ; <nl> + } <nl> /* OK , now we need to know about added descriptors . */ <nl> if (! headcount ) { <nl> if ( unlikely ( vhost_enable_notify (& net -> dev , vq ))) {
mmm drivers / staging / gdm724x / gdm_usb . c <nl> ppp drivers / staging / gdm724x / gdm_usb . c <nl> static void gdm_usb_disconnect ( struct usb_interface * intf ) <nl> { <nl> struct phy_dev * phy_dev ; <nl> struct lte_udev * udev ; <nl> - u16 idVendor , idProduct ; <nl> struct usb_device * usbdev ; <nl>  <nl> usbdev = interface_to_usbdev ( intf ); <nl> - <nl> - idVendor = __le16_to_cpu ( usbdev -> descriptor . idVendor ); <nl> - idProduct = __le16_to_cpu ( usbdev -> descriptor . idProduct ); <nl> - <nl> phy_dev = usb_get_intfdata ( intf ); <nl>  <nl> udev = phy_dev -> priv_dev ;
mmm drivers / media / video / gspca / jeilinj . c <nl> ppp drivers / media / video / gspca / jeilinj . c <nl> static int sd_start ( struct gspca_dev * gspca_dev ) <nl>  <nl> /* create the JPEG header */ <nl> dev -> jpeg_hdr = kmalloc ( JPEG_HDR_SZ , GFP_KERNEL ); <nl> + if ( dev -> jpeg_hdr == NULL ) <nl> + return - ENOMEM ; <nl> jpeg_define ( dev -> jpeg_hdr , gspca_dev -> height , gspca_dev -> width , <nl> 0x21 ); /* JPEG 422 */ <nl> jpeg_set_qual ( dev -> jpeg_hdr , dev -> quality );
mmm sound / core / seq / seq_ports . c <nl> ppp sound / core / seq / seq_ports . c <nl> int snd_seq_port_connect ( struct snd_seq_client * connector , <nl> atomic_set (& subs -> ref_count , 2 ); <nl>  <nl> down_write (& src -> list_mutex ); <nl> - down_write (& dest -> list_mutex ); <nl> + down_write_nested (& dest -> list_mutex , SINGLE_DEPTH_NESTING ); <nl>  <nl> exclusive = info -> flags & SNDRV_SEQ_PORT_SUBS_EXCLUSIVE ? 1 : 0 ; <nl> err = - EBUSY ; <nl> int snd_seq_port_disconnect ( struct snd_seq_client * connector , <nl> unsigned long flags ; <nl>  <nl> down_write (& src -> list_mutex ); <nl> - down_write (& dest -> list_mutex ); <nl> + down_write_nested (& dest -> list_mutex , SINGLE_DEPTH_NESTING ); <nl>  <nl> /* look for the connection */ <nl> list_for_each ( p , & src -> list_head ) {
mmm drivers / spi / atmel_spi . c <nl> ppp drivers / spi / atmel_spi . c <nl> static void atmel_spi_next_xfer ( struct spi_master * master , <nl> xfer , xfer -> len , xfer -> tx_buf , xfer -> tx_dma , <nl> xfer -> rx_buf , xfer -> rx_dma , spi_readl ( as , IMR )); <nl>  <nl> - spi_writel ( as , TCR , len ); <nl> spi_writel ( as , RCR , len ); <nl> + spi_writel ( as , TCR , len ); <nl> spi_writel ( as , PTCR , SPI_BIT ( TXTEN ) | SPI_BIT ( RXTEN )); <nl> } <nl> 
mmm net / bridge / netfilter / ebtables . c <nl> ppp net / bridge / netfilter / ebtables . c <nl> static int do_replace ( struct net * net , const void __user * user , <nl> if ( tmp . num_counters >= INT_MAX / sizeof ( struct ebt_counter )) <nl> return - ENOMEM ; <nl>  <nl> + tmp . name [ sizeof ( tmp . name ) - 1 ] = 0 ; <nl> + <nl> countersize = COUNTER_OFFSET ( tmp . nentries ) * nr_cpu_ids ; <nl> newinfo = vmalloc ( sizeof (* newinfo ) + countersize ); <nl> if (! newinfo )
mmm fs / btrfs / super . c <nl> ppp fs / btrfs / super . c <nl> static struct file_system_type btrfs_fs_type = { <nl> }; <nl> MODULE_ALIAS_FS (" btrfs "); <nl>  <nl> + static int btrfs_control_open ( struct inode * inode , struct file * file ) <nl> +{ <nl> + /* <nl> + * The control file ' s private_data is used to hold the <nl> + * transaction when it is started and is used to keep <nl> + * track of whether a transaction is already in progress . <nl> + */ <nl> + file -> private_data = NULL ; <nl> + return 0 ; <nl> +} <nl> + <nl> /* <nl> * used by btrfsctl to scan devices when no FS is mounted <nl> */ <nl> static const struct super_operations btrfs_super_ops = { <nl> }; <nl>  <nl> static const struct file_operations btrfs_ctl_fops = { <nl> + . open = btrfs_control_open , <nl> . unlocked_ioctl = btrfs_control_ioctl , <nl> . compat_ioctl = btrfs_control_ioctl , <nl> . owner = THIS_MODULE ,
mmm drivers / pci / pcie / aer / aerdrv_acpi . c <nl> ppp drivers / pci / pcie / aer / aerdrv_acpi . c <nl> int aer_osc_setup ( struct pcie_device * pciedev ) <nl> } <nl>  <nl> if ( handle ) { <nl> - pci_osc_support_set ( OSC_EXT_PCI_CONFIG_SUPPORT ); <nl> + pcie_osc_support_set ( OSC_EXT_PCI_CONFIG_SUPPORT ); <nl> status = pci_osc_control_set ( handle , <nl> OSC_PCI_EXPRESS_AER_CONTROL | <nl> OSC_PCI_EXPRESS_CAP_STRUCTURE_CONTROL );
mmm fs / btrfs / volumes . c <nl> ppp fs / btrfs / volumes . c <nl> int btrfs_read_sys_array ( struct btrfs_root * root ) <nl> sb_array_offset += len ; <nl> cur_offset += len ; <nl> } <nl> + clear_extent_buffer_uptodate ( sb ); <nl> free_extent_buffer_stale ( sb ); <nl> return ret ; <nl>  <nl> out_short_read : <nl> printk ( KERN_ERR " BTRFS : sys_array too short to read % u bytes at offset % u \ n ", <nl> len , cur_offset ); <nl> + clear_extent_buffer_uptodate ( sb ); <nl> free_extent_buffer_stale ( sb ); <nl> return - EIO ; <nl> }
mmm arch / x86 / mm / init_64 . c <nl> ppp arch / x86 / mm / init_64 . c <nl> void __init init_extra_mapping_uc ( unsigned long phys , unsigned long size ) <nl> void __init cleanup_highmap ( void ) <nl> { <nl> unsigned long vaddr = __START_KERNEL_map ; <nl> - unsigned long end = round_up (( unsigned long ) _end , PMD_SIZE ) - 1 ; <nl> + unsigned long end = roundup (( unsigned long ) _end , PMD_SIZE ) - 1 ; <nl> pmd_t * pmd = level2_kernel_pgt ; <nl> pmd_t * last_pmd = pmd + PTRS_PER_PMD ; <nl>  <nl> static void __init find_early_table_space ( unsigned long end ) <nl> unsigned long puds , pmds , ptes , tables , start ; <nl>  <nl> puds = ( end + PUD_SIZE - 1 ) >> PUD_SHIFT ; <nl> - tables = round_up ( puds * sizeof ( pud_t ), PAGE_SIZE ); <nl> + tables = roundup ( puds * sizeof ( pud_t ), PAGE_SIZE ); <nl> if ( direct_gbpages ) { <nl> unsigned long extra ; <nl> extra = end - (( end >> PUD_SHIFT ) << PUD_SHIFT ); <nl> pmds = ( extra + PMD_SIZE - 1 ) >> PMD_SHIFT ; <nl> } else <nl> pmds = ( end + PMD_SIZE - 1 ) >> PMD_SHIFT ; <nl> - tables += round_up ( pmds * sizeof ( pmd_t ), PAGE_SIZE ); <nl> + tables += roundup ( pmds * sizeof ( pmd_t ), PAGE_SIZE ); <nl>  <nl> if ( cpu_has_pse ) { <nl> unsigned long extra ; <nl> static void __init find_early_table_space ( unsigned long end ) <nl> ptes = ( extra + PAGE_SIZE - 1 ) >> PAGE_SHIFT ; <nl> } else <nl> ptes = ( end + PAGE_SIZE - 1 ) >> PAGE_SHIFT ; <nl> - tables += round_up ( ptes * sizeof ( pte_t ), PAGE_SIZE ); <nl> + tables += roundup ( ptes * sizeof ( pte_t ), PAGE_SIZE ); <nl>  <nl> /* <nl> * RED - PEN putting page tables only on node 0 could
mmm drivers / block / aoe / aoenet . c <nl> ppp drivers / block / aoe / aoenet . c <nl> aoenet_xmit ( struct sk_buff_head * queue ) <nl> { <nl> struct sk_buff * skb , * tmp ; <nl>  <nl> - skb_queue_walk_safe ( queue , skb , tmp ) <nl> + skb_queue_walk_safe ( queue , skb , tmp ) { <nl> + __skb_unlink ( skb , queue ); <nl> dev_queue_xmit ( skb ); <nl> + } <nl> } <nl>  <nl> /*
mmm include / linux / mmc / host . h <nl> ppp include / linux / mmc / host . h <nl> struct mmc_host_ops { <nl>  <nl> int (* start_signal_voltage_switch )( struct mmc_host * host , struct mmc_ios * ios ); <nl>  <nl> + /* Check if the card is pulling dat [ 0 : 3 ] low */ <nl> + int (* card_busy )( struct mmc_host * host ); <nl> + <nl> /* The tuning command opcode value is different for SD and eMMC cards */ <nl> int (* execute_tuning )( struct mmc_host * host , u32 opcode ); <nl> void (* enable_preset_value )( struct mmc_host * host , bool enable );
mmm drivers / media / common / siano / smscoreapi . c <nl> ppp drivers / media / common / siano / smscoreapi . c <nl> void smscore_onresponse ( struct smscore_device_t * coredev , <nl> - sizeof ( struct SmsMsgHdr_ST )); <nl> break ; <nl>  <nl> + case MSG_SMS_DVBT_BDA_DATA : <nl> + /* <nl> + * It can be received here , if the frontend is <nl> + * tuned into a valid channel and the proper firmware <nl> + * is loaded . That happens when the module got removed <nl> + * and re - inserted , without powering the device off <nl> + */ <nl> + break ; <nl> + <nl> default : <nl> sms_debug (" message % s (% d ) not handled .", <nl> smscore_translate_msg ( phdr -> msgType ),
mmm drivers / gpu / drm / i915 / gvt / handlers . c <nl> ppp drivers / gpu / drm / i915 / gvt / handlers . c <nl> static int mailbox_write ( struct intel_vgpu * vgpu , unsigned int offset , <nl> else <nl> * data0 = 0x61514b3d ; <nl> break ; <nl> + case SKL_PCODE_CDCLK_CONTROL : <nl> + * data0 = SKL_CDCLK_READY_FOR_CHANGE ; <nl> + break ; <nl> case 0x5 : <nl> * data0 |= 0x1 ; <nl> break ; <nl> static int mailbox_write ( struct intel_vgpu * vgpu , unsigned int offset , <nl>  <nl> gvt_dbg_core (" VM (% d ) write % x to mailbox , return data0 % x \ n ", <nl> vgpu -> id , value , * data0 ); <nl> - <nl> - value &= ~( 1 << 31 ); <nl> + /** <nl> + * PCODE_READY clear means ready for pcode read / write , <nl> + * PCODE_ERROR_MASK clear means no error happened . In GVT - g we <nl> + * always emulate as pcode read / write success and ready for access <nl> + * anytime , since we don ' t touch real physical registers here . <nl> + */ <nl> + value &= ~( GEN6_PCODE_READY | GEN6_PCODE_ERROR_MASK ); <nl> return intel_vgpu_default_mmio_write ( vgpu , offset , & value , bytes ); <nl> } <nl> 
mmm fs / f2fs / f2fs . h <nl> ppp fs / f2fs / f2fs . h <nl> static inline bool f2fs_has_xattr_block ( unsigned int ofs ) <nl> return ofs == XATTR_NODE_OFFSET ; <nl> } <nl>  <nl> - static inline bool __allow_reserved_blocks ( struct f2fs_sb_info * sbi ) <nl> + static inline bool __allow_reserved_blocks ( struct f2fs_sb_info * sbi , <nl> + struct inode * inode ) <nl> { <nl> + if (! inode ) <nl> + return true ; <nl> if (! test_opt ( sbi , RESERVE_ROOT )) <nl> return false ; <nl> + if ( IS_NOQUOTA ( inode )) <nl> + return true ; <nl> if ( capable ( CAP_SYS_RESOURCE )) <nl> return true ; <nl> if ( uid_eq ( sbi -> s_resuid , current_fsuid ())) <nl> static inline int inc_valid_block_count ( struct f2fs_sb_info * sbi , <nl> avail_user_block_count = sbi -> user_block_count - <nl> sbi -> current_reserved_blocks ; <nl>  <nl> - if (! __allow_reserved_blocks ( sbi )) <nl> + if (! __allow_reserved_blocks ( sbi , inode )) <nl> avail_user_block_count -= sbi -> root_reserved_blocks ; <nl>  <nl> if ( unlikely ( sbi -> total_valid_block_count > avail_user_block_count )) { <nl> static inline int inc_valid_node_count ( struct f2fs_sb_info * sbi , <nl> valid_block_count = sbi -> total_valid_block_count + <nl> sbi -> current_reserved_blocks + 1 ; <nl>  <nl> - if (! __allow_reserved_blocks ( sbi )) <nl> + if (! __allow_reserved_blocks ( sbi , inode )) <nl> valid_block_count += sbi -> root_reserved_blocks ; <nl>  <nl> if ( unlikely ( valid_block_count > sbi -> user_block_count )) {
mmm drivers / bus / imx - weim . c <nl> ppp drivers / bus / imx - weim . c <nl> static const struct imx_weim_devtype imx51_weim_devtype = { <nl> . cs_stride = 0x18 , <nl> }; <nl>  <nl> +# define MAX_CS_REGS_COUNT 6 <nl> + <nl> static const struct of_device_id weim_id_table [] = { <nl> /* i . MX1 / 21 */ <nl> { . compatible = " fsl , imx1 - weim ", . data = & imx1_weim_devtype , }, <nl> static int __init imx_weim_gpr_setup ( struct platform_device * pdev ) <nl> static int __init weim_timing_setup ( struct device_node * np , void __iomem * base , <nl> const struct imx_weim_devtype * devtype ) <nl> { <nl> - u32 cs_idx , value [ devtype -> cs_regs_count ]; <nl> + u32 cs_idx , value [ MAX_CS_REGS_COUNT ]; <nl> int i , ret ; <nl>  <nl> + if ( WARN_ON ( devtype -> cs_regs_count > MAX_CS_REGS_COUNT )) <nl> + return - EINVAL ; <nl> + <nl> /* get the CS index from this child node ' s " reg " property . */ <nl> ret = of_property_read_u32 ( np , " reg ", & cs_idx ); <nl> if ( ret )
mmm drivers / platform / x86 / asus - laptop . c <nl> ppp drivers / platform / x86 / asus - laptop . c <nl> static int asus_laptop_get_info ( struct asus_laptop * asus ) <nl> } <nl> } <nl> asus -> name = kstrdup ( string , GFP_KERNEL ); <nl> - if (! asus -> name ) <nl> + if (! asus -> name ) { <nl> + kfree ( buffer . pointer ); <nl> return - ENOMEM ; <nl> + } <nl>  <nl> if (* string ) <nl> pr_notice (" % s model detected \ n ", string );
mmm drivers / media / rc / mceusb . c <nl> ppp drivers / media / rc / mceusb . c <nl> enum mceusb_model_type { <nl> POLARIS_EVK , <nl> CX_HYBRID_TV , <nl> MULTIFUNCTION , <nl> + TIVO_KIT , <nl> }; <nl>  <nl> struct mceusb_model { <nl> static const struct mceusb_model mceusb_model [] = { <nl> . mce_gen2 = 1 , <nl> . ir_intfnum = 2 , <nl> }, <nl> + [ TIVO_KIT ] = { <nl> + . mce_gen2 = 1 , <nl> + . rc_map = RC_MAP_TIVO , <nl> + }, <nl> }; <nl>  <nl> static struct usb_device_id mceusb_dev_table [] = { <nl> static struct usb_device_id mceusb_dev_table [] = { <nl> /* Northstar Systems , Inc . eHome Infrared Transceiver */ <nl> { USB_DEVICE ( VENDOR_NORTHSTAR , 0xe004 ) }, <nl> /* TiVo PC IR Receiver */ <nl> - { USB_DEVICE ( VENDOR_TIVO , 0x2000 ) }, <nl> + { USB_DEVICE ( VENDOR_TIVO , 0x2000 ), <nl> + . driver_info = TIVO_KIT }, <nl> /* Conexant Hybrid TV " Shelby " Polaris SDK */ <nl> { USB_DEVICE ( VENDOR_CONEXANT , 0x58a1 ), <nl> . driver_info = POLARIS_EVK },
mmm arch / cris / kernel / irq . c <nl> ppp arch / cris / kernel / irq . c <nl> int show_interrupts ( struct seq_file * p , void * v ) <nl> for_each_online_cpu ( j ) <nl> seq_printf ( p , "% 10u ", kstat_irqs_cpu ( i , j )); <nl> # endif <nl> - seq_printf ( p , " % 14s ", irq_desc [ i ]. chip -> typename ); <nl> + seq_printf ( p , " % 14s ", irq_desc [ i ]. chip -> name ); <nl> seq_printf ( p , " % s ", action -> name ); <nl>  <nl> for ( action = action -> next ; action ; action = action -> next )mmm arch / cris / arch - v32 / kernel / irq . c <nl> ppp arch / cris / arch - v32 / kernel / irq . c <nl> int show_interrupts ( struct seq_file * p , void * v ) <nl> for_each_online_cpu ( j ) <nl> seq_printf ( p , "% 10u ", kstat_irqs_cpu ( i , j )); <nl> # endif <nl> - seq_printf ( p , " % 14s ", irq_desc [ i ]. chip -> typename ); <nl> + seq_printf ( p , " % 14s ", irq_desc [ i ]. chip -> name ); <nl> seq_printf ( p , " % s ", action -> name ); <nl>  <nl> for ( action = action -> next ; action ; action = action -> next ) <nl> int set_affinity_crisv32_irq ( unsigned int irq , const struct cpumask * dest ) <nl> } <nl>  <nl> static struct irq_chip crisv32_irq_type = { <nl> - . typename = " CRISv32 ", <nl> + . name = " CRISv32 ", <nl> . startup = startup_crisv32_irq , <nl> . shutdown = shutdown_crisv32_irq , <nl> . enable = enable_crisv32_irq ,mmm arch / cris / arch - v10 / kernel / irq . c <nl> ppp arch / cris / arch - v10 / kernel / irq . c <nl> int show_interrupts ( struct seq_file * p , void * v ) <nl> for_each_online_cpu ( j ) <nl> seq_printf ( p , "% 10u ", kstat_irqs_cpu ( i , j )); <nl> # endif <nl> - seq_printf ( p , " % 14s ", irq_desc [ i ]. chip -> typename ); <nl> + seq_printf ( p , " % 14s ", irq_desc [ i ]. chip -> name ); <nl> seq_printf ( p , " % s ", action -> name ); <nl>  <nl> for ( action = action -> next ; action ; action = action -> next ) <nl> int set_affinity_crisv32_irq ( unsigned int irq , const struct cpumask * dest ) <nl> } <nl>  <nl> static struct irq_chip crisv32_irq_type = { <nl> - . typename = " CRISv32 ", <nl> + . name = " CRISv32 ", <nl> . startup = startup_crisv32_irq , <nl> . shutdown = shutdown_crisv32_irq , <nl> . enable = enable_crisv32_irq , <nl> static void end_crisv10_irq ( unsigned int irq ) <nl> } <nl>  <nl> static struct irq_chip crisv10_irq_type = { <nl> - . typename = " CRISv10 ", <nl> + . name = " CRISv10 ", <nl> . startup = startup_crisv10_irq , <nl> . shutdown = shutdown_crisv10_irq , <nl> . enable = enable_crisv10_irq ,
mmm arch / x86 / kvm / emulate . c <nl> ppp arch / x86 / kvm / emulate . c <nl> int x86_decode_insn ( struct x86_emulate_ctxt * ctxt , void * insn , int insn_len ) <nl> /* Decode and fetch the destination operand : register or memory . */ <nl> rc = decode_operand ( ctxt , & ctxt -> dst , ( ctxt -> d >> DstShift ) & OpMask ); <nl>  <nl> - if ( ctxt -> rip_relative ) <nl> + if ( ctxt -> rip_relative && likely ( ctxt -> memopp )) <nl> ctxt -> memopp -> addr . mem . ea = address_mask ( ctxt , <nl> ctxt -> memopp -> addr . mem . ea + ctxt -> _eip ); <nl> 
mmm kernel / trace / trace . c <nl> ppp kernel / trace / trace . c <nl> int trace_vbprintk ( unsigned long ip , const char * fmt , va_list args ) <nl> entry -> fmt = fmt ; <nl>  <nl> memcpy ( entry -> buf , trace_buf , sizeof ( u32 ) * len ); <nl> - if (! filter_check_discard ( call , entry , buffer , event )) <nl> + if (! filter_check_discard ( call , entry , buffer , event )) { <nl> ring_buffer_unlock_commit ( buffer , event ); <nl> + ftrace_trace_stack ( buffer , flags , 6 , pc ); <nl> + } <nl>  <nl> out_unlock : <nl> arch_spin_unlock (& trace_buf_lock ); <nl> int trace_array_vprintk ( struct trace_array * tr , <nl>  <nl> memcpy (& entry -> buf , trace_buf , len ); <nl> entry -> buf [ len ] = '\ 0 '; <nl> - if (! filter_check_discard ( call , entry , buffer , event )) <nl> + if (! filter_check_discard ( call , entry , buffer , event )) { <nl> ring_buffer_unlock_commit ( buffer , event ); <nl> + ftrace_trace_stack ( buffer , irq_flags , 6 , pc ); <nl> + } <nl>  <nl> out_unlock : <nl> arch_spin_unlock (& trace_buf_lock );
mmm fs / f2fs / file . c <nl> ppp fs / f2fs / file . c <nl> static int f2fs_move_file_range ( struct file * file_in , loff_t pos_in , <nl> if ( f2fs_encrypted_inode ( src ) || f2fs_encrypted_inode ( dst )) <nl> return - EOPNOTSUPP ; <nl>  <nl> + if ( src == dst ) { <nl> + if ( pos_in == pos_out ) <nl> + return 0 ; <nl> + if ( pos_out > pos_in && pos_out < pos_in + len ) <nl> + return - EINVAL ; <nl> + } <nl> + <nl> inode_lock ( src ); <nl> if ( src != dst ) { <nl> if (! inode_trylock ( dst )) {
mmm net / ipv4 / udp . c <nl> ppp net / ipv4 / udp . c <nl> int udp_queue_rcv_skb ( struct sock * sk , struct sk_buff * skb ) <nl> up -> encap_rcv != NULL ) { <nl> int ret ; <nl>  <nl> + bh_unlock_sock ( sk ); <nl> ret = (* up -> encap_rcv )( sk , skb ); <nl> + bh_lock_sock ( sk ); <nl> if ( ret <= 0 ) { <nl> UDP_INC_STATS_BH ( sock_net ( sk ), <nl> UDP_MIB_INDATAGRAMS , <nl> static int __udp4_lib_mcast_deliver ( struct net * net , struct sk_buff * skb , <nl> if ( skb1 ) { <nl> int ret = 0 ; <nl>  <nl> - bh_lock_sock_nested ( sk ); <nl> + bh_lock_sock ( sk ); <nl> if (! sock_owned_by_user ( sk )) <nl> ret = udp_queue_rcv_skb ( sk , skb1 ); <nl> else <nl> int __udp4_lib_rcv ( struct sk_buff * skb , struct hlist_head udptable [], <nl>  <nl> if ( sk != NULL ) { <nl> int ret = 0 ; <nl> - bh_lock_sock_nested ( sk ); <nl> + bh_lock_sock ( sk ); <nl> if (! sock_owned_by_user ( sk )) <nl> ret = udp_queue_rcv_skb ( sk , skb ); <nl> elsemmm net / ipv6 / udp . c <nl> ppp net / ipv6 / udp . c <nl> int udp_queue_rcv_skb ( struct sock * sk , struct sk_buff * skb ) <nl> up -> encap_rcv != NULL ) { <nl> int ret ; <nl>  <nl> + bh_unlock_sock ( sk ); <nl> ret = (* up -> encap_rcv )( sk , skb ); <nl> + bh_lock_sock ( sk ); <nl> if ( ret <= 0 ) { <nl> UDP_INC_STATS_BH ( sock_net ( sk ), <nl> UDP_MIB_INDATAGRAMS , <nl> static int __udp4_lib_mcast_deliver ( struct net * net , struct sk_buff * skb , <nl> if ( skb1 ) { <nl> int ret = 0 ; <nl>  <nl> - bh_lock_sock_nested ( sk ); <nl> + bh_lock_sock ( sk ); <nl> if (! sock_owned_by_user ( sk )) <nl> ret = udp_queue_rcv_skb ( sk , skb1 ); <nl> else <nl> int __udp4_lib_rcv ( struct sk_buff * skb , struct hlist_head udptable [], <nl>  <nl> if ( sk != NULL ) { <nl> int ret = 0 ; <nl> - bh_lock_sock_nested ( sk ); <nl> + bh_lock_sock ( sk ); <nl> if (! sock_owned_by_user ( sk )) <nl> ret = udp_queue_rcv_skb ( sk , skb ); <nl> else <nl> static int __udp6_lib_mcast_deliver ( struct net * net , struct sk_buff * skb , <nl> uh -> source , saddr , dif ))) { <nl> struct sk_buff * buff = skb_clone ( skb , GFP_ATOMIC ); <nl> if ( buff ) { <nl> - bh_lock_sock_nested ( sk2 ); <nl> + bh_lock_sock ( sk2 ); <nl> if (! sock_owned_by_user ( sk2 )) <nl> udpv6_queue_rcv_skb ( sk2 , buff ); <nl> else <nl> static int __udp6_lib_mcast_deliver ( struct net * net , struct sk_buff * skb , <nl> bh_unlock_sock ( sk2 ); <nl> } <nl> } <nl> - bh_lock_sock_nested ( sk ); <nl> + bh_lock_sock ( sk ); <nl> if (! sock_owned_by_user ( sk )) <nl> udpv6_queue_rcv_skb ( sk , skb ); <nl> else <nl> int __udp6_lib_rcv ( struct sk_buff * skb , struct hlist_head udptable [], <nl>  <nl> /* deliver */ <nl>  <nl> - bh_lock_sock_nested ( sk ); <nl> + bh_lock_sock ( sk ); <nl> if (! sock_owned_by_user ( sk )) <nl> udpv6_queue_rcv_skb ( sk , skb ); <nl> else
mmm drivers / gpu / drm / i915 / intel_display . c <nl> ppp drivers / gpu / drm / i915 / intel_display . c <nl> i9xx_get_initial_plane_config ( struct intel_crtc * crtc , <nl> struct drm_framebuffer * fb ; <nl> struct intel_framebuffer * intel_fb ; <nl>  <nl> - intel_fb = kzalloc ( sizeof ( struct intel_framebuffer ), GFP_KERNEL ); <nl> + intel_fb = kzalloc ( sizeof (* intel_fb ), GFP_KERNEL ); <nl> if (! intel_fb ) { <nl> DRM_DEBUG_KMS (" failed to alloc fb \ n "); <nl> return ; <nl> skylake_get_initial_plane_config ( struct intel_crtc * crtc , <nl> struct drm_framebuffer * fb ; <nl> struct intel_framebuffer * intel_fb ; <nl>  <nl> - intel_fb = kzalloc ( sizeof ( struct intel_framebuffer ), GFP_KERNEL ); <nl> + intel_fb = kzalloc ( sizeof (* intel_fb ), GFP_KERNEL ); <nl> if (! intel_fb ) { <nl> DRM_DEBUG_KMS (" failed to alloc fb \ n "); <nl> return ; <nl> ironlake_get_initial_plane_config ( struct intel_crtc * crtc , <nl> struct drm_framebuffer * fb ; <nl> struct intel_framebuffer * intel_fb ; <nl>  <nl> - intel_fb = kzalloc ( sizeof ( struct intel_framebuffer ), GFP_KERNEL ); <nl> + intel_fb = kzalloc ( sizeof (* intel_fb ), GFP_KERNEL ); <nl> if (! intel_fb ) { <nl> DRM_DEBUG_KMS (" failed to alloc fb \ n "); <nl> return ;
mmm drivers / video / fbdev / sm501fb . c <nl> ppp drivers / video / fbdev / sm501fb . c <nl> static void sm501_free_init_fb ( struct sm501fb_info * info , <nl> { <nl> struct fb_info * fbi = info -> fb [ head ]; <nl>  <nl> + if (! fbi ) <nl> + return ; <nl> + <nl> fb_dealloc_cmap (& fbi -> cmap ); <nl> } <nl> 
mmm arch / parisc / mm / init . c <nl> ppp arch / parisc / mm / init . c <nl> static void __init setup_bootmem ( void ) <nl> } <nl> memset ( pfnnid_map , 0xff , sizeof ( pfnnid_map )); <nl>  <nl> - for ( i = 0 ; i < npmem_ranges ; i ++) <nl> + for ( i = 0 ; i < npmem_ranges ; i ++) { <nl> + node_set_state ( i , N_NORMAL_MEMORY ); <nl> node_set_online ( i ); <nl> + } <nl> # endif <nl>  <nl> /*
mmm drivers / gpu / drm / i915 / gvt / mmio_context . c <nl> ppp drivers / gpu / drm / i915 / gvt / mmio_context . c <nl> static struct engine_mmio gen8_engine_mmio_list [] __cacheline_aligned = { <nl> { BCS , RING_INSTPM ( BLT_RING_BASE ), 0xffff , false }, /* 0x220c0 */ <nl> { BCS , RING_HWSTAM ( BLT_RING_BASE ), 0x0 , false }, /* 0x22098 */ <nl> { BCS , RING_EXCC ( BLT_RING_BASE ), 0x0 , false }, /* 0x22028 */ <nl> - { /* Terminated */ } <nl> + { RCS , INVALID_MMIO_REG , 0 , false } /* Terminated */ <nl> }; <nl>  <nl> static struct engine_mmio gen9_engine_mmio_list [] __cacheline_aligned = { <nl> static struct engine_mmio gen9_engine_mmio_list [] __cacheline_aligned = { <nl> { RCS , GEN8_GARBCNTL , 0x0 , false }, /* 0xb004 */ <nl> { RCS , GEN7_FF_THREAD_MODE , 0x0 , false }, /* 0x20a0 */ <nl> { RCS , FF_SLICE_CS_CHICKEN2 , 0xffff , false }, /* 0x20e4 */ <nl> - { /* Terminated */ } <nl> + { RCS , INVALID_MMIO_REG , 0 , false } /* Terminated */ <nl> }; <nl>  <nl> static struct { <nl> static void switch_mmio ( struct intel_vgpu * pre , <nl> if ( IS_SKYLAKE ( dev_priv ) || IS_KABYLAKE ( dev_priv )) <nl> switch_mocs ( pre , next , ring_id ); <nl>  <nl> - mmio = dev_priv -> gvt -> engine_mmio_list ; <nl> - while ( i915_mmio_reg_offset (( mmio ++)-> reg )) { <nl> + for ( mmio = dev_priv -> gvt -> engine_mmio_list ; <nl> + i915_mmio_reg_valid ( mmio -> reg ); mmio ++) { <nl> if ( mmio -> ring_id != ring_id ) <nl> continue ; <nl> // save
mmm drivers / tty / serial / amba - pl011 . c <nl> ppp drivers / tty / serial / amba - pl011 . c <nl> static void pl011_dma_probe ( struct uart_amba_port * uap ) <nl> /* Optionally make use of an RX channel as well */ <nl> chan = dma_request_slave_channel ( dev , " rx "); <nl>  <nl> - if (! chan && plat -> dma_rx_param ) { <nl> + if (! chan && plat && plat -> dma_rx_param ) { <nl> chan = dma_request_channel ( mask , plat -> dma_filter , plat -> dma_rx_param ); <nl>  <nl> if (! chan ) {
mmm drivers / atm / eni . c <nl> ppp drivers / atm / eni . c <nl> static int eni_start ( struct atm_dev * dev ) <nl> /* initialize memory management */ <nl> buffer_mem = eni_dev -> mem - ( buf - eni_dev -> ram ); <nl> eni_dev -> free_list_size = buffer_mem / MID_MIN_BUF_SIZE / 2 ; <nl> - eni_dev -> free_list = kmalloc ( <nl> - sizeof ( struct eni_free )*( eni_dev -> free_list_size + 1 ), GFP_KERNEL ); <nl> + eni_dev -> free_list = kmalloc_array ( eni_dev -> free_list_size + 1 , <nl> + sizeof (* eni_dev -> free_list ), <nl> + GFP_KERNEL ); <nl> if (! eni_dev -> free_list ) { <nl> printk ( KERN_ERR DEV_LABEL "( itf % d ): couldn ' t get free page \ n ", <nl> dev -> number );
mmm kernel / cgroup . c <nl> ppp kernel / cgroup . c <nl> static long cgroup_create ( struct cgroup * parent , struct dentry * dentry , <nl> } <nl>  <nl> err = percpu_ref_init (& css -> refcnt , css_release ); <nl> - if ( err ) <nl> + if ( err ) { <nl> + ss -> css_free ( cgrp ); <nl> goto err_free_all ; <nl> + } <nl>  <nl> init_cgroup_css ( css , ss , cgrp ); <nl> 
mmm drivers / target / target_core_fabric_configfs . c <nl> ppp drivers / target / target_core_fabric_configfs . c <nl> static struct config_group * target_fabric_make_mappedlun ( <nl> struct se_node_acl , acl_group ); <nl> struct se_portal_group * se_tpg = se_nacl -> se_tpg ; <nl> struct target_fabric_configfs * tf = se_tpg -> se_tpg_wwn -> wwn_tf ; <nl> - struct se_lun_acl * lacl ; <nl> + struct se_lun_acl * lacl = NULL ; <nl> struct config_item * acl_ci ; <nl> struct config_group * lacl_cg = NULL , * ml_stat_grp = NULL ; <nl> char * buf ; <nl> static struct config_group * target_fabric_make_mappedlun ( <nl> out : <nl> if ( lacl_cg ) <nl> kfree ( lacl_cg -> default_groups ); <nl> + kfree ( lacl ); <nl> kfree ( buf ); <nl> return ERR_PTR ( ret ); <nl> }
mmm drivers / net / wireless / iwlwifi / dvm / mac80211 . c <nl> ppp drivers / net / wireless / iwlwifi / dvm / mac80211 . c <nl> int iwlagn_mac_setup_register ( struct iwl_priv * priv , <nl> ARRAY_SIZE ( iwlagn_iface_combinations_dualmode ); <nl> } <nl>  <nl> - hw -> wiphy -> max_remain_on_channel_duration = 1000 ; <nl> + hw -> wiphy -> max_remain_on_channel_duration = 500 ; <nl>  <nl> hw -> wiphy -> flags |= WIPHY_FLAG_CUSTOM_REGULATORY | <nl> WIPHY_FLAG_DISABLE_BEACON_HINTS |
mmm net / dsa / port . c <nl> ppp net / dsa / port . c <nl> int dsa_port_vlan_add ( struct dsa_port * dp , <nl> . vlan = vlan , <nl> }; <nl>  <nl> + if ( netif_is_bridge_master ( vlan -> obj . orig_dev )) <nl> + return - EOPNOTSUPP ; <nl> + <nl> if ( br_vlan_enabled ( dp -> bridge_dev )) <nl> return dsa_port_notify ( dp , DSA_NOTIFIER_VLAN_ADD , & info ); <nl>  <nl> int dsa_port_vlan_del ( struct dsa_port * dp , <nl> . vlan = vlan , <nl> }; <nl>  <nl> + if ( netif_is_bridge_master ( vlan -> obj . orig_dev )) <nl> + return - EOPNOTSUPP ; <nl> + <nl> if ( br_vlan_enabled ( dp -> bridge_dev )) <nl> return dsa_port_notify ( dp , DSA_NOTIFIER_VLAN_DEL , & info ); <nl> 
mmm drivers / net / ethernet / freescale / fec_main . c <nl> ppp drivers / net / ethernet / freescale / fec_main . c <nl> static void fec_enet_work ( struct work_struct * work ) <nl>  <nl> if ( fep -> delay_work . timeout ) { <nl> fep -> delay_work . timeout = false ; <nl> + rtnl_lock (); <nl> fec_restart ( fep -> netdev , fep -> full_duplex ); <nl> netif_wake_queue ( fep -> netdev ); <nl> + rtnl_unlock (); <nl> } <nl>  <nl> if ( fep -> delay_work . trig_tx ) { <nl> fec_suspend ( struct device * dev ) <nl> struct net_device * ndev = dev_get_drvdata ( dev ); <nl> struct fec_enet_private * fep = netdev_priv ( ndev ); <nl>  <nl> + rtnl_lock (); <nl> if ( netif_running ( ndev )) { <nl> phy_stop ( fep -> phy_dev ); <nl> fec_stop ( ndev ); <nl> netif_device_detach ( ndev ); <nl> } <nl> + rtnl_unlock (); <nl> + <nl> fec_enet_clk_enable ( ndev , false ); <nl> pinctrl_pm_select_sleep_state (& fep -> pdev -> dev ); <nl>  <nl> fec_resume ( struct device * dev ) <nl> if ( ret ) <nl> goto failed_clk ; <nl>  <nl> + rtnl_lock (); <nl> if ( netif_running ( ndev )) { <nl> fec_restart ( ndev , fep -> full_duplex ); <nl> netif_device_attach ( ndev ); <nl> phy_start ( fep -> phy_dev ); <nl> } <nl> + rtnl_unlock (); <nl>  <nl> return 0 ; <nl> 
mmm net / netfilter / x_tables . c <nl> ppp net / netfilter / x_tables . c <nl> xt_request_find_match ( uint8_t nfproto , const char * name , uint8_t revision ) <nl> { <nl> struct xt_match * match ; <nl>  <nl> + if ( strnlen ( name , XT_EXTENSION_MAXNAMELEN ) == XT_EXTENSION_MAXNAMELEN ) <nl> + return ERR_PTR (- EINVAL ); <nl> + <nl> match = xt_find_match ( nfproto , name , revision ); <nl> if ( IS_ERR ( match )) { <nl> request_module ("% st_ % s ", xt_prefix [ nfproto ], name ); <nl> struct xt_target * xt_request_find_target ( u8 af , const char * name , u8 revision ) <nl> { <nl> struct xt_target * target ; <nl>  <nl> + if ( strnlen ( name , XT_EXTENSION_MAXNAMELEN ) == XT_EXTENSION_MAXNAMELEN ) <nl> + return ERR_PTR (- EINVAL ); <nl> + <nl> target = xt_find_target ( af , name , revision ); <nl> if ( IS_ERR ( target )) { <nl> request_module ("% st_ % s ", xt_prefix [ af ], name );
mmm drivers / char / sx . c <nl> ppp drivers / char / sx . c <nl> static void __devexit sx_remove_card ( struct sx_board * board , <nl> del_timer (& board -> timer ); <nl> if ( pdev ) { <nl> # ifdef CONFIG_PCI <nl> - pci_iounmap ( pdev , board -> base2 ); <nl> + iounmap ( board -> base2 ); <nl> pci_release_region ( pdev , IS_CF_BOARD ( board ) ? 3 : 2 ); <nl> # endif <nl> } else { <nl> static int __devinit sx_pci_probe ( struct pci_dev * pdev , <nl> } <nl> board -> hw_base = pci_resource_start ( pdev , reg ); <nl> board -> base2 = <nl> - board -> base = pci_iomap ( pdev , reg , WINDOW_LEN ( board )); <nl> + board -> base = ioremap_nocache ( board -> hw_base , WINDOW_LEN ( board )); <nl> if (! board -> base ) { <nl> dev_err (& pdev -> dev , " ioremap failed \ n "); <nl> goto err_reg ; <nl> static int __devinit sx_pci_probe ( struct pci_dev * pdev , <nl>  <nl> return 0 ; <nl> err_unmap : <nl> - pci_iounmap ( pdev , board -> base2 ); <nl> + iounmap ( board -> base2 ); <nl> err_reg : <nl> pci_release_region ( pdev , reg ); <nl> err_flag :
mmm drivers / net / can / usb / kvaser_usb / kvaser_usb_leaf . c <nl> ppp drivers / net / can / usb / kvaser_usb / kvaser_usb_leaf . c <nl> static int kvaser_usb_leaf_simple_cmd_async ( struct kvaser_usb_net_priv * priv , <nl> struct kvaser_cmd * cmd ; <nl> int err ; <nl>  <nl> - cmd = kmalloc ( sizeof (* cmd ), GFP_ATOMIC ); <nl> + cmd = kzalloc ( sizeof (* cmd ), GFP_ATOMIC ); <nl> if (! cmd ) <nl> return - ENOMEM ; <nl>  <nl> static int kvaser_usb_leaf_set_opt_mode ( const struct kvaser_usb_net_priv * priv ) <nl> struct kvaser_cmd * cmd ; <nl> int rc ; <nl>  <nl> - cmd = kmalloc ( sizeof (* cmd ), GFP_KERNEL ); <nl> + cmd = kzalloc ( sizeof (* cmd ), GFP_KERNEL ); <nl> if (! cmd ) <nl> return - ENOMEM ; <nl>  <nl> static int kvaser_usb_leaf_flush_queue ( struct kvaser_usb_net_priv * priv ) <nl> struct kvaser_cmd * cmd ; <nl> int rc ; <nl>  <nl> - cmd = kmalloc ( sizeof (* cmd ), GFP_KERNEL ); <nl> + cmd = kzalloc ( sizeof (* cmd ), GFP_KERNEL ); <nl> if (! cmd ) <nl> return - ENOMEM ; <nl> 
mmm fs / proc / proc_misc . c <nl> ppp fs / proc / proc_misc . c <nl> static int show_stat ( struct seq_file * p , void * v ) <nl> struct timespec boottime ; <nl> unsigned int * per_irq_sum ; <nl>  <nl> - per_irq_sum = kzalloc ( sizeof ( unsigned int )* NR_IRQS , GFP_KERNEL ); <nl> + per_irq_sum = kzalloc ( sizeof ( unsigned int )* nr_irqs , GFP_KERNEL ); <nl> if (! per_irq_sum ) <nl> return - ENOMEM ; <nl>  <nl> static int show_stat ( struct seq_file * p , void * v ) <nl> softirq = cputime64_add ( softirq , kstat_cpu ( i ). cpustat . softirq ); <nl> steal = cputime64_add ( steal , kstat_cpu ( i ). cpustat . steal ); <nl> guest = cputime64_add ( guest , kstat_cpu ( i ). cpustat . guest ); <nl> - for ( j = 0 ; j < NR_IRQS ; j ++) { <nl> + for ( j = 0 ; j < nr_irqs ; j ++) { <nl> unsigned int temp = kstat_cpu ( i ). irqs [ j ]; <nl> sum += temp ; <nl> per_irq_sum [ j ] += temp ; <nl> static int show_stat ( struct seq_file * p , void * v ) <nl> } <nl> seq_printf ( p , " intr % llu ", ( unsigned long long ) sum ); <nl>  <nl> - for ( i = 0 ; i < NR_IRQS ; i ++) <nl> + for ( i = 0 ; i < nr_irqs ; i ++) <nl> seq_printf ( p , " % u ", per_irq_sum [ i ]); <nl>  <nl> seq_printf ( p , <nl> static const struct file_operations proc_stat_operations = { <nl> */ <nl> static void * int_seq_start ( struct seq_file * f , loff_t * pos ) <nl> { <nl> - return (* pos <= NR_IRQS ) ? pos : NULL ; <nl> + return (* pos <= nr_irqs ) ? pos : NULL ; <nl> } <nl>  <nl> static void * int_seq_next ( struct seq_file * f , void * v , loff_t * pos ) <nl> { <nl> (* pos )++; <nl> - if (* pos > NR_IRQS ) <nl> + if (* pos > nr_irqs ) <nl> return NULL ; <nl> return pos ; <nl> }
mmm sound / soc / intel / skylake / skl - messages . c <nl> ppp sound / soc / intel / skylake / skl - messages . c <nl> static void skl_set_updown_mixer_format ( struct skl_sst * ctx , <nl> skl_set_base_module_format ( ctx , mconfig , <nl> ( struct skl_base_cfg *) mixer_mconfig ); <nl> mixer_mconfig -> out_ch_cfg = fmt -> ch_cfg ; <nl> + mixer_mconfig -> ch_map = fmt -> ch_map ; <nl> } <nl>  <nl> /*mmm sound / soc / intel / skylake / skl - topology . h <nl> ppp sound / soc / intel / skylake / skl - topology . h <nl> static void skl_set_updown_mixer_format ( struct skl_sst * ctx , <nl> skl_set_base_module_format ( ctx , mconfig , <nl> ( struct skl_base_cfg *) mixer_mconfig ); <nl> mixer_mconfig -> out_ch_cfg = fmt -> ch_cfg ; <nl> + mixer_mconfig -> ch_map = fmt -> ch_map ; <nl> } <nl>  <nl> /* <nl> struct skl_up_down_mixer_cfg { <nl> u32 coeff_sel ; <nl> /* Pass the user coeff in this array */ <nl> s32 coeff [ UP_DOWN_MIXER_MAX_COEFF ]; <nl> + u32 ch_map ; <nl> } __packed ; <nl>  <nl> struct skl_algo_cfg {
mmm drivers / block / floppy . c <nl> ppp drivers / block / floppy . c <nl> static int set_geometry ( unsigned int cmd , struct floppy_struct * g , <nl> int cnt ; <nl>  <nl> /* sanity checking for parameters . */ <nl> - if ( g -> sect <= 0 || <nl> - g -> head <= 0 || <nl> + if (( int ) g -> sect <= 0 || <nl> + ( int ) g -> head <= 0 || <nl> + /* check for overflow in max_sector */ <nl> + ( int )( g -> sect * g -> head ) <= 0 || <nl> /* check for zero in F_SECT_PER_TRACK */ <nl> ( unsigned char )(( g -> sect << 2 ) >> FD_SIZECODE ( g )) == 0 || <nl> g -> track <= 0 || g -> track > UDP -> tracks >> STRETCH ( g ) ||
mmm arch / cris / kernel / time . c <nl> ppp arch / cris / kernel / time . c <nl> -/* $ Id : time . c , v 1 . 18 2005 / 03 / 04 08 : 16 : 17 starvik Exp $ <nl> - * <nl> +/* <nl> * linux / arch / cris / kernel / time . c <nl> * <nl> * Copyright ( C ) 1991 , 1992 , 1995 Linus Torvalds <nl> * Linux / CRIS specific code : <nl> * <nl> * Authors : Bjorn Wesen <nl> - * Johan Adolfsson <nl> + * Johan Adolfsson <nl> * <nl> */ <nl>  <nl> cris_do_profile ( struct pt_regs * regs ) <nl> # endif <nl>  <nl> # ifdef CONFIG_PROFILING <nl> - profile_tick ( CPU_PROFILING ); <nl> + profile_tick ( CPU_PROFILING , regs ); <nl> # endif <nl> } <nl>  <nl> + unsigned long long sched_clock ( void ) <nl> +{ <nl> + return ( unsigned long long ) jiffies * ( 1000000000 / HZ ) + <nl> + get_ns_in_jiffie (); <nl> +} <nl> + <nl> static int <nl> __init init_udelay ( void ) <nl> {
mmm arch / s390 / kernel / ptrace . c <nl> ppp arch / s390 / kernel / ptrace . c <nl> static int __poke_user ( struct task_struct * child , addr_t addr , addr_t data ) <nl> unsigned long mask = PSW_MASK_USER ; <nl>  <nl> mask |= is_ri_task ( child ) ? PSW_MASK_RI : 0 ; <nl> - if (( data & ~ mask ) != PSW_USER_BITS ) <nl> + if (( data ^ PSW_USER_BITS ) & ~ mask ) <nl> + /* Invalid psw mask . */ <nl> + return - EINVAL ; <nl> + if (( data & PSW_MASK_ASC ) == PSW_ASC_HOME ) <nl> + /* Invalid address - space - control bits */ <nl> return - EINVAL ; <nl> if (( data & PSW_MASK_EA ) && !( data & PSW_MASK_BA )) <nl> + /* Invalid addressing mode bits */ <nl> return - EINVAL ; <nl> } <nl> *( addr_t *)(( addr_t ) & task_pt_regs ( child )-> psw + addr ) = data ; <nl> static int __poke_user_compat ( struct task_struct * child , <nl>  <nl> mask |= is_ri_task ( child ) ? PSW32_MASK_RI : 0 ; <nl> /* Build a 64 bit psw mask from 31 bit mask . */ <nl> - if (( tmp & ~ mask ) != PSW32_USER_BITS ) <nl> + if (( tmp ^ PSW32_USER_BITS ) & ~ mask ) <nl> /* Invalid psw mask . */ <nl> return - EINVAL ; <nl> + if (( data & PSW32_MASK_ASC ) == PSW32_ASC_HOME ) <nl> + /* Invalid address - space - control bits */ <nl> + return - EINVAL ; <nl> regs -> psw . mask = ( regs -> psw . mask & ~ PSW_MASK_USER ) | <nl> ( regs -> psw . mask & PSW_MASK_BA ) | <nl> ( __u64 )( tmp & mask ) << 32 ;
mmm fs / f2fs / extent_cache . c <nl> ppp fs / f2fs / extent_cache . c <nl> static void __drop_largest_extent ( struct inode * inode , <nl> } <nl>  <nl> /* return true , if inode page is changed */ <nl> - bool f2fs_init_extent_tree ( struct inode * inode , struct f2fs_extent * i_ext ) <nl> + static bool __f2fs_init_extent_tree ( struct inode * inode , struct f2fs_extent * i_ext ) <nl> { <nl> struct f2fs_sb_info * sbi = F2FS_I_SB ( inode ); <nl> struct extent_tree * et ; <nl> bool f2fs_init_extent_tree ( struct inode * inode , struct f2fs_extent * i_ext ) <nl> return false ; <nl> } <nl>  <nl> + bool f2fs_init_extent_tree ( struct inode * inode , struct f2fs_extent * i_ext ) <nl> +{ <nl> + bool ret = __f2fs_init_extent_tree ( inode , i_ext ); <nl> + <nl> + if (! F2FS_I ( inode )-> extent_tree ) <nl> + set_inode_flag ( inode , FI_NO_EXTENT ); <nl> + <nl> + return ret ; <nl> +} <nl> + <nl> static bool f2fs_lookup_extent_tree ( struct inode * inode , pgoff_t pgofs , <nl> struct extent_info * ei ) <nl> {
mmm drivers / ata / libata - core . c <nl> ppp drivers / ata / libata - core . c <nl> struct ata_host * ata_host_alloc ( struct device * dev , int max_ports ) <nl> return NULL ; <nl>  <nl> if (! devres_open_group ( dev , NULL , GFP_KERNEL )) <nl> - return NULL ; <nl> + goto err_free ; <nl>  <nl> dr = devres_alloc ( ata_devres_release , 0 , GFP_KERNEL ); <nl> if (! dr ) <nl> struct ata_host * ata_host_alloc ( struct device * dev , int max_ports ) <nl>  <nl> err_out : <nl> devres_release_group ( dev , NULL ); <nl> + err_free : <nl> + kfree ( host ); <nl> return NULL ; <nl> } <nl> 
mmm net / rds / sysctl . c <nl> ppp net / rds / sysctl . c <nl> static struct ctl_table rds_sysctl_rds_table [] = { <nl> { <nl> . procname = " max_unacked_packets ", <nl> . data = & rds_sysctl_max_unacked_packets , <nl> - . maxlen = sizeof ( unsigned long ), <nl> + . maxlen = sizeof ( int ), <nl> . mode = 0644 , <nl> . proc_handler = proc_dointvec , <nl> }, <nl> { <nl> . procname = " max_unacked_bytes ", <nl> . data = & rds_sysctl_max_unacked_bytes , <nl> - . maxlen = sizeof ( unsigned long ), <nl> + . maxlen = sizeof ( int ), <nl> . mode = 0644 , <nl> . proc_handler = proc_dointvec , <nl> },
mmm drivers / net / e1000e / ich8lan . c <nl> ppp drivers / net / e1000e / ich8lan . c <nl> static s32 e1000_phy_hw_reset_ich8lan ( struct e1000_hw * hw ) <nl> u32 i ; <nl> u32 data , cnf_size , cnf_base_addr , sw_cfg_mask ; <nl> s32 ret_val ; <nl> - u16 word_addr , reg_data , reg_addr , phy_page = 0 ; <nl> + u16 reg , word_addr , reg_data , reg_addr , phy_page = 0 ; <nl>  <nl> ret_val = e1000e_phy_hw_reset_generic ( hw ); <nl> if ( ret_val ) <nl> static s32 e1000_phy_hw_reset_ich8lan ( struct e1000_hw * hw ) <nl> return ret_val ; <nl> } <nl>  <nl> + /* Dummy read to clear the phy wakeup bit after lcd reset */ <nl> + if ( hw -> mac . type == e1000_pchlan ) <nl> + e1e_rphy ( hw , BM_WUC , & reg ); <nl> + <nl> /* <nl> * Initialize the PHY from the NVM on ICH platforms . This <nl> * is needed due to an issue where the NVM configuration is <nl> static s32 e1000_get_bus_info_ich8lan ( struct e1000_hw * hw ) <nl> **/ <nl> static s32 e1000_reset_hw_ich8lan ( struct e1000_hw * hw ) <nl> { <nl> + u16 reg ; <nl> u32 ctrl , icr , kab ; <nl> s32 ret_val ; <nl>  <nl> static s32 e1000_reset_hw_ich8lan ( struct e1000_hw * hw ) <nl> hw_dbg ( hw , " Auto Read Done did not complete \ n "); <nl> } <nl> } <nl> + /* Dummy read to clear the phy wakeup bit after lcd reset */ <nl> + if ( hw -> mac . type == e1000_pchlan ) <nl> + e1e_rphy ( hw , BM_WUC , & reg ); <nl>  <nl> /* <nl> * For PCH , this write will make sure that any noise
mmm drivers / net / smc911x . c <nl> ppp drivers / net / smc911x . c <nl> static void smc911x_reset ( struct net_device * dev ) <nl> do { <nl> udelay ( 10 ); <nl> reg = SMC_GET_PMT_CTRL () & PMT_CTRL_READY_ ; <nl> - } while ( timeout -- && ! reg ); <nl> + } while (-- timeout && ! reg ); <nl> if ( timeout == 0 ) { <nl> PRINTK ("% s : smc911x_reset timeout waiting for PM restore \ n ", dev -> name ); <nl> return ; <nl> static void smc911x_reset ( struct net_device * dev ) <nl> resets ++; <nl> break ; <nl> } <nl> - } while ( timeout -- && ( reg & HW_CFG_SRST_ )); <nl> + } while (-- timeout && ( reg & HW_CFG_SRST_ )); <nl> } <nl> if ( timeout == 0 ) { <nl> PRINTK ("% s : smc911x_reset timeout waiting for reset \ n ", dev -> name ); <nl> static inline void smc911x_drop_pkt ( struct net_device * dev ) <nl> do { <nl> udelay ( 10 ); <nl> reg = SMC_GET_RX_DP_CTRL () & RX_DP_CTRL_FFWD_BUSY_ ; <nl> - } while ( timeout -- && reg ); <nl> + } while (-- timeout && reg ); <nl> if ( timeout == 0 ) { <nl> PRINTK ("% s : timeout waiting for RX fast forward \ n ", dev -> name ); <nl> }
mmm drivers / hwmon / asb100 . c <nl> ppp drivers / hwmon / asb100 . c <nl> static ssize_t set_vrm ( struct device * dev , struct device_attribute * attr , <nl> err = kstrtoul ( buf , 10 , & val ); <nl> if ( err ) <nl> return err ; <nl> + <nl> + if ( val > 255 ) <nl> + return - EINVAL ; <nl> + <nl> data -> vrm = val ; <nl> return count ; <nl> }
mmm sound / pci / ali5451 / ali5451 . c <nl> ppp sound / pci / ali5451 / ali5451 . c <nl> snd_ali_playback_pointer ( struct snd_pcm_substream * substream ) <nl> spin_unlock (& codec -> reg_lock ); <nl> dev_dbg ( codec -> card -> dev , " playback pointer returned cso =% xh .\ n ", cso ); <nl>  <nl> + cso %= runtime -> buffer_size ; <nl> return cso ; <nl> } <nl>  <nl> static snd_pcm_uframes_t snd_ali_pointer ( struct snd_pcm_substream * substream ) <nl> cso = inw ( ALI_REG ( codec , ALI_CSO_ALPHA_FMS + 2 )); <nl> spin_unlock (& codec -> reg_lock ); <nl>  <nl> + cso %= runtime -> buffer_size ; <nl> return cso ; <nl> } <nl> 
mmm drivers / input / touchscreen / wm97xx - core . c <nl> ppp drivers / input / touchscreen / wm97xx - core . c <nl> static int wm97xx_init_pen_irq ( struct wm97xx * wm ) <nl> * provided . */ <nl> BUG_ON (! wm -> mach_ops -> irq_enable ); <nl>  <nl> - if ( request_irq ( wm -> pen_irq , wm97xx_pen_interrupt , IRQF_SHARED , <nl> + if ( request_irq ( wm -> pen_irq , wm97xx_pen_interrupt , <nl> + IRQF_SHARED | IRQF_SAMPLE_RANDOM , <nl> " wm97xx - pen ", wm )) { <nl> dev_err ( wm -> dev , <nl> " Failed to register pen down interrupt , polling ");
mmm drivers / net / wireless / marvell / mwifiex / pcie . c <nl> ppp drivers / net / wireless / marvell / mwifiex / pcie . c <nl> static int mwifiex_pcie_alloc_cmdrsp_buf ( struct mwifiex_adapter * adapter ) <nl> } <nl> skb_put ( skb , MWIFIEX_UPLD_SIZE ); <nl> if ( mwifiex_map_pci_memory ( adapter , skb , MWIFIEX_UPLD_SIZE , <nl> - PCI_DMA_FROMDEVICE )) <nl> + PCI_DMA_FROMDEVICE )) { <nl> + kfree_skb ( skb ); <nl> return - 1 ; <nl> + } <nl>  <nl> card -> cmdrsp_buf = skb ; <nl> 
mmm drivers / staging / pi433 / pi433_if . c <nl> ppp drivers / staging / pi433 / pi433_if . c <nl> pi433_tx_thread ( void * data ) <nl> while (( repetitions > 0 ) && ( size > position )) { <nl> if (( size - position ) > device -> free_in_fifo ) { <nl> /* msg to big for fifo - take a part */ <nl> - int temp = device -> free_in_fifo ; <nl> + int write_size = device -> free_in_fifo ; <nl> + <nl> device -> free_in_fifo = 0 ; <nl> rf69_write_fifo ( spi , <nl> & device -> buffer [ position ], <nl> - temp ); <nl> - position += temp ; <nl> + write_size ); <nl> + position += write_size ; <nl> } else { <nl> /* msg fits into fifo - take all */ <nl> device -> free_in_fifo -= size ;
mmm drivers / media / platform / s3c - camif / camif - core . c <nl> ppp drivers / media / platform / s3c - camif / camif - core . c <nl> static int camif_media_dev_init ( struct camif_dev * camif ) <nl> ip_rev == S3C6410_CAMIF_IP_REV ? " 6410 " : " 244X "); <nl> strlcpy ( md -> bus_info , " platform ", sizeof ( md -> bus_info )); <nl> md -> hw_revision = ip_rev ; <nl> - md -> driver_version = KERNEL_VERSION ( 1 , 0 , 0 ); <nl> + md -> driver_version = LINUX_VERSION_CODE ; <nl>  <nl> md -> dev = camif -> dev ; <nl> 
mmm drivers / net / wireless / ath / ath9k / ar9003_phy . c <nl> ppp drivers / net / wireless / ath / ath9k / ar9003_phy . c <nl> static int ar9003_hw_set_channel ( struct ath_hw * ah , struct ath9k_channel * chan ) <nl> u32 chan_frac ; <nl>  <nl> channelSel = ( freq * 2 ) / 75 ; <nl> - chan_frac = (( freq % 75 ) * 0x20000 ) / 75 ; <nl> + chan_frac = ((( freq * 2 ) % 75 ) * 0x20000 ) / 75 ; <nl> channelSel = ( channelSel << 17 ) | chan_frac ; <nl> } else { <nl> channelSel = CHANSEL_5G ( freq );
mmm net / socket . c <nl> ppp net / socket . c <nl> static int copy_msghdr_from_user ( struct msghdr * kmsg , <nl> { <nl> if ( copy_from_user ( kmsg , umsg , sizeof ( struct msghdr ))) <nl> return - EFAULT ; <nl> + <nl> + if ( kmsg -> msg_namelen < 0 ) <nl> + return - EINVAL ; <nl> + <nl> if ( kmsg -> msg_namelen > sizeof ( struct sockaddr_storage )) <nl> kmsg -> msg_namelen = sizeof ( struct sockaddr_storage ); <nl> return 0 ;
mmm drivers / pcmcia / cs_internal . h <nl> ppp drivers / pcmcia / cs_internal . h <nl> struct pccard_resource_ops { <nl> /* Flags in socket state */ <nl> # define SOCKET_PRESENT 0x0008 <nl> # define SOCKET_INUSE 0x0010 <nl> +# define SOCKET_IN_RESUME 0x0040 <nl> # define SOCKET_SUSPEND 0x0080 <nl> # define SOCKET_WIN_REQ ( i ) ( 0x0100 <<( i )) <nl> # define SOCKET_CARDBUS 0x8000mmm drivers / pcmcia / cs . c <nl> ppp drivers / pcmcia / cs . c <nl> struct pccard_resource_ops { <nl> /* Flags in socket state */ <nl> # define SOCKET_PRESENT 0x0008 <nl> # define SOCKET_INUSE 0x0010 <nl> +# define SOCKET_IN_RESUME 0x0040 <nl> # define SOCKET_SUSPEND 0x0080 <nl> # define SOCKET_WIN_REQ ( i ) ( 0x0100 <<( i )) <nl> # define SOCKET_CARDBUS 0x8000 <nl> static int socket_insert ( struct pcmcia_socket * skt ) <nl>  <nl> static int socket_suspend ( struct pcmcia_socket * skt ) <nl> { <nl> - if ( skt -> state & SOCKET_SUSPEND ) <nl> + if (( skt -> state & SOCKET_SUSPEND ) && !( skt -> state & SOCKET_IN_RESUME )) <nl> return - EBUSY ; <nl>  <nl> mutex_lock (& skt -> ops_mutex ); <nl> - skt -> suspended_state = skt -> state ; <nl> + /* store state on first suspend , but not after spurious wakeups */ <nl> + if (!( skt -> state & SOCKET_IN_RESUME )) <nl> + skt -> suspended_state = skt -> state ; <nl>  <nl> skt -> socket = dead_socket ; <nl> skt -> ops -> set_socket ( skt , & skt -> socket ); <nl> if ( skt -> ops -> suspend ) <nl> skt -> ops -> suspend ( skt ); <nl> skt -> state |= SOCKET_SUSPEND ; <nl> + skt -> state &= ~ SOCKET_IN_RESUME ; <nl> mutex_unlock (& skt -> ops_mutex ); <nl> return 0 ; <nl> } <nl> static int socket_early_resume ( struct pcmcia_socket * skt ) <nl> skt -> ops -> set_socket ( skt , & skt -> socket ); <nl> if ( skt -> state & SOCKET_PRESENT ) <nl> skt -> resume_status = socket_setup ( skt , resume_delay ); <nl> + skt -> state |= SOCKET_IN_RESUME ; <nl> mutex_unlock (& skt -> ops_mutex ); <nl> return 0 ; <nl> } <nl> static int socket_late_resume ( struct pcmcia_socket * skt ) <nl> int ret = 0 ; <nl>  <nl> mutex_lock (& skt -> ops_mutex ); <nl> - skt -> state &= ~ SOCKET_SUSPEND ; <nl> + skt -> state &= ~( SOCKET_SUSPEND | SOCKET_IN_RESUME ); <nl> mutex_unlock (& skt -> ops_mutex ); <nl>  <nl> if (!( skt -> state & SOCKET_PRESENT )) {
mmm arch / mips / include / asm / mach - tx49xx / mangle - port . h <nl> ppp arch / mips / include / asm / mach - tx49xx / mangle - port . h <nl> # define ioswabb ( a , x ) ( x ) <nl> # define __mem_ioswabb ( a , x ) ( x ) <nl> # if defined ( CONFIG_TOSHIBA_RBTX4939 ) && \ <nl> - ( defined ( CONFIG_SMC91X ) || defined ( CONFIG_SMC91X_MODULE )) && \ <nl> + IS_ENABLED ( CONFIG_SMC91X ) && \ <nl> defined ( __BIG_ENDIAN ) <nl> # define NEEDS_TXX9_IOSWABW <nl> extern u16 (* ioswabw )( volatile u16 * a , u16 x );
mmm drivers / s390 / cio / ccwreq . c <nl> ppp drivers / s390 / cio / ccwreq . c <nl> static enum io_status ccwreq_status ( struct ccw_device * cdev , struct irb * lcirb ) <nl> /* Ask the driver what to do */ <nl> if ( cdev -> drv && cdev -> drv -> uc_handler ) { <nl> todo = cdev -> drv -> uc_handler ( cdev , lcirb ); <nl> + CIO_TRACE_EVENT ( 2 , " uc_response "); <nl> + CIO_HEX_EVENT ( 2 , & todo , sizeof ( todo )); <nl> switch ( todo ) { <nl> case UC_TODO_RETRY : <nl> return IO_STATUS_ERROR ;
mmm drivers / perf / arm_pmu . c <nl> ppp drivers / perf / arm_pmu . c <nl> int arm_pmu_device_probe ( struct platform_device * pdev , <nl> ret = of_pmu_irq_cfg ( pmu ); <nl> if (! ret ) <nl> ret = init_fn ( pmu ); <nl> - } else { <nl> + } else if ( probe_table ) { <nl> cpumask_setall (& pmu -> supported_cpus ); <nl> ret = probe_current_pmu ( pmu , probe_table ); <nl> }mmm arch / arm64 / kernel / perf_event . c <nl> ppp arch / arm64 / kernel / perf_event . c <nl> int arm_pmu_device_probe ( struct platform_device * pdev , <nl> ret = of_pmu_irq_cfg ( pmu ); <nl> if (! ret ) <nl> ret = init_fn ( pmu ); <nl> - } else { <nl> + } else if ( probe_table ) { <nl> cpumask_setall (& pmu -> supported_cpus ); <nl> ret = probe_current_pmu ( pmu , probe_table ); <nl> } <nl> # include < asm / sysreg . h > <nl> # include < asm / virt . h > <nl>  <nl> +# include < linux / acpi . h > <nl> # include < linux / of . h > <nl> # include < linux / perf / arm_pmu . h > <nl> # include < linux / platform_device . h > <nl> static const struct of_device_id armv8_pmu_of_device_ids [] = { <nl> {}, <nl> }; <nl>  <nl> + static const struct pmu_probe_info armv8_pmu_probe_table [] = { <nl> + PMU_PROBE ( 0 , 0 , armv8_pmuv3_init ), /* if all else fails ... */ <nl> + { /* sentinel value */ } <nl> +}; <nl> + <nl> static int armv8_pmu_device_probe ( struct platform_device * pdev ) <nl> { <nl> - return arm_pmu_device_probe ( pdev , armv8_pmu_of_device_ids , NULL ); <nl> + if ( acpi_disabled ) <nl> + return arm_pmu_device_probe ( pdev , armv8_pmu_of_device_ids , <nl> + NULL ); <nl> + <nl> + return arm_pmu_device_probe ( pdev , armv8_pmu_of_device_ids , <nl> + armv8_pmu_probe_table ); <nl> } <nl>  <nl> static struct platform_driver armv8_pmu_driver = {
mmm drivers / spi / spi_txx9 . c <nl> ppp drivers / spi / spi_txx9 . c <nl>  <nl>  <nl> # define SPI_FIFO_SIZE 4 <nl> +# define SPI_MAX_DIVIDER 0xff /* Max . value for SPCR1 . SER */ <nl> +# define SPI_MIN_DIVIDER 1 /* Min . value for SPCR1 . SER */ <nl>  <nl> # define TXx9_SPMCR 0x00 <nl> # define TXx9_SPCR0 0x04 <nl> static void txx9spi_work_one ( struct txx9spi * c , struct spi_message * m ) <nl>  <nl> if ( prev_speed_hz != speed_hz <nl> || prev_bits_per_word != bits_per_word ) { <nl> - u32 n = ( c -> baseclk + speed_hz - 1 ) / speed_hz ; <nl> - if ( n < 1 ) <nl> - n = 1 ; <nl> - else if ( n > 0xff ) <nl> - n = 0xff ; <nl> + int n = DIV_ROUND_UP ( c -> baseclk , speed_hz ) - 1 ; <nl> + n = clamp ( n , SPI_MIN_DIVIDER , SPI_MAX_DIVIDER ); <nl> /* enter config mode */ <nl> txx9spi_wr ( c , mcr | TXx9_SPMCR_CONFIG | TXx9_SPMCR_BCLR , <nl> TXx9_SPMCR ); <nl> static int __init txx9spi_probe ( struct platform_device * dev ) <nl> goto exit ; <nl> } <nl> c -> baseclk = clk_get_rate ( c -> clk ); <nl> - c -> min_speed_hz = ( c -> baseclk + 0xff - 1 ) / 0xff ; <nl> - c -> max_speed_hz = c -> baseclk ; <nl> + c -> min_speed_hz = DIV_ROUND_UP ( c -> baseclk , SPI_MAX_DIVIDER + 1 ); <nl> + c -> max_speed_hz = c -> baseclk / ( SPI_MIN_DIVIDER + 1 ); <nl>  <nl> res = platform_get_resource ( dev , IORESOURCE_MEM , 0 ); <nl> if (! res )
mmm fs / jbd2 / journal . c <nl> ppp fs / jbd2 / journal . c <nl> static int kjournald2 ( void * arg ) <nl> goto loop ; <nl>  <nl> end_loop : <nl> - write_unlock (& journal -> j_state_lock ); <nl> del_timer_sync (& journal -> j_commit_timer ); <nl> journal -> j_task = NULL ; <nl> wake_up (& journal -> j_wait_done_commit ); <nl> jbd_debug ( 1 , " Journal thread exiting .\ n "); <nl> + write_unlock (& journal -> j_state_lock ); <nl> return 0 ; <nl> } <nl> 
mmm drivers / staging / unisys / visorbus / visorchipset . c <nl> ppp drivers / staging / unisys / visorbus / visorchipset . c <nl> static ssize_t toolaction_store ( struct device * dev , <nl> const char * buf , size_t count ) <nl> { <nl> u8 tool_action ; <nl> - int ret ; <nl> + int err ; <nl>  <nl> if ( kstrtou8 ( buf , 10 , & tool_action )) <nl> return - EINVAL ; <nl>  <nl> - ret = visorchannel_write <nl> + err = visorchannel_write <nl> ( chipset_dev -> controlvm_channel , <nl> offsetof ( struct spar_controlvm_channel_protocol , <nl> tool_action ), <nl> & tool_action , sizeof ( u8 )); <nl>  <nl> - if ( ret ) <nl> - return ret ; <nl> + if ( err ) <nl> + return err ; <nl> return count ; <nl> } <nl> static DEVICE_ATTR_RW ( toolaction );
mmm drivers / media / usb / cx231xx / cx231xx - core . c <nl> ppp drivers / media / usb / cx231xx / cx231xx - core . c <nl> int cx231xx_set_mode ( struct cx231xx * dev , enum cx231xx_mode set_mode ) <nl> } <nl> } <nl>  <nl> - return errCode ? - EINVAL : 0 ; <nl> + if ( errCode < 0 ) { <nl> + dev_err ( dev -> dev , " Failed to set devmode to % s : error : % i ", <nl> + dev -> mode == CX231XX_DIGITAL_MODE ? " digital " : " analog ", <nl> + errCode ); <nl> + return errCode ; <nl> + } <nl> + <nl> + return 0 ; <nl> } <nl> EXPORT_SYMBOL_GPL ( cx231xx_set_mode ); <nl> 
mmm sound / soc / davinci / davinci - evm . c <nl> ppp sound / soc / davinci / davinci - evm . c <nl> static struct snd_soc_dai_link da8xx_evm_dai = { <nl> . stream_name = " AIC3X ", <nl> . cpu_dai_name = " davinci - mcasp . 0 ", <nl> . codec_dai_name = " tlv320aic3x - hifi ", <nl> - . codec_name = " tlv320aic3x - codec . 0 - 001a ", <nl> + . codec_name = " tlv320aic3x - codec . 1 - 0018 ", <nl> . platform_name = " davinci - pcm - audio ", <nl> . init = evm_aic3x_init , <nl> . ops = & evm_ops ,
mmm tools / perf / builtin - top . c <nl> ppp tools / perf / builtin - top . c <nl> static void handle_keypress ( int c ) <nl> switch ( c ) { <nl> case ' d ': <nl> prompt_integer (& delay_secs , " Enter display delay "); <nl> + if ( delay_secs < 1 ) <nl> + delay_secs = 1 ; <nl> break ; <nl> case ' e ': <nl> prompt_integer (& print_entries , " Enter display entries ( lines )");
mmm fs / f2fs / file . c <nl> ppp fs / f2fs / file . c <nl> static ssize_t f2fs_file_write_iter ( struct kiocb * iocb , struct iov_iter * from ) <nl>  <nl> ret = generic_write_checks ( iocb , from ); <nl> if ( ret > 0 ) { <nl> + bool preallocated = false ; <nl> + size_t target_size = 0 ; <nl> int err ; <nl>  <nl> if ( iov_iter_fault_in_readable ( from , iov_iter_count ( from ))) <nl> static ssize_t f2fs_file_write_iter ( struct kiocb * iocb , struct iov_iter * from ) <nl> } <nl>  <nl> } else { <nl> + preallocated = true ; <nl> + target_size = iocb -> ki_pos + iov_iter_count ( from ); <nl> + <nl> err = f2fs_preallocate_blocks ( iocb , from ); <nl> if ( err ) { <nl> clear_inode_flag ( inode , FI_NO_PREALLOC ); <nl> static ssize_t f2fs_file_write_iter ( struct kiocb * iocb , struct iov_iter * from ) <nl> blk_finish_plug (& plug ); <nl> clear_inode_flag ( inode , FI_NO_PREALLOC ); <nl>  <nl> + /* if we couldn ' t write data , we should deallocate blocks . */ <nl> + if ( preallocated && i_size_read ( inode ) < target_size ) <nl> + f2fs_truncate ( inode ); <nl> + <nl> if ( ret > 0 ) <nl> f2fs_update_iostat ( F2FS_I_SB ( inode ), APP_WRITE_IO , ret ); <nl> }
mmm kernel / srcu . c <nl> ppp kernel / srcu . c <nl> static bool srcu_readers_active_idx_check ( struct srcu_struct * sp , int idx ) <nl> */ <nl> static int srcu_readers_active ( struct srcu_struct * sp ) <nl> { <nl> - return srcu_readers_active_idx ( sp , 0 ) + srcu_readers_active_idx ( sp , 1 ); <nl> + int cpu ; <nl> + unsigned long sum = 0 ; <nl> + <nl> + for_each_possible_cpu ( cpu ) { <nl> + sum += ACCESS_ONCE ( per_cpu_ptr ( sp -> per_cpu_ref , cpu )-> c [ 0 ]); <nl> + sum += ACCESS_ONCE ( per_cpu_ptr ( sp -> per_cpu_ref , cpu )-> c [ 1 ]); <nl> + } <nl> + return sum ; <nl> } <nl>  <nl> /**
mmm tools / iio / iio_utils . c <nl> ppp tools / iio / iio_utils . c <nl> int iioutils_get_type ( unsigned * is_signed , <nl> ret = - errno ; <nl> printf (" failed to pass scan type description \ n "); <nl> goto error_close_sysfsfp ; <nl> + } else if ( ret != 5 ) { <nl> + ret = - EIO ; <nl> + printf (" scan type description didn ' t match \ n "); <nl> + goto error_close_sysfsfp ; <nl> } <nl> * be = ( endianchar == ' b '); <nl> * bytes = padint / 8 ;
mmm drivers / leds / leds - mlxcpld . c <nl> ppp drivers / leds / leds - mlxcpld . c <nl> static int __init mlxcpld_led_init ( void ) <nl> struct platform_device * pdev ; <nl> int err ; <nl>  <nl> + if (! dmi_match ( DMI_CHASSIS_VENDOR , " Mellanox Technologies Ltd .")) <nl> + return - ENODEV ; <nl> + <nl> pdev = platform_device_register_simple ( KBUILD_MODNAME , - 1 , NULL , 0 ); <nl> if ( IS_ERR ( pdev )) { <nl> pr_err (" Device allocation failed \ n "); <nl> module_exit ( mlxcpld_led_exit ); <nl>  <nl> MODULE_AUTHOR (" Vadim Pasternak < vadimp @ mellanox . com >"); <nl> MODULE_DESCRIPTION (" Mellanox board LED driver "); <nl> - MODULE_LICENSE (" GPL v2 "); <nl> + MODULE_LICENSE (" Dual BSD / GPL "); <nl> MODULE_ALIAS (" platform : leds_mlxcpld ");
mmm drivers / bluetooth / hci_intel . c <nl> ppp drivers / bluetooth / hci_intel . c <nl> static int intel_set_power ( struct hci_uart * hu , bool powered ) <nl> struct list_head * p ; <nl> int err = - ENODEV ; <nl>  <nl> + if (! hu -> tty -> dev ) <nl> + return err ; <nl> + <nl> mutex_lock (& intel_device_list_lock ); <nl>  <nl> list_for_each ( p , & intel_device_list ) { <nl> static void intel_busy_work ( struct work_struct * work ) <nl> struct intel_data * intel = container_of ( work , struct intel_data , <nl> busy_work ); <nl>  <nl> + if (! intel -> hu -> tty -> dev ) <nl> + return ; <nl> + <nl> /* Link is busy , delay the suspend */ <nl> mutex_lock (& intel_device_list_lock ); <nl> list_for_each ( p , & intel_device_list ) { <nl> static int intel_setup ( struct hci_uart * hu ) <nl> list_for_each ( p , & intel_device_list ) { <nl> struct intel_device * dev = list_entry ( p , struct intel_device , <nl> list ); <nl> + if (! hu -> tty -> dev ) <nl> + break ; <nl> if ( hu -> tty -> dev -> parent == dev -> pdev -> dev . parent ) { <nl> if ( device_may_wakeup (& dev -> pdev -> dev )) { <nl> set_bit ( STATE_LPM_ENABLED , & intel -> flags ); <nl> static int intel_enqueue ( struct hci_uart * hu , struct sk_buff * skb ) <nl>  <nl> BT_DBG (" hu % p skb % p ", hu , skb ); <nl>  <nl> + if (! hu -> tty -> dev ) <nl> + goto out_enqueue ; <nl> + <nl> /* Be sure our controller is resumed and potential LPM transaction <nl> * completed before enqueuing any packet . <nl> */ <nl> static int intel_enqueue ( struct hci_uart * hu , struct sk_buff * skb ) <nl> } <nl> } <nl> mutex_unlock (& intel_device_list_lock ); <nl> - <nl> + out_enqueue : <nl> skb_queue_tail (& intel -> txq , skb ); <nl>  <nl> return 0 ;
mmm net / ipv4 / fib_trie . c <nl> ppp net / ipv4 / fib_trie . c <nl> static int check_leaf ( struct fib_table * tb , struct trie * t , struct leaf * l , <nl>  <nl> if ( fa -> fa_tos && fa -> fa_tos != flp -> flowi4_tos ) <nl> continue ; <nl> + if ( fi -> fib_dead ) <nl> + continue ; <nl> if ( fa -> fa_info -> fib_scope < flp -> flowi4_scope ) <nl> continue ; <nl> fib_alias_accessed ( fa );
mmm drivers / gpu / drm / i915 / intel_runtime_pm . c <nl> ppp drivers / gpu / drm / i915 / intel_runtime_pm . c <nl> static void intel_power_well_enable ( struct drm_i915_private * dev_priv , <nl> power_well -> hw_enabled = true ; <nl> } <nl>  <nl> + static void intel_power_well_disable ( struct drm_i915_private * dev_priv , <nl> + struct i915_power_well * power_well ) <nl> +{ <nl> + DRM_DEBUG_KMS (" disabling % s \ n ", power_well -> name ); <nl> + power_well -> hw_enabled = false ; <nl> + power_well -> ops -> disable ( dev_priv , power_well ); <nl> +} <nl> + <nl> /* <nl> * We should only use the power well if we explicitly asked the hardware to <nl> * enable it , so check if it ' s enabled and also check if we ' ve requested it to <nl> void intel_display_power_put ( struct drm_i915_private * dev_priv , <nl> for_each_power_well_rev ( i , power_well , BIT ( domain ), power_domains ) { <nl> WARN_ON (! power_well -> count ); <nl>  <nl> - if (!-- power_well -> count && i915 . disable_power_well ) { <nl> - DRM_DEBUG_KMS (" disabling % s \ n ", power_well -> name ); <nl> - power_well -> hw_enabled = false ; <nl> - power_well -> ops -> disable ( dev_priv , power_well ); <nl> - } <nl> + if (!-- power_well -> count && i915 . disable_power_well ) <nl> + intel_power_well_disable ( dev_priv , power_well ); <nl> } <nl>  <nl> mutex_unlock (& power_domains -> lock );
mmm kernel / early_res . c <nl> ppp kernel / early_res . c <nl> static void __init drop_range_partial ( int i , u64 start , u64 end ) <nl> /* make head segment */ <nl> early_res [ i ]. end = common_start ; <nl> if ( old_end > common_end ) { <nl> + char name [ 15 ]; <nl> + <nl> + /* <nl> + * Save a local copy of the name , since the <nl> + * early_res array could get resized inside <nl> + * reserve_early_without_check () -> <nl> + * __check_and_double_early_res (), which would <nl> + * make the current name pointer invalid . <nl> + */ <nl> + strncpy ( name , early_res [ i ]. name , <nl> + sizeof ( early_res [ i ]. name ) - 1 ); <nl> /* add another for left over on tail */ <nl> - reserve_early_without_check ( common_end , old_end , <nl> - early_res [ i ]. name ); <nl> + reserve_early_without_check ( common_end , old_end , name ); <nl> } <nl> return ; <nl> } else {
mmm drivers / watchdog / bcm7038_wdt . c <nl> ppp drivers / watchdog / bcm7038_wdt . c <nl> static int bcm7038_wdt_probe ( struct platform_device * pdev ) <nl> wdt -> clk = devm_clk_get ( dev , NULL ); <nl> /* If unable to get clock , use default frequency */ <nl> if (! IS_ERR ( wdt -> clk )) { <nl> - clk_prepare_enable ( wdt -> clk ); <nl> + err = clk_prepare_enable ( wdt -> clk ); <nl> + if ( err ) <nl> + return err ; <nl> wdt -> rate = clk_get_rate ( wdt -> clk ); <nl> /* Prevent divide - by - zero exception */ <nl> if (! wdt -> rate )
mmm drivers / net / wireless / broadcom / brcm80211 / brcmfmac / fweh . c <nl> ppp drivers / net / wireless / broadcom / brcm80211 / brcmfmac / fweh . c <nl> void brcmf_fweh_process_event ( struct brcmf_pub * drvr , <nl> if ( code != BRCMF_E_IF && ! fweh -> evt_handler [ code ]) <nl> return ; <nl>  <nl> - if ( datalen > BRCMF_DCMD_MAXLEN ) <nl> + if ( datalen > BRCMF_DCMD_MAXLEN || <nl> + datalen + sizeof (* event_packet ) > packet_len ) <nl> return ; <nl>  <nl> if ( in_interrupt ())
mmm drivers / tty / tty_ldisc . c <nl> ppp drivers / tty / tty_ldisc . c <nl> EXPORT_SYMBOL_GPL ( tty_ldisc_flush ); <nl> * they are not on hot paths so a little discipline won ' t do <nl> * any harm . <nl> * <nl> + * The line discipline - related tty_struct fields are reset to <nl> + * prevent the ldisc driver from re - using stale information for <nl> + * the new ldisc instance . <nl> + * <nl> * Locking : takes termios_rwsem <nl> */ <nl>  <nl> static void tty_set_termios_ldisc ( struct tty_struct * tty , int num ) <nl> down_write (& tty -> termios_rwsem ); <nl> tty -> termios . c_line = num ; <nl> up_write (& tty -> termios_rwsem ); <nl> + <nl> + tty -> disc_data = NULL ; <nl> + tty -> receive_room = 0 ; <nl> } <nl>  <nl> /**
mmm drivers / net / bonding / bond_main . c <nl> ppp drivers / net / bonding / bond_main . c <nl> static void bond_info_show_slave ( struct seq_file * seq , <nl> seq_printf ( seq , "\ nSlave Interface : % s \ n ", slave -> dev -> name ); <nl> seq_printf ( seq , " MII Status : % s \ n ", <nl> ( slave -> link == BOND_LINK_UP ) ? " up " : " down "); <nl> + seq_printf ( seq , " Speed : % d Mbps \ n ", slave -> speed ); <nl> + seq_printf ( seq , " Duplex : % s \ n ", slave -> duplex ? " full " : " half "); <nl> seq_printf ( seq , " Link Failure Count : % u \ n ", <nl> slave -> link_failure_count ); <nl> 
mmm drivers / dma / dmaengine . c <nl> ppp drivers / dma / dmaengine . c <nl> void dma_run_dependencies ( struct dma_async_tx_descriptor * tx ) <nl> if (! dep ) <nl> return ; <nl>  <nl> + /* we ' ll submit tx -> next now , so clear the link */ <nl> + tx -> next = NULL ; <nl> chan = dep -> chan ; <nl>  <nl> /* keep submitting up until a channel switch is detected
mmm arch / arm64 / mm / dma - mapping . c <nl> ppp arch / arm64 / mm / dma - mapping . c <nl> static void * __iommu_alloc_attrs ( struct device * dev , size_t size , <nl> size >> PAGE_SHIFT ); <nl> return NULL ; <nl> } <nl> - if (! coherent ) <nl> - __dma_flush_area ( page_to_virt ( page ), iosize ); <nl> - <nl> addr = dma_common_contiguous_remap ( page , size , VM_USERMAP , <nl> prot , <nl> __builtin_return_address ( 0 )); <nl> - if (! addr ) { <nl> + if ( addr ) { <nl> + memset ( addr , 0 , size ); <nl> + if (! coherent ) <nl> + __dma_flush_area ( page_to_virt ( page ), iosize ); <nl> + } else { <nl> iommu_dma_unmap_page ( dev , * handle , iosize , 0 , attrs ); <nl> dma_release_from_contiguous ( dev , page , <nl> size >> PAGE_SHIFT );
mmm drivers / vhost / net . c <nl> ppp drivers / vhost / net . c <nl> static void vhost_net_ubuf_put_and_wait ( struct vhost_net_ubuf_ref * ubufs ) <nl> { <nl> kref_put (& ubufs -> kref , vhost_net_zerocopy_done_signal ); <nl> wait_event ( ubufs -> wait , ! atomic_read (& ubufs -> kref . refcount )); <nl> +} <nl> + <nl> + static void vhost_net_ubuf_put_wait_and_free ( struct vhost_net_ubuf_ref * ubufs ) <nl> +{ <nl> + vhost_net_ubuf_put_and_wait ( ubufs ); <nl> kfree ( ubufs ); <nl> } <nl>  <nl> static long vhost_net_set_backend ( struct vhost_net * n , unsigned index , int fd ) <nl> mutex_unlock (& vq -> mutex ); <nl>  <nl> if ( oldubufs ) { <nl> - vhost_net_ubuf_put_and_wait ( oldubufs ); <nl> + vhost_net_ubuf_put_wait_and_free ( oldubufs ); <nl> mutex_lock (& vq -> mutex ); <nl> vhost_zerocopy_signal_used ( n , vq ); <nl> mutex_unlock (& vq -> mutex ); <nl> static long vhost_net_set_backend ( struct vhost_net * n , unsigned index , int fd ) <nl> rcu_assign_pointer ( vq -> private_data , oldsock ); <nl> vhost_net_enable_vq ( n , vq ); <nl> if ( ubufs ) <nl> - vhost_net_ubuf_put_and_wait ( ubufs ); <nl> + vhost_net_ubuf_put_wait_and_free ( ubufs ); <nl> err_ubufs : <nl> fput ( sock -> file ); <nl> err_vq :
mmm net / bluetooth / mgmt . c <nl> ppp net / bluetooth / mgmt . c <nl> static int send_pin_code_neg_reply ( struct sock * sk , struct hci_dev * hdev , <nl> if (! cmd ) <nl> return - ENOMEM ; <nl>  <nl> + cmd -> cmd_complete = addr_cmd_complete ; <nl> + <nl> err = hci_send_cmd ( hdev , HCI_OP_PIN_CODE_NEG_REPLY , <nl> sizeof ( cp -> addr . bdaddr ), & cp -> addr . bdaddr ); <nl> if ( err < 0 )
mmm fs / btrfs / extent - tree . c <nl> ppp fs / btrfs / extent - tree . c <nl> static int alloc_reserved_tree_block ( struct btrfs_trans_handle * trans , <nl> ret = btrfs_insert_empty_item ( trans , fs_info -> extent_root , path , <nl> ins , size ); <nl> if ( ret ) { <nl> + btrfs_free_path ( path ); <nl> btrfs_free_and_pin_reserved_extent ( root , ins -> objectid , <nl> root -> nodesize ); <nl> - btrfs_free_path ( path ); <nl> return ret ; <nl> } <nl> 
mmm kernel / exit . c <nl> ppp kernel / exit . c <nl> long kernel_wait4 ( pid_t upid , int __user * stat_addr , int options , <nl> __WNOTHREAD | __WCLONE | __WALL )) <nl> return - EINVAL ; <nl>  <nl> + /* - INT_MIN is not defined */ <nl> + if ( upid == INT_MIN ) <nl> + return - ESRCH ; <nl> + <nl> if ( upid == - 1 ) <nl> type = PIDTYPE_MAX ; <nl> else if ( upid < 0 ) {
mmm arch / mips / kernel / smp - cps . c <nl> ppp arch / mips / kernel / smp - cps . c <nl> static void boot_core ( unsigned core ) <nl> write_gcr_access ( access ); <nl>  <nl> if ( mips_cpc_present ()) { <nl> - /* Select the appropriate core */ <nl> - write_cpc_cl_other ( core << CPC_Cx_OTHER_CORENUM_SHF ); <nl> - <nl> /* Reset the core */ <nl> + mips_cpc_lock_other ( core ); <nl> write_cpc_co_cmd ( CPC_Cx_CMD_RESET ); <nl> + mips_cpc_unlock_other (); <nl> } else { <nl> /* Take the core out of reset */ <nl> write_gcr_co_reset_release ( 0 );
mmm net / ipv6 / inet6_connection_sock . c <nl> ppp net / ipv6 / inet6_connection_sock . c <nl> int inet6_csk_bind_conflict ( const struct sock * sk , <nl> if ( ipv6_rcv_saddr_equal ( sk , sk2 )) <nl> break ; <nl> } <nl> + if (! relax && reuse && sk2 -> sk_reuse && <nl> + sk2 -> sk_state != TCP_LISTEN && <nl> + ipv6_rcv_saddr_equal ( sk , sk2 )) <nl> + break ; <nl> } <nl> } <nl> 
mmm include / asm - mips / unistd . h <nl> ppp include / asm - mips / unistd . h <nl> # define __NR_mknodat ( __NR_Linux + 290 ) <nl> # define __NR_fchownat ( __NR_Linux + 291 ) <nl> # define __NR_futimesat ( __NR_Linux + 292 ) <nl> -# define __NR_fstatat ( __NR_Linux + 293 ) <nl> +# define __NR_fstatat64 ( __NR_Linux + 293 ) <nl> # define __NR_unlinkat ( __NR_Linux + 294 ) <nl> # define __NR_renameat ( __NR_Linux + 295 ) <nl> # define __NR_linkat ( __NR_Linux + 296 ) <nl> # define __NR_mknodat ( __NR_Linux + 249 ) <nl> # define __NR_fchownat ( __NR_Linux + 250 ) <nl> # define __NR_futimesat ( __NR_Linux + 251 ) <nl> -# define __NR_fstatat ( __NR_Linux + 252 ) <nl> +# define __NR_newfstatat ( __NR_Linux + 252 ) <nl> # define __NR_unlinkat ( __NR_Linux + 253 ) <nl> # define __NR_renameat ( __NR_Linux + 254 ) <nl> # define __NR_linkat ( __NR_Linux + 255 ) <nl> # define __NR_mknodat ( __NR_Linux + 253 ) <nl> # define __NR_fchownat ( __NR_Linux + 254 ) <nl> # define __NR_futimesat ( __NR_Linux + 255 ) <nl> -# define __NR_fstatat ( __NR_Linux + 256 ) <nl> +# define __NR_newfstatat ( __NR_Linux + 256 ) <nl> # define __NR_unlinkat ( __NR_Linux + 257 ) <nl> # define __NR_renameat ( __NR_Linux + 258 ) <nl> # define __NR_linkat ( __NR_Linux + 259 )
mmm drivers / media / video / videobuf2 - vmalloc . c <nl> ppp drivers / media / video / videobuf2 - vmalloc . c <nl> # include < linux / vmalloc . h > <nl>  <nl> # include < media / videobuf2 - core . h > <nl> +# include < media / videobuf2 - vmalloc . h > <nl> # include < media / videobuf2 - memops . h > <nl>  <nl> struct vb2_vmalloc_buf {
mmm drivers / staging / omapdrm / omap_fb . c <nl> ppp drivers / staging / omapdrm / omap_fb . c <nl> struct drm_connector * omap_framebuffer_get_next_connector ( <nl> struct list_head * connector_list = & dev -> mode_config . connector_list ; <nl> struct drm_connector * connector = from ; <nl>  <nl> - if (! from ) { <nl> + if (! from ) <nl> return list_first_entry ( connector_list , typeof (* from ), head ); <nl> - } <nl>  <nl> list_for_each_entry_from ( connector , connector_list , head ) { <nl> if ( connector != from ) { <nl> struct drm_encoder * encoder = connector -> encoder ; <nl> struct drm_crtc * crtc = encoder ? encoder -> crtc : NULL ; <nl> - if ( crtc && crtc -> fb == fb ) { <nl> + if ( crtc && crtc -> fb == fb ) <nl> return connector ; <nl> - } <nl> + <nl> } <nl> } <nl>  <nl> struct drm_framebuffer * omap_framebuffer_init ( struct drm_device * dev , <nl> return fb ; <nl>  <nl> fail : <nl> - if ( fb ) { <nl> + if ( fb ) <nl> omap_framebuffer_destroy ( fb ); <nl> - } <nl> + <nl> return ERR_PTR ( ret ); <nl> }
mmm drivers / gpu / drm / i915 / i915_gem_stolen . c <nl> ppp drivers / gpu / drm / i915 / i915_gem_stolen . c <nl> int i915_gem_init_stolen ( struct drm_i915_private * dev_priv ) <nl>  <nl> mutex_init (& dev_priv -> mm . stolen_lock ); <nl>  <nl> + if ( intel_vgpu_active ( dev_priv )) { <nl> + DRM_INFO (" iGVT - g active , disabling use of stolen memory \ n "); <nl> + return 0 ; <nl> + } <nl> + <nl> # ifdef CONFIG_INTEL_IOMMU <nl> if ( intel_iommu_gfx_mapped && INTEL_GEN ( dev_priv ) < 8 ) { <nl> DRM_INFO (" DMAR active , disabling use of stolen memory \ n ");
mmm fs / block_dev . c <nl> ppp fs / block_dev . c <nl> struct block_device * bdget ( dev_t dev ) <nl>  <nl> EXPORT_SYMBOL ( bdget ); <nl>  <nl> +/** <nl> + * bdgrab -- Grab a reference to an already referenced block device <nl> + * @ bdev : Block device to grab a reference to . <nl> + */ <nl> + struct block_device * bdgrab ( struct block_device * bdev ) <nl> +{ <nl> + atomic_inc (& bdev -> bd_inode -> i_count ); <nl> + return bdev ; <nl> +} <nl> + <nl> long nr_blockdev_pages ( void ) <nl> { <nl> struct block_device * bdev ;mmm mm / swapfile . c <nl> ppp mm / swapfile . c <nl> struct block_device * bdget ( dev_t dev ) <nl>  <nl> EXPORT_SYMBOL ( bdget ); <nl>  <nl> +/** <nl> + * bdgrab -- Grab a reference to an already referenced block device <nl> + * @ bdev : Block device to grab a reference to . <nl> + */ <nl> + struct block_device * bdgrab ( struct block_device * bdev ) <nl> +{ <nl> + atomic_inc (& bdev -> bd_inode -> i_count ); <nl> + return bdev ; <nl> +} <nl> + <nl> long nr_blockdev_pages ( void ) <nl> { <nl> struct block_device * bdev ; <nl> int swap_type_of ( dev_t device , sector_t offset , struct block_device ** bdev_p ) <nl>  <nl> if (! bdev ) { <nl> if ( bdev_p ) <nl> - * bdev_p = bdget ( sis -> bdev -> bd_dev ); <nl> + * bdev_p = bdgrab ( sis -> bdev ); <nl>  <nl> spin_unlock (& swap_lock ); <nl> return i ; <nl> int swap_type_of ( dev_t device , sector_t offset , struct block_device ** bdev_p ) <nl> struct swap_extent , list ); <nl> if ( se -> start_block == offset ) { <nl> if ( bdev_p ) <nl> - * bdev_p = bdget ( sis -> bdev -> bd_dev ); <nl> + * bdev_p = bdgrab ( sis -> bdev ); <nl>  <nl> spin_unlock (& swap_lock ); <nl> bdput ( bdev );mmm include / linux / fs . h <nl> ppp include / linux / fs . h <nl> struct block_device * bdget ( dev_t dev ) <nl>  <nl> EXPORT_SYMBOL ( bdget ); <nl>  <nl> +/** <nl> + * bdgrab -- Grab a reference to an already referenced block device <nl> + * @ bdev : Block device to grab a reference to . <nl> + */ <nl> + struct block_device * bdgrab ( struct block_device * bdev ) <nl> +{ <nl> + atomic_inc (& bdev -> bd_inode -> i_count ); <nl> + return bdev ; <nl> +} <nl> + <nl> long nr_blockdev_pages ( void ) <nl> { <nl> struct block_device * bdev ; <nl> int swap_type_of ( dev_t device , sector_t offset , struct block_device ** bdev_p ) <nl>  <nl> if (! bdev ) { <nl> if ( bdev_p ) <nl> - * bdev_p = bdget ( sis -> bdev -> bd_dev ); <nl> + * bdev_p = bdgrab ( sis -> bdev ); <nl>  <nl> spin_unlock (& swap_lock ); <nl> return i ; <nl> int swap_type_of ( dev_t device , sector_t offset , struct block_device ** bdev_p ) <nl> struct swap_extent , list ); <nl> if ( se -> start_block == offset ) { <nl> if ( bdev_p ) <nl> - * bdev_p = bdget ( sis -> bdev -> bd_dev ); <nl> + * bdev_p = bdgrab ( sis -> bdev ); <nl>  <nl> spin_unlock (& swap_lock ); <nl> bdput ( bdev ); <nl> extern void putname ( const char * name ); <nl> extern int register_blkdev ( unsigned int , const char *); <nl> extern void unregister_blkdev ( unsigned int , const char *); <nl> extern struct block_device * bdget ( dev_t ); <nl> + extern struct block_device * bdgrab ( struct block_device * bdev ); <nl> extern void bd_set_size ( struct block_device *, loff_t size ); <nl> extern void bd_forget ( struct inode * inode ); <nl> extern void bdput ( struct block_device *);
mmm drivers / net / wireless / ath / ath10k / htt_tx . c <nl> ppp drivers / net / wireless / ath / ath10k / htt_tx . c <nl> void ath10k_htt_tx_free ( struct ath10k_htt * htt ) <nl> { <nl> int size ; <nl>  <nl> + tasklet_kill (& htt -> txrx_compl_task ); <nl> + <nl> idr_for_each (& htt -> pending_tx , ath10k_htt_tx_clean_up_pending , htt -> ar ); <nl> idr_destroy (& htt -> pending_tx ); <nl> 
mmm drivers / dma / amba - pl08x . c <nl> ppp drivers / dma / amba - pl08x . c <nl> static int pl08x_probe ( struct amba_device * adev , const struct amba_id * id ) <nl> if ( ret ) <nl> return ret ; <nl>  <nl> + /* Ensure that we can do DMA */ <nl> + ret = dma_set_mask_and_coherent (& adev -> dev , DMA_BIT_MASK ( 32 )); <nl> + if ( ret ) <nl> + goto out_no_pl08x ; <nl> + <nl> /* Create the driver state holder */ <nl> pl08x = kzalloc ( sizeof (* pl08x ), GFP_KERNEL ); <nl> if (! pl08x ) {
mmm net / bridge / br_fdb . c <nl> ppp net / bridge / br_fdb . c <nl> static int fdb_insert ( struct net_bridge * br , struct net_bridge_port * source , <nl> */ <nl> if ( fdb -> is_local ) <nl> return 0 ; <nl> - br_warn ( br , " adding interface % s with same address " <nl> - " as a received packet \ n ", <nl> - source ? source -> dev -> name : br -> dev -> name ); <nl> + br_warn ( br , " adding interface % s with same address as a received packet ( addr :% pM , vlan :% u )\ n ", <nl> + source ? source -> dev -> name : br -> dev -> name , addr , vid ); <nl> fdb_delete ( br , fdb ); <nl> } <nl>  <nl> void br_fdb_update ( struct net_bridge * br , struct net_bridge_port * source , <nl> /* attempt to update an entry for a local interface */ <nl> if ( unlikely ( fdb -> is_local )) { <nl> if ( net_ratelimit ()) <nl> - br_warn ( br , " received packet on % s with " <nl> - " own address as source address \ n ", <nl> - source -> dev -> name ); <nl> + br_warn ( br , " received packet on % s with own address as source address ( addr :% pM , vlan :% u )\ n ", <nl> + source -> dev -> name , addr , vid ); <nl> } else { <nl> /* fastpath : update of existing entry */ <nl> if ( unlikely ( source != fdb -> dst )) {
mmm include / linux / skbuff . h <nl> ppp include / linux / skbuff . h <nl> struct sk_buff { <nl> __u32 reserved_tailroom ; <nl> }; <nl>  <nl> + kmemcheck_bitfield_begin ( flags3 ); <nl> + /* 16 bit hole */ <nl> + kmemcheck_bitfield_end ( flags3 ); <nl> + <nl> __be16 inner_protocol ; <nl> __u16 inner_transport_header ; <nl> __u16 inner_network_header ;
mmm tools / perf / util / evsel . h <nl> ppp tools / perf / util / evsel . h <nl> int perf_evsel__fprintf_callchain ( struct perf_evsel * evsel , <nl>  <nl> int perf_evsel__fprintf_sym ( struct perf_evsel * evsel , struct perf_sample * sample , <nl> struct addr_location * al , int left_alignment , <nl> - unsigned int print_opts , unsigned int stack_depth , <nl> - FILE * fp ); <nl> + unsigned int print_opts , bool print_callchain , <nl> + unsigned int stack_depth , FILE * fp ); <nl>  <nl> bool perf_evsel__fallback ( struct perf_evsel * evsel , int err , <nl> char * msg , size_t msgsize );mmm tools / perf / builtin - script . c <nl> ppp tools / perf / builtin - script . c <nl> int perf_evsel__fprintf_callchain ( struct perf_evsel * evsel , <nl>  <nl> int perf_evsel__fprintf_sym ( struct perf_evsel * evsel , struct perf_sample * sample , <nl> struct addr_location * al , int left_alignment , <nl> - unsigned int print_opts , unsigned int stack_depth , <nl> - FILE * fp ); <nl> + unsigned int print_opts , bool print_callchain , <nl> + unsigned int stack_depth , FILE * fp ); <nl>  <nl> bool perf_evsel__fallback ( struct perf_evsel * evsel , int err , <nl> char * msg , size_t msgsize ); <nl> static void print_sample_bts ( struct perf_sample * sample , <nl> } <nl> } <nl> perf_evsel__fprintf_sym ( evsel , sample , al , 0 , print_opts , <nl> + symbol_conf . use_callchain , <nl> scripting_max_stack , stdout ); <nl> } <nl>  <nl> static void process_event ( struct perf_script * script , <nl>  <nl> perf_evsel__fprintf_sym ( evsel , sample , al , 0 , <nl> output [ attr -> type ]. print_ip_opts , <nl> + symbol_conf . use_callchain , <nl> scripting_max_stack , stdout ); <nl> } <nl> mmm tools / perf / util / evsel . c <nl> ppp tools / perf / util / evsel . c <nl> int perf_evsel__fprintf_callchain ( struct perf_evsel * evsel , <nl>  <nl> int perf_evsel__fprintf_sym ( struct perf_evsel * evsel , struct perf_sample * sample , <nl> struct addr_location * al , int left_alignment , <nl> - unsigned int print_opts , unsigned int stack_depth , <nl> - FILE * fp ); <nl> + unsigned int print_opts , bool print_callchain , <nl> + unsigned int stack_depth , FILE * fp ); <nl>  <nl> bool perf_evsel__fallback ( struct perf_evsel * evsel , int err , <nl> char * msg , size_t msgsize ); <nl> static void print_sample_bts ( struct perf_sample * sample , <nl> } <nl> } <nl> perf_evsel__fprintf_sym ( evsel , sample , al , 0 , print_opts , <nl> + symbol_conf . use_callchain , <nl> scripting_max_stack , stdout ); <nl> } <nl>  <nl> static void process_event ( struct perf_script * script , <nl>  <nl> perf_evsel__fprintf_sym ( evsel , sample , al , 0 , <nl> output [ attr -> type ]. print_ip_opts , <nl> + symbol_conf . use_callchain , <nl> scripting_max_stack , stdout ); <nl> } <nl>  <nl> int perf_evsel__fprintf_callchain ( struct perf_evsel * evsel , struct perf_sample * <nl>  <nl> int perf_evsel__fprintf_sym ( struct perf_evsel * evsel , struct perf_sample * sample , <nl> struct addr_location * al , int left_alignment , <nl> - unsigned int print_opts , unsigned int stack_depth , <nl> - FILE * fp ) <nl> + unsigned int print_opts , bool print_callchain , <nl> + unsigned int stack_depth , FILE * fp ) <nl> { <nl> int printed = 0 ; <nl> int print_ip = print_opts & EVSEL__PRINT_IP ; <nl> int perf_evsel__fprintf_sym ( struct perf_evsel * evsel , struct perf_sample * sample <nl> int print_srcline = print_opts & EVSEL__PRINT_SRCLINE ; <nl> int print_unknown_as_addr = print_opts & EVSEL__PRINT_UNKNOWN_AS_ADDR ; <nl>  <nl> - if ( symbol_conf . use_callchain && sample -> callchain ) { <nl> + if ( print_callchain && sample -> callchain ) { <nl> printed += perf_evsel__fprintf_callchain ( evsel , sample , al , left_alignment , <nl> print_opts , stack_depth , fp ); <nl> } else if (!( al -> sym && al -> sym -> ignore )) {
mmm drivers / net / gianfar . c <nl> ppp drivers / net / gianfar . c <nl> static int gfar_of_init ( struct of_device * ofdev , struct net_device ** pdev ) <nl> priv -> rx_queue [ i ] = NULL ; <nl>  <nl> for ( i = 0 ; i < priv -> num_tx_queues ; i ++) { <nl> - priv -> tx_queue [ i ] = ( struct gfar_priv_tx_q *) kzalloc ( <nl> - sizeof ( struct gfar_priv_tx_q ), GFP_KERNEL ); <nl> + priv -> tx_queue [ i ] = kzalloc ( sizeof ( struct gfar_priv_tx_q ), <nl> + GFP_KERNEL ); <nl> if (! priv -> tx_queue [ i ]) { <nl> err = - ENOMEM ; <nl> goto tx_alloc_failed ; <nl> static int gfar_of_init ( struct of_device * ofdev , struct net_device ** pdev ) <nl> } <nl>  <nl> for ( i = 0 ; i < priv -> num_rx_queues ; i ++) { <nl> - priv -> rx_queue [ i ] = ( struct gfar_priv_rx_q *) kzalloc ( <nl> - sizeof ( struct gfar_priv_rx_q ), GFP_KERNEL ); <nl> + priv -> rx_queue [ i ] = kzalloc ( sizeof ( struct gfar_priv_rx_q ), <nl> + GFP_KERNEL ); <nl> if (! priv -> rx_queue [ i ]) { <nl> err = - ENOMEM ; <nl> goto rx_alloc_failed ;
mmm lib / dma - direct . c <nl> ppp lib / dma - direct . c <nl> void * dma_direct_alloc ( struct device * dev , size_t size , dma_addr_t * dma_handle , <nl> __free_pages ( page , page_order ); <nl> page = NULL ; <nl>  <nl> + if ( IS_ENABLED ( CONFIG_ZONE_DMA32 ) && <nl> + dev -> coherent_dma_mask < DMA_BIT_MASK ( 64 ) && <nl> + !( gfp & ( GFP_DMA32 | GFP_DMA ))) { <nl> + gfp |= GFP_DMA32 ; <nl> + goto again ; <nl> + } <nl> + <nl> if ( IS_ENABLED ( CONFIG_ZONE_DMA ) && <nl> dev -> coherent_dma_mask < DMA_BIT_MASK ( 32 ) && <nl> !( gfp & GFP_DMA )) {
mmm drivers / i2c / i2c - core . c <nl> ppp drivers / i2c / i2c - core . c <nl> int i2c_attach_client ( struct i2c_client * client ) <nl> if ( client -> driver ) <nl> client -> dev . driver = & client -> driver -> driver ; <nl>  <nl> - if ( client -> driver && ! is_newstyle_driver ( client -> driver )) <nl> + if ( client -> driver && ! is_newstyle_driver ( client -> driver )) { <nl> client -> dev . release = i2c_client_release ; <nl> - else <nl> + client -> dev . uevent_suppress = 1 ; <nl> + } else <nl> client -> dev . release = i2c_client_dev_release ; <nl>  <nl> snprintf (& client -> dev . bus_id [ 0 ], sizeof ( client -> dev . bus_id ),
mmm kernel / exit . c <nl> ppp kernel / exit . c <nl> void mm_update_next_owner ( struct mm_struct * mm ) <nl> /* <nl> * Search in the siblings <nl> */ <nl> - list_for_each_entry ( c , & p -> parent -> children , sibling ) { <nl> + list_for_each_entry ( c , & p -> real_parent -> children , sibling ) { <nl> if ( c -> mm == mm ) <nl> goto assign_new_owner ; <nl> }
mmm arch / arm / mm / dma - mapping . c <nl> ppp arch / arm / mm / dma - mapping . c <nl> static void __dma_page_dev_to_cpu ( struct page * page , unsigned long off , <nl> unsigned long paddr = page_to_phys ( page ) + off ; <nl>  <nl> /* FIXME : non - speculating : not required */ <nl> - /* don ' t bother invalidating if DMA to device */ <nl> - if ( dir != DMA_TO_DEVICE ) <nl> + /* in any case , don ' t bother invalidating if DMA to device */ <nl> + if ( dir != DMA_TO_DEVICE ) { <nl> outer_inv_range ( paddr , paddr + size ); <nl>  <nl> - dma_cache_maint_page ( page , off , size , dir , dmac_unmap_area ); <nl> + dma_cache_maint_page ( page , off , size , dir , dmac_unmap_area ); <nl> + } <nl>  <nl> /* <nl> * Mark the D - cache clean for these pages to avoid extra flushing .
mmm sound / core / pcm_lib . c <nl> ppp sound / core / pcm_lib . c <nl> static int snd_pcm_update_hw_ptr_interrupt ( struct snd_pcm_substream * substream ) <nl> new_hw_ptr = hw_base + pos ; <nl> hw_ptr_interrupt = runtime -> hw_ptr_interrupt + runtime -> period_size ; <nl> delta = new_hw_ptr - hw_ptr_interrupt ; <nl> - if ( hw_ptr_interrupt == runtime -> boundary ) <nl> - hw_ptr_interrupt = 0 ; <nl> + if ( hw_ptr_interrupt >= runtime -> boundary ) { <nl> + hw_ptr_interrupt %= runtime -> boundary ; <nl> + if (! hw_base ) /* hw_base was already lapped ; recalc delta */ <nl> + delta = new_hw_ptr - hw_ptr_interrupt ; <nl> + } <nl> if ( delta < 0 ) { <nl> delta += runtime -> buffer_size ; <nl> if ( delta < 0 ) { <nl> static int snd_pcm_update_hw_ptr_interrupt ( struct snd_pcm_substream * substream ) <nl> ( long ) hw_ptr_interrupt ); <nl> /* rebase to interrupt position */ <nl> hw_base = new_hw_ptr = hw_ptr_interrupt ; <nl> + /* align hw_base to buffer_size */ <nl> + hw_base -= hw_base % runtime -> buffer_size ; <nl> delta = 0 ; <nl> } else { <nl> hw_base += runtime -> buffer_size ;
mmm drivers / net / wireless / broadcom / brcm80211 / brcmfmac / cfg80211 . c <nl> ppp drivers / net / wireless / broadcom / brcm80211 / brcmfmac / cfg80211 . c <nl> brcmf_cfg80211_start_ap ( struct wiphy * wiphy , struct net_device * ndev , <nl> ( u8 *)& settings -> beacon . head [ ie_offset ], <nl> settings -> beacon . head_len - ie_offset , <nl> WLAN_EID_SSID ); <nl> - if (! ssid_ie ) <nl> + if (! ssid_ie || ssid_ie -> len > IEEE80211_MAX_SSID_LEN ) <nl> return - EINVAL ; <nl>  <nl> memcpy ( ssid_le . SSID , ssid_ie -> data , ssid_ie -> len );
mmm drivers / ata / ata_piix . c <nl> ppp drivers / ata / ata_piix . c <nl> static void do_pata_set_dmamode ( struct ata_port * ap , struct ata_device * adev , i <nl> u16 master_data ; <nl> u8 speed = adev -> dma_mode ; <nl> int devid = adev -> devno + 2 * ap -> port_no ; <nl> - u8 udma_enable ; <nl> + u8 udma_enable = 0 ; <nl>  <nl> static const /* ISP RTC */ <nl> u8 timings [][ 2 ] = { { 0 , 0 },
mmm drivers / md / md . c <nl> ppp drivers / md / md . c <nl> static void md_clean ( mddev_t * mddev ) <nl> mddev -> plug = NULL ; <nl> } <nl>  <nl> - void md_stop_writes ( mddev_t * mddev ) <nl> + static void __md_stop_writes ( mddev_t * mddev ) <nl> { <nl> if ( mddev -> sync_thread ) { <nl> set_bit ( MD_RECOVERY_FROZEN , & mddev -> recovery ); <nl> void md_stop_writes ( mddev_t * mddev ) <nl> md_update_sb ( mddev , 1 ); <nl> } <nl> } <nl> + <nl> + void md_stop_writes ( mddev_t * mddev ) <nl> +{ <nl> + mddev_lock ( mddev ); <nl> + __md_stop_writes ( mddev ); <nl> + mddev_unlock ( mddev ); <nl> +} <nl> EXPORT_SYMBOL_GPL ( md_stop_writes ); <nl>  <nl> void md_stop ( mddev_t * mddev ) <nl> static int md_set_readonly ( mddev_t * mddev , int is_open ) <nl> goto out ; <nl> } <nl> if ( mddev -> pers ) { <nl> - md_stop_writes ( mddev ); <nl> + __md_stop_writes ( mddev ); <nl>  <nl> err = - ENXIO ; <nl> if ( mddev -> ro == 1 ) <nl> static int do_md_stop ( mddev_t * mddev , int mode , int is_open ) <nl> if ( mddev -> ro ) <nl> set_disk_ro ( disk , 0 ); <nl>  <nl> - md_stop_writes ( mddev ); <nl> + __md_stop_writes ( mddev ); <nl> md_stop ( mddev ); <nl> mddev -> queue -> merge_bvec_fn = NULL ; <nl> mddev -> queue -> unplug_fn = NULL ;
mmm drivers / ieee1394 / ieee1394_transactions . c <nl> ppp drivers / ieee1394 / ieee1394_transactions . c <nl> # ifndef HPSB_DEBUG_TLABELS <nl> static <nl> # endif <nl> - spinlock_t hpsb_tlabel_lock = SPIN_LOCK_UNLOCKED ; <nl> + DEFINE_SPINLOCK ( hpsb_tlabel_lock ); <nl>  <nl> static DECLARE_WAIT_QUEUE_HEAD ( tlabel_wq ); <nl> 
mmm fs / gfs2 / super . c <nl> ppp fs / gfs2 / super . c <nl> static int gfs2_lock_fs_check_clean ( struct gfs2_sbd * sdp , <nl> struct gfs2_holder * t_gh ) <nl> { <nl> struct gfs2_inode * ip ; <nl> - struct gfs2_holder ji_gh ; <nl> struct gfs2_jdesc * jd ; <nl> struct lfcc * lfcc ; <nl> LIST_HEAD ( list ); <nl> static int gfs2_lock_fs_check_clean ( struct gfs2_sbd * sdp , <nl> gfs2_glock_dq_uninit (& lfcc -> gh ); <nl> kfree ( lfcc ); <nl> } <nl> - gfs2_glock_dq_uninit (& ji_gh ); <nl> return error ; <nl> } <nl> 
mmm drivers / net / bnx2x_main . c <nl> ppp drivers / net / bnx2x_main . c <nl> static int __devinit bnx2x_init_one ( struct pci_dev * pdev , <nl> bp = netdev_priv ( dev ); <nl> bp -> msglevel = debug ; <nl>  <nl> + pci_set_drvdata ( pdev , dev ); <nl> + <nl> rc = bnx2x_init_dev ( pdev , dev ); <nl> if ( rc < 0 ) { <nl> free_netdev ( dev ); <nl> return rc ; <nl> } <nl>  <nl> - pci_set_drvdata ( pdev , dev ); <nl> - <nl> rc = bnx2x_init_bp ( bp ); <nl> if ( rc ) <nl> goto init_one_exit ;
mmm drivers / usb / storage / shuttle_usbat . c <nl> ppp drivers / usb / storage / shuttle_usbat . c <nl> static int usbat_probe ( struct usb_interface * intf , <nl> us -> transport_name = " Shuttle USBAT "; <nl> us -> transport = usbat_flash_transport ; <nl> us -> transport_reset = usb_stor_CB_reset ; <nl> - us -> max_lun = 1 ; <nl> + us -> max_lun = 0 ; <nl>  <nl> result = usb_stor_probe2 ( us ); <nl> return result ;
mmm drivers / infiniband / hw / hns / hns_roce_main . c <nl> ppp drivers / infiniband / hw / hns / hns_roce_main . c <nl> static struct ib_ucontext * hns_roce_alloc_ucontext ( struct ib_device * ib_dev , <nl> { <nl> int ret = 0 ; <nl> struct hns_roce_ucontext * context ; <nl> - struct hns_roce_ib_alloc_ucontext_resp resp ; <nl> + struct hns_roce_ib_alloc_ucontext_resp resp = {}; <nl> struct hns_roce_dev * hr_dev = to_hr_dev ( ib_dev ); <nl>  <nl> resp . qp_tab_size = hr_dev -> caps . num_qps ;
mmm net / sctp / socket . c <nl> ppp net / sctp / socket . c <nl> int sctp_do_peeloff ( struct sock * sk , sctp_assoc_t id , struct socket ** sockp ) <nl> struct socket * sock ; <nl> int err = 0 ; <nl>  <nl> + /* Do not peel off from one netns to another one . */ <nl> + if (! net_eq ( current -> nsproxy -> net_ns , sock_net ( sk ))) <nl> + return - EINVAL ; <nl> + <nl> if (! asoc ) <nl> return - EINVAL ; <nl> 
mmm arch / s390 / include / asm / mmu . h <nl> ppp arch / s390 / include / asm / mmu . h <nl> typedef struct { <nl> unsigned long asce ; <nl> unsigned long asce_limit ; <nl> unsigned long vdso_base ; <nl> - /* The mmu context allocates 4K page tables . */ <nl> + /* <nl> + * The following bitfields need a down_write on the mm <nl> + * semaphore when they are written to . As they are only <nl> + * written once , they can be read without a lock . <nl> + * <nl> + * The mmu context allocates 4K page tables . <nl> + */ <nl> unsigned int alloc_pgste : 1 ; <nl> /* The mmu context uses extended page tables . */ <nl> unsigned int has_pgste : 1 ;mmm arch / s390 / kvm / kvm - s390 . c <nl> ppp arch / s390 / kvm / kvm - s390 . c <nl> typedef struct { <nl> unsigned long asce ; <nl> unsigned long asce_limit ; <nl> unsigned long vdso_base ; <nl> - /* The mmu context allocates 4K page tables . */ <nl> + /* <nl> + * The following bitfields need a down_write on the mm <nl> + * semaphore when they are written to . As they are only <nl> + * written once , they can be read without a lock . <nl> + * <nl> + * The mmu context allocates 4K page tables . <nl> + */ <nl> unsigned int alloc_pgste : 1 ; <nl> /* The mmu context uses extended page tables . */ <nl> unsigned int has_pgste : 1 ; <nl> static int kvm_vm_ioctl_enable_cap ( struct kvm * kvm , struct kvm_enable_cap * cap ) <nl> r = - EINVAL ; <nl> else { <nl> r = 0 ; <nl> + down_write (& kvm -> mm -> mmap_sem ); <nl> kvm -> mm -> context . allow_gmap_hpage_1m = 1 ; <nl> + up_write (& kvm -> mm -> mmap_sem ); <nl> /* <nl> * We might have to create fake 4k page <nl> * tables . To avoid that the hardware works on
mmm drivers / usb / gadget / function / u_audio . c <nl> ppp drivers / usb / gadget / function / u_audio . c <nl> int g_audio_setup ( struct g_audio * g_audio , const char * pcm_name , <nl> if ( err < 0 ) <nl> goto snd_fail ; <nl>  <nl> - strcpy ( pcm -> name , pcm_name ); <nl> + strlcpy ( pcm -> name , pcm_name , sizeof ( pcm -> name )); <nl> pcm -> private_data = uac ; <nl> uac -> pcm = pcm ; <nl>  <nl> snd_pcm_set_ops ( pcm , SNDRV_PCM_STREAM_PLAYBACK , & uac_pcm_ops ); <nl> snd_pcm_set_ops ( pcm , SNDRV_PCM_STREAM_CAPTURE , & uac_pcm_ops ); <nl>  <nl> - strcpy ( card -> driver , card_name ); <nl> - strcpy ( card -> shortname , card_name ); <nl> + strlcpy ( card -> driver , card_name , sizeof ( card -> driver )); <nl> + strlcpy ( card -> shortname , card_name , sizeof ( card -> shortname )); <nl> sprintf ( card -> longname , "% s % i ", card_name , card -> dev -> id ); <nl>  <nl> snd_pcm_lib_preallocate_pages_for_all ( pcm , SNDRV_DMA_TYPE_CONTINUOUS ,
mmm drivers / dma / dw_dmac . c <nl> ppp drivers / dma / dw_dmac . c <nl> static int __init dw_probe ( struct platform_device * pdev ) <nl> dma_writel ( dw , CFG , DW_CFG_DMA_EN ); <nl>  <nl> printk ( KERN_INFO "% s : DesignWare DMA Controller , % d channels \ n ", <nl> - pdev -> dev . bus_id , dw -> dma . chancnt ); <nl> + dev_name (& pdev -> dev ), dw -> dma . chancnt ); <nl>  <nl> dma_async_device_register (& dw -> dma ); <nl> 
mmm net / sctp / socket . c <nl> ppp net / sctp / socket . c <nl> int sctp_do_peeloff ( struct sock * sk , sctp_assoc_t id , struct socket ** sockp ) <nl> if (! asoc ) <nl> return - EINVAL ; <nl>  <nl> + /* If there is a thread waiting on more sndbuf space for <nl> + * sending on this asoc , it cannot be peeled . <nl> + */ <nl> + if ( waitqueue_active (& asoc -> wait )) <nl> + return - EBUSY ; <nl> + <nl> /* An association cannot be branched off from an already peeled - off <nl> * socket , nor is this supported for tcp style sockets . <nl> */ <nl> static int sctp_wait_for_sndbuf ( struct sctp_association * asoc , long * timeo_p , <nl> */ <nl> release_sock ( sk ); <nl> current_timeo = schedule_timeout ( current_timeo ); <nl> - if ( sk != asoc -> base . sk ) <nl> - goto do_error ; <nl> lock_sock ( sk ); <nl>  <nl> * timeo_p = current_timeo ;
mmm drivers / net / ethernet / renesas / sh_eth . c <nl> ppp drivers / net / ethernet / renesas / sh_eth . c <nl> static int sh_mdio_init ( struct net_device * ndev , int id , <nl> /* bitbang init */ <nl> bitbang -> addr = mdp -> addr + mdp -> reg_offset [ PIR ]; <nl> bitbang -> set_gate = pd -> set_mdio_gate ; <nl> - bitbang -> mdi_msk = 0x08 ; <nl> - bitbang -> mdo_msk = 0x04 ; <nl> - bitbang -> mmd_msk = 0x02 ;/* MMD */ <nl> - bitbang -> mdc_msk = 0x01 ; <nl> + bitbang -> mdi_msk = PIR_MDI ; <nl> + bitbang -> mdo_msk = PIR_MDO ; <nl> + bitbang -> mmd_msk = PIR_MMD ; <nl> + bitbang -> mdc_msk = PIR_MDC ; <nl> bitbang -> ctrl . ops = & bb_ops ; <nl>  <nl> /* MII controller setting */
mmm drivers / platform / x86 / samsung - laptop . c <nl> ppp drivers / platform / x86 / samsung - laptop . c <nl> # include < linux / seq_file . h > <nl> # include < linux / debugfs . h > <nl> # include < linux / ctype . h > <nl> +# include < linux / efi . h > <nl> # include < acpi / video . h > <nl>  <nl> /* <nl> static int __init samsung_init ( void ) <nl> struct samsung_laptop * samsung ; <nl> int ret ; <nl>  <nl> + if ( efi_enabled ( EFI_BOOT )) <nl> + return - ENODEV ; <nl> + <nl> quirks = & samsung_unknown ; <nl> if (! force && ! dmi_check_system ( samsung_dmi_table )) <nl> return - ENODEV ;
mmm drivers / net / phy / dp83640 . c <nl> ppp drivers / net / phy / dp83640 . c <nl> static void recalibrate ( struct dp83640_clock * clock ) <nl> u16 cal_gpio , cfg0 , evnt , ptp_trig , trigger , val ; <nl>  <nl> trigger = CAL_TRIGGER ; <nl> - cal_gpio = gpio_tab [ CALIBRATE_GPIO ]; <nl> + cal_gpio = 1 + ptp_find_pin ( clock -> ptp_clock , PTP_PF_PHYSYNC , 0 ); <nl> + if ( cal_gpio < 1 ) { <nl> + pr_err (" PHY calibration pin not avaible - PHY is not calibrated ."); <nl> + return ; <nl> + } <nl>  <nl> mutex_lock (& clock -> extreg_lock ); <nl> 
mmm drivers / scsi / lpfc / lpfc_els . c <nl> ppp drivers / scsi / lpfc / lpfc_els . c <nl> lpfc_issue_els_plogi ( struct lpfc_vport * vport , uint32_t did , uint8_t retry ) <nl> if ( sp -> cmn . fcphHigh < FC_PH3 ) <nl> sp -> cmn . fcphHigh = FC_PH3 ; <nl>  <nl> + sp -> cmn . valid_vendor_ver_level = 0 ; <nl> + memset ( sp -> vendorVersion , 0 , sizeof ( sp -> vendorVersion )); <nl> + <nl> lpfc_debugfs_disc_trc ( vport , LPFC_DISC_TRC_ELS_CMD , <nl> " Issue PLOGI : did : x % x ", <nl> did , 0 , 0 ); <nl> lpfc_els_rsp_acc ( struct lpfc_vport * vport , uint32_t flag , <nl> } else { <nl> memcpy ( pcmd , & vport -> fc_sparam , <nl> sizeof ( struct serv_parm )); <nl> + <nl> + sp -> cmn . valid_vendor_ver_level = 0 ; <nl> + memset ( sp -> vendorVersion , 0 , sizeof ( sp -> vendorVersion )); <nl> } <nl>  <nl> lpfc_debugfs_disc_trc ( vport , LPFC_DISC_TRC_ELS_RSP ,mmm drivers / scsi / lpfc / lpfc_hw . h <nl> ppp drivers / scsi / lpfc / lpfc_hw . h <nl> lpfc_issue_els_plogi ( struct lpfc_vport * vport , uint32_t did , uint8_t retry ) <nl> if ( sp -> cmn . fcphHigh < FC_PH3 ) <nl> sp -> cmn . fcphHigh = FC_PH3 ; <nl>  <nl> + sp -> cmn . valid_vendor_ver_level = 0 ; <nl> + memset ( sp -> vendorVersion , 0 , sizeof ( sp -> vendorVersion )); <nl> + <nl> lpfc_debugfs_disc_trc ( vport , LPFC_DISC_TRC_ELS_CMD , <nl> " Issue PLOGI : did : x % x ", <nl> did , 0 , 0 ); <nl> lpfc_els_rsp_acc ( struct lpfc_vport * vport , uint32_t flag , <nl> } else { <nl> memcpy ( pcmd , & vport -> fc_sparam , <nl> sizeof ( struct serv_parm )); <nl> + <nl> + sp -> cmn . valid_vendor_ver_level = 0 ; <nl> + memset ( sp -> vendorVersion , 0 , sizeof ( sp -> vendorVersion )); <nl> } <nl>  <nl> lpfc_debugfs_disc_trc ( vport , LPFC_DISC_TRC_ELS_RSP , <nl> struct csp { <nl> * Word 1 Bit 30 in PLOGI request is random offset <nl> */ <nl> # define virtual_fabric_support randomOffset /* Word 1 , bit 30 */ <nl> +/* <nl> + * Word 1 Bit 29 in common service parameter is overloaded . <nl> + * Word 1 Bit 29 in FLOGI response is multiple NPort assignment <nl> + * Word 1 Bit 29 in FLOGI / PLOGI request is Valid Vendor Version Level <nl> + */ <nl> +# define valid_vendor_ver_level response_multiple_NPort /* Word 1 , bit 29 */ <nl> # ifdef __BIG_ENDIAN_BITFIELD <nl> uint16_t request_multiple_Nport : 1 ; /* FC Word 1 , bit 31 */ <nl> uint16_t randomOffset : 1 ; /* FC Word 1 , bit 30 */
mmm net / netfilter / nf_tables_api . c <nl> ppp net / netfilter / nf_tables_api . c <nl> static int nft_verdict_init ( const struct nft_ctx * ctx , struct nft_data * data , <nl> return PTR_ERR ( chain ); <nl> if ( nft_is_base_chain ( chain )) <nl> return - EOPNOTSUPP ; <nl> + if ( nft_chain_is_bound ( chain )) <nl> + return - EINVAL ; <nl> if ( desc -> flags & NFT_DATA_DESC_SETELEM && <nl> chain -> flags & NFT_CHAIN_BINDING ) <nl> return - EINVAL ;
mmm drivers / video / fbdev / fsl - diu - fb . c <nl> ppp drivers / video / fbdev / fsl - diu - fb . c <nl> static int fsl_diu_suspend ( struct platform_device * ofdev , pm_message_t state ) <nl> static int fsl_diu_resume ( struct platform_device * ofdev ) <nl> { <nl> struct fsl_diu_data * data ; <nl> + unsigned int i ; <nl>  <nl> data = dev_get_drvdata (& ofdev -> dev ); <nl> - enable_lcdc ( data -> fsl_diu_info ); <nl> + <nl> + fsl_diu_enable_interrupts ( data ); <nl> + update_lcdc ( data -> fsl_diu_info ); <nl> + for ( i = 0 ; i < NUM_AOIS ; i ++) { <nl> + if ( data -> mfb [ i ]. count ) <nl> + fsl_diu_enable_panel (& data -> fsl_diu_info [ i ]); <nl> + } <nl>  <nl> return 0 ; <nl> }
mmm drivers / net / wireless / iwlwifi / mvm / fw . c <nl> ppp drivers / net / wireless / iwlwifi / mvm / fw . c <nl> int iwl_run_init_mvm_ucode ( struct iwl_mvm * mvm , bool read_nvm ) <nl> ret = iwl_nvm_check_version ( mvm -> nvm_data , mvm -> trans ); <nl> WARN_ON ( ret ); <nl>  <nl> + /* Send TX valid antennas before triggering calibrations */ <nl> + ret = iwl_send_tx_ant_cfg ( mvm , mvm -> nvm_data -> valid_tx_ant ); <nl> + if ( ret ) <nl> + goto error ; <nl> + <nl> /* Override the calibrations from TLV and the const of fw */ <nl> iwl_set_default_calib_trigger ( mvm ); <nl> 
mmm net / bridge / br_netlink . c <nl> ppp net / bridge / br_netlink . c <nl> static inline size_t br_port_info_size ( void ) <nl> + nla_total_size ( sizeof ( u16 )) /* IFLA_BRPORT_DESIGNATED_COST */ <nl> + nla_total_size ( sizeof ( u16 )) /* IFLA_BRPORT_ID */ <nl> + nla_total_size ( sizeof ( u16 )) /* IFLA_BRPORT_NO */ <nl> + + nla_total_size ( sizeof ( u8 )) /* IFLA_BRPORT_TOPOLOGY_CHANGE_ACK */ <nl> + + nla_total_size ( sizeof ( u8 )) /* IFLA_BRPORT_CONFIG_PENDING */ <nl> + 0 ; <nl> } <nl>  <nl> static int br_port_fill_attrs ( struct sk_buff * skb , <nl> nla_put_u16 ( skb , IFLA_BRPORT_DESIGNATED_PORT , p -> designated_port ) || <nl> nla_put_u16 ( skb , IFLA_BRPORT_DESIGNATED_COST , p -> designated_cost ) || <nl> nla_put_u16 ( skb , IFLA_BRPORT_ID , p -> port_id ) || <nl> - nla_put_u16 ( skb , IFLA_BRPORT_NO , p -> port_no )) <nl> + nla_put_u16 ( skb , IFLA_BRPORT_NO , p -> port_no ) || <nl> + nla_put_u8 ( skb , IFLA_BRPORT_TOPOLOGY_CHANGE_ACK , <nl> + p -> topology_change_ack ) || <nl> + nla_put_u8 ( skb , IFLA_BRPORT_CONFIG_PENDING , p -> config_pending )) <nl> return - EMSGSIZE ; <nl>  <nl> return 0 ;mmm include / uapi / linux / if_link . h <nl> ppp include / uapi / linux / if_link . h <nl> static inline size_t br_port_info_size ( void ) <nl> + nla_total_size ( sizeof ( u16 )) /* IFLA_BRPORT_DESIGNATED_COST */ <nl> + nla_total_size ( sizeof ( u16 )) /* IFLA_BRPORT_ID */ <nl> + nla_total_size ( sizeof ( u16 )) /* IFLA_BRPORT_NO */ <nl> + + nla_total_size ( sizeof ( u8 )) /* IFLA_BRPORT_TOPOLOGY_CHANGE_ACK */ <nl> + + nla_total_size ( sizeof ( u8 )) /* IFLA_BRPORT_CONFIG_PENDING */ <nl> + 0 ; <nl> } <nl>  <nl> static int br_port_fill_attrs ( struct sk_buff * skb , <nl> nla_put_u16 ( skb , IFLA_BRPORT_DESIGNATED_PORT , p -> designated_port ) || <nl> nla_put_u16 ( skb , IFLA_BRPORT_DESIGNATED_COST , p -> designated_cost ) || <nl> nla_put_u16 ( skb , IFLA_BRPORT_ID , p -> port_id ) || <nl> - nla_put_u16 ( skb , IFLA_BRPORT_NO , p -> port_no )) <nl> + nla_put_u16 ( skb , IFLA_BRPORT_NO , p -> port_no ) || <nl> + nla_put_u8 ( skb , IFLA_BRPORT_TOPOLOGY_CHANGE_ACK , <nl> + p -> topology_change_ack ) || <nl> + nla_put_u8 ( skb , IFLA_BRPORT_CONFIG_PENDING , p -> config_pending )) <nl> return - EMSGSIZE ; <nl>  <nl> return 0 ; <nl> enum { <nl> IFLA_BRPORT_DESIGNATED_COST , <nl> IFLA_BRPORT_ID , <nl> IFLA_BRPORT_NO , <nl> + IFLA_BRPORT_TOPOLOGY_CHANGE_ACK , <nl> + IFLA_BRPORT_CONFIG_PENDING , <nl> __IFLA_BRPORT_MAX <nl> }; <nl> # define IFLA_BRPORT_MAX ( __IFLA_BRPORT_MAX - 1 )
mmm drivers / net / ethernet / broadcom / bnxt / bnxt_ethtool . c <nl> ppp drivers / net / ethernet / broadcom / bnxt / bnxt_ethtool . c <nl> static int bnxt_get_nvram_item ( struct net_device * dev , u32 index , u32 offset , <nl> dma_addr_t dma_handle ; <nl> struct hwrm_nvm_read_input req = { 0 }; <nl>  <nl> + if (! length ) <nl> + return - EINVAL ; <nl> + <nl> buf = dma_alloc_coherent (& bp -> pdev -> dev , length , & dma_handle , <nl> GFP_KERNEL ); <nl> if (! buf ) {
mmm security / tomoyo / common . c <nl> ppp security / tomoyo / common . c <nl> ssize_t tomoyo_write_control ( struct tomoyo_io_buffer * head , <nl> return - EFAULT ; <nl> if ( mutex_lock_interruptible (& head -> io_sem )) <nl> return - EINTR ; <nl> + head -> read_user_buf_avail = 0 ; <nl> idx = tomoyo_read_lock (); <nl> /* Read a line and dispatch it to the policy handler . */ <nl> while ( avail_len > 0 ) {
mmm drivers / virt / vboxguest / vboxguest_utils . c <nl> ppp drivers / virt / vboxguest / vboxguest_utils . c <nl> static int hgcm_call_preprocess_linaddr ( <nl> if (! bounce_buf ) <nl> return - ENOMEM ; <nl>  <nl> + * bounce_buf_ret = bounce_buf ; <nl> + <nl> if ( copy_in ) { <nl> ret = copy_from_user ( bounce_buf , ( void __user *) buf , len ); <nl> if ( ret ) <nl> static int hgcm_call_preprocess_linaddr ( <nl> memset ( bounce_buf , 0 , len ); <nl> } <nl>  <nl> - * bounce_buf_ret = bounce_buf ; <nl> hgcm_call_add_pagelist_size ( bounce_buf , len , extra ); <nl> return 0 ; <nl> }
mmm drivers / acpi / acpi_memhotplug . c <nl> ppp drivers / acpi / acpi_memhotplug . c <nl> static int acpi_memory_device_add ( struct acpi_device * device ) <nl> if (! acpi_memory_check_device ( mem_device )) { <nl> /* call add_memory func */ <nl> result = acpi_memory_enable_device ( mem_device ); <nl> - if ( result ) <nl> + if ( result ) { <nl> printk ( KERN_ERR PREFIX <nl> " Error in acpi_memory_enable_device \ n "); <nl> + acpi_memory_device_free ( mem_device ); <nl> + } <nl> } <nl> return result ; <nl> }
mmm fs / namespace . c <nl> ppp fs / namespace . c <nl> static inline void namespace_lock ( void ) <nl> enum umount_tree_flags { <nl> UMOUNT_SYNC = 1 , <nl> UMOUNT_PROPAGATE = 2 , <nl> + UMOUNT_CONNECTED = 4 , <nl> }; <nl> /* <nl> * mount_lock must be held <nl> static void umount_tree ( struct mount * mnt , enum umount_tree_flags how ) <nl> if ( how & UMOUNT_SYNC ) <nl> p -> mnt . mnt_flags |= MNT_SYNC_UMOUNT ; <nl>  <nl> - disconnect = ! IS_MNT_LOCKED_AND_LAZY ( p ); <nl> + disconnect = !((( how & UMOUNT_CONNECTED ) && <nl> + mnt_has_parent ( p ) && <nl> + ( p -> mnt_parent -> mnt . mnt_flags & MNT_UMOUNT )) || <nl> + IS_MNT_LOCKED_AND_LAZY ( p )); <nl>  <nl> pin_insert_group (& p -> mnt_umount , & p -> mnt_parent -> mnt , <nl> disconnect ? & unmounted : NULL ); <nl> void __detach_mounts ( struct dentry * dentry ) <nl> umount_mnt ( p ); <nl> } <nl> } <nl> - else umount_tree ( mnt , 0 ); <nl> + else umount_tree ( mnt , UMOUNT_CONNECTED ); <nl> } <nl> unlock_mount_hash (); <nl> put_mountpoint ( mp );
mmm drivers / gpu / drm / i915 / intel_display . c <nl> ppp drivers / gpu / drm / i915 / intel_display . c <nl> static int intel_modeset_checks ( struct drm_atomic_state * state ) <nl>  <nl> DRM_DEBUG_KMS (" New cdclk calculated to be atomic % u , actual % u \ n ", <nl> intel_state -> cdclk , intel_state -> dev_cdclk ); <nl> - } else <nl> + } else { <nl> to_intel_atomic_state ( state )-> cdclk = dev_priv -> atomic_cdclk_freq ; <nl> + } <nl>  <nl> intel_modeset_clear_plls ( state ); <nl>  <nl> static int intel_atomic_check ( struct drm_device * dev , <nl>  <nl> if ( ret ) <nl> return ret ; <nl> - } else <nl> - intel_state -> cdclk = dev_priv -> cdclk_freq ; <nl> + } else { <nl> + intel_state -> cdclk = dev_priv -> atomic_cdclk_freq ; <nl> + } <nl>  <nl> ret = drm_atomic_helper_check_planes ( dev , state ); <nl> if ( ret )
mmm drivers / video / via / hw . c <nl> ppp drivers / video / via / hw . c <nl> static void set_display_channel ( void ) <nl> } <nl> } <nl>  <nl> - static u8 get_sync ( struct fb_info * info ) <nl> + static u8 get_sync ( struct fb_var_screeninfo * var ) <nl> { <nl> u8 polarity = 0 ; <nl>  <nl> - if (!( info -> var . sync & FB_SYNC_HOR_HIGH_ACT )) <nl> + if (!( var -> sync & FB_SYNC_HOR_HIGH_ACT )) <nl> polarity |= VIA_HSYNC_NEGATIVE ; <nl> - if (!( info -> var . sync & FB_SYNC_VERT_HIGH_ACT )) <nl> + if (!( var -> sync & FB_SYNC_VERT_HIGH_ACT )) <nl> polarity |= VIA_VSYNC_NEGATIVE ; <nl> return polarity ; <nl> } <nl> int viafb_setmode ( int video_bpp , int video_bpp1 ) <nl> viafb_DeviceStatus = CRT_Device ; <nl> } <nl> device_on (); <nl> - if (! viafb_dual_fb ) <nl> - via_set_sync_polarity ( devices , get_sync ( viafbinfo )); <nl> + if (! viafb_SAMM_ON ) <nl> + via_set_sync_polarity ( devices , get_sync (& viafbinfo -> var )); <nl> else { <nl> via_set_sync_polarity ( viaparinfo -> shared -> iga1_devices , <nl> - get_sync ( viafbinfo )); <nl> + get_sync (& viafbinfo -> var )); <nl> via_set_sync_polarity ( viaparinfo -> shared -> iga2_devices , <nl> - get_sync ( viafbinfo1 )); <nl> + get_sync (& var2 )); <nl> } <nl>  <nl> clock . set_engine_pll_state ( VIA_STATE_ON );
mmm net / netlink / af_netlink . c <nl> ppp net / netlink / af_netlink . c <nl> static int netlink_sendmsg ( struct kiocb * kiocb , struct socket * sock , <nl> if ( NULL == siocb -> scm ) <nl> siocb -> scm = & scm ; <nl>  <nl> - err = scm_send ( sock , msg , siocb -> scm ); <nl> + err = scm_send ( sock , msg , siocb -> scm , true ); <nl> if ( err < 0 ) <nl> return err ; <nl> mmm include / net / scm . h <nl> ppp include / net / scm . h <nl> static int netlink_sendmsg ( struct kiocb * kiocb , struct socket * sock , <nl> if ( NULL == siocb -> scm ) <nl> siocb -> scm = & scm ; <nl>  <nl> - err = scm_send ( sock , msg , siocb -> scm ); <nl> + err = scm_send ( sock , msg , siocb -> scm , true ); <nl> if ( err < 0 ) <nl> return err ; <nl>  <nl> static __inline__ void scm_destroy ( struct scm_cookie * scm ) <nl> } <nl>  <nl> static __inline__ int scm_send ( struct socket * sock , struct msghdr * msg , <nl> - struct scm_cookie * scm ) <nl> + struct scm_cookie * scm , bool forcecreds ) <nl> { <nl> memset ( scm , 0 , sizeof (* scm )); <nl> + if ( forcecreds ) <nl> + scm_set_cred ( scm , task_tgid ( current ), current_cred ()); <nl> unix_get_peersec_dgram ( sock , scm ); <nl> if ( msg -> msg_controllen <= 0 ) <nl> return 0 ;mmm net / unix / af_unix . c <nl> ppp net / unix / af_unix . c <nl> static int netlink_sendmsg ( struct kiocb * kiocb , struct socket * sock , <nl> if ( NULL == siocb -> scm ) <nl> siocb -> scm = & scm ; <nl>  <nl> - err = scm_send ( sock , msg , siocb -> scm ); <nl> + err = scm_send ( sock , msg , siocb -> scm , true ); <nl> if ( err < 0 ) <nl> return err ; <nl>  <nl> static __inline__ void scm_destroy ( struct scm_cookie * scm ) <nl> } <nl>  <nl> static __inline__ int scm_send ( struct socket * sock , struct msghdr * msg , <nl> - struct scm_cookie * scm ) <nl> + struct scm_cookie * scm , bool forcecreds ) <nl> { <nl> memset ( scm , 0 , sizeof (* scm )); <nl> + if ( forcecreds ) <nl> + scm_set_cred ( scm , task_tgid ( current ), current_cred ()); <nl> unix_get_peersec_dgram ( sock , scm ); <nl> if ( msg -> msg_controllen <= 0 ) <nl> return 0 ; <nl> static int unix_dgram_sendmsg ( struct kiocb * kiocb , struct socket * sock , <nl> if ( NULL == siocb -> scm ) <nl> siocb -> scm = & tmp_scm ; <nl> wait_for_unix_gc (); <nl> - err = scm_send ( sock , msg , siocb -> scm ); <nl> + err = scm_send ( sock , msg , siocb -> scm , false ); <nl> if ( err < 0 ) <nl> return err ; <nl>  <nl> static int unix_stream_sendmsg ( struct kiocb * kiocb , struct socket * sock , <nl> if ( NULL == siocb -> scm ) <nl> siocb -> scm = & tmp_scm ; <nl> wait_for_unix_gc (); <nl> - err = scm_send ( sock , msg , siocb -> scm ); <nl> + err = scm_send ( sock , msg , siocb -> scm , false ); <nl> if ( err < 0 ) <nl> return err ; <nl> 
mmm kernel / sched . c <nl> ppp kernel / sched . c <nl> static int wake_idle ( int cpu , task_t * p ) <nl>  <nl> for_each_domain ( cpu , sd ) { <nl> if ( sd -> flags & SD_WAKE_IDLE ) { <nl> - cpus_and ( tmp , sd -> span , cpu_online_map ); <nl> - cpus_and ( tmp , tmp , p -> cpus_allowed ); <nl> + cpus_and ( tmp , sd -> span , p -> cpus_allowed ); <nl> for_each_cpu_mask ( i , tmp ) { <nl> if ( idle_cpu ( i )) <nl> return i ; <nl> } <nl> } <nl> - else break ; <nl> + else <nl> + break ; <nl> } <nl> return cpu ; <nl> }
mmm drivers / infiniband / hw / mthca / mthca_srq . c <nl> ppp drivers / infiniband / hw / mthca / mthca_srq . c <nl> int mthca_alloc_srq ( struct mthca_dev * dev , struct mthca_pd * pd , <nl> srq -> first_free = 0 ; <nl> srq -> last_free = srq -> max - 1 ; <nl>  <nl> - attr -> max_wr = srq -> max ; <nl> + attr -> max_wr = ( mthca_is_memfree ( dev )) ? srq -> max - 1 : srq -> max ; <nl> attr -> max_sge = srq -> max_gs ; <nl>  <nl> return 0 ; <nl> int mthca_query_srq ( struct ib_srq * ibsrq , struct ib_srq_attr * srq_attr ) <nl> } else <nl> srq_attr -> srq_limit = 0 ; <nl>  <nl> - srq_attr -> max_wr = srq -> max ; <nl> + srq_attr -> max_wr = ( mthca_is_memfree ( dev )) ? srq -> max - 1 : srq -> max ; <nl> srq_attr -> max_sge = srq -> max_gs ; <nl>  <nl> out :
mmm net / bluetooth / rfcomm / sock . c <nl> ppp net / bluetooth / rfcomm / sock . c <nl> static int rfcomm_sock_recvmsg ( struct kiocb * iocb , struct socket * sock , <nl>  <nl> if ( test_and_clear_bit ( RFCOMM_DEFER_SETUP , & d -> flags )) { <nl> rfcomm_dlc_accept ( d ); <nl> + msg -> msg_namelen = 0 ; <nl> return 0 ; <nl> } <nl> 
mmm fs / xfs / xfs_reflink . c <nl> ppp fs / xfs / xfs_reflink . c <nl> xfs_reflink_end_cow ( <nl> /* If there is a hole at end_fsb - 1 go to the previous extent */ <nl> if (! xfs_iext_lookup_extent ( ip , ifp , end_fsb - 1 , & idx , & got ) || <nl> got . br_startoff > end_fsb ) { <nl> - ASSERT ( idx > 0 ); <nl> + /* <nl> + * In case of racing , overlapping AIO writes no COW extents <nl> + * might be left by the time I / O completes for the loser of <nl> + * the race . In that case we are done . <nl> + */ <nl> + if ( idx <= 0 ) <nl> + goto out_cancel ; <nl> xfs_iext_get_extent ( ifp , -- idx , & got ); <nl> } <nl>  <nl> xfs_reflink_end_cow ( <nl>  <nl> out_defer : <nl> xfs_defer_cancel (& dfops ); <nl> + out_cancel : <nl> xfs_trans_cancel ( tp ); <nl> xfs_iunlock ( ip , XFS_ILOCK_EXCL ); <nl> out :
mmm drivers / of / unittest . c <nl> ppp drivers / of / unittest . c <nl> static int __init unittest_data_add ( void ) <nl> of_fdt_unflatten_tree ( unittest_data , NULL , & unittest_data_node ); <nl> if (! unittest_data_node ) { <nl> pr_warn ("% s : No tree to attach ; not running tests \ n ", __func__ ); <nl> + kfree ( unittest_data ); <nl> return - ENODATA ; <nl> } <nl> 
mmm arch / blackfin / kernel / debug - mmrs . c <nl> ppp arch / blackfin / kernel / debug - mmrs . c <nl> bfin_debug_mmrs_dma ( struct dentry * parent , unsigned long base , int num , char mdm <nl> __DMA ( CURR_DESC_PTR , curr_desc_ptr ); <nl> __DMA ( CURR_ADDR , curr_addr ); <nl> __DMA ( IRQ_STATUS , irq_status ); <nl> - __DMA ( PERIPHERAL_MAP , peripheral_map ); <nl> + if ( strcmp ( pfx , " IMDMA ") != 0 ) <nl> + __DMA ( PERIPHERAL_MAP , peripheral_map ); <nl> __DMA ( CURR_X_COUNT , curr_x_count ); <nl> __DMA ( CURR_Y_COUNT , curr_y_count ); <nl> }
mmm fs / nfs / pnfs . h <nl> ppp fs / nfs / pnfs . h <nl> pnfs_mark_layout_returned_if_empty ( struct pnfs_layout_hdr * lo ) <nl> set_bit ( NFS_LAYOUT_INVALID_STID , & lo -> plh_flags ); <nl> } <nl>  <nl> + static inline void <nl> + pnfs_copy_range ( struct pnfs_layout_range * dst , <nl> + const struct pnfs_layout_range * src ) <nl> +{ <nl> + memcpy ( dst , src , sizeof (* dst )); <nl> +} <nl> + <nl> extern unsigned int layoutstats_timer ; <nl>  <nl> # ifdef NFS_DEBUGmmm fs / nfs / pnfs . c <nl> ppp fs / nfs / pnfs . c <nl> pnfs_mark_layout_returned_if_empty ( struct pnfs_layout_hdr * lo ) <nl> set_bit ( NFS_LAYOUT_INVALID_STID , & lo -> plh_flags ); <nl> } <nl>  <nl> + static inline void <nl> + pnfs_copy_range ( struct pnfs_layout_range * dst , <nl> + const struct pnfs_layout_range * src ) <nl> +{ <nl> + memcpy ( dst , src , sizeof (* dst )); <nl> +} <nl> + <nl> extern unsigned int layoutstats_timer ; <nl>  <nl> # ifdef NFS_DEBUG <nl> pnfs_choose_layoutget_stateid ( nfs4_stateid * dst , struct pnfs_layout_hdr * lo , <nl> static struct pnfs_layout_segment * <nl> send_layoutget ( struct pnfs_layout_hdr * lo , <nl> struct nfs_open_context * ctx , <nl> - struct pnfs_layout_range * range , <nl> + const struct pnfs_layout_range * range , <nl> gfp_t gfp_flags ) <nl> { <nl> struct inode * ino = lo -> plh_inode ; <nl> send_layoutget ( struct pnfs_layout_hdr * lo , <nl> lgp -> args . minlength = i_size - range -> offset ; <nl> } <nl> lgp -> args . maxcount = PNFS_LAYOUT_MAXSIZE ; <nl> - lgp -> args . range = * range ; <nl> + pnfs_copy_range (& lgp -> args . range , range ); <nl> lgp -> args . type = server -> pnfs_curr_ld -> id ; <nl> lgp -> args . inode = ino ; <nl> lgp -> args . ctx = get_nfs_open_context ( ctx );
mmm mm / vmpressure . c <nl> ppp mm / vmpressure . c <nl> static enum vmpressure_levels vmpressure_calc_level ( unsigned long scanned , <nl> unsigned long reclaimed ) <nl> { <nl> unsigned long scale = scanned + reclaimed ; <nl> - unsigned long pressure ; <nl> + unsigned long pressure = 0 ; <nl>  <nl> + /* <nl> + * reclaimed can be greater than scanned in cases <nl> + * like THP , where the scanned is 1 and reclaimed <nl> + * could be 512 <nl> + */ <nl> + if ( reclaimed >= scanned ) <nl> + goto out ; <nl> /* <nl> * We calculate the ratio ( in percents ) of how many pages were <nl> * scanned vs . reclaimed in a given time frame ( window ). Note that <nl> static enum vmpressure_levels vmpressure_calc_level ( unsigned long scanned , <nl> pressure = scale - ( reclaimed * scale / scanned ); <nl> pressure = pressure * 100 / scale ; <nl>  <nl> + out : <nl> pr_debug ("% s : % 3lu ( s : % lu r : % lu )\ n ", __func__ , pressure , <nl> scanned , reclaimed ); <nl> 
mmm fs / udf / inode . c <nl> ppp fs / udf / inode . c <nl> static int udf_read_inode ( struct inode * inode , bool hidden_inode ) <nl> } <nl> inode -> i_generation = iinfo -> i_unique ; <nl>  <nl> + /* Sanity checks for files in ICB so that we don ' t get confused later */ <nl> + if ( iinfo -> i_alloc_type == ICBTAG_FLAG_AD_IN_ICB ) { <nl> + /* <nl> + * For file in ICB data is stored in allocation descriptor <nl> + * so sizes should match <nl> + */ <nl> + if ( iinfo -> i_lenAlloc != inode -> i_size ) <nl> + goto out ; <nl> + /* File in ICB has to fit in there ... */ <nl> + if ( inode -> i_size > inode -> i_sb -> s_blocksize - <nl> + udf_file_entry_alloc_offset ( inode )) <nl> + goto out ; <nl> + } <nl> + <nl> switch ( fe -> icbTag . fileType ) { <nl> case ICBTAG_FILE_TYPE_DIRECTORY : <nl> inode -> i_op = & udf_dir_inode_operations ;
mmm net / bluetooth / hci_sock . c <nl> ppp net / bluetooth / hci_sock . c <nl> static int hci_sock_getsockopt ( struct socket * sock , int level , int optname , <nl> { <nl> struct hci_filter * f = & hci_pi ( sk )-> filter ; <nl>  <nl> + memset (& uf , 0 , sizeof ( uf )); <nl> uf . type_mask = f -> type_mask ; <nl> uf . opcode = f -> opcode ; <nl> uf . event_mask [ 0 ] = *(( u32 *) f -> event_mask + 0 );
mmm net / bluetooth / af_bluetooth . c <nl> ppp net / bluetooth / af_bluetooth . c <nl> void bt_accept_enqueue ( struct sock * parent , struct sock * sk ) <nl> BT_DBG (" parent % p , sk % p ", parent , sk ); <nl>  <nl> sock_hold ( sk ); <nl> + lock_sock ( sk ); <nl> list_add_tail (& bt_sk ( sk )-> accept_q , & bt_sk ( parent )-> accept_q ); <nl> bt_sk ( sk )-> parent = parent ; <nl> + release_sock ( sk ); <nl> parent -> sk_ack_backlog ++; <nl> } <nl> EXPORT_SYMBOL ( bt_accept_enqueue );
mmm include / uapi / linux / usb / ch9 . h <nl> ppp include / uapi / linux / usb / ch9 . h <nl> # define USB_REQ_LOOPBACK_DATA_READ 0x16 <nl> # define USB_REQ_SET_INTERFACE_DS 0x17 <nl>  <nl> +/* specific requests for USB Power Delivery */ <nl> +# define USB_REQ_GET_PARTNER_PDO 20 <nl> +# define USB_REQ_GET_BATTERY_STATUS 21 <nl> +# define USB_REQ_SET_PDO 22 <nl> +# define USB_REQ_GET_VDM 23 <nl> +# define USB_REQ_SEND_VDM 24 <nl> + <nl> /* The Link Power Management ( LPM ) ECN defines USB_REQ_TEST_AND_SET command , <nl> * used by hubs to put ports into a new L1 suspend state , except that it <nl> * forgot to define its number ...
mmm arch / x86 / kvm / i8254 . c <nl> ppp arch / x86 / kvm / i8254 . c <nl> struct kvm_pit * kvm_create_pit ( struct kvm * kvm ) <nl> mutex_lock (& kvm -> lock ); <nl> pit -> irq_source_id = kvm_request_irq_source_id ( kvm ); <nl> mutex_unlock (& kvm -> lock ); <nl> - if ( pit -> irq_source_id < 0 ) <nl> + if ( pit -> irq_source_id < 0 ) { <nl> + kfree ( pit ); <nl> return NULL ; <nl> + } <nl>  <nl> mutex_init (& pit -> pit_state . lock ); <nl> mutex_lock (& pit -> pit_state . lock );
mmm drivers / media / usb / dvb - usb - v2 / rtl28xxu . c <nl> ppp drivers / media / usb / dvb - usb - v2 / rtl28xxu . c <nl> static int rtl2832u_tuner_attach ( struct dvb_usb_adapter * adap ) <nl> struct i2c_board_info info ; <nl> struct i2c_client * client ; <nl> struct v4l2_subdev * subdev = NULL ; <nl> + struct platform_device * pdev ; <nl> + struct rtl2832_sdr_platform_data pdata ; <nl>  <nl> dev_dbg (& d -> intf -> dev , "\ n "); <nl>  <nl> memset (& info , 0 , sizeof ( struct i2c_board_info )); <nl> + memset (& pdata , 0 , sizeof ( pdata )); <nl>  <nl> switch ( dev -> tuner ) { <nl> case TUNER_RTL2832_FC0012 : <nl> static int rtl2832u_tuner_attach ( struct dvb_usb_adapter * adap ) <nl>  <nl> /* register SDR */ <nl> switch ( dev -> tuner ) { <nl> - struct platform_device * pdev ; <nl> - struct rtl2832_sdr_platform_data pdata = {}; <nl> - <nl> case TUNER_RTL2832_FC0012 : <nl> case TUNER_RTL2832_FC0013 : <nl> case TUNER_RTL2832_E4000 :
mmm drivers / vfio / pci / vfio_pci . c <nl> ppp drivers / vfio / pci / vfio_pci . c <nl> static int vfio_pci_mmap ( void * device_data , struct vm_area_struct * vma ) <nl> return ret ; <nl>  <nl> vdev -> barmap [ index ] = pci_iomap ( pdev , index , 0 ); <nl> + if (! vdev -> barmap [ index ]) { <nl> + pci_release_selected_regions ( pdev , 1 << index ); <nl> + return - ENOMEM ; <nl> + } <nl> } <nl>  <nl> vma -> vm_private_data = vdev ;
mmm drivers / scsi / qla4xxx / ql4_init . c <nl> ppp drivers / scsi / qla4xxx / ql4_init . c <nl> void qla4xxx_free_ddb_index ( struct scsi_qla_host * ha ) <nl> ret = qla4xxx_get_fwddb_entry ( ha , idx , NULL , 0 , NULL , <nl> & next_idx , & state , & conn_err , <nl> NULL , NULL ); <nl> - if ( ret == QLA_ERROR ) <nl> + if ( ret == QLA_ERROR ) { <nl> + next_idx ++; <nl> continue ; <nl> + } <nl> if ( state == DDB_DS_NO_CONNECTION_ACTIVE || <nl> state == DDB_DS_SESSION_FAILED ) { <nl> DEBUG2 ( ql4_printk ( KERN_INFO , ha ,
mmm net / sched / cls_basic . c <nl> ppp net / sched / cls_basic . c <nl> static int basic_dump ( struct tcf_proto * tp , unsigned long fh , <nl> rta = ( struct rtattr *) b ; <nl> RTA_PUT ( skb , TCA_OPTIONS , 0 , NULL ); <nl>  <nl> + if ( f -> res . classid ) <nl> + RTA_PUT ( skb , TCA_BASIC_CLASSID , sizeof ( u32 ), & f -> res . classid ); <nl> + <nl> if ( tcf_exts_dump ( skb , & f -> exts , & basic_ext_map ) < 0 || <nl> tcf_em_tree_dump ( skb , & f -> ematches , TCA_BASIC_EMATCHES ) < 0 ) <nl> goto rtattr_failure ;
mmm drivers / gpu / drm / radeon / radeon_atombios . c <nl> ppp drivers / gpu / drm / radeon / radeon_atombios . c <nl> static bool radeon_atom_apply_quirks ( struct drm_device * dev , <nl> if (( supported_device == ATOM_DEVICE_CRT1_SUPPORT ) || <nl> ( supported_device == ATOM_DEVICE_DFP2_SUPPORT )) <nl> return false ; <nl> + if ( supported_device == ATOM_DEVICE_CRT2_SUPPORT ) <nl> + * line_mux = 0x90 ; <nl> } <nl>  <nl> /* ASUS HD 3600 XT board lists the DVI port as HDMI */
mmm drivers / s390 / net / qeth_core_main . c <nl> ppp drivers / s390 / net / qeth_core_main . c <nl> static inline void __qeth_fill_buffer ( struct sk_buff * skb , <nl> struct qdio_buffer * buffer , int is_tso , int * next_element_to_fill , <nl> int offset ) <nl> { <nl> - int length = skb -> len - offset ; <nl> + int length = skb -> len ; <nl> int length_here ; <nl> int element ; <nl> char * data ; <nl> static inline void __qeth_fill_buffer ( struct sk_buff * skb , <nl>  <nl> if ( offset >= 0 ) { <nl> data = skb -> data + offset ; <nl> + length -= offset ; <nl> first_lap = 0 ; <nl> } <nl> 
mmm net / openvswitch / vport - internal_dev . c <nl> ppp net / openvswitch / vport - internal_dev . c <nl> static int internal_dev_recv ( struct vport * vport , struct sk_buff * skb ) <nl> struct net_device * netdev = netdev_vport_priv ( vport )-> dev ; <nl> int len ; <nl>  <nl> + if ( unlikely (!( netdev -> flags & IFF_UP ))) { <nl> + kfree_skb ( skb ); <nl> + return 0 ; <nl> + } <nl> + <nl> len = skb -> len ; <nl>  <nl> skb_dst_drop ( skb );
mmm drivers / net / wireless / ath / ath10k / wmi . c <nl> ppp drivers / net / wireless / ath / ath10k / wmi . c <nl> int ath10k_wmi_beacon_send_nowait ( struct ath10k * ar , <nl> { <nl> struct wmi_bcn_tx_cmd * cmd ; <nl> struct sk_buff * skb ; <nl> + int ret ; <nl>  <nl> skb = ath10k_wmi_alloc_skb ( sizeof (* cmd ) + arg -> bcn_len ); <nl> if (! skb ) <nl> int ath10k_wmi_beacon_send_nowait ( struct ath10k * ar , <nl> cmd -> hdr . bcn_len = __cpu_to_le32 ( arg -> bcn_len ); <nl> memcpy ( cmd -> bcn , arg -> bcn , arg -> bcn_len ); <nl>  <nl> - return ath10k_wmi_cmd_send_nowait ( ar , skb , ar -> wmi . cmd -> bcn_tx_cmdid ); <nl> + ret = ath10k_wmi_cmd_send_nowait ( ar , skb , ar -> wmi . cmd -> bcn_tx_cmdid ); <nl> + if ( ret ) <nl> + dev_kfree_skb ( skb ); <nl> + <nl> + return ret ; <nl> } <nl>  <nl> static void ath10k_wmi_pdev_set_wmm_param ( struct wmi_wmm_params * params ,
mmm kernel / sched / rt . c <nl> ppp kernel / sched / rt . c <nl> static int do_sched_rt_period_timer ( struct rt_bandwidth * rt_b , int overrun ) <nl> const struct cpumask * span ; <nl>  <nl> span = sched_rt_period_mask (); <nl> +# ifdef CONFIG_RT_GROUP_SCHED <nl> + /* <nl> + * FIXME : isolated CPUs should really leave the root task group , <nl> + * whether they are isolcpus or were isolated via cpusets , lest <nl> + * the timer run on a CPU which does not service all runqueues , <nl> + * potentially leaving other CPUs indefinitely throttled . If <nl> + * isolation is really required , the user will turn the throttle <nl> + * off to kill the perturbations it causes anyway . Meanwhile , <nl> + * this maintains functionality for boot and / or troubleshooting . <nl> + */ <nl> + if ( rt_b == & root_task_group . rt_bandwidth ) <nl> + span = cpu_online_mask ; <nl> +# endif <nl> for_each_cpu ( i , span ) { <nl> int enqueue = 0 ; <nl> struct rt_rq * rt_rq = sched_rt_period_rt_rq ( rt_b , i );
mmm arch / avr32 / mm / init . c <nl> ppp arch / avr32 / mm / init . c <nl> void __init paging_init ( void ) <nl>  <nl> mem_map = NODE_DATA ( 0 )-> node_mem_map ; <nl>  <nl> - memset ( zero_page , 0 , PAGE_SIZE ); <nl> empty_zero_page = virt_to_page ( zero_page ); <nl> flush_dcache_page ( empty_zero_page ); <nl> }
mmm drivers / infiniband / hw / cxgb4 / cq . c <nl> ppp drivers / infiniband / hw / cxgb4 / cq . c <nl> struct ib_cq * c4iw_create_cq ( struct ib_device * ibdev , int entries , <nl> if (! mm2 ) <nl> goto err4 ; <nl>  <nl> + memset (& uresp , 0 , sizeof ( uresp )); <nl> uresp . qid_mask = rhp -> rdev . cqmask ; <nl> uresp . cqid = chp -> cq . cqid ; <nl> uresp . size = chp -> cq . size ;
mmm drivers / net / wireless / intel / iwlwifi / pcie / rx . c <nl> ppp drivers / net / wireless / intel / iwlwifi / pcie / rx . c <nl> int iwl_pcie_rx_init ( struct iwl_trans * trans ) <nl> else <nl> list_add (& rxb -> list , & def_rxq -> rx_used ); <nl> trans_pcie -> global_table [ i ] = rxb ; <nl> - rxb -> vid = ( u16 ) i ; <nl> + rxb -> vid = ( u16 )( i + 1 ); <nl> } <nl>  <nl> iwl_pcie_rxq_alloc_rbs ( trans , GFP_KERNEL , def_rxq ); <nl> static void iwl_pcie_rx_handle ( struct iwl_trans * trans , int queue ) <nl> */ <nl> u16 vid = le32_to_cpu ( rxq -> used_bd [ i ]) & 0x0FFF ; <nl>  <nl> - if ( WARN ( vid >= ARRAY_SIZE ( trans_pcie -> global_table ), <nl> - " Invalid rxb index from HW % u \ n ", ( u32 ) vid )) <nl> + if ( WARN (! vid || <nl> + vid > ARRAY_SIZE ( trans_pcie -> global_table ), <nl> + " Invalid rxb index from HW % u \ n ", ( u32 ) vid )) { <nl> + iwl_force_nmi ( trans ); <nl> goto out ; <nl> - rxb = trans_pcie -> global_table [ vid ]; <nl> + } <nl> + rxb = trans_pcie -> global_table [ vid - 1 ]; <nl> } else { <nl> rxb = rxq -> queue [ i ]; <nl> rxq -> queue [ i ] = NULL ;
mmm drivers / gpu / drm / radeon / r600_cs . c <nl> ppp drivers / gpu / drm / radeon / r600_cs . c <nl> static int r600_cs_packet_next_reloc_nomm ( struct radeon_cs_parser * p , <nl> idx , relocs_chunk -> length_dw ); <nl> return - EINVAL ; <nl> } <nl> - * cs_reloc = & p -> relocs [ 0 ]; <nl> + * cs_reloc = p -> relocs ; <nl> (* cs_reloc )-> lobj . gpu_offset = ( u64 ) relocs_chunk -> kdata [ idx + 3 ] << 32 ; <nl> (* cs_reloc )-> lobj . gpu_offset |= relocs_chunk -> kdata [ idx + 0 ]; <nl> return 0 ; <nl> static int r600_cs_parser_relocs_legacy ( struct radeon_cs_parser * p ) <nl> if ( p -> chunk_relocs_idx == - 1 ) { <nl> return 0 ; <nl> } <nl> - p -> relocs = kcalloc ( 1 , sizeof ( struct radeon_cs_reloc ), GFP_KERNEL ); <nl> + p -> relocs = kzalloc ( sizeof ( struct radeon_cs_reloc ), GFP_KERNEL ); <nl> if ( p -> relocs == NULL ) { <nl> return - ENOMEM ; <nl> }
mmm net / mac80211 / main . c <nl> ppp net / mac80211 / main . c <nl> struct ieee80211_hw * ieee80211_alloc_hw ( size_t priv_data_len , <nl> if ( WARN_ON ( ops -> sta_state && ( ops -> sta_add || ops -> sta_remove ))) <nl> return NULL ; <nl>  <nl> + /* check all or no channel context operations exist */ <nl> + i = !! ops -> add_chanctx + !! ops -> remove_chanctx + <nl> + !! ops -> change_chanctx + !! ops -> assign_vif_chanctx + <nl> + !! ops -> unassign_vif_chanctx ; <nl> + if ( WARN_ON ( i != 0 && i != 5 )) <nl> + return NULL ; <nl> + <nl> /* Ensure 32 - byte alignment of our private data and hw private data . <nl> * We use the wiphy priv data for both our ieee80211_local and for <nl> * the driver ' s private data
mmm drivers / net / macvlan . c <nl> ppp drivers / net / macvlan . c <nl> static int macvlan_set_mac_address ( struct net_device * dev , void * p ) <nl> if (! is_valid_ether_addr ( addr -> sa_data )) <nl> return - EADDRNOTAVAIL ; <nl>  <nl> + /* If the addresses are the same , this is a no - op */ <nl> + if ( ether_addr_equal ( dev -> dev_addr , addr -> sa_data )) <nl> + return 0 ; <nl> + <nl> if ( vlan -> mode == MACVLAN_MODE_PASSTHRU ) { <nl> dev_set_mac_address ( vlan -> lowerdev , addr ); <nl> return 0 ;
mmm fs / btrfs / tree - log . c <nl> ppp fs / btrfs / tree - log . c <nl> static int btrfs_add_log_tree ( struct btrfs_trans_handle * trans , <nl> */ <nl> new_root -> ref_cows = 0 ; <nl> new_root -> last_trans = trans -> transid ; <nl> + <nl> + /* <nl> + * we need to make sure the root block for this new tree <nl> + * is marked as dirty in the dirty_log_pages tree . This <nl> + * is how it gets flushed down to disk at tree log commit time . <nl> + * <nl> + * the tree logging mutex keeps others from coming in and changing <nl> + * the new_root -> node , so we can safely access it here <nl> + */ <nl> + set_extent_dirty (& new_root -> dirty_log_pages , new_root -> node -> start , <nl> + new_root -> node -> start + new_root -> node -> len - 1 , <nl> + GFP_NOFS ); <nl> + <nl> fail : <nl> return ret ; <nl> }
mmm drivers / acpi / video . c <nl> ppp drivers / acpi / video . c <nl> static int acpi_video_bus_put_one_device ( struct acpi_video_device * device ) <nl> status = acpi_remove_notify_handler ( device -> dev -> handle , <nl> ACPI_DEVICE_NOTIFY , <nl> acpi_video_device_notify ); <nl> - sysfs_remove_link (& device -> backlight -> dev . kobj , " device "); <nl> - backlight_device_unregister ( device -> backlight ); <nl> + if ( device -> backlight ) { <nl> + sysfs_remove_link (& device -> backlight -> dev . kobj , " device "); <nl> + backlight_device_unregister ( device -> backlight ); <nl> + device -> backlight = NULL ; <nl> + } <nl> if ( device -> cdev ) { <nl> sysfs_remove_link (& device -> dev -> dev . kobj , <nl> " thermal_cooling ");
mmm drivers / regulator / core . c <nl> ppp drivers / regulator / core . c <nl> static int set_supply ( struct regulator_dev * rdev , <nl>  <nl> rdev_info ( rdev , " supplied by % s \ n ", rdev_get_name ( supply_rdev )); <nl>  <nl> + if (! try_module_get ( supply_rdev -> owner )) <nl> + return - ENODEV ; <nl> + <nl> rdev -> supply = create_regulator ( supply_rdev , & rdev -> dev , " SUPPLY "); <nl> if ( rdev -> supply == NULL ) { <nl> err = - ENOMEM ;
mmm drivers / media / usb / usbvision / usbvision - video . c <nl> ppp drivers / media / usb / usbvision / usbvision - video . c <nl> static int usbvision_v4l2_close ( struct file * file ) <nl> usbvision_scratch_free ( usbvision ); <nl>  <nl> usbvision -> user --; <nl> + mutex_unlock (& usbvision -> v4l2_lock ); <nl>  <nl> if ( usbvision -> remove_pending ) { <nl> printk ( KERN_INFO "% s : Final disconnect \ n ", __func__ ); <nl> usbvision_release ( usbvision ); <nl> return 0 ; <nl> } <nl> - mutex_unlock (& usbvision -> v4l2_lock ); <nl>  <nl> PDEBUG ( DBG_IO , " success "); <nl> return v4l2_fh_release ( file );
mmm net / bluetooth / hci_request . c <nl> ppp net / bluetooth / hci_request . c <nl> int hci_req_sync ( struct hci_dev * hdev , int (* req )( struct hci_request * req , <nl> { <nl> int ret ; <nl>  <nl> - if (! test_bit ( HCI_UP , & hdev -> flags )) <nl> - return - ENETDOWN ; <nl> - <nl> /* Serialize all requests */ <nl> hci_req_sync_lock ( hdev ); <nl> - ret = __hci_req_sync ( hdev , req , opt , timeout , hci_status ); <nl> + /* check the state after obtaing the lock to protect the HCI_UP <nl> + * against any races from hci_dev_do_close when the controller <nl> + * gets removed . <nl> + */ <nl> + if ( test_bit ( HCI_UP , & hdev -> flags )) <nl> + ret = __hci_req_sync ( hdev , req , opt , timeout , hci_status ); <nl> + else <nl> + ret = - ENETDOWN ; <nl> hci_req_sync_unlock ( hdev ); <nl>  <nl> return ret ;
mmm fs / btrfs / inode . c <nl> ppp fs / btrfs / inode . c <nl> struct extent_map * btrfs_get_extent ( struct inode * inode , struct page * page , <nl> goto not_found ; <nl> if ( start + len <= found_key . offset ) <nl> goto not_found ; <nl> + if ( start > found_key . offset ) <nl> + goto next ; <nl> em -> start = start ; <nl> em -> orig_start = start ; <nl> em -> len = found_key . offset - start ;
mmm include / linux / fs . h <nl> ppp include / linux / fs . h <nl> struct super_block { <nl> */ <nl> struct list_lru s_dentry_lru ____cacheline_aligned_in_smp ; <nl> struct list_lru s_inode_lru ____cacheline_aligned_in_smp ; <nl> + struct rcu_head rcu ; <nl> }; <nl>  <nl> extern struct timespec current_fs_time ( struct super_block * sb );mmm fs / super . c <nl> ppp fs / super . c <nl> struct super_block { <nl> */ <nl> struct list_lru s_dentry_lru ____cacheline_aligned_in_smp ; <nl> struct list_lru s_inode_lru ____cacheline_aligned_in_smp ; <nl> + struct rcu_head rcu ; <nl> }; <nl>  <nl> extern struct timespec current_fs_time ( struct super_block * sb ); <nl> static void destroy_super ( struct super_block * s ) <nl> WARN_ON (! list_empty (& s -> s_mounts )); <nl> kfree ( s -> s_subtype ); <nl> kfree ( s -> s_options ); <nl> - kfree ( s ); <nl> + kfree_rcu ( s , rcu ); <nl> } <nl>  <nl> /**
mmm drivers / gpio / gpio - rcar . c <nl> ppp drivers / gpio / gpio - rcar . c <nl> static struct irq_domain_ops gpio_rcar_irq_domain_ops = { <nl> static void gpio_rcar_parse_pdata ( struct gpio_rcar_priv * p ) <nl> { <nl> struct gpio_rcar_config * pdata = p -> pdev -> dev . platform_data ; <nl> -# ifdef CONFIG_OF <nl> struct device_node * np = p -> pdev -> dev . of_node ; <nl> struct of_phandle_args args ; <nl> int ret ; <nl> -# endif <nl>  <nl> - if ( pdata ) <nl> + if ( pdata ) { <nl> p -> config = * pdata ; <nl> -# ifdef CONFIG_OF <nl> - else if ( np ) { <nl> + } else if ( IS_ENABLED ( CONFIG_OF ) && np ) { <nl> ret = of_parse_phandle_with_args ( np , " gpio - ranges ", <nl> "# gpio - range - cells ", 0 , & args ); <nl> p -> config . number_of_pins = ret == 0 && args . args_count == 3 <nl> static void gpio_rcar_parse_pdata ( struct gpio_rcar_priv * p ) <nl> : RCAR_MAX_GPIO_PER_BANK ; <nl> p -> config . gpio_base = - 1 ; <nl> } <nl> -# endif <nl>  <nl> if ( p -> config . number_of_pins == 0 || <nl> p -> config . number_of_pins > RCAR_MAX_GPIO_PER_BANK ) {
mmm drivers / staging / cx25821 / cx25821 - video . c <nl> ppp drivers / staging / cx25821 / cx25821 - video . c <nl> struct cx25821_fmt * cx25821_format_by_fourcc ( unsigned int fourcc ) <nl> { <nl> unsigned int i ; <nl>  <nl> - if ( fourcc == V4L2_PIX_FMT_Y41P || fourcc == V4L2_PIX_FMT_YUV411P ) { <nl> + if ( fourcc == V4L2_PIX_FMT_Y41P || fourcc == V4L2_PIX_FMT_YUV411P ) <nl> return formats + 1 ; <nl> - } <nl>  <nl> for ( i = 0 ; i < ARRAY_SIZE ( formats ); i ++) <nl> if ( formats [ i ]. fourcc == fourcc ) <nl> void cx25821_video_wakeup ( struct cx25821_dev * dev , struct cx25821_dmaqueue * q , <nl> /* count comes from the hw and it is 16bit wide -- <nl> * this trick handles wrap - arounds correctly for <nl> * up to 32767 buffers in flight ... */ <nl> - if (( s16 ) ( count - buf -> count ) < 0 ) { <nl> + if (( s16 ) ( count - buf -> count ) < 0 ) <nl> break ; <nl> - } <nl>  <nl> do_gettimeofday (& buf -> vb . ts ); <nl> buf -> vb . state = VIDEOBUF_DONE ;
mmm fs / f2fs / segment . c <nl> ppp fs / f2fs / segment . c <nl> static void f2fs_submit_discard_endio ( struct bio * bio ) <nl>  <nl> dc -> error = bio -> bi_error ; <nl> dc -> state = D_DONE ; <nl> - complete (& dc -> wait ); <nl> + complete_all (& dc -> wait ); <nl> bio_put ( bio ); <nl> } <nl> 
mmm kernel / user_namespace . c <nl> ppp kernel / user_namespace . c <nl> static bool new_idmap_permitted ( const struct file * file , <nl> u32 id = new_map -> extent [ 0 ]. lower_first ; <nl> if ( cap_setid == CAP_SETUID ) { <nl> kuid_t uid = make_kuid ( ns -> parent , id ); <nl> - if ( uid_eq ( uid , current_fsuid ())) <nl> + if ( uid_eq ( uid , file -> f_cred -> fsuid )) <nl> return true ; <nl> } <nl> else if ( cap_setid == CAP_SETGID ) { <nl> kgid_t gid = make_kgid ( ns -> parent , id ); <nl> - if ( gid_eq ( gid , current_fsgid ())) <nl> + if ( gid_eq ( gid , file -> f_cred -> fsgid )) <nl> return true ; <nl> } <nl> }
mmm net / sched / act_police . c <nl> ppp net / sched / act_police . c <nl> static int tcf_act_police_dump ( struct sk_buff * skb , struct tc_action * a , <nl> struct tcf_police * police = to_police ( a ); <nl> struct tc_police opt = { <nl> . index = police -> tcf_index , <nl> - . action = police -> tcf_action , <nl> - . mtu = police -> tcfp_mtu , <nl> - . burst = PSCHED_NS2TICKS ( police -> tcfp_burst ), <nl> . refcnt = refcount_read (& police -> tcf_refcnt ) - ref , <nl> . bindcnt = atomic_read (& police -> tcf_bindcnt ) - bind , <nl> }; <nl> struct tcf_t t ; <nl>  <nl> + spin_lock_bh (& police -> tcf_lock ); <nl> + opt . action = police -> tcf_action ; <nl> + opt . mtu = police -> tcfp_mtu ; <nl> + opt . burst = PSCHED_NS2TICKS ( police -> tcfp_burst ); <nl> if ( police -> rate_present ) <nl> psched_ratecfg_getrate (& opt . rate , & police -> rate ); <nl> if ( police -> peak_present ) <nl> static int tcf_act_police_dump ( struct sk_buff * skb , struct tc_action * a , <nl> t . expires = jiffies_to_clock_t ( police -> tcf_tm . expires ); <nl> if ( nla_put_64bit ( skb , TCA_POLICE_TM , sizeof ( t ), & t , TCA_POLICE_PAD )) <nl> goto nla_put_failure ; <nl> + spin_unlock_bh (& police -> tcf_lock ); <nl>  <nl> return skb -> len ; <nl>  <nl> nla_put_failure : <nl> + spin_unlock_bh (& police -> tcf_lock ); <nl> nlmsg_trim ( skb , b ); <nl> return - 1 ; <nl> }
mmm drivers / acpi / acpi_video . c <nl> ppp drivers / acpi / acpi_video . c <nl> static int acpi_video_device_enumerate ( struct acpi_video_bus * video ) <nl> union acpi_object * dod = NULL ; <nl> union acpi_object * obj ; <nl>  <nl> + if (! video -> cap . _DOD ) <nl> + return AE_NOT_EXIST ; <nl> + <nl> status = acpi_evaluate_object ( video -> device -> handle , " _DOD ", NULL , & buffer ); <nl> if (! ACPI_SUCCESS ( status )) { <nl> ACPI_EXCEPTION (( AE_INFO , status , " Evaluating _DOD "));
mmm drivers / extcon / extcon - palmas . c <nl> ppp drivers / extcon / extcon - palmas . c <nl> static int palmas_usb_probe ( struct platform_device * pdev ) <nl> status = devm_extcon_dev_register (& pdev -> dev , palmas_usb -> edev ); <nl> if ( status ) { <nl> dev_err (& pdev -> dev , " failed to register extcon device \ n "); <nl> - kfree ( palmas_usb -> edev -> name ); <nl> return status ; <nl> } <nl>  <nl> static int palmas_usb_probe ( struct platform_device * pdev ) <nl> if ( status < 0 ) { <nl> dev_err (& pdev -> dev , " can ' t get IRQ % d , err % d \ n ", <nl> palmas_usb -> id_irq , status ); <nl> - kfree ( palmas_usb -> edev -> name ); <nl> return status ; <nl> } <nl> } <nl> static int palmas_usb_probe ( struct platform_device * pdev ) <nl> if ( status < 0 ) { <nl> dev_err (& pdev -> dev , " can ' t get IRQ % d , err % d \ n ", <nl> palmas_usb -> vbus_irq , status ); <nl> - kfree ( palmas_usb -> edev -> name ); <nl> return status ; <nl> } <nl> } <nl> static int palmas_usb_probe ( struct platform_device * pdev ) <nl> return 0 ; <nl> } <nl>  <nl> - static int palmas_usb_remove ( struct platform_device * pdev ) <nl> -{ <nl> - struct palmas_usb * palmas_usb = platform_get_drvdata ( pdev ); <nl> - <nl> - kfree ( palmas_usb -> edev -> name ); <nl> - <nl> - return 0 ; <nl> -} <nl> - <nl> # ifdef CONFIG_PM_SLEEP <nl> static int palmas_usb_suspend ( struct device * dev ) <nl> { <nl> static const struct of_device_id of_palmas_match_tbl [] = { <nl>  <nl> static struct platform_driver palmas_usb_driver = { <nl> . probe = palmas_usb_probe , <nl> - . remove = palmas_usb_remove , <nl> . driver = { <nl> . name = " palmas - usb ", <nl> . of_match_table = of_palmas_match_tbl ,
mmm net / bluetooth / mgmt . c <nl> ppp net / bluetooth / mgmt . c <nl> static int set_connectable ( struct sock * sk , struct hci_dev * hdev , void * data , <nl>  <nl> hci_req_add (& req , HCI_OP_WRITE_SCAN_ENABLE , 1 , & scan ); <nl>  <nl> + if (! cp -> val && test_bit ( HCI_FAST_CONNECTABLE , & hdev -> dev_flags )) <nl> + write_fast_connectable (& req , false ); <nl> + <nl> err = hci_req_run (& req , set_connectable_complete ); <nl> if ( err < 0 ) <nl> mgmt_pending_remove ( cmd );
mmm drivers / staging / tm6000 / tm6000 - cards . c <nl> ppp drivers / staging / tm6000 / tm6000 - cards . c <nl> static void tm6000_config_tuner ( struct tm6000_core * dev ) <nl>  <nl> ctl . mts = 1 ; <nl> ctl . read_not_reliable = 1 ; <nl> + ctl . msleep = 10 ; <nl>  <nl> xc2028_cfg . tuner = TUNER_XC2028 ; <nl> xc2028_cfg . priv = & ctl ;
mmm drivers / gpu / drm / i915 / i915_gem . c <nl> ppp drivers / gpu / drm / i915 / i915_gem . c <nl> int i915_gem_init ( struct drm_device * dev ) <nl> i915_gem_init_global_gtt ( dev ); <nl>  <nl> ret = i915_gem_context_init ( dev ); <nl> - if ( ret ) <nl> + if ( ret ) { <nl> + mutex_unlock (& dev -> struct_mutex ); <nl> return ret ; <nl> + } <nl>  <nl> ret = i915_gem_init_hw ( dev ); <nl> mutex_unlock (& dev -> struct_mutex );
mmm drivers / rtc / rtc - ftrtc010 . c <nl> ppp drivers / rtc / rtc - ftrtc010 . c <nl> static int ftrtc010_rtc_probe ( struct platform_device * pdev ) <nl> if (! rtc -> rtc_base ) <nl> return - ENOMEM ; <nl>  <nl> + rtc -> rtc_dev = devm_rtc_allocate_device ( dev ); <nl> + if ( IS_ERR ( rtc -> rtc_dev )) <nl> + return PTR_ERR ( rtc -> rtc_dev ); <nl> + <nl> + rtc -> rtc_dev -> ops = & ftrtc010_rtc_ops ; <nl> + <nl> ret = devm_request_irq ( dev , rtc -> rtc_irq , ftrtc010_rtc_interrupt , <nl> IRQF_SHARED , pdev -> name , dev ); <nl> if ( unlikely ( ret )) <nl> return ret ; <nl>  <nl> - rtc -> rtc_dev = rtc_device_register ( pdev -> name , dev , <nl> - & ftrtc010_rtc_ops , THIS_MODULE ); <nl> - return PTR_ERR_OR_ZERO ( rtc -> rtc_dev ); <nl> + return rtc_register_device ( rtc -> rtc_dev ); <nl> } <nl>  <nl> static int ftrtc010_rtc_remove ( struct platform_device * pdev ) <nl> static int ftrtc010_rtc_remove ( struct platform_device * pdev ) <nl> clk_disable_unprepare ( rtc -> extclk ); <nl> if (! IS_ERR ( rtc -> pclk )) <nl> clk_disable_unprepare ( rtc -> pclk ); <nl> - rtc_device_unregister ( rtc -> rtc_dev ); <nl>  <nl> return 0 ; <nl> }
mmm sound / soc / intel / boards / bytcr_rt5651 . c <nl> ppp sound / soc / intel / boards / bytcr_rt5651 . c <nl> static int snd_byt_rt5651_mc_probe ( struct platform_device * pdev ) <nl>  <nl> /* fixup codec name based on HID */ <nl> i2c_name = acpi_dev_get_first_match_name ( mach -> id , NULL , - 1 ); <nl> - if ( i2c_name ) { <nl> - snprintf ( byt_rt5651_codec_name , sizeof ( byt_rt5651_codec_name ), <nl> - "% s % s ", " i2c -", i2c_name ); <nl> - <nl> - byt_rt5651_dais [ dai_index ]. codec_name = byt_rt5651_codec_name ; <nl> + if (! i2c_name ) { <nl> + dev_err (& pdev -> dev , " Error cannot find '% s ' dev \ n ", mach -> id ); <nl> + return - ENODEV ; <nl> } <nl> + snprintf ( byt_rt5651_codec_name , sizeof ( byt_rt5651_codec_name ), <nl> + "% s % s ", " i2c -", i2c_name ); <nl> + byt_rt5651_dais [ dai_index ]. codec_name = byt_rt5651_codec_name ; <nl>  <nl> /* check quirks before creating card */ <nl> dmi_check_system ( byt_rt5651_quirk_table );
mmm drivers / staging / vt6656 / wpactl . c <nl> ppp drivers / staging / vt6656 / wpactl . c <nl> int wpa_ioctl ( PSDevice pDevice , struct iw_point * p ) <nl> default : <nl> DBG_PRT ( MSG_LEVEL_DEBUG , KERN_INFO " wpa_ioctl : unknown cmd =% d \ n ", <nl> param -> cmd ); <nl> + kfree ( param ); <nl> return - EOPNOTSUPP ; <nl> } <nl> 
mmm drivers / acpi / ioapic . c <nl> ppp drivers / acpi / ioapic . c <nl> static acpi_status setup_res ( struct acpi_resource * acpi_res , void * data ) <nl> struct resource * res = data ; <nl> struct resource_win win ; <nl>  <nl> + /* <nl> + * We might assign this to ' res ' later , make sure all pointers are <nl> + * cleared before the resource is added to the global list <nl> + */ <nl> + memset (& win , 0 , sizeof ( win )); <nl> + <nl> res -> flags = 0 ; <nl> if ( acpi_dev_filter_resource_type ( acpi_res , IORESOURCE_MEM )) <nl> return AE_OK ;
mmm drivers / net / wireless / intel / iwlwifi / mvm / sta . c <nl> ppp drivers / net / wireless / intel / iwlwifi / mvm / sta . c <nl> static int iwl_mvm_free_inactive_queue ( struct iwl_mvm * mvm , int queue , <nl> spin_unlock_bh (& mvm -> queue_info_lock ); <nl>  <nl> mvmsta = iwl_mvm_sta_from_staid_protected ( mvm , sta_id ); <nl> + if ( WARN_ON (! mvmsta )) <nl> + return - EINVAL ; <nl>  <nl> disable_agg_tids = iwl_mvm_remove_sta_queue_marking ( mvm , queue ); <nl> /* Disable the queue */
mmm net / sctp / sm_make_chunk . c <nl> ppp net / sctp / sm_make_chunk . c <nl> static int sctp_process_param ( struct sctp_association * asoc , <nl> addr_param = param . v + sizeof ( sctp_addip_param_t ); <nl>  <nl> af = sctp_get_af_specific ( param_type2af ( param . p -> type )); <nl> + if ( af == NULL ) <nl> + break ; <nl> + <nl> af -> from_addr_param (& addr , addr_param , <nl> htons ( asoc -> peer . port ), 0 ); <nl> 
mmm drivers / gpu / drm / arm / malidp_planes . c <nl> ppp drivers / gpu / drm / arm / malidp_planes . c <nl> static void malidp_de_set_plane_pitches ( struct malidp_plane * mp , <nl> static void malidp_de_plane_update ( struct drm_plane * plane , <nl> struct drm_plane_state * old_state ) <nl> { <nl> - struct drm_gem_cma_object * obj ; <nl> struct malidp_plane * mp ; <nl> const struct malidp_hw_regmap * map ; <nl> struct malidp_plane_state * ms = to_malidp_plane_state ( plane -> state ); <nl> - u16 ptr ; <nl> u32 src_w , src_h , dest_w , dest_h , val ; <nl> int i ; <nl>  <nl> static void malidp_de_plane_update ( struct drm_plane * plane , <nl>  <nl> for ( i = 0 ; i < ms -> n_planes ; i ++) { <nl> /* calculate the offset for the layer ' s plane registers */ <nl> - ptr = mp -> layer -> ptr + ( i << 4 ); <nl> + u16 ptr = mp -> layer -> ptr + ( i << 4 ); <nl> + dma_addr_t fb_addr = drm_fb_cma_get_gem_addr ( plane -> state -> fb , <nl> + plane -> state , i ); <nl>  <nl> - obj = drm_fb_cma_get_gem_obj ( plane -> state -> fb , i ); <nl> - obj -> paddr += plane -> state -> fb -> offsets [ i ]; <nl> - malidp_hw_write ( mp -> hwdev , lower_32_bits ( obj -> paddr ), ptr ); <nl> - malidp_hw_write ( mp -> hwdev , upper_32_bits ( obj -> paddr ), ptr + 4 ); <nl> + malidp_hw_write ( mp -> hwdev , lower_32_bits ( fb_addr ), ptr ); <nl> + malidp_hw_write ( mp -> hwdev , upper_32_bits ( fb_addr ), ptr + 4 ); <nl> } <nl> malidp_de_set_plane_pitches ( mp , ms -> n_planes , <nl> plane -> state -> fb -> pitches );
mmm drivers / media / video / tvaudio . c <nl> ppp drivers / media / video / tvaudio . c <nl> static int tvaudio_probe ( struct i2c_client * client , const struct i2c_device_id * <nl> } <nl>  <nl> chip -> thread = NULL ; <nl> + init_timer (& chip -> wt ); <nl> if ( desc -> flags & CHIP_NEED_CHECKMODE ) { <nl> if (! desc -> getmode || ! desc -> setmode ) { <nl> /* This shouldn ' t be happen . Warn user , but keep working <nl> static int tvaudio_probe ( struct i2c_client * client , const struct i2c_device_id * <nl> return 0 ; <nl> } <nl> /* start async thread */ <nl> - init_timer (& chip -> wt ); <nl> chip -> wt . function = chip_thread_wake ; <nl> chip -> wt . data = ( unsigned long ) chip ; <nl> chip -> thread = kthread_run ( chip_thread , chip , client -> name );
mmm drivers / gpu / drm / sun4i / sun4i_tv . c <nl> ppp drivers / gpu / drm / sun4i / sun4i_tv . c <nl> static int sun4i_tv_comp_get_modes ( struct drm_connector * connector ) <nl> int i ; <nl>  <nl> for ( i = 0 ; i < ARRAY_SIZE ( tv_modes ); i ++) { <nl> - struct drm_display_mode * mode = drm_mode_create ( connector -> dev ); <nl> + struct drm_display_mode * mode ; <nl> const struct tv_mode * tv_mode = & tv_modes [ i ]; <nl>  <nl> + mode = drm_mode_create ( connector -> dev ); <nl> + if (! mode ) { <nl> + DRM_ERROR (" Failed to create a new display mode \ n "); <nl> + return 0 ; <nl> + } <nl> + <nl> strcpy ( mode -> name , tv_mode -> name ); <nl>  <nl> sun4i_tv_mode_to_drm_mode ( tv_mode , mode );
mmm drivers / mmc / host / renesas_sdhi_internal_dmac . c <nl> ppp drivers / mmc / host / renesas_sdhi_internal_dmac . c <nl> static const struct soc_device_attribute gen3_soc_whitelist [] = { <nl> /* generic ones */ <nl> { . soc_id = " r8a7795 " }, <nl> { . soc_id = " r8a7796 " }, <nl> + { . soc_id = " r8a77980 " }, <nl> { . soc_id = " r8a77995 " }, <nl> { /* sentinel */ } <nl> };
mmm net / ipv6 / ip6_gre . c <nl> ppp net / ipv6 / ip6_gre . c <nl> static netdev_tx_t ip6erspan_tunnel_xmit ( struct sk_buff * skb , <nl> truncate = true ; <nl> } <nl>  <nl> + if ( skb_cow_head ( skb , dev -> needed_headroom )) <nl> + goto tx_err ; <nl> + <nl> t -> parms . o_flags &= ~ TUNNEL_KEY ; <nl> IPCB ( skb )-> flags = 0 ; <nl> 
mmm drivers / media / video / videobuf - core . c <nl> ppp drivers / media / video / videobuf - core . c <nl> int videobuf_dqbuf ( struct videobuf_queue * q , <nl> goto done ; <nl> } <nl> buf = list_entry ( q -> stream . next , struct videobuf_buffer , stream ); <nl> + mutex_unlock (& q -> vb_lock ); <nl> retval = videobuf_waiton ( buf , nonblocking , 1 ); <nl> + mutex_lock (& q -> vb_lock ); <nl> if ( retval < 0 ) { <nl> dprintk ( 1 , " dqbuf : waiton returned % d \ n ", retval ); <nl> goto done ;
mmm fs / afs / volume . c <nl> ppp fs / afs / volume . c <nl> static struct afs_volume * afs_alloc_volume ( struct afs_mount_params * params , <nl> error_2 : <nl> afs_put_serverlist ( params -> net , slist ); <nl> error_1 : <nl> + afs_put_cell ( params -> net , volume -> cell ); <nl> kfree ( volume ); <nl> error_0 : <nl> return ERR_PTR ( ret );
mmm drivers / staging / comedi / drivers / ni_6527 . c <nl> ppp drivers / staging / comedi / drivers / ni_6527 . c <nl> static void ni6527_reset ( struct comedi_device * dev ) <nl> /* disable deglitch filters on all channels */ <nl> ni6527_set_filter_enable ( dev , 0 ); <nl>  <nl> + /* disable edge detection */ <nl> + ni6527_set_edge_detection ( dev , 0xffffffff , 0 , 0 ); <nl> + <nl> writeb ( NI6527_CLR_IRQS | NI6527_CLR_RESET_FILT , <nl> mmio + NI6527_CLR_REG ); <nl> writeb ( NI6527_CTRL_DISABLE_IRQS , mmio + NI6527_CTRL_REG );
mmm arch / powerpc / kvm / book3s_64_vio . c <nl> ppp arch / powerpc / kvm / book3s_64_vio . c <nl> long kvm_vm_ioctl_create_spapr_tce ( struct kvm * kvm , <nl> int ret = - ENOMEM ; <nl> int i ; <nl>  <nl> - if (! args -> size ) <nl> + if (! args -> size || args -> page_shift < 12 || args -> page_shift > 34 || <nl> + ( args -> offset + args -> size > ( ULLONG_MAX >> args -> page_shift ))) <nl> return - EINVAL ; <nl>  <nl> size = _ALIGN_UP ( args -> size , PAGE_SIZE >> 3 );
mmm fs / btrfs / volumes . c <nl> ppp fs / btrfs / volumes . c <nl> int btrfs_rm_device ( struct btrfs_fs_info * fs_info , const char * device_path , <nl>  <nl> if ( IS_ERR ( device )) { <nl> if ( PTR_ERR ( device ) == - ENOENT && <nl> - strcmp ( device_path , " missing ") == 0 ) <nl> + device_path && strcmp ( device_path , " missing ") == 0 ) <nl> ret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND ; <nl> else <nl> ret = PTR_ERR ( device );
mmm include / linux / phy . h <nl> ppp include / linux / phy . h <nl> static inline bool phy_is_internal ( struct phy_device * phydev ) <nl> return phydev -> is_internal ; <nl> } <nl>  <nl> +/** <nl> + * phy_interface_is_rgmii - Convenience function for testing if a PHY interface <nl> + * is RGMII ( all variants ) <nl> + * @ phydev : the phy_device struct <nl> + */ <nl> + static inline bool phy_interface_is_rgmii ( struct phy_device * phydev ) <nl> +{ <nl> + return phydev -> interface >= PHY_INTERFACE_MODE_RGMII && <nl> + phydev -> interface <= PHY_INTERFACE_MODE_RGMII_TXID ; <nl> +} <nl> + <nl> /** <nl> * phy_write_mmd - Convenience function for writing a register <nl> * on an MMD on a given PHY .
mmm drivers / net / wireless / ti / wlcore / io . h <nl> ppp drivers / net / wireless / ti / wlcore / io . h <nl> static inline int __must_check wlcore_write_reg ( struct wl1271 * wl , int reg , <nl>  <nl> static inline void wl1271_power_off ( struct wl1271 * wl ) <nl> { <nl> - int ret ; <nl> + int ret = 0 ; <nl>  <nl> if (! test_bit ( WL1271_FLAG_GPIO_POWER , & wl -> flags )) <nl> return ; <nl>  <nl> - ret = wl -> if_ops -> power ( wl -> dev , false ); <nl> + if ( wl -> if_ops -> power ) <nl> + ret = wl -> if_ops -> power ( wl -> dev , false ); <nl> if (! ret ) <nl> clear_bit ( WL1271_FLAG_GPIO_POWER , & wl -> flags ); <nl> } <nl>  <nl> static inline int wl1271_power_on ( struct wl1271 * wl ) <nl> { <nl> - int ret = wl -> if_ops -> power ( wl -> dev , true ); <nl> + int ret = 0 ; <nl> + <nl> + if ( wl -> if_ops -> power ) <nl> + ret = wl -> if_ops -> power ( wl -> dev , true ); <nl> if ( ret == 0 ) <nl> set_bit ( WL1271_FLAG_GPIO_POWER , & wl -> flags ); <nl> 
mmm arch / powerpc / platforms / powernv / pci - ioda . c <nl> ppp arch / powerpc / platforms / powernv / pci - ioda . c <nl> void __init pnv_pci_init_ioda1_phb ( struct device_node * np ) <nl> /* Allocate aux data & arrays */ <nl> size = _ALIGN_UP ( phb -> ioda . total_pe / 8 , sizeof ( unsigned long )); <nl> m32map_off = size ; <nl> - size += phb -> ioda . total_pe ; <nl> + size += phb -> ioda . total_pe * sizeof ( phb -> ioda . m32_segmap [ 0 ]); <nl> iomap_off = size ; <nl> - size += phb -> ioda . total_pe ; <nl> + size += phb -> ioda . total_pe * sizeof ( phb -> ioda . io_segmap [ 0 ]); <nl> pemap_off = size ; <nl> size += phb -> ioda . total_pe * sizeof ( struct pnv_ioda_pe ); <nl> aux = alloc_bootmem ( size );
mmm net / mac802154 / main . c <nl> ppp net / mac802154 / main . c <nl> EXPORT_SYMBOL ( ieee802154_free_hw ); <nl> int ieee802154_register_hw ( struct ieee802154_hw * hw ) <nl> { <nl> struct ieee802154_local * local = hw_to_local ( hw ); <nl> + struct net_device * dev ; <nl> int rc = - ENOSYS ; <nl>  <nl> local -> workqueue = <nl> int ieee802154_register_hw ( struct ieee802154_hw * hw ) <nl> if ( rc < 0 ) <nl> goto out_wq ; <nl>  <nl> + rtnl_lock (); <nl> + <nl> + dev = ieee802154_if_add ( local , " wpan % d ", NULL , IEEE802154_DEV_WPAN ); <nl> + if ( IS_ERR ( dev )) { <nl> + rtnl_unlock (); <nl> + rc = PTR_ERR ( dev ); <nl> + goto out_wq ; <nl> + } <nl> + <nl> + rtnl_unlock (); <nl> + <nl> return 0 ; <nl>  <nl> out_wq :
mmm fs / befs / linuxvfs . c <nl> ppp fs / befs / linuxvfs . c <nl> static void init_once ( void * foo ) <nl>  <nl> static struct inode * befs_iget ( struct super_block * sb , unsigned long ino ) <nl> { <nl> - struct buffer_head * bh = NULL ; <nl> + struct buffer_head * bh ; <nl> befs_inode * raw_inode = NULL ; <nl> struct befs_sb_info * befs_sb = BEFS_SB ( sb ); <nl> struct befs_inode_info * befs_ino = NULL ;
mmm drivers / net / ethernet / mellanox / mlxsw / pci . c <nl> ppp drivers / net / ethernet / mellanox / mlxsw / pci . c <nl> static void mlxsw_pci_eq_tasklet ( unsigned long data ) <nl> { <nl> struct mlxsw_pci_queue * q = ( struct mlxsw_pci_queue *) data ; <nl> struct mlxsw_pci * mlxsw_pci = q -> pci ; <nl> - unsigned long active_cqns [ BITS_TO_LONGS ( MLXSW_PCI_CQS_COUNT )]; <nl> + u8 cq_count = mlxsw_pci_cq_count ( mlxsw_pci ); <nl> + unsigned long active_cqns [ BITS_TO_LONGS ( MLXSW_PCI_CQS_MAX )]; <nl> char * eqe ; <nl> u8 cqn ; <nl> bool cq_handle = false ; <nl> static void mlxsw_pci_eq_tasklet ( unsigned long data ) <nl>  <nl> if (! cq_handle ) <nl> return ; <nl> - for_each_set_bit ( cqn , active_cqns , MLXSW_PCI_CQS_COUNT ) { <nl> + for_each_set_bit ( cqn , active_cqns , cq_count ) { <nl> q = mlxsw_pci_cq_get ( mlxsw_pci , cqn ); <nl> mlxsw_pci_queue_tasklet_schedule ( q ); <nl> } <nl> static int mlxsw_pci_aqs_init ( struct mlxsw_pci * mlxsw_pci , char * mbox ) <nl>  <nl> if (( num_sdqs != MLXSW_PCI_SDQS_COUNT ) || <nl> ( num_rdqs != MLXSW_PCI_RDQS_COUNT ) || <nl> - ( num_cqs != MLXSW_PCI_CQS_COUNT ) || <nl> - ( num_eqs != MLXSW_PCI_EQS_COUNT )) { <nl> + num_cqs > MLXSW_PCI_CQS_MAX || num_eqs != MLXSW_PCI_EQS_COUNT ) { <nl> dev_err (& pdev -> dev , " Unsupported number of queues \ n "); <nl> return - EINVAL ; <nl> }mmm drivers / net / ethernet / mellanox / mlxsw / pci . h <nl> ppp drivers / net / ethernet / mellanox / mlxsw / pci . h <nl> static void mlxsw_pci_eq_tasklet ( unsigned long data ) <nl> { <nl> struct mlxsw_pci_queue * q = ( struct mlxsw_pci_queue *) data ; <nl> struct mlxsw_pci * mlxsw_pci = q -> pci ; <nl> - unsigned long active_cqns [ BITS_TO_LONGS ( MLXSW_PCI_CQS_COUNT )]; <nl> + u8 cq_count = mlxsw_pci_cq_count ( mlxsw_pci ); <nl> + unsigned long active_cqns [ BITS_TO_LONGS ( MLXSW_PCI_CQS_MAX )]; <nl> char * eqe ; <nl> u8 cqn ; <nl> bool cq_handle = false ; <nl> static void mlxsw_pci_eq_tasklet ( unsigned long data ) <nl>  <nl> if (! cq_handle ) <nl> return ; <nl> - for_each_set_bit ( cqn , active_cqns , MLXSW_PCI_CQS_COUNT ) { <nl> + for_each_set_bit ( cqn , active_cqns , cq_count ) { <nl> q = mlxsw_pci_cq_get ( mlxsw_pci , cqn ); <nl> mlxsw_pci_queue_tasklet_schedule ( q ); <nl> } <nl> static int mlxsw_pci_aqs_init ( struct mlxsw_pci * mlxsw_pci , char * mbox ) <nl>  <nl> if (( num_sdqs != MLXSW_PCI_SDQS_COUNT ) || <nl> ( num_rdqs != MLXSW_PCI_RDQS_COUNT ) || <nl> - ( num_cqs != MLXSW_PCI_CQS_COUNT ) || <nl> - ( num_eqs != MLXSW_PCI_EQS_COUNT )) { <nl> + num_cqs > MLXSW_PCI_CQS_MAX || num_eqs != MLXSW_PCI_EQS_COUNT ) { <nl> dev_err (& pdev -> dev , " Unsupported number of queues \ n "); <nl> return - EINVAL ; <nl> } <nl>  <nl> # define MLXSW_PCI_RDQS_COUNT 24 <nl> # define MLXSW_PCI_SDQS_COUNT 24 <nl> -# define MLXSW_PCI_CQS_COUNT ( MLXSW_PCI_RDQS_COUNT + MLXSW_PCI_SDQS_COUNT ) <nl> +# define MLXSW_PCI_CQS_MAX 96 <nl> # define MLXSW_PCI_EQS_COUNT 2 <nl> # define MLXSW_PCI_EQ_ASYNC_NUM 0 <nl> # define MLXSW_PCI_EQ_COMP_NUM 1
mmm drivers / staging / lustre / lustre / libcfs / module . c <nl> ppp drivers / staging / lustre / lustre / libcfs / module . c <nl> static int __proc_dobitmasks ( void * data , int write , <nl> } else { <nl> rc = cfs_trace_copyin_string ( tmpstr , tmpstrlen , buffer , nob ); <nl> if ( rc < 0 ) { <nl> - cfs_trace_free_string_buffer ( tmpstr , tmpstrlen ); <nl> + kfree ( tmpstr ); <nl> return rc ; <nl> } <nl>  <nl> static int __proc_dobitmasks ( void * data , int write , <nl> * mask |= D_EMERG ; <nl> } <nl>  <nl> - cfs_trace_free_string_buffer ( tmpstr , tmpstrlen ); <nl> + kfree ( tmpstr ); <nl> return rc ; <nl> } <nl> 
mmm sound / core / timer . c <nl> ppp sound / core / timer . c <nl> static void snd_timer_user_tinterrupt ( struct snd_timer_instance * timeri , <nl> } <nl> if (( tu -> filter & ( 1 << SNDRV_TIMER_EVENT_RESOLUTION )) && <nl> tu -> last_resolution != resolution ) { <nl> + memset (& r1 , 0 , sizeof ( r1 )); <nl> r1 . event = SNDRV_TIMER_EVENT_RESOLUTION ; <nl> r1 . tstamp = tstamp ; <nl> r1 . val = resolution ;
mmm drivers / cdrom / cdrom . c <nl> ppp drivers / cdrom / cdrom . c <nl> static int cdrom_ioctl_select_disc ( struct cdrom_device_info * cdi , <nl> return - ENOSYS ; <nl>  <nl> if ( arg != CDSL_CURRENT && arg != CDSL_NONE ) { <nl> - if (( int ) arg >= cdi -> capacity ) <nl> + if ( arg >= cdi -> capacity ) <nl> return - EINVAL ; <nl> } <nl> 
mmm drivers / net / vmxnet3 / vmxnet3_ethtool . c <nl> ppp drivers / net / vmxnet3 / vmxnet3_ethtool . c <nl> vmxnet3_set_ringparam ( struct net_device * netdev , <nl> VMXNET3_RX_RING_MAX_SIZE ) <nl> return - EINVAL ; <nl>  <nl> + /* if adapter not yet initialized , do nothing */ <nl> + if ( adapter -> rx_buf_per_pkt == 0 ) { <nl> + netdev_err ( netdev , " adapter not completely initialized , " <nl> + " ring size cannot be changed yet \ n "); <nl> + return - EOPNOTSUPP ; <nl> + } <nl>  <nl> /* round it up to a multiple of VMXNET3_RING_SIZE_ALIGN */ <nl> new_tx_ring_size = ( param -> tx_pending + VMXNET3_RING_SIZE_MASK ) &mmm drivers / net / vmxnet3 / vmxnet3_drv . c <nl> ppp drivers / net / vmxnet3 / vmxnet3_drv . c <nl> vmxnet3_set_ringparam ( struct net_device * netdev , <nl> VMXNET3_RX_RING_MAX_SIZE ) <nl> return - EINVAL ; <nl>  <nl> + /* if adapter not yet initialized , do nothing */ <nl> + if ( adapter -> rx_buf_per_pkt == 0 ) { <nl> + netdev_err ( netdev , " adapter not completely initialized , " <nl> + " ring size cannot be changed yet \ n "); <nl> + return - EOPNOTSUPP ; <nl> + } <nl>  <nl> /* round it up to a multiple of VMXNET3_RING_SIZE_ALIGN */ <nl> new_tx_ring_size = ( param -> tx_pending + VMXNET3_RING_SIZE_MASK ) & <nl> vmxnet3_probe_device ( struct pci_dev * pdev , <nl>  <nl> adapter -> num_rx_queues = num_rx_queues ; <nl> adapter -> num_tx_queues = num_tx_queues ; <nl> + adapter -> rx_buf_per_pkt = 1 ; <nl>  <nl> size = sizeof ( struct Vmxnet3_TxQueueDesc ) * adapter -> num_tx_queues ; <nl> size += sizeof ( struct Vmxnet3_RxQueueDesc ) * adapter -> num_rx_queues ;mmm drivers / net / vmxnet3 / vmxnet3_int . h <nl> ppp drivers / net / vmxnet3 / vmxnet3_int . h <nl> vmxnet3_set_ringparam ( struct net_device * netdev , <nl> VMXNET3_RX_RING_MAX_SIZE ) <nl> return - EINVAL ; <nl>  <nl> + /* if adapter not yet initialized , do nothing */ <nl> + if ( adapter -> rx_buf_per_pkt == 0 ) { <nl> + netdev_err ( netdev , " adapter not completely initialized , " <nl> + " ring size cannot be changed yet \ n "); <nl> + return - EOPNOTSUPP ; <nl> + } <nl>  <nl> /* round it up to a multiple of VMXNET3_RING_SIZE_ALIGN */ <nl> new_tx_ring_size = ( param -> tx_pending + VMXNET3_RING_SIZE_MASK ) & <nl> vmxnet3_probe_device ( struct pci_dev * pdev , <nl>  <nl> adapter -> num_rx_queues = num_rx_queues ; <nl> adapter -> num_tx_queues = num_tx_queues ; <nl> + adapter -> rx_buf_per_pkt = 1 ; <nl>  <nl> size = sizeof ( struct Vmxnet3_TxQueueDesc ) * adapter -> num_tx_queues ; <nl> size += sizeof ( struct Vmxnet3_RxQueueDesc ) * adapter -> num_rx_queues ; <nl> /* <nl> * Version numbers <nl> */ <nl> -# define VMXNET3_DRIVER_VERSION_STRING " 1 . 1 . 29 . 0 - k " <nl> +# define VMXNET3_DRIVER_VERSION_STRING " 1 . 1 . 30 . 0 - k " <nl>  <nl> /* a 32 - bit int , each byte encode a verion number in VMXNET3_DRIVER_VERSION */ <nl> -# define VMXNET3_DRIVER_VERSION_NUM 0x01011D00 <nl> +# define VMXNET3_DRIVER_VERSION_NUM 0x01011E00 <nl>  <nl> # if defined ( CONFIG_PCI_MSI ) <nl> /* RSS only makes sense if MSI - X is supported . */
mmm mm / memory . c <nl> ppp mm / memory . c <nl> int handle_mm_fault ( struct mm_struct * mm , struct vm_area_struct * vma , <nl> if ( pmd_trans_huge ( orig_pmd )) { <nl> unsigned int dirty = flags & FAULT_FLAG_WRITE ; <nl>  <nl> + /* <nl> + * If the pmd is splitting , return and retry the <nl> + * the fault . Alternative : wait until the split <nl> + * is done , and goto retry . <nl> + */ <nl> + if ( pmd_trans_splitting ( orig_pmd )) <nl> + return 0 ; <nl> + <nl> if ( pmd_numa ( orig_pmd )) <nl> return do_huge_pmd_numa_page ( mm , vma , address , <nl> orig_pmd , pmd );
mmm drivers / net / hyperv / netvsc . c <nl> ppp drivers / net / hyperv / netvsc . c <nl> static int netvsc_init_buf ( struct hv_device * device ) <nl> net_device -> map_words = DIV_ROUND_UP ( net_device -> send_section_cnt , <nl> BITS_PER_LONG ); <nl>  <nl> - net_device -> send_section_map = <nl> - kzalloc ( net_device -> map_words * sizeof ( ulong ), GFP_KERNEL ); <nl> + net_device -> send_section_map = kcalloc ( net_device -> map_words , <nl> + sizeof ( ulong ), GFP_KERNEL ); <nl> if ( net_device -> send_section_map == NULL ) { <nl> ret = - ENOMEM ; <nl> goto cleanup ;
mmm net / core / sock . c <nl> ppp net / core / sock . c <nl> EXPORT_SYMBOL ( sock_kmalloc ); <nl> */ <nl> void sock_kfree_s ( struct sock * sk , void * mem , int size ) <nl> { <nl> + if ( WARN_ON_ONCE (! mem )) <nl> + return ; <nl> kfree ( mem ); <nl> atomic_sub ( size , & sk -> sk_omem_alloc ); <nl> }
mmm fs / proc / root . c <nl> ppp fs / proc / root . c <nl> static struct dentry * proc_mount ( struct file_system_type * fs_type , <nl> if ( IS_ERR ( sb )) <nl> return ERR_CAST ( sb ); <nl>  <nl> + /* <nl> + * procfs isn ' t actually a stacking filesystem ; however , there is <nl> + * too much magic going on inside it to permit stacking things on <nl> + * top of it <nl> + */ <nl> + sb -> s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH ; <nl> + <nl> if (! proc_parse_options ( options , ns )) { <nl> deactivate_locked_super ( sb ); <nl> return ERR_PTR (- EINVAL );
mmm drivers / net / ethernet / intel / i40e / i40e_main . c <nl> ppp drivers / net / ethernet / intel / i40e / i40e_main . c <nl> static void i40e_service_task ( struct work_struct * work ) <nl> service_task ); <nl> unsigned long start_time = jiffies ; <nl>  <nl> + /* don ' t bother with service tasks if a reset is in progress */ <nl> + if ( test_bit ( __I40E_RESET_RECOVERY_PENDING , & pf -> state )) { <nl> + i40e_service_event_complete ( pf ); <nl> + return ; <nl> + } <nl> + <nl> i40e_reset_subtask ( pf ); <nl> i40e_handle_mdd_event ( pf ); <nl> i40e_vc_process_vflr_event ( pf );
mmm arch / arm / mach - sa1100 / cpu - sa1110 . c <nl> ppp arch / arm / mach - sa1100 / cpu - sa1110 . c <nl> static int __init sa1110_clk_init ( void ) <nl> struct sdram_params * sdram ; <nl> const char * name = sdram_name ; <nl>  <nl> + if (! cpu_is_sa1110 ()) <nl> + return - ENODEV ; <nl> + <nl> if (! name [ 0 ]) { <nl> if ( machine_is_assabet ()) <nl> name = " TC59SM716 - CL3 ";
mmm drivers / net / wireless / ath / ath10k / wmi . c <nl> ppp drivers / net / wireless / ath / ath10k / wmi . c <nl> ath10k_wmi_10_4_gen_update_fw_tdls_state ( struct ath10k * ar , u32 vdev_id , <nl> if (! skb ) <nl> return ERR_PTR (- ENOMEM ); <nl>  <nl> - if ( test_bit ( WMI_SERVICE_TDLS_EXPLICIT_MODE_ONLY , ar -> wmi . svc_map )) <nl> + if ( test_bit ( WMI_SERVICE_TDLS_EXPLICIT_MODE_ONLY , ar -> wmi . svc_map ) && <nl> + state == WMI_TDLS_ENABLE_ACTIVE ) <nl> state = WMI_TDLS_ENABLE_PASSIVE ; <nl>  <nl> if ( test_bit ( WMI_SERVICE_TDLS_UAPSD_BUFFER_STA , ar -> wmi . svc_map ))
mmm drivers / power / max17042_battery . c <nl> ppp drivers / power / max17042_battery . c <nl> static int __devinit max17042_probe ( struct i2c_client * client , <nl> reg |= CONFIG_ALRT_BIT_ENBL ; <nl> max17042_write_reg ( client , MAX17042_CONFIG , reg ); <nl> max17042_set_soc_threshold ( chip , 1 ); <nl> - } else <nl> + } else { <nl> + client -> irq = 0 ; <nl> dev_err (& client -> dev , "% s (): cannot get IRQ \ n ", <nl> __func__ ); <nl> + } <nl> } <nl>  <nl> reg = max17042_read_reg ( chip -> client , MAX17042_STATUS );
mmm drivers / mtd / mtdpart . c <nl> ppp drivers / mtd / mtdpart . c <nl> int add_mtd_partitions ( struct mtd_info * master , <nl>  <nl> for ( i = 0 ; i < nbparts ; i ++) { <nl> slave = allocate_partition ( master , parts + i , i , cur_offset ); <nl> - if ( IS_ERR ( slave )) <nl> + if ( IS_ERR ( slave )) { <nl> + del_mtd_partitions ( master ); <nl> return PTR_ERR ( slave ); <nl> + } <nl>  <nl> mutex_lock (& mtd_partitions_mutex ); <nl> list_add (& slave -> list , & mtd_partitions );
mmm arch / powerpc / platforms / cell / spufs / sched . c <nl> ppp arch / powerpc / platforms / cell / spufs / sched . c <nl> void spu_deactivate ( struct spu_context * ctx ) <nl> */ <nl> void spu_yield ( struct spu_context * ctx ) <nl> { <nl> - mutex_lock (& ctx -> state_mutex ); <nl> - __spu_deactivate ( ctx , 0 , MAX_PRIO ); <nl> - mutex_unlock (& ctx -> state_mutex ); <nl> + if (!( ctx -> flags & SPU_CREATE_NOSCHED )) { <nl> + mutex_lock (& ctx -> state_mutex ); <nl> + __spu_deactivate ( ctx , 0 , MAX_PRIO ); <nl> + mutex_unlock (& ctx -> state_mutex ); <nl> + } <nl> } <nl>  <nl> void spu_sched_tick ( struct work_struct * work )
mmm drivers / gpu / drm / vmwgfx / vmwgfx_kms . c <nl> ppp drivers / gpu / drm / vmwgfx / vmwgfx_kms . c <nl> int vmw_du_crtc_cursor_set ( struct drm_crtc * crtc , struct drm_file * file_priv , <nl> if (! ret ) { <nl> if (! surface -> snooper . image ) { <nl> DRM_ERROR (" surface not suitable for cursor \ n "); <nl> + vmw_surface_unreference (& surface ); <nl> return - EINVAL ; <nl> } <nl> } else {
mmm drivers / net / ethernet / mellanox / mlx4 / resource_tracker . c <nl> ppp drivers / net / ethernet / mellanox / mlx4 / resource_tracker . c <nl> static void adjust_proxy_tun_qkey ( struct mlx4_dev * dev , struct mlx4_vhcr * vhcr , <nl> context -> qkey = cpu_to_be32 ( qkey ); <nl> } <nl>  <nl> + static int adjust_qp_sched_queue ( struct mlx4_dev * dev , int slave , <nl> + struct mlx4_qp_context * qpc , <nl> + struct mlx4_cmd_mailbox * inbox ); <nl> + <nl> int mlx4_RST2INIT_QP_wrapper ( struct mlx4_dev * dev , int slave , <nl> struct mlx4_vhcr * vhcr , <nl> struct mlx4_cmd_mailbox * inbox , <nl> int mlx4_RST2INIT_QP_wrapper ( struct mlx4_dev * dev , int slave , <nl> struct res_srq * srq ; <nl> int local_qpn = be32_to_cpu ( qpc -> local_qpn ) & 0xffffff ; <nl>  <nl> + err = adjust_qp_sched_queue ( dev , slave , qpc , inbox ); <nl> + if ( err ) <nl> + return err ; <nl> + <nl> err = qp_res_start_move_to ( dev , slave , qpn , RES_QP_HW , & qp , 0 ); <nl> if ( err ) <nl> return err ;
mmm drivers / usb / core / quirks . c <nl> ppp drivers / usb / core / quirks . c <nl> static const struct usb_device_id usb_quirk_list [] = { <nl> { USB_DEVICE ( 0x0b05 , 0x17e0 ), . driver_info = <nl> USB_QUIRK_IGNORE_REMOTE_WAKEUP }, <nl>  <nl> + /* Protocol and OTG Electrical Test Device */ <nl> + { USB_DEVICE ( 0x1a0a , 0x0200 ), . driver_info = <nl> + USB_QUIRK_LINEAR_UFRAME_INTR_BINTERVAL }, <nl> + <nl> { } /* terminating entry must be last */ <nl> }; <nl> mmm drivers / usb / core / otg_whitelist . h <nl> ppp drivers / usb / core / otg_whitelist . h <nl> static const struct usb_device_id usb_quirk_list [] = { <nl> { USB_DEVICE ( 0x0b05 , 0x17e0 ), . driver_info = <nl> USB_QUIRK_IGNORE_REMOTE_WAKEUP }, <nl>  <nl> + /* Protocol and OTG Electrical Test Device */ <nl> + { USB_DEVICE ( 0x1a0a , 0x0200 ), . driver_info = <nl> + USB_QUIRK_LINEAR_UFRAME_INTR_BINTERVAL }, <nl> + <nl> { } /* terminating entry must be last */ <nl> }; <nl>  <nl> static int is_targeted ( struct usb_device * dev ) <nl> le16_to_cpu ( dev -> descriptor . idProduct ) == 0xbadd )) <nl> return 0 ; <nl>  <nl> + /* OTG PET device is always targeted ( see OTG 2 . 0 ECN 6 . 4 . 2 ) */ <nl> + if (( le16_to_cpu ( dev -> descriptor . idVendor ) == 0x1a0a && <nl> + le16_to_cpu ( dev -> descriptor . idProduct ) == 0x0200 )) <nl> + return 1 ; <nl> + <nl> /* NOTE : can ' t use usb_match_id () since interface caches <nl> * aren ' t set up yet . this is cut / paste from that code . <nl> */
mmm net / netfilter / nf_tables_api . c <nl> ppp net / netfilter / nf_tables_api . c <nl> static int nf_tables_delflowtable ( struct net * net , struct sock * nlsk , <nl> struct nft_table * table ; <nl> struct nft_ctx ctx ; <nl>  <nl> + if (! nla [ NFTA_FLOWTABLE_TABLE ] || <nl> + (! nla [ NFTA_FLOWTABLE_NAME ] && <nl> + ! nla [ NFTA_FLOWTABLE_HANDLE ])) <nl> + return - EINVAL ; <nl> + <nl> table = nf_tables_table_lookup ( net , nla [ NFTA_FLOWTABLE_TABLE ], <nl> family , genmask ); <nl> if ( IS_ERR ( table ))
mmm sound / soc / soc - jack . c <nl> ppp sound / soc / soc - jack . c <nl> int snd_soc_jack_add_gpios ( struct snd_soc_jack * jack , int count , <nl> goto undo ; <nl> } <nl>  <nl> - if ( gpios [ i ]. gpiod_dev ) { <nl> - /* GPIO descriptor */ <nl> + if ( gpios [ i ]. desc ) { <nl> + /* Already have a GPIO descriptor . */ <nl> + goto got_gpio ; <nl> + } else if ( gpios [ i ]. gpiod_dev ) { <nl> + /* Get a GPIO descriptor */ <nl> gpios [ i ]. desc = gpiod_get_index ( gpios [ i ]. gpiod_dev , <nl> gpios [ i ]. name , <nl> gpios [ i ]. idx , GPIOD_IN ); <nl> int snd_soc_jack_add_gpios ( struct snd_soc_jack * jack , int count , <nl>  <nl> gpios [ i ]. desc = gpio_to_desc ( gpios [ i ]. gpio ); <nl> } <nl> - <nl> + got_gpio : <nl> INIT_DELAYED_WORK (& gpios [ i ]. work , gpio_work ); <nl> gpios [ i ]. jack = jack ; <nl> 
mmm net / netfilter / xt_time . c <nl> ppp net / netfilter / xt_time . c <nl> static struct xt_match xt_time_mt_reg __read_mostly = { <nl>  <nl> static int __init time_mt_init ( void ) <nl> { <nl> + int minutes = sys_tz . tz_minuteswest ; <nl> + <nl> + if ( minutes < 0 ) /* east of Greenwich */ <nl> + printk ( KERN_INFO KBUILD_MODNAME <nl> + ": kernel timezone is +% 02d % 02d \ n ", <nl> + - minutes / 60 , - minutes % 60 ); <nl> + else /* west of Greenwich */ <nl> + printk ( KERN_INFO KBUILD_MODNAME <nl> + ": kernel timezone is -% 02d % 02d \ n ", <nl> + minutes / 60 , minutes % 60 ); <nl> + <nl> return xt_register_match (& xt_time_mt_reg ); <nl> } <nl> 
mmm drivers / media / platform / coda / coda - bit . c <nl> ppp drivers / media / platform / coda / coda - bit . c <nl> static int coda_alloc_framebuffers ( struct coda_ctx * ctx , <nl> dev -> devtype -> product != CODA_DX6 ) <nl> size += ysize / 4 ; <nl> name = kasprintf ( GFP_KERNEL , " fb % d ", i ); <nl> + if (! name ) { <nl> + coda_free_framebuffers ( ctx ); <nl> + return - ENOMEM ; <nl> + } <nl> ret = coda_alloc_context_buf ( ctx , & ctx -> internal_frames [ i ], <nl> size , name ); <nl> kfree ( name );
mmm net / mac80211 / iface . c <nl> ppp net / mac80211 / iface . c <nl> int ieee80211_if_add ( struct ieee80211_local * local , const char * name , <nl>  <nl> ret = dev_alloc_name ( ndev , ndev -> name ); <nl> if ( ret < 0 ) { <nl> - free_netdev ( ndev ); <nl> + ieee80211_if_free ( ndev ); <nl> return ret ; <nl> } <nl>  <nl> int ieee80211_if_add ( struct ieee80211_local * local , const char * name , <nl>  <nl> ret = register_netdevice ( ndev ); <nl> if ( ret ) { <nl> - free_netdev ( ndev ); <nl> + ieee80211_if_free ( ndev ); <nl> return ret ; <nl> } <nl> }
mmm arch / x86_64 / kernel / pci - calgary . c <nl> ppp arch / x86_64 / kernel / pci - calgary . c <nl> void * calgary_alloc_coherent ( struct device * dev , size_t size , <nl> return ret ; <nl> } <nl>  <nl> - static struct dma_mapping_ops calgary_dma_ops = { <nl> + static const struct dma_mapping_ops calgary_dma_ops = { <nl> . alloc_coherent = calgary_alloc_coherent , <nl> . map_single = calgary_map_single , <nl> . unmap_single = calgary_unmap_single ,mmm include / asm - x86_64 / dma - mapping . h <nl> ppp include / asm - x86_64 / dma - mapping . h <nl> void * calgary_alloc_coherent ( struct device * dev , size_t size , <nl> return ret ; <nl> } <nl>  <nl> - static struct dma_mapping_ops calgary_dma_ops = { <nl> + static const struct dma_mapping_ops calgary_dma_ops = { <nl> . alloc_coherent = calgary_alloc_coherent , <nl> . map_single = calgary_map_single , <nl> . unmap_single = calgary_unmap_single , <nl> struct dma_mapping_ops { <nl> }; <nl>  <nl> extern dma_addr_t bad_dma_address ; <nl> - extern struct dma_mapping_ops * dma_ops ; <nl> + extern const struct dma_mapping_ops * dma_ops ; <nl> extern int iommu_merge ; <nl>  <nl> static inline int dma_mapping_error ( dma_addr_t dma_addr )mmm arch / x86_64 / mm / init . c <nl> ppp arch / x86_64 / mm / init . c <nl> void * calgary_alloc_coherent ( struct device * dev , size_t size , <nl> return ret ; <nl> } <nl>  <nl> - static struct dma_mapping_ops calgary_dma_ops = { <nl> + static const struct dma_mapping_ops calgary_dma_ops = { <nl> . alloc_coherent = calgary_alloc_coherent , <nl> . map_single = calgary_map_single , <nl> . unmap_single = calgary_unmap_single , <nl> struct dma_mapping_ops { <nl> }; <nl>  <nl> extern dma_addr_t bad_dma_address ; <nl> - extern struct dma_mapping_ops * dma_ops ; <nl> + extern const struct dma_mapping_ops * dma_ops ; <nl> extern int iommu_merge ; <nl>  <nl> static inline int dma_mapping_error ( dma_addr_t dma_addr ) <nl> # define Dprintk ( x ...) <nl> # endif <nl>  <nl> - struct dma_mapping_ops * dma_ops ; <nl> + const struct dma_mapping_ops * dma_ops ; <nl> EXPORT_SYMBOL ( dma_ops ); <nl>  <nl> static unsigned long dma_reserve __initdata ;mmm arch / x86_64 / kernel / pci - swiotlb . c <nl> ppp arch / x86_64 / kernel / pci - swiotlb . c <nl> void * calgary_alloc_coherent ( struct device * dev , size_t size , <nl> return ret ; <nl> } <nl>  <nl> - static struct dma_mapping_ops calgary_dma_ops = { <nl> + static const struct dma_mapping_ops calgary_dma_ops = { <nl> . alloc_coherent = calgary_alloc_coherent , <nl> . map_single = calgary_map_single , <nl> . unmap_single = calgary_unmap_single , <nl> struct dma_mapping_ops { <nl> }; <nl>  <nl> extern dma_addr_t bad_dma_address ; <nl> - extern struct dma_mapping_ops * dma_ops ; <nl> + extern const struct dma_mapping_ops * dma_ops ; <nl> extern int iommu_merge ; <nl>  <nl> static inline int dma_mapping_error ( dma_addr_t dma_addr ) <nl> # define Dprintk ( x ...) <nl> # endif <nl>  <nl> - struct dma_mapping_ops * dma_ops ; <nl> + const struct dma_mapping_ops * dma_ops ; <nl> EXPORT_SYMBOL ( dma_ops ); <nl>  <nl> static unsigned long dma_reserve __initdata ; <nl> int swiotlb __read_mostly ; <nl> EXPORT_SYMBOL ( swiotlb ); <nl>  <nl> - struct dma_mapping_ops swiotlb_dma_ops = { <nl> + const struct dma_mapping_ops swiotlb_dma_ops = { <nl> . mapping_error = swiotlb_dma_mapping_error , <nl> . alloc_coherent = swiotlb_alloc_coherent , <nl> . free_coherent = swiotlb_free_coherent ,mmm arch / x86_64 / kernel / pci - nommu . c <nl> ppp arch / x86_64 / kernel / pci - nommu . c <nl> void * calgary_alloc_coherent ( struct device * dev , size_t size , <nl> return ret ; <nl> } <nl>  <nl> - static struct dma_mapping_ops calgary_dma_ops = { <nl> + static const struct dma_mapping_ops calgary_dma_ops = { <nl> . alloc_coherent = calgary_alloc_coherent , <nl> . map_single = calgary_map_single , <nl> . unmap_single = calgary_unmap_single , <nl> struct dma_mapping_ops { <nl> }; <nl>  <nl> extern dma_addr_t bad_dma_address ; <nl> - extern struct dma_mapping_ops * dma_ops ; <nl> + extern const struct dma_mapping_ops * dma_ops ; <nl> extern int iommu_merge ; <nl>  <nl> static inline int dma_mapping_error ( dma_addr_t dma_addr ) <nl> # define Dprintk ( x ...) <nl> # endif <nl>  <nl> - struct dma_mapping_ops * dma_ops ; <nl> + const struct dma_mapping_ops * dma_ops ; <nl> EXPORT_SYMBOL ( dma_ops ); <nl>  <nl> static unsigned long dma_reserve __initdata ; <nl> int swiotlb __read_mostly ; <nl> EXPORT_SYMBOL ( swiotlb ); <nl>  <nl> - struct dma_mapping_ops swiotlb_dma_ops = { <nl> + const struct dma_mapping_ops swiotlb_dma_ops = { <nl> . mapping_error = swiotlb_dma_mapping_error , <nl> . alloc_coherent = swiotlb_alloc_coherent , <nl> . free_coherent = swiotlb_free_coherent , <nl> void nommu_unmap_sg ( struct device * dev , struct scatterlist * sg , <nl> { <nl> } <nl>  <nl> - struct dma_mapping_ops nommu_dma_ops = { <nl> + const struct dma_mapping_ops nommu_dma_ops = { <nl> . map_single = nommu_map_single , <nl> . unmap_single = nommu_unmap_single , <nl> . map_sg = nommu_map_sg ,mmm arch / x86_64 / kernel / pci - gart . c <nl> ppp arch / x86_64 / kernel / pci - gart . c <nl> void * calgary_alloc_coherent ( struct device * dev , size_t size , <nl> return ret ; <nl> } <nl>  <nl> - static struct dma_mapping_ops calgary_dma_ops = { <nl> + static const struct dma_mapping_ops calgary_dma_ops = { <nl> . alloc_coherent = calgary_alloc_coherent , <nl> . map_single = calgary_map_single , <nl> . unmap_single = calgary_unmap_single , <nl> struct dma_mapping_ops { <nl> }; <nl>  <nl> extern dma_addr_t bad_dma_address ; <nl> - extern struct dma_mapping_ops * dma_ops ; <nl> + extern const struct dma_mapping_ops * dma_ops ; <nl> extern int iommu_merge ; <nl>  <nl> static inline int dma_mapping_error ( dma_addr_t dma_addr ) <nl> # define Dprintk ( x ...) <nl> # endif <nl>  <nl> - struct dma_mapping_ops * dma_ops ; <nl> + const struct dma_mapping_ops * dma_ops ; <nl> EXPORT_SYMBOL ( dma_ops ); <nl>  <nl> static unsigned long dma_reserve __initdata ; <nl> int swiotlb __read_mostly ; <nl> EXPORT_SYMBOL ( swiotlb ); <nl>  <nl> - struct dma_mapping_ops swiotlb_dma_ops = { <nl> + const struct dma_mapping_ops swiotlb_dma_ops = { <nl> . mapping_error = swiotlb_dma_mapping_error , <nl> . alloc_coherent = swiotlb_alloc_coherent , <nl> . free_coherent = swiotlb_free_coherent , <nl> void nommu_unmap_sg ( struct device * dev , struct scatterlist * sg , <nl> { <nl> } <nl>  <nl> - struct dma_mapping_ops nommu_dma_ops = { <nl> + const struct dma_mapping_ops nommu_dma_ops = { <nl> . map_single = nommu_map_single , <nl> . unmap_single = nommu_unmap_single , <nl> . map_sg = nommu_map_sg , <nl> static __init int init_k8_gatt ( struct agp_kern_info * info ) <nl>  <nl> extern int agp_amd64_init ( void ); <nl>  <nl> - static struct dma_mapping_ops gart_dma_ops = { <nl> + static const struct dma_mapping_ops gart_dma_ops = { <nl> . mapping_error = NULL , <nl> . map_single = gart_map_single , <nl> . map_simple = gart_map_simple ,
mmm drivers / media / video / cx23885 / cx23885 - dvb . c <nl> ppp drivers / media / video / cx23885 / cx23885 - dvb . c <nl> int cx23885_dvb_unregister ( struct cx23885_tsport * port ) <nl> * implement MFE support . <nl> */ <nl> fe0 = videobuf_dvb_get_frontend (& port -> frontends , 1 ); <nl> - if ( fe0 -> dvb . frontend ) <nl> + if ( fe0 && fe0 -> dvb . frontend ) <nl> videobuf_dvb_unregister_bus (& port -> frontends ); <nl>  <nl> switch ( port -> dev -> board ) {
mmm drivers / video / console / fbcon . c <nl> ppp drivers / video / console / fbcon . c <nl> static void fbcon_deinit ( struct vc_data * vc ) <nl> finished : <nl>  <nl> fbcon_free_font ( p , free_font ); <nl> + if ( free_font ) <nl> + vc -> vc_font . data = NULL ; <nl>  <nl> if (! con_is_bound (& fb_con )) <nl> fbcon_exit ();
mmm drivers / gpu / drm / amd / display / dc / core / dc_resource . c <nl> ppp drivers / gpu / drm / amd / display / dc / core / dc_resource . c <nl> static void set_avi_info_frame ( <nl> info_packet -> hb2 = <nl> info_frame . avi_info_packet . info_packet_hdmi . packet_raw_data . hb2 ; <nl>  <nl> - for ( byte_index = 0 ; byte_index < sizeof ( info_packet -> sb ); byte_index ++) <nl> + for ( byte_index = 0 ; byte_index < sizeof ( info_frame . avi_info_packet . <nl> + info_packet_hdmi . packet_raw_data . sb ); byte_index ++) <nl> info_packet -> sb [ byte_index ] = info_frame . avi_info_packet . <nl> - info_packet_hdmi . packet_raw_data . sb [ byte_index ]; <nl> + info_packet_hdmi . packet_raw_data . sb [ byte_index ]; <nl>  <nl> info_packet -> valid = true ; <nl> }
mmm kernel / fork . c <nl> ppp kernel / fork . c <nl> static struct task_struct * copy_process ( unsigned long clone_flags , <nl> if (( clone_flags & ( CLONE_NEWNS | CLONE_FS )) == ( CLONE_NEWNS | CLONE_FS )) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> + if (( clone_flags & ( CLONE_NEWUSER | CLONE_FS )) == ( CLONE_NEWUSER | CLONE_FS )) <nl> + return ERR_PTR (- EINVAL ); <nl> + <nl> /* <nl> * Thread groups must share signals as well , and detached threads <nl> * can only be started up within the thread group . <nl> SYSCALL_DEFINE1 ( unshare , unsigned long , unshare_flags ) <nl> * If unsharing a user namespace must also unshare the thread . <nl> */ <nl> if ( unshare_flags & CLONE_NEWUSER ) <nl> - unshare_flags |= CLONE_THREAD ; <nl> + unshare_flags |= CLONE_THREAD | CLONE_FS ; <nl> /* <nl> * If unsharing a pid namespace must also unshare the thread . <nl> */mmm kernel / user_namespace . c <nl> ppp kernel / user_namespace . c <nl> static struct task_struct * copy_process ( unsigned long clone_flags , <nl> if (( clone_flags & ( CLONE_NEWNS | CLONE_FS )) == ( CLONE_NEWNS | CLONE_FS )) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> + if (( clone_flags & ( CLONE_NEWUSER | CLONE_FS )) == ( CLONE_NEWUSER | CLONE_FS )) <nl> + return ERR_PTR (- EINVAL ); <nl> + <nl> /* <nl> * Thread groups must share signals as well , and detached threads <nl> * can only be started up within the thread group . <nl> SYSCALL_DEFINE1 ( unshare , unsigned long , unshare_flags ) <nl> * If unsharing a user namespace must also unshare the thread . <nl> */ <nl> if ( unshare_flags & CLONE_NEWUSER ) <nl> - unshare_flags |= CLONE_THREAD ; <nl> + unshare_flags |= CLONE_THREAD | CLONE_FS ; <nl> /* <nl> * If unsharing a pid namespace must also unshare the thread . <nl> */ <nl> # include < linux / uaccess . h > <nl> # include < linux / ctype . h > <nl> # include < linux / projid . h > <nl> +# include < linux / fs_struct . h > <nl>  <nl> static struct kmem_cache * user_ns_cachep __read_mostly ; <nl>  <nl> static int userns_install ( struct nsproxy * nsproxy , void * ns ) <nl> if ( atomic_read (& current -> mm -> mm_users ) > 1 ) <nl> return - EINVAL ; <nl>  <nl> + if ( current -> fs -> users != 1 ) <nl> + return - EINVAL ; <nl> + <nl> if (! ns_capable ( user_ns , CAP_SYS_ADMIN )) <nl> return - EPERM ; <nl> 
mmm drivers / net / macvlan . c <nl> ppp drivers / net / macvlan . c <nl> static void macvlan_process_broadcast ( struct work_struct * w ) <nl> static void macvlan_broadcast_enqueue ( struct macvlan_port * port , <nl> struct sk_buff * skb ) <nl> { <nl> + struct sk_buff * nskb ; <nl> int err = - ENOMEM ; <nl>  <nl> - skb = skb_clone ( skb , GFP_ATOMIC ); <nl> - if (! skb ) <nl> + nskb = skb_clone ( skb , GFP_ATOMIC ); <nl> + if (! nskb ) <nl> goto err ; <nl>  <nl> spin_lock (& port -> bc_queue . lock ); <nl> if ( skb_queue_len (& port -> bc_queue ) < skb -> dev -> tx_queue_len ) { <nl> - __skb_queue_tail (& port -> bc_queue , skb ); <nl> + __skb_queue_tail (& port -> bc_queue , nskb ); <nl> err = 0 ; <nl> } <nl> spin_unlock (& port -> bc_queue . lock ); <nl>  <nl> if ( err ) <nl> - goto err ; <nl> + goto free_nskb ; <nl>  <nl> schedule_work (& port -> bc_work ); <nl> return ; <nl>  <nl> + free_nskb : <nl> + kfree_skb ( nskb ); <nl> err : <nl> atomic_long_inc (& skb -> dev -> rx_dropped ); <nl> }
mmm fs / io_uring . c <nl> ppp fs / io_uring . c <nl> static __cold void io_flush_timeouts ( struct io_ring_ctx * ctx ) <nl> __must_hold (& ctx -> completion_lock ) <nl> { <nl> u32 seq = ctx -> cached_cq_tail - atomic_read (& ctx -> cq_timeouts ); <nl> + struct io_kiocb * req , * tmp ; <nl>  <nl> spin_lock_irq (& ctx -> timeout_lock ); <nl> - while (! list_empty (& ctx -> timeout_list )) { <nl> + list_for_each_entry_safe ( req , tmp , & ctx -> timeout_list , timeout . list ) { <nl> u32 events_needed , events_got ; <nl> - struct io_kiocb * req = list_first_entry (& ctx -> timeout_list , <nl> - struct io_kiocb , timeout . list ); <nl>  <nl> if ( io_is_timeout_noseq ( req )) <nl> break ; <nl> static __cold void io_flush_timeouts ( struct io_ring_ctx * ctx ) <nl> if ( events_got < events_needed ) <nl> break ; <nl>  <nl> - list_del_init (& req -> timeout . list ); <nl> io_kill_timeout ( req , 0 ); <nl> } <nl> ctx -> cq_last_tm_flush = seq ; <nl> static int io_timeout_prep ( struct io_kiocb * req , const struct io_uring_sqe * sqe , <nl> if ( data -> ts . tv_sec < 0 || data -> ts . tv_nsec < 0 ) <nl> return - EINVAL ; <nl>  <nl> + INIT_LIST_HEAD (& req -> timeout . list ); <nl> data -> mode = io_translate_timeout_mode ( flags ); <nl> hrtimer_init (& data -> timer , io_timeout_get_clock ( data ), data -> mode ); <nl> 
mmm net / socket . c <nl> ppp net / socket . c <nl> static ssize_t sock_sendpage ( struct file * file , struct page * page , <nl> if ( more ) <nl> flags |= MSG_MORE ; <nl>  <nl> - return sock -> ops -> sendpage ( sock , page , offset , size , flags ); <nl> + return kernel_sendpage ( sock , page , offset , size , flags ); <nl> } <nl>  <nl> static ssize_t sock_splice_read ( struct file * file , loff_t * ppos ,
mmm kernel / sched . c <nl> ppp kernel / sched . c <nl> static inline void ttwu_post_activation ( struct task_struct * p , struct rq * rq , <nl> if ( p -> sched_class -> task_woken ) <nl> p -> sched_class -> task_woken ( rq , p ); <nl>  <nl> - if ( unlikely ( rq -> idle_stamp )) { <nl> + if ( rq -> idle_stamp ) { <nl> u64 delta = rq -> clock - rq -> idle_stamp ; <nl> u64 max = 2 * sysctl_sched_migration_cost ; <nl> 
mmm drivers / ssb / main . c <nl> ppp drivers / ssb / main . c <nl> static int __init ssb_modinit ( void ) <nl> ssb_buses_lock (); <nl> err = ssb_attach_queued_buses (); <nl> ssb_buses_unlock (); <nl> - if ( err ) <nl> + if ( err ) { <nl> bus_unregister (& ssb_bustype ); <nl> + goto out ; <nl> + } <nl>  <nl> err = b43_pci_ssb_bridge_init (); <nl> if ( err ) { <nl> static int __init ssb_modinit ( void ) <nl> /* don ' t fail SSB init because of this */ <nl> err = 0 ; <nl> } <nl> - <nl> + out : <nl> return err ; <nl> } <nl> /* ssb must be initialized after PCI but before the ssb drivers .
mmm include / linux / fsnotify_backend . h <nl> ppp include / linux / fsnotify_backend . h <nl> static inline void __fsnotify_update_dcache_flags ( struct dentry * dentry ) <nl> assert_spin_locked (& dentry -> d_lock ); <nl>  <nl> parent = dentry -> d_parent ; <nl> - if ( fsnotify_inode_watches_children ( parent -> d_inode )) <nl> + if ( parent -> d_inode && fsnotify_inode_watches_children ( parent -> d_inode )) <nl> dentry -> d_flags |= DCACHE_FSNOTIFY_PARENT_WATCHED ; <nl> else <nl> dentry -> d_flags &= ~ DCACHE_FSNOTIFY_PARENT_WATCHED ;
mmm arch / mips / mm / tlb - r4k . c <nl> ppp arch / mips / mm / tlb - r4k . c <nl> void local_flush_tlb_all ( void ) <nl>  <nl> entry = read_c0_wired (); <nl>  <nl> - /* Blast ' em all away . */ <nl> - if ( cpu_has_tlbinv ) { <nl> + /* <nl> + * Blast ' em all away . <nl> + * If there are any wired entries , fall back to iterating <nl> + */ <nl> + if ( cpu_has_tlbinv && ! entry ) { <nl> if ( current_cpu_data . tlbsizevtlb ) { <nl> write_c0_index ( 0 ); <nl> mtc0_tlbw_hazard ();
mmm drivers / cpufreq / pcc - cpufreq . c <nl> ppp drivers / cpufreq / pcc - cpufreq . c <nl> static int pcc_get_offset ( int cpu ) <nl> pr = per_cpu ( processors , cpu ); <nl> pcc_cpu_data = per_cpu_ptr ( pcc_cpu_info , cpu ); <nl>  <nl> + if (! pr ) <nl> + return - ENODEV ; <nl> + <nl> status = acpi_evaluate_object ( pr -> handle , " PCCP ", NULL , & buffer ); <nl> if ( ACPI_FAILURE ( status )) <nl> return - ENODEV ;
mmm drivers / misc / mei / bus . c <nl> ppp drivers / misc / mei / bus . c <nl> void mei_cl_bus_rescan_work ( struct work_struct * work ) <nl> container_of ( work , struct mei_device , bus_rescan_work ); <nl> struct mei_me_client * me_cl ; <nl>  <nl> - mutex_lock (& bus -> device_lock ); <nl> me_cl = mei_me_cl_by_uuid ( bus , & mei_amthif_guid ); <nl> if ( me_cl ) <nl> mei_amthif_host_init ( bus , me_cl ); <nl> mei_me_cl_put ( me_cl ); <nl> - mutex_unlock (& bus -> device_lock ); <nl>  <nl> mei_cl_bus_rescan ( bus ); <nl> }mmm drivers / misc / mei / amthif . c <nl> ppp drivers / misc / mei / amthif . c <nl> void mei_cl_bus_rescan_work ( struct work_struct * work ) <nl> container_of ( work , struct mei_device , bus_rescan_work ); <nl> struct mei_me_client * me_cl ; <nl>  <nl> - mutex_lock (& bus -> device_lock ); <nl> me_cl = mei_me_cl_by_uuid ( bus , & mei_amthif_guid ); <nl> if ( me_cl ) <nl> mei_amthif_host_init ( bus , me_cl ); <nl> mei_me_cl_put ( me_cl ); <nl> - mutex_unlock (& bus -> device_lock ); <nl>  <nl> mei_cl_bus_rescan ( bus ); <nl> } <nl> int mei_amthif_host_init ( struct mei_device * dev , struct mei_me_client * me_cl ) <nl> struct mei_cl * cl = & dev -> iamthif_cl ; <nl> int ret ; <nl>  <nl> - if ( mei_cl_is_connected ( cl )) <nl> - return 0 ; <nl> + mutex_lock (& dev -> device_lock ); <nl> + <nl> + if ( mei_cl_is_connected ( cl )) { <nl> + ret = 0 ; <nl> + goto out ; <nl> + } <nl>  <nl> dev -> iamthif_state = MEI_IAMTHIF_IDLE ; <nl>  <nl> int mei_amthif_host_init ( struct mei_device * dev , struct mei_me_client * me_cl ) <nl> ret = mei_cl_link ( cl ); <nl> if ( ret < 0 ) { <nl> dev_err ( dev -> dev , " amthif : failed cl_link % d \ n ", ret ); <nl> - return ret ; <nl> + goto out ; <nl> } <nl>  <nl> ret = mei_cl_connect ( cl , me_cl , NULL ); <nl>  <nl> + out : <nl> + mutex_unlock (& dev -> device_lock ); <nl> return ret ; <nl> } <nl> 
mmm net / ipv4 / fib_frontend . c <nl> ppp net / ipv4 / fib_frontend . c <nl> __be32 fib_compute_spec_dst ( struct sk_buff * skb ) <nl> if (! ipv4_is_zeronet ( ip_hdr ( skb )-> saddr )) { <nl> struct flowi4 fl4 = { <nl> . flowi4_iif = LOOPBACK_IFINDEX , <nl> + . flowi4_oif = l3mdev_master_ifindex_rcu ( dev ), <nl> . daddr = ip_hdr ( skb )-> saddr , <nl> . flowi4_tos = RT_TOS ( ip_hdr ( skb )-> tos ), <nl> . flowi4_scope = scope ,
mmm drivers / input / input . c <nl> ppp drivers / input / input . c <nl> void input_unregister_device ( struct input_dev * dev ) <nl> sysfs_remove_group (& dev -> cdev . kobj , & input_dev_caps_attr_group ); <nl> sysfs_remove_group (& dev -> cdev . kobj , & input_dev_id_attr_group ); <nl> sysfs_remove_group (& dev -> cdev . kobj , & input_dev_attr_group ); <nl> - class_device_unregister (& dev -> cdev ); <nl>  <nl> mutex_lock (& dev -> mutex ); <nl> dev -> name = dev -> phys = dev -> uniq = NULL ; <nl> mutex_unlock (& dev -> mutex ); <nl>  <nl> + class_device_unregister (& dev -> cdev ); <nl> + <nl> input_wakeup_procfs_readers (); <nl> } <nl> EXPORT_SYMBOL ( input_unregister_device );
mmm drivers / input / misc / uinput . c <nl> ppp drivers / input / misc / uinput . c <nl> static inline int uinput_request_reserve_slot ( struct uinput_device * udev , struct <nl>  <nl> static void uinput_request_done ( struct uinput_device * udev , struct uinput_request * request ) <nl> { <nl> - complete (& request -> done ); <nl> - <nl> /* Mark slot as available */ <nl> udev -> requests [ request -> id ] = NULL ; <nl> wake_up_interruptible (& udev -> requests_waitq ); <nl> + <nl> + complete (& request -> done ); <nl> } <nl>  <nl> static int uinput_request_submit ( struct input_dev * dev , struct uinput_request * request )
mmm include / asm - um / mmu_context . h <nl> ppp include / asm - um / mmu_context . h <nl> static inline void activate_mm ( struct mm_struct * old , struct mm_struct * new ) <nl> * possible . <nl> */ <nl> if ( old != new && ( current -> flags & PF_BORROWED_MM )) <nl> - force_flush_all (); <nl> + CHOOSE_MODE ( force_flush_all (), <nl> + switch_mm_skas (& new -> context . skas . id )); <nl> } <nl>  <nl> static inline void switch_mm ( struct mm_struct * prev , struct mm_struct * next ,
mmm arch / arm / mach - mx2 / eukrea_mbimx27 - baseboard . c <nl> ppp arch / arm / mach - mx2 / eukrea_mbimx27 - baseboard . c <nl> static struct platform_device * platform_devices [] __initdata = { <nl> & leds_gpio , <nl> }; <nl>  <nl> + static struct imxmmc_platform_data sdhc_pdata = { <nl> + . dat3_card_detect = 1 , <nl> +}; <nl> + <nl> /* <nl> * system init for baseboard usage . Will be called by cpuimx27 init . <nl> * <nl> void __init eukrea_mbimx27_baseboard_init ( void ) <nl> # endif <nl>  <nl> mxc_register_device (& mxc_fb_device , & eukrea_mbimx27_fb_data ); <nl> - mxc_register_device (& mxc_sdhc_device0 , NULL ); <nl> + mxc_register_device (& mxc_sdhc_device0 , & sdhc_pdata ); <nl>  <nl> # if defined ( CONFIG_TOUCHSCREEN_ADS7846 ) \ <nl> || defined ( CONFIG_TOUCHSCREEN_ADS7846_MODULE )
mmm drivers / ata / libata - core . c <nl> ppp drivers / ata / libata - core . c <nl> unsigned ata_exec_internal_sg ( struct ata_device * dev , <nl> qc -> tf = * tf ; <nl> if ( cdb ) <nl> memcpy ( qc -> cdb , cdb , ATAPI_CDB_LEN ); <nl> + <nl> + /* some SATA bridges need us to indicate data xfer direction */ <nl> + if ( tf -> protocol == ATAPI_PROT_DMA && ( dev -> flags & ATA_DFLAG_DMADIR ) && <nl> + dma_dir == DMA_FROM_DEVICE ) <nl> + qc -> tf . feature |= ATAPI_DMADIR ; <nl> + <nl> qc -> flags |= ATA_QCFLAG_RESULT_TF ; <nl> qc -> dma_dir = dma_dir ; <nl> if ( dma_dir != DMA_NONE ) {
mmm net / wireless / nl80211 . c <nl> ppp net / wireless / nl80211 . c <nl> static int nl80211_set_rekey_data ( struct sk_buff * skb , struct genl_info * info ) <nl> if ( err ) <nl> return err ; <nl>  <nl> + if (! tb [ NL80211_REKEY_DATA_REPLAY_CTR ] || ! tb [ NL80211_REKEY_DATA_KEK ] || <nl> + ! tb [ NL80211_REKEY_DATA_KCK ]) <nl> + return - EINVAL ; <nl> if ( nla_len ( tb [ NL80211_REKEY_DATA_REPLAY_CTR ]) != NL80211_REPLAY_CTR_LEN ) <nl> return - ERANGE ; <nl> if ( nla_len ( tb [ NL80211_REKEY_DATA_KEK ]) != NL80211_KEK_LEN )
mmm drivers / iio / potentiostat / lmp91000 . c <nl> ppp drivers / iio / potentiostat / lmp91000 . c <nl> static int lmp91000_probe ( struct i2c_client * client , <nl> indio_dev -> channels = lmp91000_channels ; <nl> indio_dev -> num_channels = ARRAY_SIZE ( lmp91000_channels ); <nl> indio_dev -> name = LMP91000_DRV_NAME ; <nl> + indio_dev -> dev . parent = & client -> dev ; <nl> indio_dev -> modes = INDIO_DIRECT_MODE ; <nl> i2c_set_clientdata ( client , indio_dev ); <nl> 
mmm drivers / scsi / sg . c <nl> ppp drivers / scsi / sg . c <nl> sg_unlink_reserve ( Sg_fd * sfp , Sg_request * srp ) <nl> req_schp -> page_order = 0 ; <nl> req_schp -> sglist_len = 0 ; <nl> srp -> res_used = 0 ; <nl> + /* Called without mutex lock to avoid deadlock */ <nl> + sfp -> res_in_use = 0 ; <nl> } <nl>  <nl> static Sg_request *
mmm drivers / hwmon / ina2xx . c <nl> ppp drivers / hwmon / ina2xx . c <nl> static int ina2xx_probe ( struct i2c_client * client , <nl> data -> config = & ina2xx_config [ data -> kind ]; <nl> data -> client = client ; <nl>  <nl> - if ( data -> rshunt <= 0 ) <nl> + if ( data -> rshunt <= 0 || <nl> + data -> rshunt > data -> config -> calibration_factor ) <nl> return - ENODEV ; <nl>  <nl> ret = ina2xx_init ( data );
mmm drivers / net / cxgb4vf / cxgb4vf_main . c <nl> ppp drivers / net / cxgb4vf / cxgb4vf_main . c <nl> static int cxgb4vf_open ( struct net_device * dev ) <nl> if ( err ) <nl> return err ; <nl> set_bit ( pi -> port_id , & adapter -> open_device_map ); <nl> - link_start ( dev ); <nl> + err = link_start ( dev ); <nl> + if ( err ) <nl> + return err ; <nl> netif_tx_start_all_queues ( dev ); <nl> return 0 ; <nl> }
mmm sound / core / timer . c <nl> ppp sound / core / timer . c <nl> int snd_timer_open ( struct snd_timer_instance ** ti , <nl> goto unlock ; <nl> } <nl> if (! list_empty (& timer -> open_list_head )) { <nl> - timeri = list_entry ( timer -> open_list_head . next , <nl> + struct snd_timer_instance * t = <nl> + list_entry ( timer -> open_list_head . next , <nl> struct snd_timer_instance , open_list ); <nl> - if ( timeri -> flags & SNDRV_TIMER_IFLG_EXCLUSIVE ) { <nl> + if ( t -> flags & SNDRV_TIMER_IFLG_EXCLUSIVE ) { <nl> err = - EBUSY ; <nl> - timeri = NULL ; <nl> goto unlock ; <nl> } <nl> }
mmm drivers / staging / rtl8192u / ieee80211 / ieee80211_tx . c <nl> ppp drivers / staging / rtl8192u / ieee80211 / ieee80211_tx . c <nl> static struct ieee80211_txb * ieee80211_alloc_txb ( int nr_frags , int txb_size , <nl>  <nl> memset ( txb , 0 , sizeof ( struct ieee80211_txb )); <nl> txb -> nr_frags = nr_frags ; <nl> - txb -> frag_size = txb_size ; <nl> + txb -> frag_size = __cpu_to_le16 ( txb_size ); <nl>  <nl> for ( i = 0 ; i < nr_frags ; i ++) { <nl> txb -> fragments [ i ] = dev_alloc_skb ( txb_size ); <nl> int ieee80211_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl> goto failed ; <nl> } <nl> txb -> encrypted = encrypt ; <nl> - txb -> payload_size = bytes ; <nl> + txb -> payload_size = __cpu_to_le16 ( bytes ); <nl>  <nl> // if ( ieee -> current_network . QoS_Enable ) <nl> if ( qos_actived ) <nl> int ieee80211_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl> } <nl>  <nl> txb -> encrypted = 0 ; <nl> - txb -> payload_size = skb -> len ; <nl> + txb -> payload_size = __cpu_to_le16 ( skb -> len ); <nl> memcpy ( skb_put ( txb -> fragments [ 0 ], skb -> len ), skb -> data , skb -> len ); <nl> } <nl>  <nl> int ieee80211_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl> } else { <nl> if ((* ieee -> hard_start_xmit )( txb , dev ) == 0 ) { <nl> stats -> tx_packets ++; <nl> - stats -> tx_bytes += txb -> payload_size ; <nl> + stats -> tx_bytes += __le16_to_cpu ( txb -> payload_size ); <nl> return 0 ; <nl> } <nl> ieee80211_txb_free ( txb );
mmm net / ipv6 / addrconf . c <nl> ppp net / ipv6 / addrconf . c <nl> static int modify_prefix_route ( struct inet6_ifaddr * ifp , <nl> unsigned long expires , u32 flags ) <nl> { <nl> struct fib6_info * f6i ; <nl> + u32 prio ; <nl>  <nl> f6i = addrconf_get_prefix_route (& ifp -> addr , <nl> ifp -> prefix_len , <nl> static int modify_prefix_route ( struct inet6_ifaddr * ifp , <nl> if (! f6i ) <nl> return - ENOENT ; <nl>  <nl> - if ( f6i -> fib6_metric != ifp -> rt_priority ) { <nl> + prio = ifp -> rt_priority ? : IP6_RT_PRIO_ADDRCONF ; <nl> + if ( f6i -> fib6_metric != prio ) { <nl> + /* delete old one */ <nl> + ip6_del_rt ( dev_net ( ifp -> idev -> dev ), f6i ); <nl> + <nl> /* add new one */ <nl> addrconf_prefix_route (& ifp -> addr , ifp -> prefix_len , <nl> ifp -> rt_priority , ifp -> idev -> dev , <nl> expires , flags , GFP_KERNEL ); <nl> - /* delete old one */ <nl> - ip6_del_rt ( dev_net ( ifp -> idev -> dev ), f6i ); <nl> } else { <nl> if (! expires ) <nl> fib6_clean_expires ( f6i );
mmm drivers / usb / class / cdc - acm . c <nl> ppp drivers / usb / class / cdc - acm . c <nl> static int acm_probe ( struct usb_interface * intf , <nl> i = device_create_file (& intf -> dev , & dev_attr_wCountryCodes ); <nl> if ( i < 0 ) { <nl> kfree ( acm -> country_codes ); <nl> + acm -> country_codes = NULL ; <nl> + acm -> country_code_size = 0 ; <nl> goto skip_countries ; <nl> } <nl>  <nl> static int acm_probe ( struct usb_interface * intf , <nl> if ( i < 0 ) { <nl> device_remove_file (& intf -> dev , & dev_attr_wCountryCodes ); <nl> kfree ( acm -> country_codes ); <nl> + acm -> country_codes = NULL ; <nl> + acm -> country_code_size = 0 ; <nl> goto skip_countries ; <nl> } <nl> }
mmm include / linux / sched . h <nl> ppp include / linux / sched . h <nl> struct task_struct { <nl> int exit_state ; <nl> int exit_code , exit_signal ; <nl> int pdeath_signal ; /* The signal sent when the parent dies */ <nl> - unsigned int jobctl ; /* JOBCTL_ *, siglock protected */ <nl> + unsigned long jobctl ; /* JOBCTL_ *, siglock protected */ <nl>  <nl> /* Used for emulating ABI behavior of previous Linux versions */ <nl> unsigned int personality ;
mmm sound / usb / endpoint . c <nl> ppp sound / usb / endpoint . c <nl> struct snd_usb_endpoint * snd_usb_add_endpoint ( struct snd_usb_audio * chip , <nl> struct snd_usb_endpoint * ep ; <nl> int is_playback = direction == SNDRV_PCM_STREAM_PLAYBACK ; <nl>  <nl> + if ( WARN_ON (! alts )) <nl> + return NULL ; <nl> + <nl> mutex_lock (& chip -> mutex ); <nl>  <nl> list_for_each_entry ( ep , & chip -> ep_list , list ) {
mmm drivers / mmc / host / mmci . c <nl> ppp drivers / mmc / host / mmci . c <nl> static irqreturn_t mmci_irq ( int irq , void * dev_id ) <nl>  <nl> dev_dbg ( mmc_dev ( host -> mmc ), " irq0 ( data + cmd ) % 08x \ n ", status ); <nl>  <nl> + cmd = host -> cmd ; <nl> + if ( status & ( MCI_CMDCRCFAIL | MCI_CMDTIMEOUT | MCI_CMDSENT | <nl> + MCI_CMDRESPEND ) && cmd ) <nl> + mmci_cmd_irq ( host , cmd , status ); <nl> + <nl> data = host -> data ; <nl> if ( status & ( MCI_DATACRCFAIL | MCI_DATATIMEOUT | MCI_STARTBITERR | <nl> MCI_TXUNDERRUN | MCI_RXOVERRUN | MCI_DATAEND | <nl> MCI_DATABLOCKEND ) && data ) <nl> mmci_data_irq ( host , data , status ); <nl>  <nl> - cmd = host -> cmd ; <nl> - if ( status & ( MCI_CMDCRCFAIL | MCI_CMDTIMEOUT | MCI_CMDSENT | MCI_CMDRESPEND ) && cmd ) <nl> - mmci_cmd_irq ( host , cmd , status ); <nl> - <nl> ret = 1 ; <nl> } while ( status ); <nl> 
mmm arch / x86 / kvm / vmx . c <nl> ppp arch / x86 / kvm / vmx . c <nl> static void add_atomic_switch_msr ( struct vcpu_vmx * vmx , unsigned msr , <nl> if ( m -> guest [ i ]. index == msr ) <nl> break ; <nl>  <nl> - if ( i == m -> nr ) { <nl> + if ( i == NR_AUTOLOAD_MSRS ) { <nl> + printk_once ( KERN_WARNING " Not enough mst switch entries . " <nl> + " Can ' t add msr % x \ n ", msr ); <nl> + return ; <nl> + } else if ( i == m -> nr ) { <nl> ++ m -> nr ; <nl> vmcs_write32 ( VM_ENTRY_MSR_LOAD_COUNT , m -> nr ); <nl> vmcs_write32 ( VM_EXIT_MSR_LOAD_COUNT , m -> nr );
mmm kernel / trace / trace_events . c <nl> ppp kernel / trace / trace_events . c <nl> subsystem_filter_write ( struct file * filp , const char __user * ubuf , size_t cnt , <nl>  <nl> err = filter_add_subsystem_pred ( system , pred ); <nl> if ( err < 0 ) { <nl> - filter_free_subsystem_preds ( system ); <nl> filter_free_pred ( pred ); <nl> return err ; <nl> }
mmm drivers / atm / iphase . c <nl> ppp drivers / atm / iphase . c <nl> static int tx_init ( struct atm_dev * dev ) <nl> buf_desc_ptr ++; <nl> tx_pkt_start += iadev -> tx_buf_sz ; <nl> } <nl> - iadev -> tx_buf = kmalloc ( iadev -> num_tx_desc * sizeof ( struct cpcs_trailer_desc ), GFP_KERNEL ); <nl> + iadev -> tx_buf = kmalloc_array ( iadev -> num_tx_desc , <nl> + sizeof (* iadev -> tx_buf ), <nl> + GFP_KERNEL ); <nl> if (! iadev -> tx_buf ) { <nl> printk ( KERN_ERR DEV_LABEL " couldn ' t get mem \ n "); <nl> goto err_free_dle ; <nl> static int tx_init ( struct atm_dev * dev ) <nl> sizeof (* cpcs ), <nl> DMA_TO_DEVICE ); <nl> } <nl> - iadev -> desc_tbl = kmalloc ( iadev -> num_tx_desc * <nl> - sizeof ( struct desc_tbl_t ), GFP_KERNEL ); <nl> + iadev -> desc_tbl = kmalloc_array ( iadev -> num_tx_desc , <nl> + sizeof (* iadev -> desc_tbl ), <nl> + GFP_KERNEL ); <nl> if (! iadev -> desc_tbl ) { <nl> printk ( KERN_ERR DEV_LABEL " couldn ' t get mem \ n "); <nl> goto err_free_all_tx_bufs ; <nl> static int tx_init ( struct atm_dev * dev ) <nl> memset (( caddr_t )( iadev -> seg_ram + i ), 0 , iadev -> num_vc * 4 ); <nl> vc = ( struct main_vc *) iadev -> MAIN_VC_TABLE_ADDR ; <nl> evc = ( struct ext_vc *) iadev -> EXT_VC_TABLE_ADDR ; <nl> - iadev -> testTable = kmalloc ( sizeof ( long )* iadev -> num_vc , GFP_KERNEL ); <nl> + iadev -> testTable = kmalloc_array ( iadev -> num_vc , <nl> + sizeof (* iadev -> testTable ), <nl> + GFP_KERNEL ); <nl> if (! iadev -> testTable ) { <nl> printk (" Get freepage failed \ n "); <nl> goto err_free_desc_tbl ;
mmm arch / arm / kvm / arm . c <nl> ppp arch / arm / kvm / arm . c <nl> static void vcpu_pause ( struct kvm_vcpu * vcpu ) <nl> wait_event_interruptible (* wq , ! vcpu -> arch . pause ); <nl> } <nl>  <nl> + static int kvm_vcpu_initialized ( struct kvm_vcpu * vcpu ) <nl> +{ <nl> + return vcpu -> arch . target >= 0 ; <nl> +} <nl> + <nl> /** <nl> * kvm_arch_vcpu_ioctl_run - the main VCPU run function to execute guest code <nl> * @ vcpu : The VCPU pointer <nl> int kvm_arch_vcpu_ioctl_run ( struct kvm_vcpu * vcpu , struct kvm_run * run ) <nl> int ret ; <nl> sigset_t sigsaved ; <nl>  <nl> - /* Make sure they initialize the vcpu with KVM_ARM_VCPU_INIT */ <nl> - if ( unlikely ( vcpu -> arch . target < 0 )) <nl> + if ( unlikely (! kvm_vcpu_initialized ( vcpu ))) <nl> return - ENOEXEC ; <nl>  <nl> ret = kvm_vcpu_first_run_init ( vcpu ); <nl> long kvm_arch_vcpu_ioctl ( struct file * filp , <nl> case KVM_SET_ONE_REG : <nl> case KVM_GET_ONE_REG : { <nl> struct kvm_one_reg reg ; <nl> + <nl> + if ( unlikely (! kvm_vcpu_initialized ( vcpu ))) <nl> + return - ENOEXEC ; <nl> + <nl> if ( copy_from_user (& reg , argp , sizeof ( reg ))) <nl> return - EFAULT ; <nl> if ( ioctl == KVM_SET_ONE_REG ) <nl> long kvm_arch_vcpu_ioctl ( struct file * filp , <nl> struct kvm_reg_list reg_list ; <nl> unsigned n ; <nl>  <nl> + if ( unlikely (! kvm_vcpu_initialized ( vcpu ))) <nl> + return - ENOEXEC ; <nl> + <nl> if ( copy_from_user (& reg_list , user_list , sizeof ( reg_list ))) <nl> return - EFAULT ; <nl> n = reg_list . n ;
mmm drivers / net / ethernet / micrel / ks8851 . c <nl> ppp drivers / net / ethernet / micrel / ks8851 . c <nl> static int __devinit ks8851_probe ( struct spi_device * spi ) <nl>  <nl>  <nl> err_netdev : <nl> - free_irq ( ndev -> irq , ndev ); <nl> + free_irq ( ndev -> irq , ks ); <nl>  <nl> err_id : <nl> err_irq :
mmm drivers / gpu / drm / i915 / i915_gem_gtt . c <nl> ppp drivers / gpu / drm / i915 / i915_gem_gtt . c <nl> static bool gen8_ppgtt_clear_pt ( struct i915_address_space * vm , <nl> GEM_BUG_ON ( pte_end > GEN8_PTES ); <nl>  <nl> bitmap_clear ( pt -> used_ptes , pte , num_entries ); <nl> - <nl> - if ( bitmap_empty ( pt -> used_ptes , GEN8_PTES )) <nl> - return true ; <nl> + if ( USES_FULL_PPGTT ( vm -> i915 )) { <nl> + if ( bitmap_empty ( pt -> used_ptes , GEN8_PTES )) <nl> + return true ; <nl> + } <nl>  <nl> pt_vaddr = kmap_px ( pt ); <nl> 
mmm scripts / mod / modpost . c <nl> ppp scripts / mod / modpost . c <nl> static int init_section_ref_ok ( const char * name ) <nl> if ( strncmp (* s , name , strlen (* s )) == 0 ) <nl> return 1 ; <nl> for ( s = namelist3 ; * s ; s ++) <nl> - if ( strstr (* s , name ) != NULL ) <nl> + if ( strstr ( name , * s ) != NULL ) <nl> return 1 ; <nl> return 0 ; <nl> } <nl> static int exit_section_ref_ok ( const char * name ) <nl> if ( strncmp (* s , name , strlen (* s )) == 0 ) <nl> return 1 ; <nl> for ( s = namelist3 ; * s ; s ++) <nl> - if ( strstr (* s , name ) != NULL ) <nl> + if ( strstr ( name , * s ) != NULL ) <nl> return 1 ; <nl> return 0 ; <nl> }
mmm drivers / net / ethernet / broadcom / bcmsysport . c <nl> ppp drivers / net / ethernet / broadcom / bcmsysport . c <nl> static u16 bcm_sysport_select_queue ( struct net_device * dev , struct sk_buff * skb , <nl> port = BRCM_TAG_GET_PORT ( queue ); <nl> tx_ring = priv -> ring_map [ q + port * priv -> per_port_num_tx_queues ]; <nl>  <nl> + if ( unlikely (! tx_ring )) <nl> + return fallback ( dev , skb ); <nl> + <nl> return tx_ring -> index ; <nl> } <nl> 
mmm fs / nfsd / nfssvc . c <nl> ppp fs / nfsd / nfssvc . c <nl> static int nfsd_startup ( unsigned short port , int nrservs ) <nl> ret = nfs4_state_start (); <nl> if ( ret ) <nl> goto out_lockd ; <nl> - nfsd_reset_versions (); <nl> nfsd_up = true ; <nl> return 0 ; <nl> out_lockd : <nl> int nfsd_create_serv ( void ) <nl> nfsd_max_blksize >= 8 * 1024 * 2 ) <nl> nfsd_max_blksize /= 2 ; <nl> } <nl> + nfsd_reset_versions (); <nl>  <nl> nfsd_serv = svc_create_pooled (& nfsd_program , nfsd_max_blksize , <nl> nfsd_last_thread , nfsd , THIS_MODULE );
mmm net / atm / common . c <nl> ppp net / atm / common . c <nl> int vcc_getsockopt ( struct socket * sock , int level , int optname , <nl>  <nl> if (! vcc -> dev || ! test_bit ( ATM_VF_ADDR , & vcc -> flags )) <nl> return - ENOTCONN ; <nl> + memset (& pvc , 0 , sizeof ( pvc )); <nl> pvc . sap_family = AF_ATMPVC ; <nl> pvc . sap_addr . itf = vcc -> dev -> number ; <nl> pvc . sap_addr . vpi = vcc -> vpi ;
mmm net / batman - adv / bridge_loop_avoidance . c <nl> ppp net / batman - adv / bridge_loop_avoidance . c <nl> int batadv_bla_tx ( struct batadv_priv * bat_priv , struct sk_buff * skb , <nl> if (! atomic_read (& bat_priv -> bridge_loop_avoidance )) <nl> goto allow ; <nl>  <nl> - /* in VLAN case , the mac header might not be set . */ <nl> - skb_reset_mac_header ( skb ); <nl> - <nl> if ( batadv_bla_process_claim ( bat_priv , primary_if , skb )) <nl> goto handled ; <nl> 
mmm drivers / cpufreq / cpufreq_conservative . c <nl> ppp drivers / cpufreq / cpufreq_conservative . c <nl> static int cpufreq_governor_dbs ( struct cpufreq_policy * policy , <nl> if ( latency == 0 ) <nl> latency = 1 ; <nl>  <nl> - def_sampling_rate = latency * <nl> + def_sampling_rate = 10 * latency * <nl> DEF_SAMPLING_RATE_LATENCY_MULTIPLIER ; <nl>  <nl> if ( def_sampling_rate < MIN_STAT_SAMPLING_RATE )
mmm drivers / gpu / drm / i915 / intel_runtime_pm . c <nl> ppp drivers / gpu / drm / i915 / intel_runtime_pm . c <nl> static void assert_can_enable_dc9 ( struct drm_i915_private * dev_priv ) <nl> " DC9 already programmed to be enabled .\ n "); <nl> WARN_ONCE ( I915_READ ( DC_STATE_EN ) & DC_STATE_EN_UPTO_DC5 , <nl> " DC5 still not disabled to enable DC9 .\ n "); <nl> - WARN_ONCE ( I915_READ ( HSW_PWR_WELL_DRIVER ), " Power well on .\ n "); <nl> + WARN_ONCE ( I915_READ ( HSW_PWR_WELL_DRIVER ) & <nl> + SKL_POWER_WELL_REQ ( SKL_DISP_PW_2 ), <nl> + " Power well 2 on .\ n "); <nl> WARN_ONCE ( intel_irqs_enabled ( dev_priv ), <nl> " Interrupts not disabled yet .\ n "); <nl> 
mmm drivers / net / ntb_netdev . c <nl> ppp drivers / net / ntb_netdev . c <nl> static int ntb_netdev_open ( struct net_device * ndev ) <nl>  <nl> rc = ntb_transport_rx_enqueue ( dev -> qp , skb , skb -> data , <nl> ndev -> mtu + ETH_HLEN ); <nl> - if ( rc == - EINVAL ) <nl> + if ( rc == - EINVAL ) { <nl> + dev_kfree_skb ( skb ); <nl> goto err ; <nl> + } <nl> } <nl>  <nl> netif_carrier_off ( ndev );
mmm sound / soc / intel / skylake / skl - topology . c <nl> ppp sound / soc / intel / skylake / skl - topology . c <nl> static int skl_tplg_tlv_control_get ( struct snd_kcontrol * kcontrol , <nl> if ( bc -> params ) { <nl> if ( copy_to_user ( data , & bc -> param_id , sizeof ( u32 ))) <nl> return - EFAULT ; <nl> - if ( copy_to_user ( data + sizeof ( u32 ), & size , sizeof ( u32 ))) <nl> + if ( copy_to_user ( data + 1 , & size , sizeof ( u32 ))) <nl> return - EFAULT ; <nl> - if ( copy_to_user ( data + 2 * sizeof ( u32 ), bc -> params , size )) <nl> + if ( copy_to_user ( data + 2 , bc -> params , size )) <nl> return - EFAULT ; <nl> } <nl> 
mmm drivers / scsi / sd_zbc . c <nl> ppp drivers / scsi / sd_zbc . c <nl> static int sd_zbc_check_capacity ( struct scsi_disk * sdkp , unsigned char * buf ) <nl> return 0 ; <nl> } <nl>  <nl> -# define SD_ZBC_BUF_SIZE 131072 <nl> +# define SD_ZBC_BUF_SIZE 131072U <nl>  <nl> /** <nl> * sd_zbc_check_zone_size - Check the device zone sizes <nl> static int sd_zbc_check_zone_size ( struct scsi_disk * sdkp ) <nl> /* Parse REPORT ZONES header */ <nl> list_length = get_unaligned_be32 (& buf [ 0 ]) + 64 ; <nl> rec = buf + 64 ; <nl> - if ( list_length < SD_ZBC_BUF_SIZE ) <nl> - buf_len = list_length ; <nl> - else <nl> - buf_len = SD_ZBC_BUF_SIZE ; <nl> + buf_len = min ( list_length , SD_ZBC_BUF_SIZE ); <nl>  <nl> /* Parse zone descriptors */ <nl> while ( rec < buf + buf_len ) { <nl> static int sd_zbc_setup ( struct scsi_disk * sdkp ) <nl> /* chunk_sectors indicates the zone size */ <nl> blk_queue_chunk_sectors ( sdkp -> disk -> queue , <nl> logical_to_sectors ( sdkp -> device , sdkp -> zone_blocks )); <nl> - sdkp -> nr_zones = sdkp -> capacity >> sdkp -> zone_shift ; <nl> - if ( sdkp -> capacity & ( sdkp -> zone_blocks - 1 )) <nl> - sdkp -> nr_zones ++; <nl> + sdkp -> nr_zones = <nl> + round_up ( sdkp -> capacity , sdkp -> zone_blocks ) >> sdkp -> zone_shift ; <nl>  <nl> if (! sdkp -> zones_wlock ) { <nl> sdkp -> zones_wlock = kcalloc ( BITS_TO_LONGS ( sdkp -> nr_zones ),
mmm net / rxrpc / ar - internal . h <nl> ppp net / rxrpc / ar - internal . h <nl> static inline bool rxrpc_set_call_completion ( struct rxrpc_call * call , <nl> u32 abort_code , <nl> int error ) <nl> { <nl> - int ret ; <nl> + bool ret ; <nl>  <nl> write_lock_bh (& call -> state_lock ); <nl> ret = __rxrpc_set_call_completion ( call , compl , abort_code , error ); <nl> static inline bool rxrpc_set_call_completion ( struct rxrpc_call * call , <nl> /* <nl> * Record that a call successfully completed . <nl> */ <nl> - static inline void __rxrpc_call_completed ( struct rxrpc_call * call ) <nl> + static inline bool __rxrpc_call_completed ( struct rxrpc_call * call ) <nl> { <nl> - __rxrpc_set_call_completion ( call , RXRPC_CALL_SUCCEEDED , 0 , 0 ); <nl> + return __rxrpc_set_call_completion ( call , RXRPC_CALL_SUCCEEDED , 0 , 0 ); <nl> } <nl>  <nl> - static inline void rxrpc_call_completed ( struct rxrpc_call * call ) <nl> + static inline bool rxrpc_call_completed ( struct rxrpc_call * call ) <nl> { <nl> + bool ret ; <nl> + <nl> write_lock_bh (& call -> state_lock ); <nl> - __rxrpc_call_completed ( call ); <nl> + ret = __rxrpc_call_completed ( call ); <nl> write_unlock_bh (& call -> state_lock ); <nl> + return ret ; <nl> } <nl>  <nl> /*
mmm kernel / rcu / rcutorture . c <nl> ppp kernel / rcu / rcutorture . c <nl> rcu_torture_init ( void ) <nl> if ( firsterr ) <nl> goto unwind ; <nl> } <nl> - if ( test_no_idle_hz ) { <nl> + if ( test_no_idle_hz && shuffle_interval > 0 ) { <nl> firsterr = torture_shuffle_init ( shuffle_interval * HZ ); <nl> if ( firsterr ) <nl> goto unwind ;
mmm drivers / media / rc / ir - lirc - codec . c <nl> ppp drivers / media / rc / ir - lirc - codec . c <nl> static long ir_lirc_ioctl ( struct file * filep , unsigned int cmd , <nl> return 0 ; <nl>  <nl> case LIRC_GET_REC_RESOLUTION : <nl> + if (! dev -> rx_resolution ) <nl> + return - ENOTTY ; <nl> + <nl> val = dev -> rx_resolution ; <nl> break ; <nl>  <nl> static int ir_lirc_register ( struct rc_dev * dev ) <nl> if ( rc ) <nl> goto rbuf_init_failed ; <nl>  <nl> - if ( dev -> driver_type != RC_DRIVER_IR_RAW_TX ) <nl> + if ( dev -> driver_type != RC_DRIVER_IR_RAW_TX ) { <nl> features |= LIRC_CAN_REC_MODE2 ; <nl> + if ( dev -> rx_resolution ) <nl> + features |= LIRC_CAN_GET_REC_RESOLUTION ; <nl> + } <nl> if ( dev -> tx_ir ) { <nl> features |= LIRC_CAN_SEND_PULSE ; <nl> if ( dev -> s_tx_mask )
mmm drivers / net / ethernet / mellanox / mlxsw / spectrum . c <nl> ppp drivers / net / ethernet / mellanox / mlxsw / spectrum . c <nl> mlxsw_sp_port_add_cls_matchall_mirror ( struct mlxsw_sp_port * mlxsw_sp_port , <nl>  <nl> if (! mlxsw_sp_port_dev_check ( to_dev )) { <nl> netdev_err ( mlxsw_sp_port -> dev , " Cannot mirror to a non - spectrum port "); <nl> - return - ENOTSUPP ; <nl> + return - EOPNOTSUPP ; <nl> } <nl> to_port = netdev_priv ( to_dev ); <nl>  <nl> static int mlxsw_sp_port_add_cls_matchall ( struct mlxsw_sp_port * mlxsw_sp_port , <nl>  <nl> if (! tc_single_action ( cls -> exts )) { <nl> netdev_err ( mlxsw_sp_port -> dev , " only singular actions are supported \ n "); <nl> - return - ENOTSUPP ; <nl> + return - EOPNOTSUPP ; <nl> } <nl>  <nl> mall_tc_entry = kzalloc ( sizeof (* mall_tc_entry ), GFP_KERNEL ); <nl> static int mlxsw_sp_setup_tc ( struct net_device * dev , u32 handle , <nl> } <nl> } <nl>  <nl> - return - ENOTSUPP ; <nl> + return - EOPNOTSUPP ; <nl> } <nl>  <nl> static const struct net_device_ops mlxsw_sp_port_netdev_ops = { <nl> mlxsw_sp_get_hw_stats_by_group ( struct mlxsw_sp_port_hw_stats ** p_hw_stats , <nl> break ; <nl> default : <nl> WARN_ON ( 1 ); <nl> - return - ENOTSUPP ; <nl> + return - EOPNOTSUPP ; <nl> } <nl> return 0 ; <nl> }
mmm drivers / net / ethernet / intel / i40e / i40e_main . c <nl> ppp drivers / net / ethernet / intel / i40e / i40e_main . c <nl> void i40e_vsi_reset_stats ( struct i40e_vsi * vsi ) <nl> **/ <nl> void i40e_pf_reset_stats ( struct i40e_pf * pf ) <nl> { <nl> + int i ; <nl> + <nl> memset (& pf -> stats , 0 , sizeof ( pf -> stats )); <nl> memset (& pf -> stats_offsets , 0 , sizeof ( pf -> stats_offsets )); <nl> pf -> stat_offsets_loaded = false ; <nl> + <nl> + for ( i = 0 ; i < I40E_MAX_VEB ; i ++) { <nl> + if ( pf -> veb [ i ]) { <nl> + memset (& pf -> veb [ i ]-> stats , 0 , <nl> + sizeof ( pf -> veb [ i ]-> stats )); <nl> + memset (& pf -> veb [ i ]-> stats_offsets , 0 , <nl> + sizeof ( pf -> veb [ i ]-> stats_offsets )); <nl> + pf -> veb [ i ]-> stat_offsets_loaded = false ; <nl> + } <nl> + } <nl> } <nl>  <nl> /**
mmm include / linux / mm . h <nl> ppp include / linux / mm . h <nl> struct shrink_control { <nl> struct shrinker { <nl> int (* shrink )( struct shrinker *, struct shrink_control * sc ); <nl> int seeks ; /* seeks to recreate an obj */ <nl> + long batch ; /* reclaim batch size , 0 = default */ <nl>  <nl> /* These are for internal use */ <nl> struct list_head list ;mmm mm / vmscan . c <nl> ppp mm / vmscan . c <nl> struct shrink_control { <nl> struct shrinker { <nl> int (* shrink )( struct shrinker *, struct shrink_control * sc ); <nl> int seeks ; /* seeks to recreate an obj */ <nl> + long batch ; /* reclaim batch size , 0 = default */ <nl>  <nl> /* These are for internal use */ <nl> struct list_head list ; <nl> unsigned long shrink_slab ( struct shrink_control * shrink , <nl> int shrink_ret = 0 ; <nl> long nr ; <nl> long new_nr ; <nl> + long batch_size = shrinker -> batch ? shrinker -> batch <nl> + : SHRINK_BATCH ; <nl>  <nl> /* <nl> * copy the current shrinker scan count into a local variable <nl> unsigned long shrink_slab ( struct shrink_control * shrink , <nl> nr_pages_scanned , lru_pages , <nl> max_pass , delta , total_scan ); <nl>  <nl> - while ( total_scan >= SHRINK_BATCH ) { <nl> - long this_scan = SHRINK_BATCH ; <nl> + while ( total_scan >= batch_size ) { <nl> int nr_before ; <nl>  <nl> nr_before = do_shrinker_shrink ( shrinker , shrink , 0 ); <nl> shrink_ret = do_shrinker_shrink ( shrinker , shrink , <nl> - this_scan ); <nl> + batch_size ); <nl> if ( shrink_ret == - 1 ) <nl> break ; <nl> if ( shrink_ret < nr_before ) <nl> ret += nr_before - shrink_ret ; <nl> - count_vm_events ( SLABS_SCANNED , this_scan ); <nl> - total_scan -= this_scan ; <nl> + count_vm_events ( SLABS_SCANNED , batch_size ); <nl> + total_scan -= batch_size ; <nl>  <nl> cond_resched (); <nl> }
mmm fs / aio . c <nl> ppp fs / aio . c <nl> static int read_events ( struct kioctx * ctx , <nl> break ; <nl> if ( min_nr <= i ) <nl> break ; <nl> - ret = 0 ; <nl> + if ( unlikely ( ctx -> dead )) { <nl> + ret = - EINVAL ; <nl> + break ; <nl> + } <nl> if ( to . timed_out ) /* Only check after read evt */ <nl> break ; <nl> /* Try to only show up in io wait if there are ops <nl> static void io_destroy ( struct kioctx * ioctx ) <nl>  <nl> aio_cancel_all ( ioctx ); <nl> wait_for_all_aios ( ioctx ); <nl> + <nl> + /* <nl> + * Wake up any waiters . The setting of ctx -> dead must be seen <nl> + * by other CPUs at this point . Right now , we rely on the <nl> + * locking done by the above calls to ensure this consistency . <nl> + */ <nl> + wake_up (& ioctx -> wait ); <nl> put_ioctx ( ioctx ); /* once for the lookup */ <nl> } <nl> 
mmm net / ipv4 / ip_output . c <nl> ppp net / ipv4 / ip_output . c <nl> static inline int ip_ufo_append_data ( struct sock * sk , <nl> /* initialize protocol header pointer */ <nl> skb -> transport_header = skb -> network_header + fragheaderlen ; <nl>  <nl> - skb -> ip_summed = CHECKSUM_PARTIAL ; <nl> skb -> csum = 0 ; <nl>  <nl> - /* specify the length of each IP datagram fragment */ <nl> - skb_shinfo ( skb )-> gso_size = maxfraglen - fragheaderlen ; <nl> - skb_shinfo ( skb )-> gso_type = SKB_GSO_UDP ; <nl> + <nl> __skb_queue_tail ( queue , skb ); <nl> + } else if ( skb_is_gso ( skb )) { <nl> + goto append ; <nl> } <nl>  <nl> + skb -> ip_summed = CHECKSUM_PARTIAL ; <nl> + /* specify the length of each IP datagram fragment */ <nl> + skb_shinfo ( skb )-> gso_size = maxfraglen - fragheaderlen ; <nl> + skb_shinfo ( skb )-> gso_type = SKB_GSO_UDP ; <nl> + <nl> + append : <nl> return skb_append_datato_frags ( sk , skb , getfrag , from , <nl> ( length - transhdrlen )); <nl> }
mmm drivers / rpmsg / rpmsg_core . c <nl> ppp drivers / rpmsg / rpmsg_core . c <nl> static int rpmsg_dev_match ( struct device * dev , struct device_driver * drv ) <nl> const struct rpmsg_device_id * ids = rpdrv -> id_table ; <nl> unsigned int i ; <nl>  <nl> + if ( rpdev -> driver_override ) <nl> + return ! strcmp ( rpdev -> driver_override , drv -> name ); <nl> + <nl> if ( ids ) <nl> for ( i = 0 ; ids [ i ]. name [ 0 ]; i ++) <nl> if ( rpmsg_id_match ( rpdev , & ids [ i ]))mmm include / linux / rpmsg . h <nl> ppp include / linux / rpmsg . h <nl> static int rpmsg_dev_match ( struct device * dev , struct device_driver * drv ) <nl> const struct rpmsg_device_id * ids = rpdrv -> id_table ; <nl> unsigned int i ; <nl>  <nl> + if ( rpdev -> driver_override ) <nl> + return ! strcmp ( rpdev -> driver_override , drv -> name ); <nl> + <nl> if ( ids ) <nl> for ( i = 0 ; ids [ i ]. name [ 0 ]; i ++) <nl> if ( rpmsg_id_match ( rpdev , & ids [ i ])) <nl> struct rpmsg_channel_info { <nl> * rpmsg_device - device that belong to the rpmsg bus <nl> * @ dev : the device struct <nl> * @ id : device id ( used to match between rpmsg drivers and devices ) <nl> + * @ driver_override : driver name to force a match <nl> * @ src : local address <nl> * @ dst : destination address <nl> * @ ept : the rpmsg endpoint of this channel <nl> struct rpmsg_channel_info { <nl> struct rpmsg_device { <nl> struct device dev ; <nl> struct rpmsg_device_id id ; <nl> + char * driver_override ; <nl> u32 src ; <nl> u32 dst ; <nl> struct rpmsg_endpoint * ept ;
mmm fs / xfs / xfs_sysfs . c <nl> ppp fs / xfs / xfs_sysfs . c <nl> xfs_error_get_cfg ( <nl> { <nl> struct xfs_error_cfg * cfg ; <nl>  <nl> + if ( error < 0 ) <nl> + error = - error ; <nl> + <nl> switch ( error ) { <nl> case EIO : <nl> cfg = & mp -> m_error_cfg [ error_class ][ XFS_ERR_EIO ];
mmm arch / arm / mach - omap2 / board - omap3beagle . c <nl> ppp arch / arm / mach - omap2 / board - omap3beagle . c <nl> static int beagle_twl_gpio_setup ( struct device * dev , <nl>  <nl> /* TWL4030_GPIO_MAX + 0 == ledA , EHCI nEN_USB_PWR ( out , active low ) */ <nl> gpio_request ( gpio + TWL4030_GPIO_MAX , " nEN_USB_PWR "); <nl> - gpio_direction_output ( gpio + TWL4030_GPIO_MAX , 1 ); <nl> + gpio_direction_output ( gpio + TWL4030_GPIO_MAX , 0 ); <nl>  <nl> /* TWL4030_GPIO_MAX + 1 == ledB , PMU_STAT ( out , active low LED ) */ <nl> gpio_leds [ 2 ]. gpio = gpio + TWL4030_GPIO_MAX + 1 ;
mmm net / tipc / discover . c <nl> ppp net / tipc / discover . c <nl> void tipc_disc_rcv ( struct net * net , struct sk_buff * skb , <nl> u16 caps = msg_node_capabilities ( hdr ); <nl> bool respond = false ; <nl> bool dupl_addr = false ; <nl> + int err ; <nl>  <nl> - bearer -> media -> msg2addr ( bearer , & maddr , msg_media_addr ( hdr )); <nl> + err = bearer -> media -> msg2addr ( bearer , & maddr , msg_media_addr ( hdr )); <nl> kfree_skb ( skb ); <nl> + if ( err ) <nl> + return ; <nl>  <nl> /* Ensure message from node is valid and communication is permitted */ <nl> if ( net_id != tn -> net_id )
mmm drivers / rtc / rtc - sun6i . c <nl> ppp drivers / rtc / rtc - sun6i . c <nl> static void __init sun6i_rtc_clk_init ( struct device_node * node ) <nl>  <nl> clk_data = kzalloc ( sizeof (* clk_data ) + ( sizeof (* clk_data -> hws ) * 2 ), <nl> GFP_KERNEL ); <nl> - if (! clk_data ) <nl> + if (! clk_data ) { <nl> + kfree ( rtc ); <nl> return ; <nl> + } <nl>  <nl> spin_lock_init (& rtc -> lock ); <nl> 
mmm fs / logfs / logfs . h <nl> ppp fs / logfs / logfs . h <nl> static inline int logfs_get_sb_bdev ( struct logfs_super * s , <nl>  <nl> /* dev_mtd . c */ <nl> # ifdef CONFIG_MTD <nl> - int logfs_get_sb_mtd ( struct logfs_super * s , int mtdnr ) <nl> + int logfs_get_sb_mtd ( struct logfs_super * s , int mtdnr ); <nl> # else <nl> static inline int logfs_get_sb_mtd ( struct logfs_super * s , int mtdnr ) <nl> {
mmm fs / namespace . c <nl> ppp fs / namespace . c <nl> static int do_loopback ( struct path * path , const char * old_name , <nl>  <nl> if ( IS_ERR ( mnt )) { <nl> err = PTR_ERR ( mnt ); <nl> - goto out ; <nl> + goto out2 ; <nl> } <nl>  <nl> err = graft_tree ( mnt , path );
mmm net / wireless / util . c <nl> ppp net / wireless / util . c <nl> int cfg80211_validate_key_settings ( struct cfg80211_registered_device * rdev , <nl> struct key_params * params , int key_idx , <nl> bool pairwise , const u8 * mac_addr ) <nl> { <nl> - if ( key_idx > 5 ) <nl> + if ( key_idx < 0 || key_idx > 5 ) <nl> return - EINVAL ; <nl>  <nl> if (! pairwise && mac_addr && !( rdev -> wiphy . flags & WIPHY_FLAG_IBSS_RSN )) <nl> int cfg80211_validate_key_settings ( struct cfg80211_registered_device * rdev , <nl> /* Disallow BIP ( group - only ) cipher as pairwise cipher */ <nl> if ( pairwise ) <nl> return - EINVAL ; <nl> + if ( key_idx < 4 ) <nl> + return - EINVAL ; <nl> break ; <nl> + case WLAN_CIPHER_SUITE_WEP40 : <nl> + case WLAN_CIPHER_SUITE_WEP104 : <nl> + if ( key_idx > 3 ) <nl> + return - EINVAL ; <nl> default : <nl> break ; <nl> }
mmm kernel / sched / core . c <nl> ppp kernel / sched / core . c <nl> migration_call ( struct notifier_block * nfb , unsigned long action , void * hcpu ) <nl> migrate_tasks ( rq ); <nl> BUG_ON ( rq -> nr_running != 1 ); /* the migration thread */ <nl> raw_spin_unlock_irqrestore (& rq -> lock , flags ); <nl> - break ; <nl> - <nl> - case CPU_DEAD : <nl> calc_load_migrate ( rq ); <nl> break ; <nl> # endif
mmm drivers / idle / intel_idle . c <nl> ppp drivers / idle / intel_idle . c <nl> static int __init intel_idle_init ( void ) <nl> if ( retval ) <nl> return retval ; <nl>  <nl> + intel_idle_cpuidle_devices = alloc_percpu ( struct cpuidle_device ); <nl> + if ( intel_idle_cpuidle_devices == NULL ) <nl> + return - ENOMEM ; <nl> + <nl> intel_idle_cpuidle_driver_init (); <nl> retval = cpuidle_register_driver (& intel_idle_driver ); <nl> if ( retval ) { <nl> struct cpuidle_driver * drv = cpuidle_get_driver (); <nl> printk ( KERN_DEBUG PREFIX " intel_idle yielding to % s ", <nl> drv ? drv -> name : " none "); <nl> + free_percpu ( intel_idle_cpuidle_devices ); <nl> return retval ; <nl> } <nl>  <nl> - intel_idle_cpuidle_devices = alloc_percpu ( struct cpuidle_device ); <nl> - if ( intel_idle_cpuidle_devices == NULL ) <nl> - return - ENOMEM ; <nl> - <nl> cpu_notifier_register_begin (); <nl>  <nl> for_each_online_cpu ( i ) {
mmm tools / perf / util / symbol . c <nl> ppp tools / perf / util / symbol . c <nl> static int dso__load_sym ( struct dso * self , int fd , const char * name , <nl>  <nl> nr_syms = shdr . sh_size / shdr . sh_entsize ; <nl>  <nl> + memset (& sym , 0 , sizeof ( sym )); <nl> + <nl> elf_symtab__for_each_symbol ( syms , nr_syms , index , sym ) { <nl> struct symbol * f ; <nl> uint64_t obj_start ;
mmm drivers / nvme / host / core . c <nl> ppp drivers / nvme / host / core . c <nl> int __nvme_submit_user_cmd ( struct request_queue * q , struct nvme_command * cmd , <nl> goto out_unmap ; <nl> } <nl>  <nl> - if ( meta_buffer ) { <nl> + if ( meta_buffer && meta_len ) { <nl> struct bio_integrity_payload * bip ; <nl>  <nl> meta = kmalloc ( meta_len , GFP_KERNEL );
mmm kernel / bpf / verifier . c <nl> ppp kernel / bpf / verifier . c <nl> static int check_stack_boundary ( struct bpf_verifier_env * env , int regno , <nl> tnum_strn ( tn_buf , sizeof ( tn_buf ), regs [ regno ]. var_off ); <nl> verbose ( env , " invalid variable stack read R % d var_off =% s \ n ", <nl> regno , tn_buf ); <nl> + return - EACCES ; <nl> } <nl> off = regs [ regno ]. off + regs [ regno ]. var_off . value ; <nl> if ( off >= 0 || off < - MAX_BPF_STACK || off + access_size > 0 ||
mmm drivers / staging / unisys / visorbus / visorchipset . c <nl> ppp drivers / staging / unisys / visorbus / visorchipset . c <nl> static ssize_t error_store ( struct device * dev , struct device_attribute * attr , <nl> const char * buf , size_t count ) <nl> { <nl> u32 error ; <nl> - int ret ; <nl> + int err ; <nl>  <nl> if ( kstrtou32 ( buf , 10 , & error )) <nl> return - EINVAL ; <nl>  <nl> - ret = visorchannel_write <nl> + err = visorchannel_write <nl> ( chipset_dev -> controlvm_channel , <nl> offsetof ( struct spar_controlvm_channel_protocol , <nl> installation_error ), <nl> & error , sizeof ( u32 )); <nl> - if ( ret ) <nl> - return ret ; <nl> + if ( err ) <nl> + return err ; <nl> return count ; <nl> } <nl> static DEVICE_ATTR_RW ( error );
mmm include / linux / topology . h <nl> ppp include / linux / topology . h <nl> void arch_update_cpu_topology ( void ); <nl> . busy_idx = 3 , \ <nl> . idle_idx = 3 , \ <nl> . flags = SD_LOAD_BALANCE \ <nl> - | SD_SERIALIZE , \ <nl> + | SD_BALANCE_NEWIDLE \ <nl> + | SD_WAKE_AFFINE \ <nl> + | SD_SERIALIZE , \ <nl> . last_balance = jiffies , \ <nl> . balance_interval = 64 , \ <nl> }
mmm block / partitions / efi . c <nl> ppp block / partitions / efi . c <nl> static gpt_entry * alloc_read_gpt_entries ( struct parsed_partitions * state , <nl> le32_to_cpu ( gpt -> sizeof_partition_entry ); <nl> if (! count ) <nl> return NULL ; <nl> - pte = kzalloc ( count , GFP_KERNEL ); <nl> + pte = kmalloc ( count , GFP_KERNEL ); <nl> if (! pte ) <nl> return NULL ; <nl>  <nl> static gpt_header * alloc_read_gpt_header ( struct parsed_partitions * state , <nl> gpt_header * gpt ; <nl> unsigned ssz = bdev_logical_block_size ( state -> bdev ); <nl>  <nl> - gpt = kzalloc ( ssz , GFP_KERNEL ); <nl> + gpt = kmalloc ( ssz , GFP_KERNEL ); <nl> if (! gpt ) <nl> return NULL ; <nl> 
mmm fs / cifs / transport . c <nl> ppp fs / cifs / transport . c <nl> smb_send_kvec ( struct TCP_Server_Info * server , struct kvec * iov , size_t n_vec , <nl>  <nl> * sent = 0 ; <nl>  <nl> - if ( ssocket == NULL ) <nl> - return - ENOTSOCK ; /* BB eventually add reconnect code here */ <nl> - <nl> smb_msg . msg_name = ( struct sockaddr *) & server -> dstaddr ; <nl> smb_msg . msg_namelen = sizeof ( struct sockaddr ); <nl> smb_msg . msg_control = NULL ; <nl> smb_send_rqst ( struct TCP_Server_Info * server , struct smb_rqst * rqst ) <nl> struct socket * ssocket = server -> ssocket ; <nl> int val = 1 ; <nl>  <nl> + if ( ssocket == NULL ) <nl> + return - ENOTSOCK ; <nl> + <nl> cFYI ( 1 , " Sending smb : smb_len =% u ", smb_buf_length ); <nl> dump_smb ( iov [ 0 ]. iov_base , iov [ 0 ]. iov_len ); <nl> 
mmm drivers / irqchip / irq - stm32 - exti . c <nl> ppp drivers / irqchip / irq - stm32 - exti . c <nl> static void stm32_exti_free ( struct irq_domain * d , unsigned int virq , <nl> irq_domain_reset_irq_data ( data ); <nl> } <nl>  <nl> - struct irq_domain_ops irq_exti_domain_ops = { <nl> + static const struct irq_domain_ops irq_exti_domain_ops = { <nl> . map = irq_map_generic_chip , <nl> . alloc = stm32_exti_alloc , <nl> . free = stm32_exti_free , <nl> __init stm32_exti_init ( const struct stm32_exti_bank ** stm32_exti_banks , <nl> handle_edge_irq , clr , 0 , 0 ); <nl> if ( ret ) { <nl> pr_err ("% pOF : Could not allocate generic interrupt chip .\ n ", <nl> - node ); <nl> + node ); <nl> goto out_free_domain ; <nl> } <nl> 
mmm drivers / scsi / lpfc / lpfc_attr . c <nl> ppp drivers / scsi / lpfc / lpfc_attr . c <nl> lpfc_nvme_info_show ( struct device * dev , struct device_attribute * attr , <nl> wwn_to_u64 ( vport -> fc_nodename . u . wwn ), <nl> phba -> targetport -> port_id ); <nl>  <nl> - len += snprintf ( buf + len , PAGE_SIZE , <nl> + len += snprintf ( buf + len , PAGE_SIZE - len , <nl> "\ nNVME Target : Statistics \ n "); <nl> tgtp = ( struct lpfc_nvmet_tgtport *) phba -> targetport -> private ; <nl> len += snprintf ( buf + len , PAGE_SIZE - len , <nl> lpfc_nvme_info_show ( struct device * dev , struct device_attribute * attr , <nl> } <nl> spin_unlock_irq ( shost -> host_lock ); <nl>  <nl> - len += snprintf ( buf + len , PAGE_SIZE , "\ nNVME Statistics \ n "); <nl> + len += snprintf ( buf + len , PAGE_SIZE - len , "\ nNVME Statistics \ n "); <nl> len += snprintf ( buf + len , PAGE_SIZE - len , <nl> " LS : Xmt % 016llx Cmpl % 016llx \ n ", <nl> phba -> fc4NvmeLsRequests ,
mmm net / netfilter / nf_tables_api . c <nl> ppp net / netfilter / nf_tables_api . c <nl> static int nf_tables_getset ( struct net * net , struct sock * nlsk , <nl> /* Only accept unspec with dump */ <nl> if ( nfmsg -> nfgen_family == NFPROTO_UNSPEC ) <nl> return - EAFNOSUPPORT ; <nl> + if (! nla [ NFTA_SET_TABLE ]) <nl> + return - EINVAL ; <nl>  <nl> set = nf_tables_set_lookup ( ctx . table , nla [ NFTA_SET_NAME ]); <nl> if ( IS_ERR ( set ))
mmm sound / pci / hda / hda_codec . c <nl> ppp sound / pci / hda / hda_codec . c <nl> int snd_hda_multi_out_analog_open ( struct hda_codec * codec , <nl> if ( mout -> spdif_maxbps < hinfo -> maxbps ) <nl> hinfo -> maxbps = mout -> spdif_maxbps ; <nl> } <nl> + mutex_unlock (& codec -> spdif_mutex ); <nl> } <nl> - mutex_unlock (& codec -> spdif_mutex ); <nl> return snd_pcm_hw_constraint_step ( substream -> runtime , 0 , <nl> SNDRV_PCM_HW_PARAM_CHANNELS , 2 ); <nl> }
mmm drivers / regulator / max8973 - regulator . c <nl> ppp drivers / regulator / max8973 - regulator . c <nl> static int max8973_probe ( struct i2c_client * client , <nl> } <nl>  <nl> if ( pdata ) { <nl> - max -> dvs_gpio = pdata -> dvs_gpio ; <nl> + max -> dvs_gpio = ( pdata -> dvs_gpio ) ? pdata -> dvs_gpio : - EINVAL ; <nl> max -> enable_external_control = pdata -> enable_ext_control ; <nl> max -> curr_gpio_val = pdata -> dvs_def_state ; <nl> max -> curr_vout_reg = MAX8973_VOUT + pdata -> dvs_def_state ;
mmm drivers / scsi / scsi_debug . c <nl> ppp drivers / scsi / scsi_debug . c <nl> static int inquiry_evpd_b0 ( unsigned char * arr ) <nl> return sizeof ( vpdb0_data ); <nl> } <nl>  <nl> + static int inquiry_evpd_b1 ( unsigned char * arr ) <nl> +{ <nl> + memset ( arr , 0 , 0x3c ); <nl> + arr [ 0 ] = 0 ; <nl> + arr [ 1 ] = 1 ; <nl> + <nl> + return 0x3c ; <nl> +} <nl>  <nl> # define SDEBUG_LONG_INQ_SZ 96 <nl> # define SDEBUG_MAX_INQ_ARR_SZ 584 <nl> static int resp_inquiry ( struct scsi_cmnd * scp , int target , <nl> arr [ n ++] = 0x88 ; /* SCSI ports */ <nl> arr [ n ++] = 0x89 ; /* ATA information */ <nl> arr [ n ++] = 0xb0 ; /* Block limits ( SBC ) */ <nl> + arr [ n ++] = 0xb1 ; /* Block characteristics ( SBC ) */ <nl> arr [ 3 ] = n - 4 ; /* number of supported VPD pages */ <nl> } else if ( 0x80 == cmd [ 2 ]) { /* unit serial number */ <nl> arr [ 1 ] = cmd [ 2 ]; /* sanity */ <nl> static int resp_inquiry ( struct scsi_cmnd * scp , int target , <nl> } else if ( 0xb0 == cmd [ 2 ]) { /* Block limits ( SBC ) */ <nl> arr [ 1 ] = cmd [ 2 ]; /* sanity */ <nl> arr [ 3 ] = inquiry_evpd_b0 (& arr [ 4 ]); <nl> + } else if ( 0xb1 == cmd [ 2 ]) { /* Block characteristics ( SBC ) */ <nl> + arr [ 1 ] = cmd [ 2 ]; /* sanity */ <nl> + arr [ 3 ] = inquiry_evpd_b1 (& arr [ 4 ]); <nl> } else { <nl> /* Illegal request , invalid field in cdb */ <nl> mk_sense_buffer ( devip , ILLEGAL_REQUEST ,
mmm drivers / infiniband / core / uverbs_main . c <nl> ppp drivers / infiniband / core / uverbs_main . c <nl> static ssize_t ib_uverbs_write ( struct file * filp , const char __user * buf , <nl> goto out ; <nl> } <nl>  <nl> + if (! file -> ucontext && <nl> + command != IB_USER_VERBS_CMD_GET_CONTEXT ) { <nl> + ret = - EINVAL ; <nl> + goto out ; <nl> + } <nl> + <nl> flags = ( hdr . command & <nl> IB_USER_VERBS_CMD_FLAGS_MASK ) >> IB_USER_VERBS_CMD_FLAGS_SHIFT ; <nl>  <nl> static ssize_t ib_uverbs_write ( struct file * filp , const char __user * buf , <nl> goto out ; <nl> } <nl>  <nl> - if (! file -> ucontext && <nl> - command != IB_USER_VERBS_CMD_GET_CONTEXT ) { <nl> - ret = - EINVAL ; <nl> - goto out ; <nl> - } <nl> - <nl> if ( hdr . in_words * 4 != count ) { <nl> ret = - EINVAL ; <nl> goto out ;
mmm fs / ubifs / lpt . c <nl> ppp fs / ubifs / lpt . c <nl> int ubifs_lpt_scan_nolock ( struct ubifs_info * c , int start_lnum , int end_lnum , <nl>  <nl> if ( path [ h ]. in_tree ) <nl> continue ; <nl> - nnode = kmalloc ( sz , GFP_NOFS ); <nl> + nnode = kmemdup (& path [ h ]. nnode , sz , GFP_NOFS ); <nl> if (! nnode ) { <nl> err = - ENOMEM ; <nl> goto out ; <nl> } <nl> - memcpy ( nnode , & path [ h ]. nnode , sz ); <nl> parent = nnode -> parent ; <nl> parent -> nbranch [ nnode -> iip ]. nnode = nnode ; <nl> path [ h ]. ptr . nnode = nnode ; <nl> int ubifs_lpt_scan_nolock ( struct ubifs_info * c , int start_lnum , int end_lnum , <nl> const size_t sz = sizeof ( struct ubifs_pnode ); <nl> struct ubifs_nnode * parent ; <nl>  <nl> - pnode = kmalloc ( sz , GFP_NOFS ); <nl> + pnode = kmemdup (& path [ h ]. pnode , sz , GFP_NOFS ); <nl> if (! pnode ) { <nl> err = - ENOMEM ; <nl> goto out ; <nl> } <nl> - memcpy ( pnode , & path [ h ]. pnode , sz ); <nl> parent = pnode -> parent ; <nl> parent -> nbranch [ pnode -> iip ]. pnode = pnode ; <nl> path [ h ]. ptr . pnode = pnode ;mmm fs / ubifs / tnc . c <nl> ppp fs / ubifs / tnc . c <nl> int ubifs_lpt_scan_nolock ( struct ubifs_info * c , int start_lnum , int end_lnum , <nl>  <nl> if ( path [ h ]. in_tree ) <nl> continue ; <nl> - nnode = kmalloc ( sz , GFP_NOFS ); <nl> + nnode = kmemdup (& path [ h ]. nnode , sz , GFP_NOFS ); <nl> if (! nnode ) { <nl> err = - ENOMEM ; <nl> goto out ; <nl> } <nl> - memcpy ( nnode , & path [ h ]. nnode , sz ); <nl> parent = nnode -> parent ; <nl> parent -> nbranch [ nnode -> iip ]. nnode = nnode ; <nl> path [ h ]. ptr . nnode = nnode ; <nl> int ubifs_lpt_scan_nolock ( struct ubifs_info * c , int start_lnum , int end_lnum , <nl> const size_t sz = sizeof ( struct ubifs_pnode ); <nl> struct ubifs_nnode * parent ; <nl>  <nl> - pnode = kmalloc ( sz , GFP_NOFS ); <nl> + pnode = kmemdup (& path [ h ]. pnode , sz , GFP_NOFS ); <nl> if (! pnode ) { <nl> err = - ENOMEM ; <nl> goto out ; <nl> } <nl> - memcpy ( pnode , & path [ h ]. pnode , sz ); <nl> parent = pnode -> parent ; <nl> parent -> nbranch [ pnode -> iip ]. pnode = pnode ; <nl> path [ h ]. ptr . pnode = pnode ; <nl> static int lnc_add ( struct ubifs_info * c , struct ubifs_zbranch * zbr , <nl> return err ; <nl> } <nl>  <nl> - lnc_node = kmalloc ( zbr -> len , GFP_NOFS ); <nl> + lnc_node = kmemdup ( node , zbr -> len , GFP_NOFS ); <nl> if (! lnc_node ) <nl> /* We don ' t have to have the cache , so no error */ <nl> return 0 ; <nl>  <nl> - memcpy ( lnc_node , node , zbr -> len ); <nl> zbr -> leaf = lnc_node ; <nl> return 0 ; <nl> }mmm fs / ubifs / xattr . c <nl> ppp fs / ubifs / xattr . c <nl> int ubifs_lpt_scan_nolock ( struct ubifs_info * c , int start_lnum , int end_lnum , <nl>  <nl> if ( path [ h ]. in_tree ) <nl> continue ; <nl> - nnode = kmalloc ( sz , GFP_NOFS ); <nl> + nnode = kmemdup (& path [ h ]. nnode , sz , GFP_NOFS ); <nl> if (! nnode ) { <nl> err = - ENOMEM ; <nl> goto out ; <nl> } <nl> - memcpy ( nnode , & path [ h ]. nnode , sz ); <nl> parent = nnode -> parent ; <nl> parent -> nbranch [ nnode -> iip ]. nnode = nnode ; <nl> path [ h ]. ptr . nnode = nnode ; <nl> int ubifs_lpt_scan_nolock ( struct ubifs_info * c , int start_lnum , int end_lnum , <nl> const size_t sz = sizeof ( struct ubifs_pnode ); <nl> struct ubifs_nnode * parent ; <nl>  <nl> - pnode = kmalloc ( sz , GFP_NOFS ); <nl> + pnode = kmemdup (& path [ h ]. pnode , sz , GFP_NOFS ); <nl> if (! pnode ) { <nl> err = - ENOMEM ; <nl> goto out ; <nl> } <nl> - memcpy ( pnode , & path [ h ]. pnode , sz ); <nl> parent = pnode -> parent ; <nl> parent -> nbranch [ pnode -> iip ]. pnode = pnode ; <nl> path [ h ]. ptr . pnode = pnode ; <nl> static int lnc_add ( struct ubifs_info * c , struct ubifs_zbranch * zbr , <nl> return err ; <nl> } <nl>  <nl> - lnc_node = kmalloc ( zbr -> len , GFP_NOFS ); <nl> + lnc_node = kmemdup ( node , zbr -> len , GFP_NOFS ); <nl> if (! lnc_node ) <nl> /* We don ' t have to have the cache , so no error */ <nl> return 0 ; <nl>  <nl> - memcpy ( lnc_node , node , zbr -> len ); <nl> zbr -> leaf = lnc_node ; <nl> return 0 ; <nl> } <nl> static int create_xattr ( struct ubifs_info * c , struct inode * host , <nl> ui = ubifs_inode ( inode ); <nl> ui -> xattr = 1 ; <nl> ui -> flags |= UBIFS_XATTR_FL ; <nl> - ui -> data = kmalloc ( size , GFP_NOFS ); <nl> + ui -> data = kmemdup ( value , size , GFP_NOFS ); <nl> if (! ui -> data ) { <nl> err = - ENOMEM ; <nl> goto out_free ; <nl> } <nl> - memcpy ( ui -> data , value , size ); <nl> inode -> i_size = ui -> ui_size = size ; <nl> ui -> data_len = size ; <nl>  <nl> static int change_xattr ( struct ubifs_info * c , struct inode * host , <nl> return err ; <nl>  <nl> kfree ( ui -> data ); <nl> - ui -> data = kmalloc ( size , GFP_NOFS ); <nl> + ui -> data = kmemdup ( value , size , GFP_NOFS ); <nl> if (! ui -> data ) { <nl> err = - ENOMEM ; <nl> goto out_free ; <nl> } <nl> - memcpy ( ui -> data , value , size ); <nl> inode -> i_size = ui -> ui_size = size ; <nl> ui -> data_len = size ; <nl> 
mmm arch / arm / mach - omap2 / usb - tusb6010 . c <nl> ppp arch / arm / mach - omap2 / usb - tusb6010 . c <nl> int tusb6010_platform_retime ( unsigned is_refclk ) <nl> unsigned sysclk_ps ; <nl> int status ; <nl>  <nl> - if (! refclk_psec || sysclk_ps == 0 ) <nl> + if (! refclk_psec || fclk_ps == 0 ) <nl> return - ENODEV ; <nl>  <nl> sysclk_ps = is_refclk ? refclk_psec : TUSB6010_OSCCLK_60 ;
mmm drivers / isdn / i4l / isdn_common . c <nl> ppp drivers / isdn / i4l / isdn_common . c <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> if ( copy_from_user (& iocts , argp , <nl> sizeof ( isdn_ioctl_struct ))) <nl> return - EFAULT ; <nl> + iocts . drvid [ sizeof ( iocts . drvid )- 1 ] = 0 ; <nl> if ( strlen ( iocts . drvid )) { <nl> if (( p = strchr ( iocts . drvid , ','))) <nl> * p = 0 ; <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> if ( copy_from_user (& iocts , argp , <nl> sizeof ( isdn_ioctl_struct ))) <nl> return - EFAULT ; <nl> + iocts . drvid [ sizeof ( iocts . drvid )- 1 ] = 0 ; <nl> if ( strlen ( iocts . drvid )) { <nl> drvidx = - 1 ; <nl> for ( i = 0 ; i < ISDN_MAX_DRIVERS ; i ++) <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> } else { <nl> p = ( char __user *) iocts . arg ; <nl> for ( i = 0 ; i < 10 ; i ++) { <nl> - sprintf ( bname , "% s % s ", <nl> + snprintf ( bname , sizeof ( bname ), "% s % s ", <nl> strlen ( dev -> drv [ drvidx ]-> msn2eaz [ i ]) ? <nl> dev -> drv [ drvidx ]-> msn2eaz [ i ] : " _ ", <nl> ( i < 9 ) ? "," : "\ 0 "); <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> char * p ; <nl> if ( copy_from_user (& iocts , argp , sizeof ( isdn_ioctl_struct ))) <nl> return - EFAULT ; <nl> + iocts . drvid [ sizeof ( iocts . drvid )- 1 ] = 0 ; <nl> if ( strlen ( iocts . drvid )) { <nl> if (( p = strchr ( iocts . drvid , ','))) <nl> * p = 0 ;
mmm mm / hugetlb . c <nl> ppp mm / hugetlb . c <nl> static int dissolve_free_huge_page ( struct page * page ) <nl> int dissolve_free_huge_pages ( unsigned long start_pfn , unsigned long end_pfn ) <nl> { <nl> unsigned long pfn ; <nl> + struct page * page ; <nl> int rc = 0 ; <nl>  <nl> if (! hugepages_supported ()) <nl> return rc ; <nl>  <nl> - for ( pfn = start_pfn ; pfn < end_pfn ; pfn += 1 << minimum_order ) <nl> - if ( rc = dissolve_free_huge_page ( pfn_to_page ( pfn ))) <nl> - break ; <nl> + for ( pfn = start_pfn ; pfn < end_pfn ; pfn += 1 << minimum_order ) { <nl> + page = pfn_to_page ( pfn ); <nl> + if ( PageHuge ( page ) && ! page_count ( page )) { <nl> + rc = dissolve_free_huge_page ( page ); <nl> + if ( rc ) <nl> + break ; <nl> + } <nl> + } <nl>  <nl> return rc ; <nl> }
mmm drivers / gpu / drm / amd / amdgpu / amdgpu_cs . c <nl> ppp drivers / gpu / drm / amd / amdgpu / amdgpu_cs . c <nl> static int amdgpu_cs_wait_any_fence ( struct amdgpu_device * adev , <nl> wait -> out . status = ( r > 0 ); <nl> wait -> out . first_signaled = first ; <nl>  <nl> - if ( array [ first ]) <nl> + if ( first < fence_count && array [ first ]) <nl> r = array [ first ]-> error ; <nl> else <nl> r = 0 ;
mmm fs / ceph / mds_client . c <nl> ppp fs / ceph / mds_client . c <nl> static int __do_request ( struct ceph_mds_client * mdsc , <nl> int mds = - 1 ; <nl> int err = - EAGAIN ; <nl>  <nl> - if ( req -> r_err || req -> r_got_result ) <nl> + if ( req -> r_err || req -> r_got_result ) { <nl> + if ( req -> r_aborted ) <nl> + __unregister_request ( mdsc , req ); <nl> goto out ; <nl> + } <nl>  <nl> if ( req -> r_timeout && <nl> time_after_eq ( jiffies , req -> r_started + req -> r_timeout )) {
mmm drivers / media / platform / soc_camera / soc_camera . c <nl> ppp drivers / media / platform / soc_camera / soc_camera . c <nl> static int soc_camera_s_selection ( struct file * file , void * fh , <nl>  <nl> /* In all these cases cropping emulation will not help */ <nl> if ( s -> type != V4L2_BUF_TYPE_VIDEO_CAPTURE || <nl> - ( s -> target != V4L2_SEL_TGT_COMPOSE_ACTIVE && <nl> - s -> target != V4L2_SEL_TGT_CROP_ACTIVE )) <nl> + ( s -> target != V4L2_SEL_TGT_COMPOSE && <nl> + s -> target != V4L2_SEL_TGT_CROP )) <nl> return - EINVAL ; <nl>  <nl> - if ( s -> target == V4L2_SEL_TGT_COMPOSE_ACTIVE ) { <nl> + if ( s -> target == V4L2_SEL_TGT_COMPOSE ) { <nl> /* No output size change during a running capture ! */ <nl> if ( is_streaming ( ici , icd ) && <nl> ( icd -> user_width != s -> r . width || <nl> static int soc_camera_s_selection ( struct file * file , void * fh , <nl>  <nl> ret = ici -> ops -> set_selection ( icd , s ); <nl> if (! ret && <nl> - s -> target == V4L2_SEL_TGT_COMPOSE_ACTIVE ) { <nl> + s -> target == V4L2_SEL_TGT_COMPOSE ) { <nl> icd -> user_width = s -> r . width ; <nl> icd -> user_height = s -> r . height ; <nl> if (! icd -> streamer )
mmm kernel / cgroup . c <nl> ppp kernel / cgroup . c <nl> static struct dentry * cgroup_mount ( struct file_system_type * fs_type , <nl> mutex_lock (& cgroup_mutex ); <nl> mutex_lock (& cgroup_root_mutex ); <nl>  <nl> - root_cgrp -> id = idr_alloc (& root -> cgroup_idr , root_cgrp , <nl> - 0 , 1 , GFP_KERNEL ); <nl> - if ( root_cgrp -> id < 0 ) <nl> + ret = idr_alloc (& root -> cgroup_idr , root_cgrp , 0 , 1 , GFP_KERNEL ); <nl> + if ( ret < 0 ) <nl> goto unlock_drop ; <nl> + root_cgrp -> id = ret ; <nl>  <nl> /* Check for name clashes with existing mounts */ <nl> ret = - EBUSY ;
mmm drivers / gpu / drm / i915 / intel_pm . c <nl> ppp drivers / gpu / drm / i915 / intel_pm . c <nl> static void valleyview_disable_rps ( struct drm_device * dev ) <nl>  <nl> int intel_enable_rc6 ( const struct drm_device * dev ) <nl> { <nl> + /* No RC6 before Ironlake */ <nl> + if ( INTEL_INFO ( dev )-> gen < 5 ) <nl> + return 0 ; <nl> + <nl> /* Respect the kernel parameter if it is set */ <nl> if ( i915_enable_rc6 >= 0 ) <nl> return i915_enable_rc6 ;
mmm sound / soc / atmel / atmel_ssc_dai . c <nl> ppp sound / soc / atmel / atmel_ssc_dai . c <nl> static int atmel_ssc_set_dai_clkdiv ( struct snd_soc_dai * cpu_dai , <nl> * transmit and receive , so if a value has already <nl> * been set , it must match this value . <nl> */ <nl> - if ( ssc_p -> cmr_div == 0 ) <nl> + if ( ssc_p -> dir_mask != <nl> + ( SSC_DIR_MASK_PLAYBACK | SSC_DIR_MASK_CAPTURE )) <nl> + ssc_p -> cmr_div = div ; <nl> + else if ( ssc_p -> cmr_div == 0 ) <nl> ssc_p -> cmr_div = div ; <nl> else <nl> if ( div != ssc_p -> cmr_div )
mmm net / rds / tcp_connect . c <nl> ppp net / rds / tcp_connect . c <nl> int rds_tcp_conn_connect ( struct rds_connection * conn ) <nl> rds_tcp_set_callbacks ( sock , conn ); <nl> ret = sock -> ops -> connect ( sock , ( struct sockaddr *)& dest , sizeof ( dest ), <nl> O_NONBLOCK ); <nl> - sock = NULL ; <nl>  <nl> rdsdebug (" connect to address % pI4 returned % d \ n ", & conn -> c_faddr , ret ); <nl> if ( ret == - EINPROGRESS ) <nl> ret = 0 ; <nl> + if ( ret == 0 ) <nl> + sock = NULL ; <nl> + else <nl> + rds_tcp_restore_callbacks ( sock , conn -> c_transport_data ); <nl>  <nl> out : <nl> if ( sock )
mmm drivers / acpi / sleep / main . c <nl> ppp drivers / acpi / sleep / main . c <nl> int acpi_suspend ( u32 acpi_state ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + static int acpi_pm_state_valid ( suspend_state_t pm_state ) <nl> +{ <nl> + u32 acpi_state = acpi_suspend_states [ pm_state ]; <nl> + <nl> + return sleep_states [ acpi_state ]; <nl> +} <nl> + <nl> static struct pm_ops acpi_pm_ops = { <nl> + . valid = acpi_pm_state_valid , <nl> . prepare = acpi_pm_prepare , <nl> . enter = acpi_pm_enter , <nl> . finish = acpi_pm_finish ,mmm include / linux / pm . h <nl> ppp include / linux / pm . h <nl> int acpi_suspend ( u32 acpi_state ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + static int acpi_pm_state_valid ( suspend_state_t pm_state ) <nl> +{ <nl> + u32 acpi_state = acpi_suspend_states [ pm_state ]; <nl> + <nl> + return sleep_states [ acpi_state ]; <nl> +} <nl> + <nl> static struct pm_ops acpi_pm_ops = { <nl> + . valid = acpi_pm_state_valid , <nl> . prepare = acpi_pm_prepare , <nl> . enter = acpi_pm_enter , <nl> . finish = acpi_pm_finish , <nl> typedef int __bitwise suspend_disk_method_t ; <nl>  <nl> struct pm_ops { <nl> suspend_disk_method_t pm_disk_mode ; <nl> + int (* valid )( suspend_state_t state ); <nl> int (* prepare )( suspend_state_t state ); <nl> int (* enter )( suspend_state_t state ); <nl> int (* finish )( suspend_state_t state );mmm kernel / power / main . c <nl> ppp kernel / power / main . c <nl> int acpi_suspend ( u32 acpi_state ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + static int acpi_pm_state_valid ( suspend_state_t pm_state ) <nl> +{ <nl> + u32 acpi_state = acpi_suspend_states [ pm_state ]; <nl> + <nl> + return sleep_states [ acpi_state ]; <nl> +} <nl> + <nl> static struct pm_ops acpi_pm_ops = { <nl> + . valid = acpi_pm_state_valid , <nl> . prepare = acpi_pm_prepare , <nl> . enter = acpi_pm_enter , <nl> . finish = acpi_pm_finish , <nl> typedef int __bitwise suspend_disk_method_t ; <nl>  <nl> struct pm_ops { <nl> suspend_disk_method_t pm_disk_mode ; <nl> + int (* valid )( suspend_state_t state ); <nl> int (* prepare )( suspend_state_t state ); <nl> int (* enter )( suspend_state_t state ); <nl> int (* finish )( suspend_state_t state ); <nl> static int enter_state ( suspend_state_t state ) <nl> { <nl> int error ; <nl>  <nl> + if ( pm_ops -> valid && ! pm_ops -> valid ( state )) <nl> + return - ENODEV ; <nl> if ( down_trylock (& pm_sem )) <nl> return - EBUSY ; <nl>  <nl> static ssize_t state_show ( struct subsystem * subsys , char * buf ) <nl> char * s = buf ; <nl>  <nl> for ( i = 0 ; i < PM_SUSPEND_MAX ; i ++) { <nl> - if ( pm_states [ i ]) <nl> + if ( pm_states [ i ] && pm_ops && (! pm_ops -> valid <nl> + ||( pm_ops -> valid && pm_ops -> valid ( i )))) <nl> s += sprintf ( s ,"% s ", pm_states [ i ]); <nl> } <nl> s += sprintf ( s ,"\ n ");
mmm sound / pci / hda / patch_realtek . c <nl> ppp sound / pci / hda / patch_realtek . c <nl> static const char * alc_get_line_out_pfx ( const struct auto_pin_cfg * cfg , <nl>  <nl> switch ( cfg -> line_out_type ) { <nl> case AUTO_PIN_SPEAKER_OUT : <nl> - return " Speaker "; <nl> + if ( cfg -> line_outs == 1 ) <nl> + return " Speaker "; <nl> + break ; <nl> case AUTO_PIN_HP_OUT : <nl> return " Headphone "; <nl> default :
mmm drivers / net / hyperv / netvsc . c <nl> ppp drivers / net / hyperv / netvsc . c <nl> static u32 netvsc_copy_to_send_buf ( struct netvsc_device * net_device , <nl> packet -> page_buf_cnt ; <nl>  <nl> /* Add padding */ <nl> - if ( skb && skb -> xmit_more && remain && <nl> - ! packet -> cp_partial ) { <nl> + if ( skb -> xmit_more && remain && ! packet -> cp_partial ) { <nl> padding = net_device -> pkt_align - remain ; <nl> rndis_msg -> msg_len += padding ; <nl> packet -> total_data_buflen += padding ; <nl> int netvsc_send ( struct hv_device * device , <nl> if ( msdp -> pkt ) <nl> msd_len = msdp -> pkt -> total_data_buflen ; <nl>  <nl> - try_batch = ( skb != NULL ) && msd_len > 0 && msdp -> count < <nl> - net_device -> max_pkt ; <nl> - <nl> + try_batch = msd_len > 0 && msdp -> count < net_device -> max_pkt ; <nl> if ( try_batch && msd_len + pktlen + net_device -> pkt_align < <nl> net_device -> send_section_size ) { <nl> section_index = msdp -> pkt -> send_buf_index ; <nl> int netvsc_send ( struct hv_device * device , <nl> section_index = msdp -> pkt -> send_buf_index ; <nl> packet -> cp_partial = true ; <nl>  <nl> - } else if (( skb != NULL ) && pktlen + net_device -> pkt_align < <nl> + } else if ( pktlen + net_device -> pkt_align < <nl> net_device -> send_section_size ) { <nl> section_index = netvsc_get_next_send_section ( net_device ); <nl> if ( section_index != NETVSC_INVALID_INDEX ) {
mmm drivers / input / serio / ams_delta_serio . c <nl> ppp drivers / input / serio / ams_delta_serio . c <nl> static void __exit ams_delta_serio_exit ( void ) <nl> free_irq ( OMAP_GPIO_IRQ ( AMS_DELTA_GPIO_PIN_KEYBRD_CLK ), 0 ); <nl> gpio_free ( AMS_DELTA_GPIO_PIN_KEYBRD_CLK ); <nl> gpio_free ( AMS_DELTA_GPIO_PIN_KEYBRD_DATA ); <nl> - kfree ( ams_delta_serio ); <nl> } <nl> module_exit ( ams_delta_serio_exit );
mmm drivers / staging / ccree / hash_defs . h <nl> ppp drivers / staging / ccree / hash_defs . h <nl> enum HashCipherDoPadding { <nl>  <nl> typedef struct SepHashPrivateContext { <nl> /* The current length is placed at the end of the context buffer because the hash <nl> - context is used for all HMAC operations as well . HMAC context includes a 64 bytes <nl> - K0 field . The size of struct drv_ctx_hash reserved field is 88 / 184 bytes depend if t <nl> - he SHA512 is supported ( in this case teh context size is 256 bytes ). <nl> - The size of struct drv_ctx_hash reseved field is 20 or 52 depend if the SHA512 is supported . <nl> - This means that this structure size ( without the reserved field can be up to 20 bytes , <nl> - in case sha512 is not suppported it is 20 bytes ( SEP_HASH_LENGTH_WORDS define to 2 ) and in the other <nl> - case it is 28 ( SEP_HASH_LENGTH_WORDS define to 4 ) */ <nl> + * context is used for all HMAC operations as well . HMAC context includes a 64 bytes <nl> + * K0 field . The size of struct drv_ctx_hash reserved field is 88 / 184 bytes depend if t <nl> + * he SHA512 is supported ( in this case teh context size is 256 bytes ). <nl> + * The size of struct drv_ctx_hash reseved field is 20 or 52 depend if the SHA512 is supported . <nl> + * This means that this structure size ( without the reserved field can be up to 20 bytes , <nl> + * in case sha512 is not suppported it is 20 bytes ( SEP_HASH_LENGTH_WORDS define to 2 ) and in the other <nl> + * case it is 28 ( SEP_HASH_LENGTH_WORDS define to 4 ) <nl> + */ <nl> u32 reserved [( sizeof ( struct drv_ctx_hash )/ sizeof ( u32 )) - SEP_HASH_LENGTH_WORDS - 3 ]; <nl> u32 CurrentDigestedLength [ SEP_HASH_LENGTH_WORDS ]; <nl> u32 KeyType ;
mmm include / net / esp . h <nl> ppp include / net / esp . h <nl>  <nl> # include < linux / skbuff . h > <nl>  <nl> +# define ESP_SKB_FRAG_MAXSIZE ( PAGE_SIZE << SKB_FRAG_PAGE_ORDER ) <nl> + <nl> struct ip_esp_hdr ; <nl>  <nl> static inline struct ip_esp_hdr * ip_esp_hdr ( const struct sk_buff * skb )mmm net / ipv4 / esp4 . c <nl> ppp net / ipv4 / esp4 . c <nl>  <nl> # include < linux / skbuff . h > <nl>  <nl> +# define ESP_SKB_FRAG_MAXSIZE ( PAGE_SIZE << SKB_FRAG_PAGE_ORDER ) <nl> + <nl> struct ip_esp_hdr ; <nl>  <nl> static inline struct ip_esp_hdr * ip_esp_hdr ( const struct sk_buff * skb ) <nl> int esp_output_head ( struct xfrm_state * x , struct sk_buff * skb , struct esp_info * <nl> struct page * page ; <nl> struct sk_buff * trailer ; <nl> int tailen = esp -> tailen ; <nl> + unsigned int allocsz ; <nl>  <nl> /* this is non - NULL only with TCP / UDP Encapsulation */ <nl> if ( x -> encap ) { <nl> int esp_output_head ( struct xfrm_state * x , struct sk_buff * skb , struct esp_info * <nl> return err ; <nl> } <nl>  <nl> + allocsz = ALIGN ( skb -> data_len + tailen , L1_CACHE_BYTES ); <nl> + if ( allocsz > ESP_SKB_FRAG_MAXSIZE ) <nl> + goto cow ; <nl> + <nl> if (! skb_cloned ( skb )) { <nl> if ( tailen <= skb_tailroom ( skb )) { <nl> nfrags = 1 ;mmm net / ipv6 / esp6 . c <nl> ppp net / ipv6 / esp6 . c <nl>  <nl> # include < linux / skbuff . h > <nl>  <nl> +# define ESP_SKB_FRAG_MAXSIZE ( PAGE_SIZE << SKB_FRAG_PAGE_ORDER ) <nl> + <nl> struct ip_esp_hdr ; <nl>  <nl> static inline struct ip_esp_hdr * ip_esp_hdr ( const struct sk_buff * skb ) <nl> int esp_output_head ( struct xfrm_state * x , struct sk_buff * skb , struct esp_info * <nl> struct page * page ; <nl> struct sk_buff * trailer ; <nl> int tailen = esp -> tailen ; <nl> + unsigned int allocsz ; <nl>  <nl> /* this is non - NULL only with TCP / UDP Encapsulation */ <nl> if ( x -> encap ) { <nl> int esp_output_head ( struct xfrm_state * x , struct sk_buff * skb , struct esp_info * <nl> return err ; <nl> } <nl>  <nl> + allocsz = ALIGN ( skb -> data_len + tailen , L1_CACHE_BYTES ); <nl> + if ( allocsz > ESP_SKB_FRAG_MAXSIZE ) <nl> + goto cow ; <nl> + <nl> if (! skb_cloned ( skb )) { <nl> if ( tailen <= skb_tailroom ( skb )) { <nl> nfrags = 1 ; <nl> int esp6_output_head ( struct xfrm_state * x , struct sk_buff * skb , struct esp_info <nl> struct page * page ; <nl> struct sk_buff * trailer ; <nl> int tailen = esp -> tailen ; <nl> + unsigned int allocsz ; <nl>  <nl> if ( x -> encap ) { <nl> int err = esp6_output_encap ( x , skb , esp ); <nl> int esp6_output_head ( struct xfrm_state * x , struct sk_buff * skb , struct esp_info <nl> return err ; <nl> } <nl>  <nl> + allocsz = ALIGN ( skb -> data_len + tailen , L1_CACHE_BYTES ); <nl> + if ( allocsz > ESP_SKB_FRAG_MAXSIZE ) <nl> + goto cow ; <nl> + <nl> if (! skb_cloned ( skb )) { <nl> if ( tailen <= skb_tailroom ( skb )) { <nl> nfrags = 1 ;
mmm net / sched / act_api . c <nl> ppp net / sched / act_api . c <nl> tc_dump_action ( struct sk_buff * skb , struct netlink_callback * cb ) <nl> nla_nest_end ( skb , nest ); <nl> ret = skb -> len ; <nl> } else <nl> - nla_nest_cancel ( skb , nest ); <nl> + nlmsg_trim ( skb , b ); <nl>  <nl> nlh -> nlmsg_len = skb_tail_pointer ( skb ) - b ; <nl> if ( NETLINK_CB ( cb -> skb ). portid && ret )
mmm net / phonet / af_phonet . c <nl> ppp net / phonet / af_phonet . c <nl> static int pn_send ( struct sk_buff * skb , struct net_device * dev , <nl> struct phonethdr * ph ; <nl> int err ; <nl>  <nl> - if ( skb -> len + 2 > 0xffff ) { <nl> - /* Phonet length field would overflow */ <nl> + if ( skb -> len + 2 > 0xffff /* Phonet length field limit */ || <nl> + skb -> len + sizeof ( struct phonethdr ) > dev -> mtu ) { <nl> err = - EMSGSIZE ; <nl> goto drop ; <nl> }
mmm net / sctp / sm_statefuns . c <nl> ppp net / sctp / sm_statefuns . c <nl> sctp_disposition_t sctp_sf_do_5_1D_ce ( struct net * net , <nl> struct sctp_chunk auth ; <nl> sctp_ierror_t ret ; <nl>  <nl> + /* Make sure that we and the peer are AUTH capable */ <nl> + if (! net -> sctp . auth_enable || ! new_asoc -> peer . auth_capable ) { <nl> + kfree_skb ( chunk -> auth_chunk ); <nl> + sctp_association_free ( new_asoc ); <nl> + return sctp_sf_pdiscard ( net , ep , asoc , type , arg , commands ); <nl> + } <nl> + <nl> /* set - up our fake chunk so that we can process it */ <nl> auth . skb = chunk -> auth_chunk ; <nl> auth . asoc = chunk -> asoc ;
mmm drivers / regulator / tps65023 - regulator . c <nl> ppp drivers / regulator / tps65023 - regulator . c <nl> static int __devinit tps_65023_probe ( struct i2c_client * client , <nl>  <nl> tps -> desc [ i ]. name = info -> name ; <nl> tps -> desc [ i ]. id = i ; <nl> - tps -> desc [ i ]. n_voltages = info -> table_len ; <nl> + if ( info -> fixed ) <nl> + tps -> desc [ i ]. n_voltages = 1 ; <nl> + else <nl> + tps -> desc [ i ]. n_voltages = info -> table_len ; <nl> tps -> desc [ i ]. ops = ( i > TPS65023_DCDC_3 ? <nl> & tps65023_ldo_ops : & tps65023_dcdc_ops ); <nl> tps -> desc [ i ]. type = REGULATOR_VOLTAGE ;
mmm drivers / scsi / qla2xxx / qla_mr . c <nl> ppp drivers / scsi / qla2xxx / qla_mr . c <nl> qlafx00_soc_cpu_reset ( scsi_qla_host_t * vha ) <nl> /* Kick in Core0 to start boot process */ <nl> QLAFX00_SET_HBA_SOC_REG ( ha , SOC_SW_RST_CONTROL_REG_CORE0 , ( 0xF00 )); <nl>  <nl> + spin_unlock_irqrestore (& ha -> hardware_lock , flags ); <nl> + <nl> /* Wait 10secs for soft - reset to complete . */ <nl> for ( cnt = 10 ; cnt ; cnt --) { <nl> msleep ( 1000 ); <nl> barrier (); <nl> } <nl> - spin_unlock_irqrestore (& ha -> hardware_lock , flags ); <nl> } <nl>  <nl> /**
mmm drivers / phy / rockchip / phy - rockchip - typec . c <nl> ppp drivers / phy / rockchip / phy - rockchip - typec . c <nl> static int tcphy_get_mode ( struct rockchip_typec_phy * tcphy ) <nl> u8 mode ; <nl> int ret ; <nl>  <nl> + if (! edev ) <nl> + return MODE_DFP_USB ; <nl> + <nl> ufp = extcon_get_state ( edev , EXTCON_USB ); <nl> dp = extcon_get_state ( edev , EXTCON_DISP_DP ); <nl>  <nl> static int rockchip_typec_phy_probe ( struct platform_device * pdev ) <nl>  <nl> tcphy -> extcon = extcon_get_edev_by_phandle ( dev , 0 ); <nl> if ( IS_ERR ( tcphy -> extcon )) { <nl> - if ( PTR_ERR ( tcphy -> extcon ) != - EPROBE_DEFER ) <nl> - dev_err ( dev , " Invalid or missing extcon \ n "); <nl> - return PTR_ERR ( tcphy -> extcon ); <nl> + if ( PTR_ERR ( tcphy -> extcon ) == - ENODEV ) { <nl> + tcphy -> extcon = NULL ; <nl> + } else { <nl> + if ( PTR_ERR ( tcphy -> extcon ) != - EPROBE_DEFER ) <nl> + dev_err ( dev , " Invalid or missing extcon \ n "); <nl> + return PTR_ERR ( tcphy -> extcon ); <nl> + } <nl> } <nl>  <nl> pm_runtime_enable ( dev );
mmm drivers / gpu / drm / ttm / ttm_memory . c <nl> ppp drivers / gpu / drm / ttm / ttm_memory . c <nl> static int ttm_mem_init_dma32_zone ( struct ttm_mem_global * glob , <nl> * No special dma32 zone needed . <nl> */ <nl>  <nl> - if ( mem <= (( uint64_t ) 1ULL << 32 )) <nl> + if ( mem <= (( uint64_t ) 1ULL << 32 )) { <nl> + kfree ( zone ); <nl> return 0 ; <nl> + } <nl>  <nl> /* <nl> * Limit max dma32 memory to 4GB for now
mmm drivers / staging / tidspbridge / dynload / cload . c <nl> ppp drivers / staging / tidspbridge / dynload / cload . c <nl> static void dload_symbols ( struct dload_state * dlthis ) <nl> struct local_symbol * sp ; <nl> struct dynload_symbol * symp ; <nl> struct dynload_symbol * newsym ; <nl> + struct doff_syment_t * my_sym_buf ; <nl>  <nl> sym_count = dlthis -> dfile_hdr . df_no_syms ; <nl> if ( sym_count == 0 ) <nl> static void dload_symbols ( struct dload_state * dlthis ) <nl> become defined from the global symbol table */ <nl> checks = dlthis -> verify . dv_sym_tab_checksum ; <nl> symbols_left = sym_count ; <nl> + <nl> + my_sym_buf = kzalloc ( sizeof (* my_sym_buf ) * MY_SYM_BUF_SIZ , GFP_KERNEL ); <nl> + if (! my_sym_buf ) <nl> + return ; <nl> + <nl> do { /* read all symbols */ <nl> char * sname ; <nl> u32 val ; <nl> s32 delta ; <nl> struct doff_syment_t * input_sym ; <nl> unsigned syms_in_buf ; <nl> - struct doff_syment_t my_sym_buf [ MY_SYM_BUF_SIZ ]; <nl> + <nl> input_sym = my_sym_buf ; <nl> syms_in_buf = symbols_left > MY_SYM_BUF_SIZ ? <nl> MY_SYM_BUF_SIZ : symbols_left ; <nl> static void dload_symbols ( struct dload_state * dlthis ) <nl> if ( dlthis -> strm -> read_buffer ( dlthis -> strm , input_sym , siz ) != <nl> siz ) { <nl> DL_ERROR ( readstrm , sym_errid ); <nl> - return ; <nl> + goto free_sym_buf ; <nl> } <nl> if ( dlthis -> reorder_map ) <nl> dload_reorder ( input_sym , siz , dlthis -> reorder_map ); <nl> static void dload_symbols ( struct dload_state * dlthis ) <nl> DL_ERROR (" Absolute symbol % s is " <nl> " defined multiple times with " <nl> " different values ", sname ); <nl> - return ; <nl> + goto free_sym_buf ; <nl> } <nl> } <nl> loop_itr : <nl> static void dload_symbols ( struct dload_state * dlthis ) <nl> if (~ checks ) <nl> dload_error ( dlthis , " Checksum of symbols failed "); <nl>  <nl> + free_sym_buf : <nl> + kfree ( my_sym_buf ); <nl> + return ; <nl> } /* dload_symbols */ <nl>  <nl> /*****************************************************************************
mmm drivers / net / slip / slip . c <nl> ppp drivers / net / slip / slip . c <nl> static void sl_tx_timeout ( struct net_device * dev , unsigned int txqueue ) <nl> spin_lock (& sl -> lock ); <nl>  <nl> if ( netif_queue_stopped ( dev )) { <nl> - if (! netif_running ( dev )) <nl> + if (! netif_running ( dev ) || ! sl -> tty ) <nl> goto out ; <nl>  <nl> /* May be we must check transmitter timeout here ?
mmm drivers / iommu / amd_iommu . c <nl> ppp drivers / iommu / amd_iommu . c <nl> static struct protection_domain * get_domain ( struct device * dev ) <nl> domain = to_pdomain ( io_domain ); <nl> attach_device ( dev , domain ); <nl> } <nl> + if ( domain == NULL ) <nl> + return ERR_PTR (- EBUSY ); <nl> + <nl> if (! dma_ops_domain ( domain )) <nl> return ERR_PTR (- EBUSY ); <nl> 
mmm drivers / s390 / cio / qdio_main . c <nl> ppp drivers / s390 / cio / qdio_main . c <nl> static int qdio_siga_output ( struct qdio_q * q , unsigned int * busy_bit , <nl> int retries = 0 , cc ; <nl> unsigned long laob = 0 ; <nl>  <nl> + WARN_ON_ONCE ( aob && (( queue_type ( q ) != QDIO_IQDIO_QFMT ) || <nl> + ! q -> u . out . use_cq )); <nl> if ( q -> u . out . use_cq && aob != 0 ) { <nl> fc = QDIO_SIGA_WRITEQ ; <nl> laob = aob ; <nl> static int qdio_siga_output ( struct qdio_q * q , unsigned int * busy_bit , <nl> fc |= QDIO_SIGA_QEBSM_FLAG ; <nl> } <nl> again : <nl> - WARN_ON_ONCE (( aob && queue_type ( q ) != QDIO_IQDIO_QFMT ) || <nl> - ( aob && fc != QDIO_SIGA_WRITEQ )); <nl> cc = do_siga_output ( schid , q -> mask , busy_bit , fc , laob ); <nl>  <nl> /* hipersocket busy condition */
mmm drivers / vfio / pci / vfio_pci_intrs . c <nl> ppp drivers / vfio / pci / vfio_pci_intrs . c <nl> int vfio_pci_set_irqs_ioctl ( struct vfio_pci_device * vdev , uint32_t flags , <nl> func = vfio_pci_set_err_trigger ; <nl> break ; <nl> } <nl> + break ; <nl> case VFIO_PCI_REQ_IRQ_INDEX : <nl> switch ( flags & VFIO_IRQ_SET_ACTION_TYPE_MASK ) { <nl> case VFIO_IRQ_SET_ACTION_TRIGGER : <nl> func = vfio_pci_set_req_trigger ; <nl> break ; <nl> } <nl> + break ; <nl> } <nl>  <nl> if (! func )
mmm drivers / gpu / drm / vc4 / vc4_dsi . c <nl> ppp drivers / gpu / drm / vc4 / vc4_dsi . c <nl> static void vc4_dsi_latch_ulps ( struct vc4_dsi * dsi , bool latch ) <nl> /* Enters or exits Ultra Low Power State . */ <nl> static void vc4_dsi_ulps ( struct vc4_dsi * dsi , bool ulps ) <nl> { <nl> - bool continuous = dsi -> mode_flags & MIPI_DSI_CLOCK_NON_CONTINUOUS ; <nl> - u32 phyc_ulps = (( continuous ? DSI_PORT_BIT ( PHYC_CLANE_ULPS ) : 0 ) | <nl> + bool non_continuous = dsi -> mode_flags & MIPI_DSI_CLOCK_NON_CONTINUOUS ; <nl> + u32 phyc_ulps = (( non_continuous ? DSI_PORT_BIT ( PHYC_CLANE_ULPS ) : 0 ) | <nl> DSI_PHYC_DLANE0_ULPS | <nl> ( dsi -> lanes > 1 ? DSI_PHYC_DLANE1_ULPS : 0 ) | <nl> ( dsi -> lanes > 2 ? DSI_PHYC_DLANE2_ULPS : 0 ) | <nl> ( dsi -> lanes > 3 ? DSI_PHYC_DLANE3_ULPS : 0 )); <nl> - u32 stat_ulps = (( continuous ? DSI1_STAT_PHY_CLOCK_ULPS : 0 ) | <nl> + u32 stat_ulps = (( non_continuous ? DSI1_STAT_PHY_CLOCK_ULPS : 0 ) | <nl> DSI1_STAT_PHY_D0_ULPS | <nl> ( dsi -> lanes > 1 ? DSI1_STAT_PHY_D1_ULPS : 0 ) | <nl> ( dsi -> lanes > 2 ? DSI1_STAT_PHY_D2_ULPS : 0 ) | <nl> ( dsi -> lanes > 3 ? DSI1_STAT_PHY_D3_ULPS : 0 )); <nl> - u32 stat_stop = (( continuous ? DSI1_STAT_PHY_CLOCK_STOP : 0 ) | <nl> + u32 stat_stop = (( non_continuous ? DSI1_STAT_PHY_CLOCK_STOP : 0 ) | <nl> DSI1_STAT_PHY_D0_STOP | <nl> ( dsi -> lanes > 1 ? DSI1_STAT_PHY_D1_STOP : 0 ) | <nl> ( dsi -> lanes > 2 ? DSI1_STAT_PHY_D2_STOP : 0 ) |
mmm drivers / ieee1394 / nodemgr . c <nl> ppp drivers / ieee1394 / nodemgr . c <nl> static int nodemgr_host_thread ( void * data ) <nl> g = get_hpsb_generation ( host ); <nl> for ( i = 0 ; i < 4 ; i ++) { <nl> msleep_interruptible ( 63 ); <nl> + try_to_freeze (); <nl> if ( kthread_should_stop ()) <nl> goto exit ; <nl>  <nl> static int nodemgr_host_thread ( void * data ) <nl> /* Sleep 3 seconds */ <nl> for ( i = 3000 / 200 ; i ; i --) { <nl> msleep_interruptible ( 200 ); <nl> + try_to_freeze (); <nl> if ( kthread_should_stop ()) <nl> goto exit ; <nl> 
mmm drivers / net / ethernet / rocker / rocker_main . c <nl> ppp drivers / net / ethernet / rocker / rocker_main . c <nl> static void rocker_switchdev_event_work ( struct work_struct * work ) <nl> switch ( switchdev_work -> event ) { <nl> case SWITCHDEV_FDB_ADD_TO_DEVICE : <nl> fdb_info = & switchdev_work -> fdb_info ; <nl> + if (! fdb_info -> added_by_user ) <nl> + break ; <nl> err = rocker_world_port_fdb_add ( rocker_port , fdb_info ); <nl> if ( err ) { <nl> netdev_dbg ( rocker_port -> dev , " fdb add failed err =% d \ n ", err ); <nl> static void rocker_switchdev_event_work ( struct work_struct * work ) <nl> break ; <nl> case SWITCHDEV_FDB_DEL_TO_DEVICE : <nl> fdb_info = & switchdev_work -> fdb_info ; <nl> + if (! fdb_info -> added_by_user ) <nl> + break ; <nl> err = rocker_world_port_fdb_del ( rocker_port , fdb_info ); <nl> if ( err ) <nl> netdev_dbg ( rocker_port -> dev , " fdb add failed err =% d \ n ", err ); <nl> static int rocker_switchdev_event ( struct notifier_block * unused , <nl> switch ( event ) { <nl> case SWITCHDEV_FDB_ADD_TO_DEVICE : /* fall through */ <nl> case SWITCHDEV_FDB_DEL_TO_DEVICE : <nl> - if (! fdb_info -> added_by_user ) <nl> - break ; <nl> memcpy (& switchdev_work -> fdb_info , ptr , <nl> sizeof ( switchdev_work -> fdb_info )); <nl> switchdev_work -> fdb_info . addr = kzalloc ( ETH_ALEN , GFP_ATOMIC );
mmm arch / x86 / crypto / salsa20_glue . c <nl> ppp arch / x86 / crypto / salsa20_glue . c <nl> static int encrypt ( struct blkcipher_desc * desc , <nl>  <nl> salsa20_ivsetup ( ctx , walk . iv ); <nl>  <nl> - if ( likely ( walk . nbytes == nbytes )) <nl> - { <nl> - salsa20_encrypt_bytes ( ctx , walk . src . virt . addr , <nl> - walk . dst . virt . addr , nbytes ); <nl> - return blkcipher_walk_done ( desc , & walk , 0 ); <nl> - } <nl> - <nl> while ( walk . nbytes >= 64 ) { <nl> salsa20_encrypt_bytes ( ctx , walk . src . virt . addr , <nl> walk . dst . virt . addr ,mmm crypto / salsa20_generic . c <nl> ppp crypto / salsa20_generic . c <nl> static int encrypt ( struct blkcipher_desc * desc , <nl>  <nl> salsa20_ivsetup ( ctx , walk . iv ); <nl>  <nl> - if ( likely ( walk . nbytes == nbytes )) <nl> - { <nl> - salsa20_encrypt_bytes ( ctx , walk . src . virt . addr , <nl> - walk . dst . virt . addr , nbytes ); <nl> - return blkcipher_walk_done ( desc , & walk , 0 ); <nl> - } <nl> - <nl> while ( walk . nbytes >= 64 ) { <nl> salsa20_encrypt_bytes ( ctx , walk . src . virt . addr , <nl> walk . dst . virt . addr , <nl> static int encrypt ( struct blkcipher_desc * desc , <nl>  <nl> salsa20_ivsetup ( ctx , walk . iv ); <nl>  <nl> - if ( likely ( walk . nbytes == nbytes )) <nl> - { <nl> - salsa20_encrypt_bytes ( ctx , walk . dst . virt . addr , <nl> - walk . src . virt . addr , nbytes ); <nl> - return blkcipher_walk_done ( desc , & walk , 0 ); <nl> - } <nl> - <nl> while ( walk . nbytes >= 64 ) { <nl> salsa20_encrypt_bytes ( ctx , walk . dst . virt . addr , <nl> walk . src . virt . addr ,
mmm drivers / i2c / busses / i2c - pxa . c <nl> ppp drivers / i2c / busses / i2c - pxa . c <nl> static int i2c_pxa_xfer ( struct i2c_adapter * adap , struct i2c_msg msgs [], int num <nl> struct pxa_i2c * i2c = adap -> algo_data ; <nl> int ret , i ; <nl>  <nl> + /* If the I2C controller is disabled we need to reset it ( probably due <nl> + to a suspend / resume destroying state ). We do this here as we can then <nl> + avoid worrying about resuming the controller before its users . */ <nl> + if (!( ICR & ICR_IUE )) <nl> + i2c_pxa_reset ( i2c ); <nl> + <nl> for ( i = adap -> retries ; i >= 0 ; i --) { <nl> ret = i2c_pxa_do_xfer ( i2c , msgs , num ); <nl> if ( ret != I2C_RETRY ) <nl> static struct pxa_i2c i2c_pxa = { <nl> static int i2c_pxa_probe ( struct platform_device * dev ) <nl> { <nl> struct pxa_i2c * i2c = & i2c_pxa ; <nl> +# ifdef CONFIG_I2C_PXA_SLAVE <nl> struct i2c_pxa_platform_data * plat = dev -> dev . platform_data ; <nl> +# endif <nl> int ret ; <nl>  <nl> # ifdef CONFIG_PXA27x <nl> static void i2c_adap_pxa_exit ( void ) <nl> return platform_driver_unregister (& i2c_pxa_driver ); <nl> } <nl>  <nl> + MODULE_LICENSE (" GPL "); <nl> + <nl> module_init ( i2c_adap_pxa_init ); <nl> module_exit ( i2c_adap_pxa_exit );
mmm fs / btrfs / ioctl . c <nl> ppp fs / btrfs / ioctl . c <nl> static noinline int btrfs_ioctl_resize ( struct btrfs_root * root , <nl> } <nl> ret = btrfs_grow_device ( trans , device , new_size ); <nl> btrfs_commit_transaction ( trans , root ); <nl> - } else { <nl> + } else if ( new_size < old_size ) { <nl> ret = btrfs_shrink_device ( device , new_size ); <nl> } <nl> 
mmm arch / x86 / kvm / vmx . c <nl> ppp arch / x86 / kvm / vmx . c <nl> static void kvm_do_inject_irq ( struct kvm_vcpu * vcpu ) <nl> clear_bit ( bit_index , & vcpu -> arch . irq_pending [ word_index ]); <nl> if (! vcpu -> arch . irq_pending [ word_index ]) <nl> clear_bit ( word_index , & vcpu -> arch . irq_summary ); <nl> - vmx_inject_irq ( vcpu , irq ); <nl> + kvm_queue_interrupt ( vcpu , irq ); <nl> } <nl>  <nl>  <nl> static void do_interrupt_requests ( struct kvm_vcpu * vcpu , <nl> ( vmcs_read32 ( GUEST_INTERRUPTIBILITY_INFO ) & 3 ) == 0 ); <nl>  <nl> if ( vcpu -> arch . interrupt_window_open && <nl> - vcpu -> arch . irq_summary && <nl> - !( vmcs_read32 ( VM_ENTRY_INTR_INFO_FIELD ) & INTR_INFO_VALID_MASK )) <nl> - /* <nl> - * If interrupts enabled , and not blocked by sti or mov ss . Good . <nl> - */ <nl> + vcpu -> arch . irq_summary && ! vcpu -> arch . interrupt . pending ) <nl> kvm_do_inject_irq ( vcpu ); <nl>  <nl> + if ( vcpu -> arch . interrupt_window_open && vcpu -> arch . interrupt . pending ) <nl> + vmx_inject_irq ( vcpu , vcpu -> arch . interrupt . nr ); <nl> + <nl> cpu_based_vm_exec_control = vmcs_read32 ( CPU_BASED_VM_EXEC_CONTROL ); <nl> if (! vcpu -> arch . interrupt_window_open && <nl> ( vcpu -> arch . irq_summary || kvm_run -> request_interrupt_window ))
mmm drivers / infiniband / hw / nes / nes_cm . c <nl> ppp drivers / infiniband / hw / nes / nes_cm . c <nl> int schedule_nes_timer ( struct nes_cm_node * cm_node , struct sk_buff * skb , <nl> int ret = 0 ; <nl> u32 was_timer_set ; <nl>  <nl> + if (! cm_node ) <nl> + return - EINVAL ; <nl> new_send = kzalloc ( sizeof (* new_send ), GFP_ATOMIC ); <nl> if (! new_send ) <nl> return - 1 ; <nl> - if (! cm_node ) <nl> - return - EINVAL ; <nl>  <nl> /* new_send -> timetosend = currenttime */ <nl> new_send -> retrycount = NES_DEFAULT_RETRYS ;
mmm drivers / acpi / processor_idle . c <nl> ppp drivers / acpi / processor_idle . c <nl> static void acpi_processor_power_verify_c3 ( struct acpi_processor * pr , <nl> } <nl>  <nl> if ( pr -> flags . bm_check ) { <nl> - /* bus mastering control is necessary */ <nl> if (! pr -> flags . bm_control ) { <nl> - /* In this case we enter C3 without bus mastering */ <nl> - ACPI_DEBUG_PRINT (( ACPI_DB_INFO , <nl> - " C3 support without bus mastering control \ n ")); <nl> + if ( pr -> flags . has_cst != 1 ) { <nl> + /* bus mastering control is necessary */ <nl> + ACPI_DEBUG_PRINT (( ACPI_DB_INFO , <nl> + " C3 support requires BM control \ n ")); <nl> + return ; <nl> + } else { <nl> + /* Here we enter C3 without bus mastering */ <nl> + ACPI_DEBUG_PRINT (( ACPI_DB_INFO , <nl> + " C3 support without BM control \ n ")); <nl> + } <nl> } <nl> } else { <nl> /*
mmm drivers / nvdimm / btt . c <nl> ppp drivers / nvdimm / btt . c <nl> int nvdimm_namespace_attach_btt ( struct nd_namespace_common * ndns ) <nl> } <nl>  <nl> btt_sb = devm_kzalloc (& nd_btt -> dev , sizeof (* btt_sb ), GFP_KERNEL ); <nl> + if (! btt_sb ) <nl> + return - ENOMEM ; <nl>  <nl> /* <nl> * If this returns < 0 , that is ok as it just means there wasn ' t
mmm drivers / acpi / debugfs . c <nl> ppp drivers / acpi / debugfs . c <nl> int __init acpi_debugfs_init ( void ) <nl> if (! acpi_dir ) <nl> goto err ; <nl>  <nl> - cm_dentry = debugfs_create_file (" custom_method ", S_IWUGO , <nl> + cm_dentry = debugfs_create_file (" custom_method ", S_IWUSR , <nl> acpi_dir , NULL , & cm_fops ); <nl> if (! cm_dentry ) <nl> goto err ;
mmm arch / powerpc / xmon / xmon . c <nl> ppp arch / powerpc / xmon / xmon . c <nl> static unsigned long nidump = 16 ; <nl> static unsigned long ncsum = 4096 ; <nl> static int termch ; <nl> static char tmpstr [ 128 ]; <nl> + static int tracing_enabled ; <nl>  <nl> static long bus_error_jmp [ JMP_BUF_LEN ]; <nl> static int catch_memory_errors ; <nl> static int xmon_core ( struct pt_regs * regs , int fromipi ) <nl> local_irq_save ( flags ); <nl> hard_irq_disable (); <nl>  <nl> + tracing_enabled = tracing_is_on (); <nl> + tracing_off (); <nl> + <nl> bp = in_breakpoint_table ( regs -> nip , & offset ); <nl> if ( bp != NULL ) { <nl> regs -> nip = bp -> address + offset ; <nl> cmds ( struct pt_regs * excp ) <nl> break ; <nl> case ' x ': <nl> case ' X ': <nl> + if ( tracing_enabled ) <nl> + tracing_on (); <nl> return cmd ; <nl> case EOF : <nl> printf (" < no input ...>\ n "); <nl> static void dump_tracing ( void ) <nl> ftrace_dump ( DUMP_ORIG ); <nl> else <nl> ftrace_dump ( DUMP_ALL ); <nl> - <nl> - tracing_on (); <nl> } <nl>  <nl> # ifdef CONFIG_PPC64
mmm arch / tile / mm / init . c <nl> ppp arch / tile / mm / init . c <nl> static long __write_once initfree = 1 ; <nl> static int __init set_initfree ( char * str ) <nl> { <nl> long val ; <nl> - if ( strict_strtol ( str , 0 , & val )) { <nl> + if ( strict_strtol ( str , 0 , & val ) == 0 ) { <nl> initfree = val ; <nl> pr_info (" initfree : % s free init pages \ n ", <nl> initfree ? " will " : " won ' t ");
mmm arch / x86 / xen / apic . c <nl> ppp arch / x86 / xen / apic . c <nl> static u32 xen_apic_read ( u32 reg ) <nl>  <nl> ret = HYPERVISOR_platform_op (& op ); <nl> if ( ret ) <nl> - return 0 ; <nl> + op . u . pcpu_info . apic_id = BAD_APICID ; <nl>  <nl> return op . u . pcpu_info . apic_id << 24 ; <nl> } <nl> static void xen_silent_inquire ( int apicid ) <nl> { <nl> } <nl>  <nl> + static int xen_cpu_present_to_apicid ( int cpu ) <nl> +{ <nl> + if ( cpu_present ( cpu )) <nl> + return xen_get_apic_id ( xen_apic_read ( APIC_ID )); <nl> + else <nl> + return BAD_APICID ; <nl> +} <nl> + <nl> static struct apic xen_pv_apic = { <nl> . name = " Xen PV ", <nl> . probe = xen_apic_probe_pv , <nl> static struct apic xen_pv_apic = { <nl>  <nl> . ioapic_phys_id_map = default_ioapic_phys_id_map , /* Used on 32 - bit */ <nl> . setup_apic_routing = NULL , <nl> - . cpu_present_to_apicid = default_cpu_present_to_apicid , <nl> + . cpu_present_to_apicid = xen_cpu_present_to_apicid , <nl> . apicid_to_cpu_present = physid_set_mask_of_physid , /* Used on 32 - bit */ <nl> . check_phys_apicid_present = default_check_phys_apicid_present , /* smp_sanity_check needs it */ <nl> . phys_pkg_id = xen_phys_pkg_id , /* detect_ht */
mmm net / ipv4 / tcp_output . c <nl> ppp net / ipv4 / tcp_output . c <nl> static bool tcp_write_xmit ( struct sock * sk , unsigned int mss_now , int nonagle , <nl>  <nl> /* Send one loss probe per tail loss episode . */ <nl> if ( push_one != 2 ) <nl> - tcp_schedule_loss_probe ( sk ); <nl> + tcp_schedule_loss_probe ( sk , false ); <nl> is_cwnd_limited |= ( tcp_packets_in_flight ( tp ) >= tp -> snd_cwnd ); <nl> tcp_cwnd_validate ( sk , is_cwnd_limited ); <nl> return false ; <nl> static bool tcp_write_xmit ( struct sock * sk , unsigned int mss_now , int nonagle , <nl> return ! tp -> packets_out && ! tcp_write_queue_empty ( sk ); <nl> } <nl>  <nl> - bool tcp_schedule_loss_probe ( struct sock * sk ) <nl> + bool tcp_schedule_loss_probe ( struct sock * sk , bool advancing_rto ) <nl> { <nl> struct inet_connection_sock * icsk = inet_csk ( sk ); <nl> struct tcp_sock * tp = tcp_sk ( sk ); <nl> bool tcp_schedule_loss_probe ( struct sock * sk ) <nl> } <nl>  <nl> /* If the RTO formula yields an earlier time , then use that time . */ <nl> - rto_delta_us = tcp_rto_delta_us ( sk ); /* How far in future is RTO ? */ <nl> + rto_delta_us = advancing_rto ? <nl> + jiffies_to_usecs ( inet_csk ( sk )-> icsk_rto ) : <nl> + tcp_rto_delta_us ( sk ); /* How far in future is RTO ? */ <nl> if ( rto_delta_us > 0 ) <nl> timeout = min_t ( u32 , timeout , usecs_to_jiffies ( rto_delta_us )); <nl> mmm include / net / tcp . h <nl> ppp include / net / tcp . h <nl> static bool tcp_write_xmit ( struct sock * sk , unsigned int mss_now , int nonagle , <nl>  <nl> /* Send one loss probe per tail loss episode . */ <nl> if ( push_one != 2 ) <nl> - tcp_schedule_loss_probe ( sk ); <nl> + tcp_schedule_loss_probe ( sk , false ); <nl> is_cwnd_limited |= ( tcp_packets_in_flight ( tp ) >= tp -> snd_cwnd ); <nl> tcp_cwnd_validate ( sk , is_cwnd_limited ); <nl> return false ; <nl> static bool tcp_write_xmit ( struct sock * sk , unsigned int mss_now , int nonagle , <nl> return ! tp -> packets_out && ! tcp_write_queue_empty ( sk ); <nl> } <nl>  <nl> - bool tcp_schedule_loss_probe ( struct sock * sk ) <nl> + bool tcp_schedule_loss_probe ( struct sock * sk , bool advancing_rto ) <nl> { <nl> struct inet_connection_sock * icsk = inet_csk ( sk ); <nl> struct tcp_sock * tp = tcp_sk ( sk ); <nl> bool tcp_schedule_loss_probe ( struct sock * sk ) <nl> } <nl>  <nl> /* If the RTO formula yields an earlier time , then use that time . */ <nl> - rto_delta_us = tcp_rto_delta_us ( sk ); /* How far in future is RTO ? */ <nl> + rto_delta_us = advancing_rto ? <nl> + jiffies_to_usecs ( inet_csk ( sk )-> icsk_rto ) : <nl> + tcp_rto_delta_us ( sk ); /* How far in future is RTO ? */ <nl> if ( rto_delta_us > 0 ) <nl> timeout = min_t ( u32 , timeout , usecs_to_jiffies ( rto_delta_us )); <nl>  <nl> void tcp_push_one ( struct sock *, unsigned int mss_now ); <nl> void tcp_send_ack ( struct sock * sk ); <nl> void tcp_send_delayed_ack ( struct sock * sk ); <nl> void tcp_send_loss_probe ( struct sock * sk ); <nl> - bool tcp_schedule_loss_probe ( struct sock * sk ); <nl> + bool tcp_schedule_loss_probe ( struct sock * sk , bool advancing_rto ); <nl> void tcp_skb_collapse_tstamp ( struct sk_buff * skb , <nl> const struct sk_buff * next_skb ); <nl> mmm net / ipv4 / tcp_input . c <nl> ppp net / ipv4 / tcp_input . c <nl> static bool tcp_write_xmit ( struct sock * sk , unsigned int mss_now , int nonagle , <nl>  <nl> /* Send one loss probe per tail loss episode . */ <nl> if ( push_one != 2 ) <nl> - tcp_schedule_loss_probe ( sk ); <nl> + tcp_schedule_loss_probe ( sk , false ); <nl> is_cwnd_limited |= ( tcp_packets_in_flight ( tp ) >= tp -> snd_cwnd ); <nl> tcp_cwnd_validate ( sk , is_cwnd_limited ); <nl> return false ; <nl> static bool tcp_write_xmit ( struct sock * sk , unsigned int mss_now , int nonagle , <nl> return ! tp -> packets_out && ! tcp_write_queue_empty ( sk ); <nl> } <nl>  <nl> - bool tcp_schedule_loss_probe ( struct sock * sk ) <nl> + bool tcp_schedule_loss_probe ( struct sock * sk , bool advancing_rto ) <nl> { <nl> struct inet_connection_sock * icsk = inet_csk ( sk ); <nl> struct tcp_sock * tp = tcp_sk ( sk ); <nl> bool tcp_schedule_loss_probe ( struct sock * sk ) <nl> } <nl>  <nl> /* If the RTO formula yields an earlier time , then use that time . */ <nl> - rto_delta_us = tcp_rto_delta_us ( sk ); /* How far in future is RTO ? */ <nl> + rto_delta_us = advancing_rto ? <nl> + jiffies_to_usecs ( inet_csk ( sk )-> icsk_rto ) : <nl> + tcp_rto_delta_us ( sk ); /* How far in future is RTO ? */ <nl> if ( rto_delta_us > 0 ) <nl> timeout = min_t ( u32 , timeout , usecs_to_jiffies ( rto_delta_us )); <nl>  <nl> void tcp_push_one ( struct sock *, unsigned int mss_now ); <nl> void tcp_send_ack ( struct sock * sk ); <nl> void tcp_send_delayed_ack ( struct sock * sk ); <nl> void tcp_send_loss_probe ( struct sock * sk ); <nl> - bool tcp_schedule_loss_probe ( struct sock * sk ); <nl> + bool tcp_schedule_loss_probe ( struct sock * sk , bool advancing_rto ); <nl> void tcp_skb_collapse_tstamp ( struct sk_buff * skb , <nl> const struct sk_buff * next_skb ); <nl>  <nl> void tcp_rearm_rto ( struct sock * sk ) <nl> /* Try to schedule a loss probe ; if that doesn ' t work , then schedule an RTO . */ <nl> static void tcp_set_xmit_timer ( struct sock * sk ) <nl> { <nl> - if (! tcp_schedule_loss_probe ( sk )) <nl> + if (! tcp_schedule_loss_probe ( sk , true )) <nl> tcp_rearm_rto ( sk ); <nl> } <nl> 
mmm net / socket . c <nl> ppp net / socket . c <nl> static int do_siocgstamp ( struct net * net , struct socket * sock , <nl> err = sock_do_ioctl ( net , sock , cmd , ( unsigned long )& ktv ); <nl> set_fs ( old_fs ); <nl> if (! err ) <nl> - err = compat_put_timeval ( up , & ktv ); <nl> + err = compat_put_timeval (& ktv , up ); <nl>  <nl> return err ; <nl> } <nl> static int do_siocgstampns ( struct net * net , struct socket * sock , <nl> err = sock_do_ioctl ( net , sock , cmd , ( unsigned long )& kts ); <nl> set_fs ( old_fs ); <nl> if (! err ) <nl> - err = compat_put_timespec ( up , & kts ); <nl> + err = compat_put_timespec (& kts , up ); <nl>  <nl> return err ; <nl> }
mmm drivers / ssb / scan . c <nl> ppp drivers / ssb / scan . c <nl> int ssb_bus_scan ( struct ssb_bus * bus , <nl> bus -> pcicore . dev = dev ; <nl> # endif /* CONFIG_SSB_DRIVER_PCICORE */ <nl> break ; <nl> + case SSB_DEV_ETHERNET : <nl> + if ( bus -> bustype == SSB_BUSTYPE_PCI ) { <nl> + if ( bus -> host_pci -> vendor == PCI_VENDOR_ID_BROADCOM && <nl> + ( bus -> host_pci -> device & 0xFF00 ) == 0x4300 ) { <nl> + /* This is a dangling ethernet core on a <nl> + * wireless device . Ignore it . */ <nl> + continue ; <nl> + } <nl> + } <nl> + break ; <nl> default : <nl> break ; <nl> }
mmm arch / s390 / kernel / kprobes . c <nl> ppp arch / s390 / kernel / kprobes . c <nl> static void copy_instruction ( struct kprobe * p ) <nl> ftrace_generate_nop_insn (( struct ftrace_insn *) p -> ainsn . insn ); <nl> p -> ainsn . is_ftrace_insn = 1 ; <nl> } else <nl> - memcpy ( p -> ainsn . insn , p -> addr , insn_length ( p -> opcode >> 8 )); <nl> + memcpy ( p -> ainsn . insn , p -> addr , insn_length (* p -> addr >> 8 )); <nl> p -> opcode = p -> ainsn . insn [ 0 ]; <nl> if (! probe_is_insn_relative_long ( p -> ainsn . insn )) <nl> return ;
mmm arch / x86_64 / kernel / setup . c <nl> ppp arch / x86_64 / kernel / setup . c <nl> static __init void parse_cmdline_early ( char ** cmdline_p ) <nl> if (! memcmp ( from , " noapic ", 6 )) <nl> skip_ioapic_setup = 1 ; <nl>  <nl> - if (! memcmp ( from , " apic ", 4 )) { <nl> + /* Make sure to not confuse with apic = */ <nl> + if (! memcmp ( from , " apic ", 4 ) && <nl> + ( from [ 4 ] == ' ' || from [ 4 ] == 0 )) { <nl> skip_ioapic_setup = 0 ; <nl> ioapic_force = 1 ; <nl> }
mmm drivers / iommu / intel_irq_remapping . c <nl> ppp drivers / iommu / intel_irq_remapping . c <nl> intel_ioapic_set_affinity ( struct irq_data * data , const struct cpumask * mask , <nl>  <nl> err = apic -> cpu_mask_to_apicid_and ( cfg -> domain , mask , & dest ); <nl> if ( err ) { <nl> - if ( assign_irq_vector ( irq , cfg , data -> affinity )); <nl> + if ( assign_irq_vector ( irq , cfg , data -> affinity )) <nl> pr_err (" Failed to recover vector for irq % d \ n ", irq ); <nl> return err ; <nl> }
mmm drivers / media / common / tuners / qt1010 . c <nl> ppp drivers / media / common / tuners / qt1010 . c <nl> static int qt1010_get_bandwidth ( struct dvb_frontend * fe , u32 * bandwidth ) <nl> return 0 ; <nl> } <nl>  <nl> + static int qt1010_get_if_frequency ( struct dvb_frontend * fe , u32 * frequency ) <nl> +{ <nl> + * frequency = 36125000 ; <nl> + return 0 ; <nl> +} <nl> + <nl> static const struct dvb_tuner_ops qt1010_tuner_ops = { <nl> . info = { <nl> . name = " Quantek QT1010 ", <nl> static const struct dvb_tuner_ops qt1010_tuner_ops = { <nl>  <nl> . set_params = qt1010_set_params , <nl> . get_frequency = qt1010_get_frequency , <nl> - . get_bandwidth = qt1010_get_bandwidth <nl> + . get_bandwidth = qt1010_get_bandwidth , <nl> + . get_if_frequency = qt1010_get_if_frequency , <nl> }; <nl>  <nl> struct dvb_frontend * qt1010_attach ( struct dvb_frontend * fe ,
mmm sound / usb / quirks . c <nl> ppp sound / usb / quirks . c <nl> u64 snd_usb_interface_dsd_format_quirks ( struct snd_usb_audio * chip , <nl> } <nl> } <nl> break ; <nl> + case USB_ID ( 0x16d0 , 0x0a23 ): <nl> + if ( fp -> altsetting == 2 ) <nl> + return SNDRV_PCM_FMTBIT_DSD_U32_BE ; <nl> + break ; <nl>  <nl> default : <nl> break ;
mmm drivers / media / platform / vivid / vivid - osd . c <nl> ppp drivers / media / platform / vivid / vivid - osd . c <nl> static int vivid_fb_ioctl ( struct fb_info * info , unsigned cmd , unsigned long arg ) <nl> case FBIOGET_VBLANK : { <nl> struct fb_vblank vblank ; <nl>  <nl> + memset (& vblank , 0 , sizeof ( vblank )); <nl> vblank . flags = FB_VBLANK_HAVE_COUNT | FB_VBLANK_HAVE_VCOUNT | <nl> FB_VBLANK_HAVE_VSYNC ; <nl> vblank . count = 0 ;
mmm sound / isa / opti9xx / miro . c <nl> ppp sound / isa / opti9xx / miro . c <nl> static int __devinit snd_miro_probe ( struct snd_card * card ) <nl>  <nl> error = snd_card_miro_aci_detect ( card , miro ); <nl> if ( error < 0 ) { <nl> - snd_card_free ( card ); <nl> snd_printk ( KERN_ERR " unable to detect aci chip \ n "); <nl> return - ENODEV ; <nl> }
mmm net / packet / af_packet . c <nl> ppp net / packet / af_packet . c <nl> static int tpacket_rcv ( struct sk_buff * skb , struct net_device * dev , <nl> struct timespec ts ; <nl> __u32 ts_status ; <nl> bool is_drop_n_account = false ; <nl> + bool do_vnet = false ; <nl>  <nl> /* struct tpacket { 2 , 3 } _hdr is aligned to a multiple of TPACKET_ALIGNMENT . <nl> * We may add members to them until current aligned size without forcing <nl> static int tpacket_rcv ( struct sk_buff * skb , struct net_device * dev , <nl> netoff = TPACKET_ALIGN ( po -> tp_hdrlen + <nl> ( maclen < 16 ? 16 : maclen )) + <nl> po -> tp_reserve ; <nl> - if ( po -> has_vnet_hdr ) <nl> + if ( po -> has_vnet_hdr ) { <nl> netoff += sizeof ( struct virtio_net_hdr ); <nl> + do_vnet = true ; <nl> + } <nl> macoff = netoff - maclen ; <nl> } <nl> if ( po -> tp_version <= TPACKET_V2 ) { <nl> static int tpacket_rcv ( struct sk_buff * skb , struct net_device * dev , <nl> skb_set_owner_r ( copy_skb , sk ); <nl> } <nl> snaplen = po -> rx_ring . frame_size - macoff ; <nl> - if (( int ) snaplen < 0 ) <nl> + if (( int ) snaplen < 0 ) { <nl> snaplen = 0 ; <nl> + do_vnet = false ; <nl> + } <nl> } <nl> } else if ( unlikely ( macoff + snaplen > <nl> GET_PBDQC_FROM_RB (& po -> rx_ring )-> max_frame_len )) { <nl> static int tpacket_rcv ( struct sk_buff * skb , struct net_device * dev , <nl> if ( unlikely (( int ) snaplen < 0 )) { <nl> snaplen = 0 ; <nl> macoff = GET_PBDQC_FROM_RB (& po -> rx_ring )-> max_frame_len ; <nl> + do_vnet = false ; <nl> } <nl> } <nl> spin_lock (& sk -> sk_receive_queue . lock ); <nl> static int tpacket_rcv ( struct sk_buff * skb , struct net_device * dev , <nl> } <nl> spin_unlock (& sk -> sk_receive_queue . lock ); <nl>  <nl> - if ( po -> has_vnet_hdr ) { <nl> + if ( do_vnet ) { <nl> if ( virtio_net_hdr_from_skb ( skb , h . raw + macoff - <nl> sizeof ( struct virtio_net_hdr ), <nl> vio_le (), true )) {
mmm drivers / gpu / drm / i915 / i915_gem_execbuffer . c <nl> ppp drivers / gpu / drm / i915 / i915_gem_execbuffer . c <nl> static int eb_relocate_vma ( struct i915_execbuffer * eb , struct i915_vma * vma ) <nl> * to read . However , if the array is not writable the user loses <nl> * the updated relocation values . <nl> */ <nl> - if ( unlikely (! access_ok ( VERIFY_READ , urelocs , remain * sizeof ( urelocs )))) <nl> + if ( unlikely (! access_ok ( VERIFY_READ , urelocs , remain * sizeof (* urelocs )))) <nl> return - EFAULT ; <nl>  <nl> do {
mmm fs / ext4 / extents . c <nl> ppp fs / ext4 / extents . c <nl> int ext4_insert_range ( struct inode * inode , loff_t offset , loff_t len ) <nl> up_write (& EXT4_I ( inode )-> i_data_sem ); <nl> goto out_stop ; <nl> } <nl> + } else { <nl> + ext4_ext_drop_refs ( path ); <nl> + kfree ( path ); <nl> } <nl>  <nl> ret = ext4_es_remove_extent ( inode , offset_lblk ,
mmm fs / aio . c <nl> ppp fs / aio . c <nl> static long aio_read_events_ring ( struct kioctx * ctx , <nl> if ( head == tail ) <nl> goto out ; <nl>  <nl> + head %= ctx -> nr_events ; <nl> + tail %= ctx -> nr_events ; <nl> + <nl> while ( ret < nr ) { <nl> long avail ; <nl> struct io_event * ev ;
mmm net / ipx / af_ipx . c <nl> ppp net / ipx / af_ipx . c <nl> static int ipxitf_ioctl ( unsigned int cmd , void __user * arg ) <nl> sipx -> sipx_network = ipxif -> if_netnum ; <nl> memcpy ( sipx -> sipx_node , ipxif -> if_node , <nl> sizeof ( sipx -> sipx_node )); <nl> - rc = - EFAULT ; <nl> + rc = 0 ; <nl> if ( copy_to_user ( arg , & ifr , sizeof ( ifr ))) <nl> - break ; <nl> + rc = - EFAULT ; <nl> ipxitf_put ( ipxif ); <nl> - rc = 0 ; <nl> break ; <nl> } <nl> case SIOCAIPXITFCRT :
mmm drivers / power / bq20z75 . c <nl> ppp drivers / power / bq20z75 . c <nl> static int __devinit bq20z75_probe ( struct i2c_client * client , <nl>  <nl> INIT_DELAYED_WORK (& bq20z75_device -> work , bq20z75_delayed_work ); <nl>  <nl> + bq20z75_device -> enable_detection = true ; <nl> + <nl> return 0 ; <nl>  <nl> exit_psupply :
mmm drivers / net / skge . c <nl> ppp drivers / net / skge . c <nl> static int skge_xmit_frame ( struct sk_buff * skb , struct net_device * dev ) <nl> } <nl>  <nl> if ( unlikely ( skge -> tx_avail < skb_shinfo ( skb )-> nr_frags + 1 )) { <nl> - netif_stop_queue ( dev ); <nl> - spin_unlock_irqrestore (& skge -> tx_lock , flags ); <nl> + if (! netif_stopped ( dev )) { <nl> + netif_stop_queue ( dev ); <nl>  <nl> - printk ( KERN_WARNING PFX "% s : ring full when queue awake !\ n ", <nl> - dev -> name ); <nl> + printk ( KERN_WARNING PFX "% s : ring full when queue awake !\ n ", <nl> + dev -> name ); <nl> + } <nl> + spin_unlock_irqrestore (& skge -> tx_lock , flags ); <nl> return NETDEV_TX_BUSY ; <nl> } <nl> 
mmm arch / x86 / platform / efi / efi . c <nl> ppp arch / x86 / platform / efi / efi . c <nl> void __init efi_enter_virtual_mode ( void ) <nl> new_memmap = krealloc ( new_memmap , <nl> ( count + 1 ) * memmap . desc_size , <nl> GFP_KERNEL ); <nl> + if (! new_memmap ) <nl> + goto err_out ; <nl> + <nl> memcpy ( new_memmap + ( count * memmap . desc_size ), md , <nl> memmap . desc_size ); <nl> count ++; <nl> void __init efi_enter_virtual_mode ( void ) <nl> EFI_VARIABLE_BOOTSERVICE_ACCESS | <nl> EFI_VARIABLE_RUNTIME_ACCESS , <nl> 0 , NULL ); <nl> + <nl> + return ; <nl> + <nl> + err_out : <nl> + pr_err (" Error reallocating memory , EFI runtime non - functional !\ n "); <nl> } <nl>  <nl> /*
mmm include / asm - generic / pgtable . h <nl> ppp include / asm - generic / pgtable . h <nl> static inline int pmd_none_or_trans_huge_or_clear_bad ( pmd_t * pmd ) <nl> # ifdef CONFIG_TRANSPARENT_HUGEPAGE <nl> barrier (); <nl> # endif <nl> - if ( pmd_none ( pmdval )) <nl> + if ( pmd_none ( pmdval ) || pmd_trans_huge ( pmdval )) <nl> return 1 ; <nl> if ( unlikely ( pmd_bad ( pmdval ))) { <nl> - if (! pmd_trans_huge ( pmdval )) <nl> - pmd_clear_bad ( pmd ); <nl> + pmd_clear_bad ( pmd ); <nl> return 1 ; <nl> } <nl> return 0 ;
mmm net / xfrm / xfrm_user . c <nl> ppp net / xfrm / xfrm_user . c <nl> static int build_expire ( struct sk_buff * skb , struct xfrm_state * x , int hard ) <nl> static int xfrm_exp_state_notify ( struct xfrm_state * x , struct km_event * c ) <nl> { <nl> struct sk_buff * skb ; <nl> + int len = NLMSG_LENGTH ( sizeof ( struct xfrm_user_expire )); <nl>  <nl> - /* fix to do alloc using NLM macros */ <nl> - skb = alloc_skb ( sizeof ( struct xfrm_user_expire ) + 16 , GFP_ATOMIC ); <nl> + skb = alloc_skb ( len , GFP_ATOMIC ); <nl> if ( skb == NULL ) <nl> return - ENOMEM ; <nl> 
mmm drivers / gpu / drm / amd / include / atomfirmware . h <nl> ppp drivers / gpu / drm / amd / include / atomfirmware . h <nl> enum atom_smu11_syspll_id { <nl> SMU11_SYSPLL3_1_ID = 6 , <nl> }; <nl>  <nl> - <nl> enum atom_smu11_syspll0_clock_id { <nl> - SMU11_SYSPLL0_SOCCLK_ID = 0 , // SOCCLK <nl> - SMU11_SYSPLL0_MP0CLK_ID = 1 , // MP0CLK <nl> - SMU11_SYSPLL0_DCLK_ID = 2 , // DCLK <nl> - SMU11_SYSPLL0_VCLK_ID = 3 , // VCLK <nl> - SMU11_SYSPLL0_ECLK_ID = 4 , // ECLK <nl> + SMU11_SYSPLL0_ECLK_ID = 0 , // ECLK <nl> + SMU11_SYSPLL0_SOCCLK_ID = 1 , // SOCCLK <nl> + SMU11_SYSPLL0_MP0CLK_ID = 2 , // MP0CLK <nl> + SMU11_SYSPLL0_DCLK_ID = 3 , // DCLK <nl> + SMU11_SYSPLL0_VCLK_ID = 4 , // VCLK <nl> SMU11_SYSPLL0_DCEFCLK_ID = 5 , // DCEFCLK <nl> }; <nl>  <nl> - <nl> enum atom_smu11_syspll1_0_clock_id { <nl> SMU11_SYSPLL1_0_UCLKA_ID = 0 , // UCLK_a <nl> };
mmm drivers / input / tablet / kbtab . c <nl> ppp drivers / input / tablet / kbtab . c <nl> static int kbtab_probe ( struct usb_interface * intf , const struct usb_device_id * i <nl> return 0 ; <nl>  <nl> fail3 : usb_free_urb ( kbtab -> irq ); <nl> - fail2 : usb_buffer_free ( dev , 10 , kbtab -> data , kbtab -> data_dma ); <nl> + fail2 : usb_buffer_free ( dev , 8 , kbtab -> data , kbtab -> data_dma ); <nl> fail1 : input_free_device ( input_dev ); <nl> kfree ( kbtab ); <nl> return error ; <nl> static void kbtab_disconnect ( struct usb_interface * intf ) <nl> usb_kill_urb ( kbtab -> irq ); <nl> input_unregister_device ( kbtab -> dev ); <nl> usb_free_urb ( kbtab -> irq ); <nl> - usb_buffer_free ( interface_to_usbdev ( intf ), 10 , kbtab -> data , kbtab -> data_dma ); <nl> + usb_buffer_free ( interface_to_usbdev ( intf ), 8 , kbtab -> data , kbtab -> data_dma ); <nl> kfree ( kbtab ); <nl> } <nl> }
mmm sound / core / timer . c <nl> ppp sound / core / timer . c <nl> void snd_timer_interrupt ( struct snd_timer * timer , unsigned long ticks_left ) <nl> } else { <nl> ti -> flags &= ~ SNDRV_TIMER_IFLG_RUNNING ; <nl> if (-- timer -> running ) <nl> - list_del (& ti -> active_list ); <nl> + list_del_init (& ti -> active_list ); <nl> } <nl> if (( timer -> hw . flags & SNDRV_TIMER_HW_TASKLET ) || <nl> ( ti -> flags & SNDRV_TIMER_IFLG_FAST ))
mmm drivers / staging / vt6655 / wroute . c <nl> ppp drivers / staging / vt6655 / wroute . c <nl> BOOL ROUTEbRelay ( PSDevice pDevice , PBYTE pbySkbData , UINT uDataLen , UINT uNodeI <nl> } <nl>  <nl> if ( pDevice -> bEnableHostWEP ) { <nl> - if ( uNodeIndex >= 0 ) { <nl> + if ( uNodeIndex < MAX_NODE_NUM + 1 ) { <nl> pTransmitKey = & STempKey ; <nl> pTransmitKey -> byCipherSuite = pMgmt -> sNodeDBTable [ uNodeIndex ]. byCipherSuite ; <nl> pTransmitKey -> dwKeyIndex = pMgmt -> sNodeDBTable [ uNodeIndex ]. dwKeyIndex ;mmm drivers / staging / vt6656 / rxtx . c <nl> ppp drivers / staging / vt6656 / rxtx . c <nl> BOOL ROUTEbRelay ( PSDevice pDevice , PBYTE pbySkbData , UINT uDataLen , UINT uNodeI <nl> } <nl>  <nl> if ( pDevice -> bEnableHostWEP ) { <nl> - if ( uNodeIndex >= 0 ) { <nl> + if ( uNodeIndex < MAX_NODE_NUM + 1 ) { <nl> pTransmitKey = & STempKey ; <nl> pTransmitKey -> byCipherSuite = pMgmt -> sNodeDBTable [ uNodeIndex ]. byCipherSuite ; <nl> pTransmitKey -> dwKeyIndex = pMgmt -> sNodeDBTable [ uNodeIndex ]. dwKeyIndex ; <nl> bRelayPacketSend ( <nl> } <nl>  <nl> if ( pDevice -> bEnableHostWEP ) { <nl> - if ( uNodeIndex >= 0 ) { <nl> + if ( uNodeIndex < MAX_NODE_NUM + 1 ) { <nl> pTransmitKey = & STempKey ; <nl> pTransmitKey -> byCipherSuite = pMgmt -> sNodeDBTable [ uNodeIndex ]. byCipherSuite ; <nl> pTransmitKey -> dwKeyIndex = pMgmt -> sNodeDBTable [ uNodeIndex ]. dwKeyIndex ;
mmm sound / pci / hda / patch_realtek . c <nl> ppp sound / pci / hda / patch_realtek . c <nl> static int alc662_parse_auto_config ( struct hda_codec * codec ) <nl> if ( codec -> vendor_id == 0x10ec0663 ) <nl> spec -> init_verbs [ spec -> num_init_verbs ++] = <nl> alc663_auto_init_verbs ; <nl> + <nl> + err = alc_auto_add_mic_boost ( codec ); <nl> + if ( err < 0 ) <nl> + return err ; <nl> + <nl> spec -> mixers [ spec -> num_mixers ] = alc662_capture_mixer ; <nl> spec -> num_mixers ++; <nl> return 1 ;
mmm drivers / staging / ste_rmi4 / synaptics_i2c_rmi4 . c <nl> ppp drivers / staging / ste_rmi4 / synaptics_i2c_rmi4 . c <nl> static int synpatics_rmi4_touchpad_report ( struct synaptics_rmi4_data * pdata , <nl> * 10 = finger present but data may not be accurate , <nl> * 11 = reserved for product use . <nl> */ <nl> - finger_registers = ( fingers_supported + 3 )/ 4 ; <nl> + finger_registers = ( fingers_supported + 3 ) / 4 ; <nl> data_base_addr = rfi -> fn_desc . data_base_addr ; <nl> retval = synaptics_rmi4_i2c_block_read ( pdata , data_base_addr , values , <nl> finger_registers ); <nl> static int synpatics_rmi4_touchpad_report ( struct synaptics_rmi4_data * pdata , <nl> data_reg_blk_size = rfi -> size_of_data_register_block ; <nl> for ( finger = 0 ; finger < fingers_supported ; finger ++) { <nl> /* determine which data byte the finger status is in */ <nl> - reg = finger / 4 ; <nl> + reg = finger / 4 ; <nl> /* bit shift to get finger ' s status */ <nl> finger_shift = ( finger % 4 ) * 2 ; <nl> finger_status = ( values [ reg ] >> finger_shift ) & 3 ; <nl> static int synpatics_rmi4_touchpad_detect ( struct synaptics_rmi4_data * pdata , <nl> } <nl> pdata -> fingers_supported = rfi -> num_of_data_points ; <nl> /* Need to get interrupt info for handling interrupts */ <nl> - rfi -> index_to_intr_reg = ( interruptcount + 7 )/ 8 ; <nl> + rfi -> index_to_intr_reg = ( interruptcount + 7 ) / 8 ; <nl> if ( rfi -> index_to_intr_reg != 0 ) <nl> rfi -> index_to_intr_reg -= 1 ; <nl> /*
mmm fs / ubifs / lprops . c <nl> ppp fs / ubifs / lprops . c <nl> static int scan_check_cb ( struct ubifs_info * c , <nl> } <nl> } <nl>  <nl> - buf = __vmalloc ( c -> leb_size , GFP_NOFS , PAGE_KERNEL ); <nl> - if (! buf ) <nl> - return - ENOMEM ; <nl> - <nl> /* <nl> * After an unclean unmount , empty and freeable LEBs <nl> * may contain garbage - do not scan them . <nl> static int scan_check_cb ( struct ubifs_info * c , <nl> return LPT_SCAN_CONTINUE ; <nl> } <nl>  <nl> + buf = __vmalloc ( c -> leb_size , GFP_NOFS , PAGE_KERNEL ); <nl> + if (! buf ) <nl> + return - ENOMEM ; <nl> + <nl> sleb = ubifs_scan ( c , lnum , 0 , buf , 0 ); <nl> if ( IS_ERR ( sleb )) { <nl> ret = PTR_ERR ( sleb );
mmm drivers / media / platform / s3c - camif / camif - core . c <nl> ppp drivers / media / platform / s3c - camif / camif - core . c <nl> static struct s3c_camif_drvdata s3c6410_camif_drvdata = { <nl> . bus_clk_freq = 133000000UL , <nl> }; <nl>  <nl> - static struct platform_device_id s3c_camif_driver_ids [] = { <nl> + static const struct platform_device_id s3c_camif_driver_ids [] = { <nl> { <nl> . name = " s3c2440 - camif ", <nl> . driver_data = ( unsigned long )& s3c244x_camif_drvdata ,
mmm net / sched / cls_route . c <nl> ppp net / sched / cls_route . c <nl> static int route4_change ( struct net * net , struct sk_buff * in_skb , <nl> fp = & b -> ht [ h ]; <nl> for ( pfp = rtnl_dereference (* fp ); pfp ; <nl> fp = & pfp -> next , pfp = rtnl_dereference (* fp )) { <nl> - if ( pfp == f ) { <nl> - * fp = f -> next ; <nl> + if ( pfp == fold ) { <nl> + rcu_assign_pointer (* fp , fold -> next ); <nl> break ; <nl> } <nl> }
mmm net / ax25 / af_ax25 . c <nl> ppp net / ax25 / af_ax25 . c <nl> static int ax25_recvmsg ( struct kiocb * iocb , struct socket * sock , <nl> ax25_address src ; <nl> const unsigned char * mac = skb_mac_header ( skb ); <nl>  <nl> + memset ( sax , 0 , sizeof ( struct full_sockaddr_ax25 )); <nl> ax25_addr_parse ( mac + 1 , skb -> data - mac - 1 , & src , NULL , <nl> & digi , NULL , NULL ); <nl> sax -> sax25_family = AF_AX25 ;
mmm arch / x86 / xen / time . c <nl> ppp arch / x86 / xen / time . c <nl> static const struct clock_event_device xen_vcpuop_clockevent = { <nl>  <nl> static const struct clock_event_device * xen_clockevent = <nl> & xen_timerop_clockevent ; <nl> - static DEFINE_PER_CPU ( struct clock_event_device , xen_clock_events ); <nl> + static DEFINE_PER_CPU ( struct clock_event_device , xen_clock_events ) = { . irq = - 1 }; <nl>  <nl> static irqreturn_t xen_timer_interrupt ( int irq , void * dev_id ) <nl> { <nl> void xen_setup_timer ( int cpu ) <nl> struct clock_event_device * evt ; <nl> int irq ; <nl>  <nl> + evt = & per_cpu ( xen_clock_events , cpu ); <nl> + WARN ( evt -> irq >= 0 , " IRQ % d for CPU % d is already allocated \ n ", evt -> irq , cpu ); <nl> + <nl> printk ( KERN_INFO " installing Xen timer for CPU % d \ n ", cpu ); <nl>  <nl> name = kasprintf ( GFP_KERNEL , " timer % d ", cpu ); <nl> void xen_setup_timer ( int cpu ) <nl> IRQF_FORCE_RESUME , <nl> name , NULL ); <nl>  <nl> - evt = & per_cpu ( xen_clock_events , cpu ); <nl> memcpy ( evt , xen_clockevent , sizeof (* evt )); <nl>  <nl> evt -> cpumask = cpumask_of ( cpu ); <nl> void xen_teardown_timer ( int cpu ) <nl> BUG_ON ( cpu == 0 ); <nl> evt = & per_cpu ( xen_clock_events , cpu ); <nl> unbind_from_irqhandler ( evt -> irq , NULL ); <nl> + evt -> irq = - 1 ; <nl> } <nl>  <nl> void xen_setup_cpu_clockevents ( void )
mmm sound / soc / intel / common / sst - firmware . c <nl> ppp sound / soc / intel / common / sst - firmware . c <nl> void sst_dsp_dma_put_channel ( struct sst_dsp * dsp ) <nl> } <nl> EXPORT_SYMBOL_GPL ( sst_dsp_dma_put_channel ); <nl>  <nl> - int sst_dma_new ( struct sst_dsp * sst ) <nl> + static int sst_dma_new ( struct sst_dsp * sst ) <nl> { <nl> struct sst_pdata * sst_pdata = sst -> pdata ; <nl> struct sst_dma * dma ; <nl> int sst_dma_new ( struct sst_dsp * sst ) <nl> devm_kfree ( sst -> dev , dma ); <nl> return ret ; <nl> } <nl> - EXPORT_SYMBOL ( sst_dma_new ); <nl>  <nl> - void sst_dma_free ( struct sst_dma * dma ) <nl> + static void sst_dma_free ( struct sst_dma * dma ) <nl> { <nl>  <nl> if ( dma == NULL ) <nl> void sst_dma_free ( struct sst_dma * dma ) <nl> dw_remove ( dma -> chip ); <nl>  <nl> } <nl> - EXPORT_SYMBOL ( sst_dma_free ); <nl>  <nl> /* create new generic firmware object */ <nl> struct sst_fw * sst_fw_new ( struct sst_dsp * dsp ,
mmm fs / btrfs / async - thread . c <nl> ppp fs / btrfs / async - thread . c <nl> void btrfs_destroy_workqueue ( struct btrfs_workqueue * wq ) <nl> if ( wq -> high ) <nl> __btrfs_destroy_workqueue ( wq -> high ); <nl> __btrfs_destroy_workqueue ( wq -> normal ); <nl> + kfree ( wq ); <nl> } <nl>  <nl> void btrfs_workqueue_set_max ( struct btrfs_workqueue * wq , int max )
mmm tools / perf / util / ui / browsers / annotate . c <nl> ppp tools / perf / util / ui / browsers / annotate . c <nl> static int annotate_browser__run ( struct annotate_browser * self , int evidx , <nl> nd = self -> curr_hot ; <nl> break ; <nl> case ' H ': <nl> + case ' h ': <nl> nd = self -> curr_hot ; <nl> break ; <nl> case ' S ': <nl> + case ' s ': <nl> if ( annotate_browser__toggle_source ( self )) <nl> ui_helpline__puts ( help ); <nl> continue ;
mmm arch / x86 / kvm / vmx . c <nl> ppp arch / x86 / kvm / vmx . c <nl> static inline bool nested_cpu_has_posted_intr ( struct vmcs12 * vmcs12 ) <nl> return vmcs12 -> pin_based_vm_exec_control & PIN_BASED_POSTED_INTR ; <nl> } <nl>  <nl> - static inline bool is_exception ( u32 intr_info ) <nl> + static inline bool is_nmi ( u32 intr_info ) <nl> { <nl> return ( intr_info & ( INTR_INFO_INTR_TYPE_MASK | INTR_INFO_VALID_MASK )) <nl> - == ( INTR_TYPE_HARD_EXCEPTION | INTR_INFO_VALID_MASK ); <nl> + == ( INTR_TYPE_NMI_INTR | INTR_INFO_VALID_MASK ); <nl> } <nl>  <nl> static void nested_vmx_vmexit ( struct kvm_vcpu * vcpu , u32 exit_reason , <nl> static int handle_exception ( struct kvm_vcpu * vcpu ) <nl> if ( is_machine_check ( intr_info )) <nl> return handle_machine_check ( vcpu ); <nl>  <nl> - if (( intr_info & INTR_INFO_INTR_TYPE_MASK ) == INTR_TYPE_NMI_INTR ) <nl> + if ( is_nmi ( intr_info )) <nl> return 1 ; /* already handled by vmx_vcpu_run () */ <nl>  <nl> if ( is_no_device ( intr_info )) { <nl> static bool nested_vmx_exit_handled ( struct kvm_vcpu * vcpu ) <nl>  <nl> switch ( exit_reason ) { <nl> case EXIT_REASON_EXCEPTION_NMI : <nl> - if (! is_exception ( intr_info )) <nl> + if ( is_nmi ( intr_info )) <nl> return false ; <nl> else if ( is_page_fault ( intr_info )) <nl> return enable_ept ; <nl> static void vmx_complete_atomic_exit ( struct vcpu_vmx * vmx ) <nl> kvm_machine_check (); <nl>  <nl> /* We need to handle NMIs before interrupts are enabled */ <nl> - if (( exit_intr_info & INTR_INFO_INTR_TYPE_MASK ) == INTR_TYPE_NMI_INTR && <nl> - ( exit_intr_info & INTR_INFO_VALID_MASK )) { <nl> + if ( is_nmi ( exit_intr_info )) { <nl> kvm_before_handle_nmi (& vmx -> vcpu ); <nl> asm (" int $ 2 "); <nl> kvm_after_handle_nmi (& vmx -> vcpu );
mmm drivers / block / floppy . c <nl> ppp drivers / block / floppy . c <nl> static int raw_cmd_copyin ( int cmd , void __user * param , <nl> return - ENOMEM ; <nl> * rcmd = ptr ; <nl> ret = copy_from_user ( ptr , param , sizeof (* ptr )); <nl> - if ( ret ) <nl> - return - EFAULT ; <nl> ptr -> next = NULL ; <nl> ptr -> buffer_length = 0 ; <nl> + ptr -> kernel_data = NULL ; <nl> + if ( ret ) <nl> + return - EFAULT ; <nl> param += sizeof ( struct floppy_raw_cmd ); <nl> if ( ptr -> cmd_count > 33 ) <nl> /* the command may now also take up the space <nl> static int raw_cmd_copyin ( int cmd , void __user * param , <nl> for ( i = 0 ; i < 16 ; i ++) <nl> ptr -> reply [ i ] = 0 ; <nl> ptr -> resultcode = 0 ; <nl> - ptr -> kernel_data = NULL ; <nl>  <nl> if ( ptr -> flags & ( FD_RAW_READ | FD_RAW_WRITE )) { <nl> if ( ptr -> length <= 0 )
mmm fs / nfsd / nfs4recover . c <nl> ppp fs / nfsd / nfs4recover . c <nl> cld_pipe_downcall ( struct file * filp , const char __user * src , size_t mlen ) <nl> struct cld_upcall * tmp , * cup ; <nl> struct cld_msg __user * cmsg = ( struct cld_msg __user *) src ; <nl> uint32_t xid ; <nl> - struct nfsd_net * nn = net_generic ( filp -> f_dentry -> d_sb -> s_fs_info , <nl> + struct nfsd_net * nn = net_generic ( file_inode ( filp )-> i_sb -> s_fs_info , <nl> nfsd_net_id ); <nl> struct cld_net * cn = nn -> cld_net ; <nl> 
mmm drivers / scsi / hpsa . c <nl> ppp drivers / scsi / hpsa . c <nl> static int hpsa_eh_device_reset_handler ( struct scsi_cmnd * scsicmd ) <nl> return FAILED ; <nl> } <nl>  <nl> + if ( dev -> devtype == TYPE_ENCLOSURE ) <nl> + return SUCCESS ; <nl> + <nl> /* if controller locked up , we can guarantee command won ' t complete */ <nl> if ( lockup_detected ( h )) { <nl> snprintf ( msg , sizeof ( msg ),
mmm sound / pci / hda / patch_realtek . c <nl> ppp sound / pci / hda / patch_realtek . c <nl> static void alc889_fixup_dac_route ( struct hda_codec * codec , <nl> const struct alc_fixup * fix , int action ) <nl> { <nl> if ( action == ALC_FIXUP_ACT_PRE_PROBE ) { <nl> + /* fake the connections during parsing the tree */ <nl> hda_nid_t conn1 [ 2 ] = { 0x0c , 0x0d }; <nl> hda_nid_t conn2 [ 2 ] = { 0x0e , 0x0f }; <nl> snd_hda_override_conn_list ( codec , 0x14 , 2 , conn1 ); <nl> snd_hda_override_conn_list ( codec , 0x15 , 2 , conn1 ); <nl> snd_hda_override_conn_list ( codec , 0x18 , 2 , conn2 ); <nl> snd_hda_override_conn_list ( codec , 0x1a , 2 , conn2 ); <nl> + } else if ( action == ALC_FIXUP_ACT_PROBE ) { <nl> + /* restore the connections */ <nl> + hda_nid_t conn [ 5 ] = { 0x0c , 0x0d , 0x0e , 0x0f , 0x26 }; <nl> + snd_hda_override_conn_list ( codec , 0x14 , 5 , conn ); <nl> + snd_hda_override_conn_list ( codec , 0x15 , 5 , conn ); <nl> + snd_hda_override_conn_list ( codec , 0x18 , 5 , conn ); <nl> + snd_hda_override_conn_list ( codec , 0x1a , 5 , conn ); <nl> } <nl> } <nl> 
mmm kernel / exit . c <nl> ppp kernel / exit . c <nl> void do_exit ( long code ) <nl>  <nl> module_put ( task_thread_info ( tsk )-> exec_domain -> module ); <nl>  <nl> - proc_exit_connector ( tsk ); <nl> /* <nl> * FIXME : do that only when needed , using sched_exit tracepoint <nl> */ <nl> flush_ptrace_hw_breakpoint ( tsk ); <nl>  <nl> exit_notify ( tsk , group_dead ); <nl> + proc_exit_connector ( tsk ); <nl> # ifdef CONFIG_NUMA <nl> task_lock ( tsk ); <nl> mpol_put ( tsk -> mempolicy );
mmm drivers / staging / comedi / drivers / das16 . c <nl> ppp drivers / staging / comedi / drivers / das16 . c <nl> static struct comedi_driver das16_driver = { <nl> module_comedi_driver ( das16_driver ); <nl>  <nl> MODULE_AUTHOR (" Comedi http :// www . comedi . org "); <nl> - MODULE_DESCRIPTION (" Comedi low - level driver "); <nl> + MODULE_DESCRIPTION (" Comedi driver for DAS16 compatible boards "); <nl> MODULE_LICENSE (" GPL ");
mmm drivers / staging / most / dim2 / dim2 . c <nl> ppp drivers / staging / most / dim2 / dim2 . c <nl> static int dim2_probe ( struct platform_device * pdev ) <nl> if ( ret ) <nl> return ret ; <nl>  <nl> - dev -> disable_platform = pdata ? pdata -> disable : 0 ; <nl> + dev -> disable_platform = pdata ? pdata -> disable : NULL ; <nl>  <nl> dev_info (& pdev -> dev , " sync : num of frames per sub - buffer : % u \ n ", fcnt ); <nl> hal_ret = dim_startup ( dev -> io_base , dev -> clk_speed , fcnt );
mmm drivers / net / wireless / marvell / mwifiex / scan . c <nl> ppp drivers / net / wireless / marvell / mwifiex / scan . c <nl> int mwifiex_ret_802_11_scan ( struct mwifiex_private * priv , <nl>  <nl> pmatch = adapter -> nd_info -> matches [ idx ]; <nl>  <nl> - if (! pmatch ) { <nl> + if ( pmatch ) { <nl> memset ( pmatch , 0 , sizeof (* pmatch )); <nl> if ( chan_band_tlv ) { <nl> pmatch -> n_channels = 1 ;
mmm drivers / net / hamradio / 6pack . c <nl> ppp drivers / net / hamradio / 6pack . c <nl> static void sixpack_close ( struct tty_struct * tty ) <nl> */ <nl> netif_stop_queue ( sp -> dev ); <nl>  <nl> + unregister_netdev ( sp -> dev ); <nl> + <nl> del_timer_sync (& sp -> tx_t ); <nl> del_timer_sync (& sp -> resync_t ); <nl>  <nl> - unregister_netdev ( sp -> dev ); <nl> - <nl> /* Free all 6pack frame buffers after unreg . */ <nl> kfree ( sp -> rbuff ); <nl> kfree ( sp -> xbuff );
mmm arch / arm / plat - s3c64xx / s3c6400 - clock . c <nl> ppp arch / arm / plat - s3c64xx / s3c6400 - clock . c <nl> static int s3c64xx_setrate_clksrc ( struct clk * clk , unsigned long rate ) <nl>  <nl> rate = clk_round_rate ( clk , rate ); <nl> div = clk_get_rate ( clk -> parent ) / rate ; <nl> + if ( div > 16 ) <nl> + return - EINVAL ; <nl>  <nl> val = __raw_readl ( reg ); <nl> - val &= ~ sclk -> mask ; <nl> - val |= ( rate - 1 ) << sclk -> shift ; <nl> + val &= ~( 0xf << sclk -> shift ); <nl> + val |= ( div - 1 ) << sclk -> shift ; <nl> __raw_writel ( val , reg ); <nl>  <nl> return 0 ;
mmm drivers / scsi / lpfc / lpfc_hbadisc . c <nl> ppp drivers / scsi / lpfc / lpfc_hbadisc . c <nl> lpfc_filter_by_rpi ( struct lpfc_nodelist * ndlp , void * param ) <nl> { <nl> uint16_t * rpi = param ; <nl>  <nl> + /* check for active node */ <nl> + if (! NLP_CHK_NODE_ACT ( ndlp )) <nl> + return 0 ; <nl> + <nl> return ndlp -> nlp_rpi == * rpi ; <nl> } <nl> mmm drivers / scsi / lpfc / lpfc_init . c <nl> ppp drivers / scsi / lpfc / lpfc_init . c <nl> lpfc_filter_by_rpi ( struct lpfc_nodelist * ndlp , void * param ) <nl> { <nl> uint16_t * rpi = param ; <nl>  <nl> + /* check for active node */ <nl> + if (! NLP_CHK_NODE_ACT ( ndlp )) <nl> + return 0 ; <nl> + <nl> return ndlp -> nlp_rpi == * rpi ; <nl> } <nl>  <nl> lpfc_cleanup ( struct lpfc_vport * vport ) <nl> continue ; <nl> } <nl>  <nl> + /* take care of nodes in unused state before the state <nl> + * machine taking action . <nl> + */ <nl> + if ( ndlp -> nlp_state == NLP_STE_UNUSED_NODE ) { <nl> + lpfc_nlp_put ( ndlp ); <nl> + continue ; <nl> + } <nl> + <nl> if ( ndlp -> nlp_type & NLP_FABRIC ) <nl> lpfc_disc_state_machine ( vport , ndlp , NULL , <nl> NLP_EVT_DEVICE_RECOVERY ); <nl>  <nl> lpfc_disc_state_machine ( vport , ndlp , NULL , <nl> NLP_EVT_DEVICE_RM ); <nl> - <nl> } <nl>  <nl> /* At this point , ALL ndlp ' s should be gonemmm drivers / scsi / lpfc / lpfc_els . c <nl> ppp drivers / scsi / lpfc / lpfc_els . c <nl> lpfc_filter_by_rpi ( struct lpfc_nodelist * ndlp , void * param ) <nl> { <nl> uint16_t * rpi = param ; <nl>  <nl> + /* check for active node */ <nl> + if (! NLP_CHK_NODE_ACT ( ndlp )) <nl> + return 0 ; <nl> + <nl> return ndlp -> nlp_rpi == * rpi ; <nl> } <nl>  <nl> lpfc_cleanup ( struct lpfc_vport * vport ) <nl> continue ; <nl> } <nl>  <nl> + /* take care of nodes in unused state before the state <nl> + * machine taking action . <nl> + */ <nl> + if ( ndlp -> nlp_state == NLP_STE_UNUSED_NODE ) { <nl> + lpfc_nlp_put ( ndlp ); <nl> + continue ; <nl> + } <nl> + <nl> if ( ndlp -> nlp_type & NLP_FABRIC ) <nl> lpfc_disc_state_machine ( vport , ndlp , NULL , <nl> NLP_EVT_DEVICE_RECOVERY ); <nl>  <nl> lpfc_disc_state_machine ( vport , ndlp , NULL , <nl> NLP_EVT_DEVICE_RM ); <nl> - <nl> } <nl>  <nl> /* At this point , ALL ndlp ' s should be gone <nl> lpfc_plogi_confirm_nport ( struct lpfc_hba * phba , uint32_t * prsp , <nl> memcpy (& ndlp -> active_rrqs . xri_bitmap , <nl> & rrq . xri_bitmap , <nl> sizeof ( ndlp -> active_rrqs . xri_bitmap )); <nl> - lpfc_nlp_set_state ( vport , ndlp , NLP_STE_NPR_NODE ); <nl> /* Since we are swapping the ndlp passed in with the new one <nl> * and the did has already been swapped , copy over the <nl> * state and names . <nl> lpfc_plogi_confirm_nport ( struct lpfc_hba * phba , uint32_t * prsp , <nl> memcpy (& new_ndlp -> nlp_nodename , & ndlp -> nlp_nodename , <nl> sizeof ( struct lpfc_name )); <nl> new_ndlp -> nlp_state = ndlp -> nlp_state ; <nl> + lpfc_nlp_set_state ( vport , ndlp , NLP_STE_NPR_NODE ); <nl> /* Fix up the rport accordingly */ <nl> rport = ndlp -> rport ; <nl> if ( rport ) {
mmm net / ipv4 / route . c <nl> ppp net / ipv4 / route . c <nl> static void __ip_rt_update_pmtu ( struct rtable * rt , struct flowi4 * fl4 , u32 mtu ) <nl> if ( mtu < ip_rt_min_pmtu ) <nl> mtu = ip_rt_min_pmtu ; <nl>  <nl> + if ( rt -> rt_pmtu == mtu && <nl> + time_before ( jiffies , dst -> expires - ip_rt_mtu_expires / 2 )) <nl> + return ; <nl> + <nl> rcu_read_lock (); <nl> if ( fib_lookup ( dev_net ( dst -> dev ), fl4 , & res ) == 0 ) { <nl> struct fib_nh * nh = & FIB_RES_NH ( res );
mmm drivers / gpu / drm / sun4i / sun4i_backend . h <nl> ppp drivers / gpu / drm / sun4i / sun4i_backend . h <nl> # define SUN4I_BACKEND_LAYFB_L32ADD_REG ( l ) ( 0x850 + ( 0x4 * ( l ))) <nl>  <nl> # define SUN4I_BACKEND_LAYFB_H4ADD_REG 0x860 <nl> -# define SUN4I_BACKEND_LAYFB_H4ADD_MSK ( l ) GENMASK ( 3 + (( l ) * 8 ), 0 ) <nl> -# define SUN4I_BACKEND_LAYFB_H4ADD ( l , val ) (( val ) << (( l ) * 8 )) <nl> +# define SUN4I_BACKEND_LAYFB_H4ADD_MSK ( l ) GENMASK ( 3 + (( l ) * 8 ), ( l ) * 8 ) <nl> +# define SUN4I_BACKEND_LAYFB_H4ADD ( l , val ) (( val ) << (( l ) * 8 )) <nl>  <nl> # define SUN4I_BACKEND_REGBUFFCTL_REG 0x870 <nl> # define SUN4I_BACKEND_REGBUFFCTL_AUTOLOAD_DIS BIT ( 1 )
mmm fs / btrfs / inode . c <nl> ppp fs / btrfs / inode . c <nl> static noinline int compress_file_range ( struct inode * inode , <nl> nr_pages = ( end >> PAGE_CACHE_SHIFT ) - ( start >> PAGE_CACHE_SHIFT ) + 1 ; <nl> nr_pages = min ( nr_pages , ( 128 * 1024UL ) / PAGE_CACHE_SIZE ); <nl>  <nl> + /* <nl> + * we don ' t want to send crud past the end of i_size through <nl> + * compression , that ' s just a waste of CPU time . So , if the <nl> + * end of the file is before the start of our current <nl> + * requested range of bytes , we bail out to the uncompressed <nl> + * cleanup code that can deal with all of this . <nl> + * <nl> + * It isn ' t really the fastest way to fix things , but this is a <nl> + * very uncommon corner . <nl> + */ <nl> + if ( actual_end <= start ) <nl> + goto cleanup_and_bail_uncompressed ; <nl> + <nl> total_compressed = actual_end - start ; <nl>  <nl> /* we want to make sure that amount of ram required to uncompress <nl> static noinline int compress_file_range ( struct inode * inode , <nl> goto again ; <nl> } <nl> } else { <nl> + cleanup_and_bail_uncompressed : <nl> /* <nl> * No compression , but we still need to write the pages in <nl> * the file we ' ve been given so far . redirty the locked
mmm drivers / hid / usbhid / hid - core . c <nl> ppp drivers / hid / usbhid / hid - core . c <nl> static int usbhid_parse ( struct hid_device * hid ) <nl> unsigned int rsize = 0 ; <nl> char * rdesc ; <nl> int ret , n ; <nl> + int num_descriptors ; <nl> + size_t offset = offsetof ( struct hid_descriptor , desc ); <nl>  <nl> quirks = usbhid_lookup_quirk ( le16_to_cpu ( dev -> descriptor . idVendor ), <nl> le16_to_cpu ( dev -> descriptor . idProduct )); <nl> static int usbhid_parse ( struct hid_device * hid ) <nl> return - ENODEV ; <nl> } <nl>  <nl> + if ( hdesc -> bLength < sizeof ( struct hid_descriptor )) { <nl> + dbg_hid (" hid descriptor is too short \ n "); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> hid -> version = le16_to_cpu ( hdesc -> bcdHID ); <nl> hid -> country = hdesc -> bCountryCode ; <nl>  <nl> - for ( n = 0 ; n < hdesc -> bNumDescriptors ; n ++) <nl> + num_descriptors = min_t ( int , hdesc -> bNumDescriptors , <nl> + ( hdesc -> bLength - offset ) / sizeof ( struct hid_class_descriptor )); <nl> + <nl> + for ( n = 0 ; n < num_descriptors ; n ++) <nl> if ( hdesc -> desc [ n ]. bDescriptorType == HID_DT_REPORT ) <nl> rsize = le16_to_cpu ( hdesc -> desc [ n ]. wDescriptorLength ); <nl> 
mmm drivers / net / wireless / iwlwifi / iwl - trans - pcie . c <nl> ppp drivers / net / wireless / iwlwifi / iwl - trans - pcie . c <nl> static int iwl_trans_pcie_start_hw ( struct iwl_trans * trans ) <nl> err = iwl_prepare_card_hw ( trans ); <nl> if ( err ) { <nl> IWL_ERR ( trans , " Error while preparing HW : % d ", err ); <nl> - goto error ; <nl> + goto err_free_irq ; <nl> } <nl>  <nl> iwl_apm_init ( trans ); <nl> static int iwl_trans_pcie_start_hw ( struct iwl_trans * trans ) <nl>  <nl> return err ; <nl>  <nl> + err_free_irq : <nl> + free_irq ( trans -> irq , trans ); <nl> error : <nl> iwl_free_isr_ict ( trans ); <nl> tasklet_kill (& trans_pcie -> irq_tasklet );
mmm security / keys / gc . c <nl> ppp security / keys / gc . c <nl> static noinline void key_gc_unused_keys ( struct list_head * keys ) <nl> kdebug ("- % u ", key -> serial ); <nl> key_check ( key ); <nl>  <nl> - /* Throw away the key data */ <nl> - if ( key -> type -> destroy ) <nl> + /* Throw away the key data if the key is instantiated */ <nl> + if ( test_bit ( KEY_FLAG_INSTANTIATED , & key -> flags ) && <nl> + ! test_bit ( KEY_FLAG_NEGATIVE , & key -> flags ) && <nl> + key -> type -> destroy ) <nl> key -> type -> destroy ( key ); <nl>  <nl> security_key_free ( key );
mmm arch / arm / mach - omap2 / clock34xx . c <nl> ppp arch / arm / mach - omap2 / clock34xx . c <nl> static int omap3_noncore_dpll_program ( struct clk * clk , u16 m , u8 n , u16 freqsel ) <nl> /* 3430 ES2 TRM : 4 . 7 . 6 . 9 DPLL Programming Sequence */ <nl> _omap3_noncore_dpll_bypass ( clk ); <nl>  <nl> + /* Set jitter correction */ <nl> + v = __raw_readl ( dd -> control_reg ); <nl> + v &= ~ dd -> freqsel_mask ; <nl> + v |= freqsel << __ffs ( dd -> freqsel_mask ); <nl> + __raw_writel ( v , dd -> control_reg ); <nl> + <nl> + /* Set DPLL multiplier , divider */ <nl> v = __raw_readl ( dd -> mult_div1_reg ); <nl> v &= ~( dd -> mult_mask | dd -> div1_mask ); <nl> - <nl> - /* Set mult ( M ), div1 ( N ), freqsel */ <nl> v |= m << __ffs ( dd -> mult_mask ); <nl> - v |= n << __ffs ( dd -> div1_mask ); <nl> - v |= freqsel << __ffs ( dd -> freqsel_mask ); <nl> - <nl> + v |= ( n - 1 ) << __ffs ( dd -> div1_mask ); <nl> __raw_writel ( v , dd -> mult_div1_reg ); <nl>  <nl> /* We let the clock framework set the other output dividers later */
mmm arch / arm / mach - integrator / integrator_ap . c <nl> ppp arch / arm / mach - integrator / integrator_ap . c <nl> # include < linux / clockchips . h > <nl> # include < linux / interrupt . h > <nl> # include < linux / io . h > <nl> +# include < linux / mtd / physmap . h > <nl>  <nl> # include < mach / hardware . h > <nl> # include < mach / platform . h > <nl> # include < mach / lm . h > <nl>  <nl> # include < asm / mach / arch . h > <nl> -# include < asm / mach / flash . h > <nl> # include < asm / mach / irq . h > <nl> # include < asm / mach / map . h > <nl> # include < asm / mach / time . h > <nl> device_initcall ( irq_init_sysfs ); <nl> # define EBI_CSR1 ( VA_EBI_BASE + INTEGRATOR_EBI_CSR1_OFFSET ) <nl> # define EBI_LOCK ( VA_EBI_BASE + INTEGRATOR_EBI_LOCK_OFFSET ) <nl>  <nl> - static int ap_flash_init ( void ) <nl> + static int ap_flash_init ( struct platform_device * dev ) <nl> { <nl> u32 tmp ; <nl>  <nl> static int ap_flash_init ( void ) <nl> return 0 ; <nl> } <nl>  <nl> - static void ap_flash_exit ( void ) <nl> + static void ap_flash_exit ( struct platform_device * dev ) <nl> { <nl> u32 tmp ; <nl>  <nl> static void ap_flash_exit ( void ) <nl> } <nl> } <nl>  <nl> - static void ap_flash_set_vpp ( int on ) <nl> + static void ap_flash_set_vpp ( struct map_info * map , int on ) <nl> { <nl> void __iomem * reg = on ? SC_CTRLS : SC_CTRLC ; <nl>  <nl> writel ( INTEGRATOR_SC_CTRL_nFLVPPEN , reg ); <nl> } <nl>  <nl> - static struct flash_platform_data ap_flash_data = { <nl> - . map_name = " cfi_probe ", <nl> + static struct physmap_flash_data ap_flash_data = { <nl> . width = 4 , <nl> . init = ap_flash_init , <nl> . exit = ap_flash_exit , <nl> static struct resource cfi_flash_resource = { <nl> }; <nl>  <nl> static struct platform_device cfi_flash_device = { <nl> - . name = " armflash ", <nl> + . name = " physmap - flash ", <nl> . id = 0 , <nl> . dev = { <nl> . platform_data = & ap_flash_data ,
mmm drivers / hwtracing / coresight / coresight - etm - perf . c <nl> ppp drivers / hwtracing / coresight / coresight - etm - perf . c <nl> static void * etm_setup_aux ( int event_cpu , void ** pages , <nl> if (! sink_ops ( sink )-> alloc_buffer ) <nl> goto err ; <nl>  <nl> + cpu = cpumask_first ( mask ); <nl> /* Get the AUX specific data from the sink buffer */ <nl> event_data -> snk_config = <nl> sink_ops ( sink )-> alloc_buffer ( sink , cpu , pages ,
mmm drivers / media / video / em28xx / em28xx - cards . c <nl> ppp drivers / media / video / em28xx / em28xx - cards . c <nl> void em28xx_pre_card_setup ( struct em28xx * dev ) <nl> if ( rc > 0 ) { <nl> dev -> chip_id = rc ; <nl> switch ( rc ) { <nl> + case CHIP_ID_EM2820 : <nl> + em28xx_info (" chip ID is em2820 \ n "); <nl> + break ; <nl> + case CHIP_ID_EM2840 : <nl> + em28xx_info (" chip ID is em2840 \ n "); <nl> + break ; <nl> case CHIP_ID_EM2860 : <nl> em28xx_info (" chip ID is em2860 \ n "); <nl> break ;mmm drivers / media / video / em28xx / em28xx - reg . h <nl> ppp drivers / media / video / em28xx / em28xx - reg . h <nl> void em28xx_pre_card_setup ( struct em28xx * dev ) <nl> if ( rc > 0 ) { <nl> dev -> chip_id = rc ; <nl> switch ( rc ) { <nl> + case CHIP_ID_EM2820 : <nl> + em28xx_info (" chip ID is em2820 \ n "); <nl> + break ; <nl> + case CHIP_ID_EM2840 : <nl> + em28xx_info (" chip ID is em2840 \ n "); <nl> + break ; <nl> case CHIP_ID_EM2860 : <nl> em28xx_info (" chip ID is em2860 \ n "); <nl> break ; <nl>  <nl> /* FIXME : Need to be populated with the other chip ID ' s */ <nl> enum em28xx_chip_id { <nl> + CHIP_ID_EM2820 = 18 , <nl> + CHIP_ID_EM2840 = 20 , <nl> CHIP_ID_EM2860 = 34 , <nl> CHIP_ID_EM2883 = 36 , <nl> CHIP_ID_EM2874 = 65 ,
mmm net / bridge / br_multicast . c <nl> ppp net / bridge / br_multicast . c <nl> static void __br_multicast_send_query ( struct net_bridge * br , <nl> return ; <nl>  <nl> if ( port ) { <nl> - __skb_push ( skb , sizeof ( struct ethhdr )); <nl> skb -> dev = port -> dev ; <nl> NF_HOOK ( NFPROTO_BRIDGE , NF_BR_LOCAL_OUT , skb , NULL , skb -> dev , <nl> - dev_queue_xmit ); <nl> + br_dev_queue_push_xmit ); <nl> } else { <nl> br_multicast_select_own_querier ( br , ip , skb ); <nl> netif_rx ( skb );
mmm drivers / block / paride / pcd . c <nl> ppp drivers / block / paride / pcd . c <nl> static void pcd_init_units ( void ) <nl> disk -> queue = blk_mq_init_sq_queue (& cd -> tag_set , & pcd_mq_ops , <nl> 1 , BLK_MQ_F_SHOULD_MERGE ); <nl> if ( IS_ERR ( disk -> queue )) { <nl> + put_disk ( disk ); <nl> disk -> queue = NULL ; <nl> continue ; <nl> } <nl> static int pcd_detect ( void ) <nl>  <nl> printk ("% s : No CD - ROM drive found \ n ", name ); <nl> for ( unit = 0 , cd = pcd ; unit < PCD_UNITS ; unit ++, cd ++) { <nl> + if (! cd -> disk ) <nl> + continue ; <nl> blk_cleanup_queue ( cd -> disk -> queue ); <nl> cd -> disk -> queue = NULL ; <nl> blk_mq_free_tag_set (& cd -> tag_set ); <nl> static int __init pcd_init ( void ) <nl> pcd_probe_capabilities (); <nl>  <nl> if ( register_blkdev ( major , name )) { <nl> - for ( unit = 0 , cd = pcd ; unit < PCD_UNITS ; unit ++, cd ++) <nl> + for ( unit = 0 , cd = pcd ; unit < PCD_UNITS ; unit ++, cd ++) { <nl> + if (! cd -> disk ) <nl> + continue ; <nl> + <nl> + blk_cleanup_queue ( cd -> disk -> queue ); <nl> + blk_mq_free_tag_set (& cd -> tag_set ); <nl> put_disk ( cd -> disk ); <nl> + } <nl> return - EBUSY ; <nl> } <nl>  <nl> static void __exit pcd_exit ( void ) <nl> int unit ; <nl>  <nl> for ( unit = 0 , cd = pcd ; unit < PCD_UNITS ; unit ++, cd ++) { <nl> + if (! cd -> disk ) <nl> + continue ; <nl> + <nl> if ( cd -> present ) { <nl> del_gendisk ( cd -> disk ); <nl> pi_release ( cd -> pi );
mmm tools / perf / builtin - sched . c <nl> ppp tools / perf / builtin - sched . c <nl> static int perf_sched__read_events ( struct perf_sched * sched ) <nl> struct perf_data_file file = { <nl> . path = input_name , <nl> . mode = PERF_DATA_MODE_READ , <nl> + . force = sched -> force , <nl> }; <nl> int rc = - 1 ; <nl> 
mmm drivers / acpi / tables . c <nl> ppp drivers / acpi / tables . c <nl> int __init acpi_table_init ( void ) <nl>  <nl> static int __init acpi_parse_apic_instance ( char * str ) <nl> { <nl> + if (! str ) <nl> + return - EINVAL ; <nl>  <nl> acpi_apic_instance = simple_strtoul ( str , NULL , 0 ); <nl> 
mmm drivers / staging / media / go7007 / wis - saa7115 . c <nl> ppp drivers / staging / media / go7007 / wis - saa7115 . c <nl> static int wis_saa7115_probe ( struct i2c_client * client , <nl> dec -> hue = 0 ; <nl> i2c_set_clientdata ( client , dec ); <nl>  <nl> - printk ( KERN_DEBUG <nl> + dev_dbg (& client -> dev , <nl> " wis - saa7115 : initializing SAA7115 at address % d on % s \ n ", <nl> client -> addr , adapter -> name ); <nl>  <nl> if ( write_regs ( client , initial_registers ) < 0 ) { <nl> - printk ( KERN_ERR <nl> + dev_err (& client -> dev , <nl> " wis - saa7115 : error initializing SAA7115 \ n "); <nl> kfree ( dec ); <nl> return - ENODEV ;
mmm drivers / usb / serial / option . c <nl> ppp drivers / usb / serial / option . c <nl> static void option_instat_callback ( struct urb * urb ) <nl> dev_dbg ( dev , "% s : type % x req % x \ n ", __func__ , <nl> req_pkt -> bRequestType , req_pkt -> bRequest ); <nl> } <nl> + } else if ( status == - ENOENT || status == - ESHUTDOWN ) { <nl> + dev_dbg ( dev , "% s : urb stopped : % d \ n ", __func__ , status ); <nl> } else <nl> dev_err ( dev , "% s : error % d \ n ", __func__ , status ); <nl> 
mmm fs / eventpoll . c <nl> ppp fs / eventpoll . c <nl> static void ep_free ( struct eventpoll * ep ) <nl> } <nl>  <nl> mutex_unlock (& epmutex ); <nl> - <nl> mutex_destroy (& ep -> mtx ); <nl> + kfree ( ep ); <nl> } <nl>  <nl> static int ep_eventpoll_release ( struct inode * inode , struct file * file ) <nl> { <nl> struct eventpoll * ep = file -> private_data ; <nl>  <nl> - if ( ep ) { <nl> + if ( ep ) <nl> ep_free ( ep ); <nl> - kfree ( ep ); <nl> - } <nl>  <nl> DNPRINTK ( 3 , ( KERN_INFO "[% p ] eventpoll : close () ep =% p \ n ", current , ep )); <nl> return 0 ; <nl> asmlinkage long sys_epoll_create ( int size ) <nl>  <nl> error_free : <nl> ep_free ( ep ); <nl> - kfree ( ep ); <nl> error_return : <nl> DNPRINTK ( 3 , ( KERN_INFO "[% p ] eventpoll : sys_epoll_create (% d ) = % d \ n ", <nl> current , size , error ));
mmm drivers / staging / android / ion / ion_carveout_heap . c <nl> ppp drivers / staging / android / ion / ion_carveout_heap . c <nl> static int ion_carveout_heap_allocate ( struct ion_heap * heap , <nl> unsigned long size , unsigned long align , <nl> unsigned long flags ) <nl> { <nl> + if ( align > PAGE_SIZE ) <nl> + return - EINVAL ; <nl> + <nl> buffer -> priv_phys = ion_carveout_allocate ( heap , size , align ); <nl> return buffer -> priv_phys == ION_CARVEOUT_ALLOCATE_FAIL ? - ENOMEM : 0 ; <nl> }
mmm drivers / usb / gadget / f_fs . c <nl> ppp drivers / usb / gadget / f_fs . c <nl> static ssize_t ffs_epfile_io ( struct file * file , <nl> char __user * buf , size_t len , int read ) <nl> { <nl> struct ffs_epfile * epfile = file -> private_data ; <nl> - struct usb_gadget * gadget = epfile -> ffs -> gadget ; <nl> struct ffs_ep * ep ; <nl> char * data = NULL ; <nl> ssize_t ret , data_len ; <nl> static ssize_t ffs_epfile_io ( struct file * file , <nl>  <nl> /* Allocate & copy */ <nl> if (! halt ) { <nl> + /* <nl> + * if we _do_ wait above , the epfile -> ffs -> gadget might be NULL <nl> + * before the waiting completes , so do not assign to ' gadget ' earlier <nl> + */ <nl> + struct usb_gadget * gadget = epfile -> ffs -> gadget ; <nl> + <nl> /* <nl> * Controller may require buffer size to be aligned to <nl> * maxpacketsize of an out endpoint .
mmm fs / ecryptfs / file . c <nl> ppp fs / ecryptfs / file . c <nl> static int read_or_initialize_metadata ( struct dentry * dentry ) <nl> return rc ; <nl> } <nl>  <nl> + static int ecryptfs_mmap ( struct file * file , struct vm_area_struct * vma ) <nl> +{ <nl> + struct file * lower_file = ecryptfs_file_to_lower ( file ); <nl> + /* <nl> + * Don ' t allow mmap on top of file systems that don ' t support it <nl> + * natively . If FILESYSTEM_MAX_STACK_DEPTH > 2 or ecryptfs <nl> + * allows recursive mounting , this will need to be extended . <nl> + */ <nl> + if (! lower_file -> f_op -> mmap ) <nl> + return - ENODEV ; <nl> + return generic_file_mmap ( file , vma ); <nl> +} <nl> + <nl> /** <nl> * ecryptfs_open <nl> * @ inode : inode specifying file to open <nl> const struct file_operations ecryptfs_main_fops = { <nl> # ifdef CONFIG_COMPAT <nl> . compat_ioctl = ecryptfs_compat_ioctl , <nl> # endif <nl> - . mmap = generic_file_mmap , <nl> + . mmap = ecryptfs_mmap , <nl> . open = ecryptfs_open , <nl> . flush = ecryptfs_flush , <nl> . release = ecryptfs_release ,
mmm kernel / fork . c <nl> ppp kernel / fork . c <nl> noinline struct pt_regs * __cpuinit __attribute__ (( weak )) idle_regs ( struct pt_re <nl> return regs ; <nl> } <nl>  <nl> + static inline void init_idle_pids ( struct pid_link * links ) <nl> +{ <nl> + enum pid_type type ; <nl> + <nl> + for ( type = PIDTYPE_PID ; type < PIDTYPE_MAX ; ++ type ) { <nl> + INIT_HLIST_NODE (& links [ type ]. node ); /* not really needed */ <nl> + links [ type ]. pid = & init_struct_pid ; <nl> + } <nl> +} <nl> + <nl> struct task_struct * __cpuinit fork_idle ( int cpu ) <nl> { <nl> struct task_struct * task ; <nl> struct task_struct * __cpuinit fork_idle ( int cpu ) <nl>  <nl> task = copy_process ( CLONE_VM , 0 , idle_regs (& regs ), 0 , NULL , <nl> & init_struct_pid , 0 ); <nl> - if (! IS_ERR ( task )) <nl> + if (! IS_ERR ( task )) { <nl> + init_idle_pids ( task -> pids ); <nl> init_idle ( task , cpu ); <nl> + } <nl>  <nl> return task ; <nl> }
mmm net / bridge / br_mdb . c <nl> ppp net / bridge / br_mdb . c <nl> static int __br_mdb_add ( struct net * net , struct net_bridge * br , <nl> if (! p || p -> br != br || p -> state == BR_STATE_DISABLED ) <nl> return - EINVAL ; <nl>  <nl> + memset (& ip , 0 , sizeof ( ip )); <nl> ip . proto = entry -> addr . proto ; <nl> if ( ip . proto == htons ( ETH_P_IP )) <nl> ip . u . ip4 = entry -> addr . u . ip4 ; <nl> static int __br_mdb_del ( struct net_bridge * br , struct br_mdb_entry * entry ) <nl> if (! netif_running ( br -> dev ) || br -> multicast_disabled ) <nl> return - EINVAL ; <nl>  <nl> + memset (& ip , 0 , sizeof ( ip )); <nl> ip . proto = entry -> addr . proto ; <nl> if ( ip . proto == htons ( ETH_P_IP )) { <nl> if ( timer_pending (& br -> ip4_other_query . timer ))
mmm kernel / trace / trace_output . c <nl> ppp kernel / trace / trace_output . c <nl> static enum print_line_t trace_stack_print ( struct trace_iterator * iter , <nl>  <nl> trace_assign_type ( field , iter -> ent ); <nl>  <nl> + if (! trace_seq_puts ( s , "\ n ")) <nl> + goto partial ; <nl> for ( i = 0 ; i < FTRACE_STACK_ENTRIES ; i ++) { <nl> - if (! field -> caller [ i ]) <nl> + if (! field -> caller [ i ] || ( field -> caller [ i ] == ULONG_MAX )) <nl> break ; <nl> - if ( i ) { <nl> - if (! trace_seq_puts ( s , " <= ")) <nl> - goto partial ; <nl> + if (! trace_seq_puts ( s , " => ")) <nl> + goto partial ; <nl>  <nl> - if (! seq_print_ip_sym ( s , field -> caller [ i ], flags )) <nl> - goto partial ; <nl> - } <nl> + if (! seq_print_ip_sym ( s , field -> caller [ i ], flags )) <nl> + goto partial ; <nl> if (! trace_seq_puts ( s , "\ n ")) <nl> goto partial ; <nl> }
mmm fs / btrfs / send . c <nl> ppp fs / btrfs / send . c <nl> static int iterate_dir_item ( struct btrfs_root * root , struct btrfs_path * path , <nl> buf = tmp ; <nl> } <nl> if (! buf ) { <nl> - buf = vmalloc ( buf_len ); <nl> + buf = kvmalloc ( buf_len , GFP_KERNEL ); <nl> if (! buf ) { <nl> ret = - ENOMEM ; <nl> goto out ;
mmm arch / x86 / vdso / vdso2c . h <nl> ppp arch / x86 / vdso / vdso2c . h <nl> static void BITSFUNC ( go )( void * raw_addr , size_t raw_len , <nl>  <nl> /* Validate mapping addresses . */ <nl> for ( i = 0 ; i < sizeof ( special_pages ) / sizeof ( special_pages [ 0 ]); i ++) { <nl> - if (! syms [ i ]) <nl> + INT_BITS symval = syms [ special_pages [ i ]]; <nl> + <nl> + if (! symval ) <nl> continue ; /* The mapping isn ' t used ; ignore it . */ <nl>  <nl> - if ( syms [ i ] % 4096 ) <nl> + if ( symval % 4096 ) <nl> fail ("% s must be a multiple of 4096 \ n ", <nl> required_syms [ i ]. name ); <nl> - if ( syms [ sym_vvar_start ] > syms [ i ] + 4096 ) <nl> - fail ("% s underruns begin_vvar \ n ", <nl> + if ( symval + 4096 < syms [ sym_vvar_start ]) <nl> + fail ("% s underruns vvar_start \ n ", <nl> required_syms [ i ]. name ); <nl> - if ( syms [ i ] + 4096 > 0 ) <nl> + if ( symval + 4096 > 0 ) <nl> fail ("% s is on the wrong side of the vdso text \ n ", <nl> required_syms [ i ]. name ); <nl> }
mmm kernel / events / core . c <nl> ppp kernel / events / core . c <nl> static int perf_copy_attr ( struct perf_event_attr __user * uattr , <nl> if ( ret ) <nl> return - EFAULT ; <nl>  <nl> + attr -> size = size ; <nl> + <nl> if ( attr -> __reserved_1 ) <nl> return - EINVAL ; <nl> 
mmm drivers / spi / spi - imx . c <nl> ppp drivers / spi / spi - imx . c <nl> static int spi_imx_probe ( struct platform_device * pdev ) <nl> goto out_clk_put ; <nl> } <nl>  <nl> + if (! master -> cs_gpios ) { <nl> + dev_err (& pdev -> dev , " No CS GPIOs available \ n "); <nl> + goto out_clk_put ; <nl> + } <nl> + <nl> for ( i = 0 ; i < master -> num_chipselect ; i ++) { <nl> if (! gpio_is_valid ( master -> cs_gpios [ i ])) <nl> continue ;
mmm drivers / target / target_core_configfs . c <nl> ppp drivers / target / target_core_configfs . c <nl> static ssize_t target_core_alua_tg_pt_gp_store_attr_alua_access_state ( <nl> " tg_pt_gp ID : % hu \ n ", tg_pt_gp -> tg_pt_gp_valid_id ); <nl> return - EINVAL ; <nl> } <nl> + if (!( dev -> dev_flags & DF_CONFIGURED )) { <nl> + pr_err (" Unable to set alua_access_state while device is " <nl> + " not configured \ n "); <nl> + return - ENODEV ; <nl> + } <nl>  <nl> ret = kstrtoul ( page , 0 , & tmp ); <nl> if ( ret < 0 ) {
mmm fs / namei . c <nl> ppp fs / namei . c <nl> static struct file * path_openat ( int dfd , struct filename * pathname , <nl>  <nl> if ( unlikely ( file -> f_flags & __O_TMPFILE )) { <nl> error = do_tmpfile ( dfd , pathname , nd , flags , op , file , & opened ); <nl> - goto out ; <nl> + goto out2 ; <nl> } <nl>  <nl> error = path_init ( dfd , pathname , flags , nd ); <nl> static struct file * path_openat ( int dfd , struct filename * pathname , <nl> } <nl> out : <nl> path_cleanup ( nd ); <nl> + out2 : <nl> if (!( opened & FILE_OPENED )) { <nl> BUG_ON (! error ); <nl> put_filp ( file );
mmm drivers / crypto / chelsio / chtls / chtls_main . c <nl> ppp drivers / crypto / chelsio / chtls / chtls_main . c <nl> static int do_chtls_setsockopt ( struct sock * sk , int optname , <nl>  <nl> switch ( tmp_crypto_info . cipher_type ) { <nl> case TLS_CIPHER_AES_GCM_128 : { <nl> - rc = copy_from_user ( crypto_info , optval , <nl> - sizeof ( struct <nl> - tls12_crypto_info_aes_gcm_128 )); <nl> + /* Obtain version and type from previous copy */ <nl> + crypto_info [ 0 ] = tmp_crypto_info ; <nl> + /* Now copy the following data */ <nl> + rc = copy_from_user (( char *) crypto_info + sizeof (* crypto_info ), <nl> + optval + sizeof (* crypto_info ), <nl> + sizeof ( struct tls12_crypto_info_aes_gcm_128 ) <nl> + - sizeof (* crypto_info )); <nl>  <nl> if ( rc ) { <nl> rc = - EFAULT ;
mmm drivers / net / pcnet32 . c <nl> ppp drivers / net / pcnet32 . c <nl> static int pcnet32_phys_id ( struct net_device * dev , u32 data ) <nl> if ((! data ) || ( data > ( u32 )( MAX_SCHEDULE_TIMEOUT / HZ ))) <nl> data = ( u32 )( MAX_SCHEDULE_TIMEOUT / HZ ); <nl>  <nl> - schedule_timeout ( data * HZ ); <nl> + msleep_interruptible ( data * 1000 ); <nl> del_timer_sync (& lp -> blink_timer ); <nl>  <nl> /* Restore the original value of the bcrs */
mmm arch / x86 / kvm / x86 . c <nl> ppp arch / x86 / kvm / x86 . c <nl> int kvm_arch_vcpu_init ( struct kvm_vcpu * vcpu ) <nl> } <nl> vcpu -> arch . mcg_cap = KVM_MAX_MCE_BANKS ; <nl>  <nl> - if (! zalloc_cpumask_var (& vcpu -> arch . wbinvd_dirty_mask , GFP_KERNEL )) <nl> + if (! zalloc_cpumask_var (& vcpu -> arch . wbinvd_dirty_mask , GFP_KERNEL )) { <nl> + r = - ENOMEM ; <nl> goto fail_free_mce_banks ; <nl> + } <nl>  <nl> r = fx_init ( vcpu ); <nl> if ( r )
mmm fs / nfs / flexfilelayout / flexfilelayoutdev . c <nl> ppp fs / nfs / flexfilelayout / flexfilelayoutdev . c <nl> static bool ff_layout_mirror_valid ( struct pnfs_layout_segment * lseg , <nl> } else <nl> goto outerr ; <nl> } <nl> + <nl> + if ( IS_ERR ( mirror -> mirror_ds )) <nl> + goto outerr ; <nl> + <nl> if ( mirror -> mirror_ds -> ds == NULL ) { <nl> struct nfs4_deviceid_node * devid ; <nl> devid = & mirror -> mirror_ds -> id_node ;
mmm drivers / hwmon / scmi - hwmon . c <nl> ppp drivers / hwmon / scmi - hwmon . c <nl> static int scmi_hwmon_probe ( struct scmi_device * sdev ) <nl> scmi_chip_info . info = ptr_scmi_ci ; <nl> chip_info = & scmi_chip_info ; <nl>  <nl> - for ( type = 0 ; type < hwmon_max && nr_count [ type ]; type ++) { <nl> + for ( type = 0 ; type < hwmon_max ; type ++) { <nl> + if (! nr_count [ type ]) <nl> + continue ; <nl> + <nl> scmi_hwmon_add_chan_info ( scmi_hwmon_chan , dev , nr_count [ type ], <nl> type , hwmon_attributes [ type ]); <nl> * ptr_scmi_ci ++ = scmi_hwmon_chan ++;
mmm drivers / media / usb / dvb - usb / gp8psk . c <nl> ppp drivers / media / usb / dvb - usb / gp8psk . c <nl> int gp8psk_usb_in_op ( struct dvb_usb_device * d , u8 req , u16 value , u16 index , u8 <nl> struct gp8psk_state * st = d -> priv ; <nl> int ret = 0 , try = 0 ; <nl>  <nl> + if ( blen > sizeof ( st -> data )) <nl> + return - EIO ; <nl> + <nl> if (( ret = mutex_lock_interruptible (& d -> usb_mutex ))) <nl> return ret ; <nl>  <nl> int gp8psk_usb_out_op ( struct dvb_usb_device * d , u8 req , u16 value , <nl> deb_xfer (" out : req . % x , val : % x , ind : % x , buffer : ", req , value , index ); <nl> debug_dump ( b , blen , deb_xfer ); <nl>  <nl> + if ( blen > sizeof ( st -> data )) <nl> + return - EIO ; <nl> + <nl> if (( ret = mutex_lock_interruptible (& d -> usb_mutex ))) <nl> return ret ; <nl>  <nl> static int gp8psk_load_bcm4500fw ( struct dvb_usb_device * d ) <nl> err (" failed to load bcm4500 firmware ."); <nl> goto out_free ; <nl> } <nl> + if ( buflen > 64 ) { <nl> + err (" firmare chunk size bigger than 64 bytes ."); <nl> + goto out_free ; <nl> + } <nl> + <nl> memcpy ( buf , ptr , buflen ); <nl> if ( dvb_usb_generic_write ( d , buf , buflen )) { <nl> err (" failed to load bcm4500 firmware .");
mmm arch / x86 / kvm / vmx . c <nl> ppp arch / x86 / kvm / vmx . c <nl> static int check_vmentry_postreqs ( struct kvm_vcpu * vcpu , struct vmcs12 * vmcs12 , <nl> return 1 ; <nl> } <nl>  <nl> + if (( vmcs12 -> vm_entry_controls & VM_ENTRY_LOAD_BNDCFGS ) && <nl> + ( is_noncanonical_address ( vmcs12 -> guest_bndcfgs & PAGE_MASK , vcpu ) || <nl> + ( vmcs12 -> guest_bndcfgs & MSR_IA32_BNDCFGS_RSVD ))) <nl> + return 1 ; <nl> + <nl> return 0 ; <nl> } <nl> 
mmm drivers / scsi / aha1542 . c <nl> ppp drivers / scsi / aha1542 . c <nl> static void setup_mailboxes ( int base_io , struct Scsi_Host * shpnt ); <nl> static int aha1542_restart ( struct Scsi_Host * shost ); <nl> static void aha1542_intr_handle ( struct Scsi_Host * shost ); <nl>  <nl> -# define aha1542_intr_reset ( base ) outb ( IRST , CONTROL ( base )) <nl> + static inline void aha1542_intr_reset ( u16 base ) <nl> +{ <nl> + outb ( IRST , CONTROL ( base )); <nl> +} <nl>  <nl> # define WAIT ( port , mask , allof , noneof ) \ <nl> { register int WAITbits ; \
mmm fs / xfs / xfs_itable . c <nl> ppp fs / xfs / xfs_itable . c <nl> xfs_inumbers ( <nl> return error ; <nl>  <nl> bcount = MIN ( left , ( int )( PAGE_SIZE / sizeof (* buffer ))); <nl> - buffer = kmem_alloc ( bcount * sizeof (* buffer ), KM_SLEEP ); <nl> + buffer = kmem_zalloc ( bcount * sizeof (* buffer ), KM_SLEEP ); <nl> do { <nl> struct xfs_inobt_rec_incore r ; <nl> int stat ;
mmm tools / perf / util / intel - pt - decoder / intel - pt - insn - decoder . c <nl> ppp tools / perf / util / intel - pt - decoder / intel - pt - insn - decoder . c <nl> static void intel_pt_insn_decoder ( struct insn * insn , <nl> enum intel_pt_insn_branch branch = INTEL_PT_BR_NO_BRANCH ; <nl> int ext ; <nl>  <nl> + intel_pt_insn -> rel = 0 ; <nl> + <nl> if ( insn_is_avx ( insn )) { <nl> intel_pt_insn -> op = INTEL_PT_OP_OTHER ; <nl> intel_pt_insn -> branch = INTEL_PT_BR_NO_BRANCH ;
mmm mm / backing - dev . c <nl> ppp mm / backing - dev . c <nl> int bdi_register ( struct backing_dev_info * bdi , struct device * parent , <nl> int ret = 0 ; <nl> struct device * dev ; <nl>  <nl> + if ( WARN_ON ( bdi -> dev )) <nl> + goto exit ; <nl> + <nl> va_start ( args , fmt ); <nl> dev = device_create_vargs ( bdi_class , parent , MKDEV ( 0 , 0 ), bdi , fmt , args ); <nl> va_end ( args );
mmm drivers / gpu / drm / i915 / intel_atomic . c <nl> ppp drivers / gpu / drm / i915 / intel_atomic . c <nl> int intel_atomic_check ( struct drm_device * dev , <nl> state -> allow_modeset = false ; <nl> for ( i = 0 ; i < ncrtcs ; i ++) { <nl> struct intel_crtc * crtc = to_intel_crtc ( state -> crtcs [ i ]); <nl> + if ( crtc ) <nl> + memset (& crtc -> atomic , 0 , sizeof ( crtc -> atomic )); <nl> if ( crtc && crtc -> pipe != nuclear_pipe ) <nl> not_nuclear = true ; <nl> }
mmm drivers / char / cyclades . c <nl> ppp drivers / char / cyclades . c <nl> static irqreturn_t cyy_interrupt ( int irq , void * dev_id ) <nl> card_base_addr = cinfo -> base_addr ; <nl> index = cinfo -> bus_index ; <nl>  <nl> + /* card was not initialized yet ( e . g . DEBUG_SHIRQ ) */ <nl> + if ( unlikely ( card_base_addr == NULL )) <nl> + return IRQ_HANDLED ; <nl> + <nl> /* This loop checks all chips in the card . Make a note whenever <nl> _any_ chip had some work to do , as this is considered an <nl> indication that there will be more to do . Only when no chip
mmm drivers / gpu / drm / i915 / intel_pm . c <nl> ppp drivers / gpu / drm / i915 / intel_pm . c <nl> static int ilk_compute_pipe_wm ( struct intel_crtc * intel_crtc , <nl> return PTR_ERR ( cstate ); <nl>  <nl> pipe_wm = & cstate -> wm . optimal . ilk ; <nl> + memset ( pipe_wm , 0 , sizeof (* pipe_wm )); <nl>  <nl> for_each_intel_plane_on_crtc ( dev , intel_crtc , intel_plane ) { <nl> ps = drm_atomic_get_plane_state ( state ,
mmm include / linux / init_task . h <nl> ppp include / linux / init_task . h <nl> extern struct group_info init_groups ; <nl> # define INIT_STRUCT_PID { \ <nl> . count = ATOMIC_INIT ( 1 ), \ <nl> . tasks = { \ <nl> - { . first = & init_task . pids [ PIDTYPE_PID ]. node }, \ <nl> - { . first = & init_task . pids [ PIDTYPE_PGID ]. node }, \ <nl> - { . first = & init_task . pids [ PIDTYPE_SID ]. node }, \ <nl> + { . first = NULL }, \ <nl> + { . first = NULL }, \ <nl> + { . first = NULL }, \ <nl> }, \ <nl> . level = 0 , \ <nl> . numbers = { { \ <nl> extern struct group_info init_groups ; <nl> { \ <nl> . node = { \ <nl> . next = NULL , \ <nl> - . pprev = & init_struct_pid . tasks [ type ]. first , \ <nl> + . pprev = NULL , \ <nl> }, \ <nl> . pid = & init_struct_pid , \ <nl> }
mmm sound / soc / fsl / mpc5200_psc_i2s . c <nl> ppp sound / soc / fsl / mpc5200_psc_i2s . c <nl> static struct snd_soc_dai_driver psc_i2s_dai [] = {{ <nl> . ops = & psc_i2s_dai_ops , <nl> } }; <nl>  <nl> + static const struct snd_soc_component_driver psc_i2s_component = { <nl> + . name = " mpc5200 - i2s ", <nl> +}; <nl> + <nl> /* --------------------------------------------------------------------- <nl> * OF platform bus binding code : <nl> * - Probe / remove operations <nl> static int psc_i2s_of_probe ( struct platform_device * op ) <nl> if ( rc != 0 ) <nl> return rc ; <nl>  <nl> - rc = snd_soc_register_dais (& op -> dev , psc_i2s_dai , ARRAY_SIZE ( psc_i2s_dai )); <nl> + rc = snd_soc_register_component (& op -> dev , & psc_i2s_component , <nl> + psc_i2s_dai , ARRAY_SIZE ( psc_i2s_dai )); <nl> if ( rc != 0 ) { <nl> pr_err (" Failed to register DAI \ n "); <nl> return rc ; <nl> static int psc_i2s_of_probe ( struct platform_device * op ) <nl> static int psc_i2s_of_remove ( struct platform_device * op ) <nl> { <nl> mpc5200_audio_dma_destroy ( op ); <nl> - snd_soc_unregister_dais (& op -> dev , ARRAY_SIZE ( psc_i2s_dai )); <nl> + snd_soc_unregister_component (& op -> dev ); <nl> return 0 ; <nl> } <nl> 
mmm drivers / mmc / host / mxcmmc . c <nl> ppp drivers / mmc / host / mxcmmc . c <nl> static int mxcmci_probe ( struct platform_device * pdev ) <nl>  <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> irq = platform_get_irq ( pdev , 0 ); <nl> - if ( irq < 0 ) <nl> - return - EINVAL ; <nl> + if ( irq < 0 ) { <nl> + dev_err (& pdev -> dev , " failed to get IRQ : % d \ n ", irq ); <nl> + return irq ; <nl> + } <nl>  <nl> mmc = mmc_alloc_host ( sizeof (* host ), & pdev -> dev ); <nl> if (! mmc )
mmm drivers / char / random . c <nl> ppp drivers / char / random . c <nl> void add_interrupt_randomness ( int irq , int irq_flags ) <nl>  <nl> fast_mix ( fast_pool ); <nl> add_interrupt_bench ( cycles ); <nl> + this_cpu_add ( net_rand_state . s1 , fast_pool -> pool [ cycles & 3 ]); <nl>  <nl> if ( unlikely ( crng_init == 0 )) { <nl> if (( fast_pool -> count >= 64 ) &&mmm include / linux / random . h <nl> ppp include / linux / random . h <nl> void add_interrupt_randomness ( int irq , int irq_flags ) <nl>  <nl> fast_mix ( fast_pool ); <nl> add_interrupt_bench ( cycles ); <nl> + this_cpu_add ( net_rand_state . s1 , fast_pool -> pool [ cycles & 3 ]); <nl>  <nl> if ( unlikely ( crng_init == 0 )) { <nl> if (( fast_pool -> count >= 64 ) && <nl> # include < linux / kernel . h > <nl> # include < linux / list . h > <nl> # include < linux / once . h > <nl> +# include < linux / percpu . h > <nl>  <nl> # include < uapi / linux / random . h > <nl>  <nl> struct rnd_state { <nl> __u32 s1 , s2 , s3 , s4 ; <nl> }; <nl>  <nl> + DECLARE_PER_CPU ( struct rnd_state , net_rand_state ) __latent_entropy ; <nl> + <nl> u32 prandom_u32_state ( struct rnd_state * state ); <nl> void prandom_bytes_state ( struct rnd_state * state , void * buf , size_t nbytes ); <nl> void prandom_seed_full_state ( struct rnd_state __percpu * pcpu_state );mmm kernel / time / timer . c <nl> ppp kernel / time / timer . c <nl> void add_interrupt_randomness ( int irq , int irq_flags ) <nl>  <nl> fast_mix ( fast_pool ); <nl> add_interrupt_bench ( cycles ); <nl> + this_cpu_add ( net_rand_state . s1 , fast_pool -> pool [ cycles & 3 ]); <nl>  <nl> if ( unlikely ( crng_init == 0 )) { <nl> if (( fast_pool -> count >= 64 ) && <nl> # include < linux / kernel . h > <nl> # include < linux / list . h > <nl> # include < linux / once . h > <nl> +# include < linux / percpu . h > <nl>  <nl> # include < uapi / linux / random . h > <nl>  <nl> struct rnd_state { <nl> __u32 s1 , s2 , s3 , s4 ; <nl> }; <nl>  <nl> + DECLARE_PER_CPU ( struct rnd_state , net_rand_state ) __latent_entropy ; <nl> + <nl> u32 prandom_u32_state ( struct rnd_state * state ); <nl> void prandom_bytes_state ( struct rnd_state * state , void * buf , size_t nbytes ); <nl> void prandom_seed_full_state ( struct rnd_state __percpu * pcpu_state ); <nl> # include < linux / sched / debug . h > <nl> # include < linux / slab . h > <nl> # include < linux / compat . h > <nl> +# include < linux / random . h > <nl>  <nl> # include < linux / uaccess . h > <nl> # include < asm / unistd . h > <nl> void update_process_times ( int user_tick ) <nl> scheduler_tick (); <nl> if ( IS_ENABLED ( CONFIG_POSIX_TIMERS )) <nl> run_posix_cpu_timers (); <nl> + <nl> + /* The current CPU might make use of net randoms without receiving IRQs <nl> + * to renew them often enough . Let ' s update the net_rand_state from a <nl> + * non - constant value that ' s not affine to the number of calls to make <nl> + * sure it ' s updated when there ' s some activity ( we don ' t care in idle ). <nl> + */ <nl> + this_cpu_add ( net_rand_state . s1 , rol32 ( jiffies , 24 ) + user_tick ); <nl> } <nl>  <nl> /**mmm lib / random32 . c <nl> ppp lib / random32 . c <nl> void add_interrupt_randomness ( int irq , int irq_flags ) <nl>  <nl> fast_mix ( fast_pool ); <nl> add_interrupt_bench ( cycles ); <nl> + this_cpu_add ( net_rand_state . s1 , fast_pool -> pool [ cycles & 3 ]); <nl>  <nl> if ( unlikely ( crng_init == 0 )) { <nl> if (( fast_pool -> count >= 64 ) && <nl> # include < linux / kernel . h > <nl> # include < linux / list . h > <nl> # include < linux / once . h > <nl> +# include < linux / percpu . h > <nl>  <nl> # include < uapi / linux / random . h > <nl>  <nl> struct rnd_state { <nl> __u32 s1 , s2 , s3 , s4 ; <nl> }; <nl>  <nl> + DECLARE_PER_CPU ( struct rnd_state , net_rand_state ) __latent_entropy ; <nl> + <nl> u32 prandom_u32_state ( struct rnd_state * state ); <nl> void prandom_bytes_state ( struct rnd_state * state , void * buf , size_t nbytes ); <nl> void prandom_seed_full_state ( struct rnd_state __percpu * pcpu_state ); <nl> # include < linux / sched / debug . h > <nl> # include < linux / slab . h > <nl> # include < linux / compat . h > <nl> +# include < linux / random . h > <nl>  <nl> # include < linux / uaccess . h > <nl> # include < asm / unistd . h > <nl> void update_process_times ( int user_tick ) <nl> scheduler_tick (); <nl> if ( IS_ENABLED ( CONFIG_POSIX_TIMERS )) <nl> run_posix_cpu_timers (); <nl> + <nl> + /* The current CPU might make use of net randoms without receiving IRQs <nl> + * to renew them often enough . Let ' s update the net_rand_state from a <nl> + * non - constant value that ' s not affine to the number of calls to make <nl> + * sure it ' s updated when there ' s some activity ( we don ' t care in idle ). <nl> + */ <nl> + this_cpu_add ( net_rand_state . s1 , rol32 ( jiffies , 24 ) + user_tick ); <nl> } <nl>  <nl> /** <nl> static inline void prandom_state_selftest ( void ) <nl> } <nl> # endif <nl>  <nl> - static DEFINE_PER_CPU ( struct rnd_state , net_rand_state ) __latent_entropy ; <nl> + DEFINE_PER_CPU ( struct rnd_state , net_rand_state ) __latent_entropy ; <nl>  <nl> /** <nl> * prandom_u32_state - seeded pseudo - random number generator .
mmm drivers / pci / hotplug / pciehp_hpc . c <nl> ppp drivers / pci / hotplug / pciehp_hpc . c <nl> static void pcie_disable_notification ( struct controller * ctrl ) <nl> u16 mask ; <nl> mask = ( PCI_EXP_SLTCTL_PDCE | PCI_EXP_SLTCTL_ABPE | <nl> PCI_EXP_SLTCTL_MRLSCE | PCI_EXP_SLTCTL_PFDE | <nl> - PCI_EXP_SLTCTL_HPIE | PCI_EXP_SLTCTL_CCIE ); <nl> + PCI_EXP_SLTCTL_HPIE | PCI_EXP_SLTCTL_CCIE | <nl> + PCI_EXP_SLTCTL_DLLSCE ); <nl> if ( pcie_write_cmd ( ctrl , 0 , mask )) <nl> ctrl_warn ( ctrl , " Cannot disable software notification \ n "); <nl> }
mmm kernel / sched / fair . c <nl> ppp kernel / sched / fair . c <nl> ___update_load_avg ( u64 now , int cpu , struct sched_avg * sa , <nl>  <nl> sa -> last_update_time += delta << 10 ; <nl>  <nl> + /* <nl> + * running is a subset of runnable ( weight ) so running can ' t be set if <nl> + * runnable is clear . But there are some corner cases where the current <nl> + * se has been already dequeued but cfs_rq -> curr still points to it . <nl> + * This means that weight will be 0 but not running for a sched_entity <nl> + * but also for a cfs_rq if the latter becomes idle . As an example , <nl> + * this happens during idle_balance () which calls <nl> + * update_blocked_averages () <nl> + */ <nl> + if (! weight ) <nl> + running = 0 ; <nl> + <nl> /* <nl> * Now we know we crossed measurement unit boundaries . The * _avg <nl> * accrues by two steps :
mmm drivers / platform / x86 / acer - wmi . c <nl> ppp drivers / platform / x86 / acer - wmi . c <nl> static acpi_status WMID_set_capabilities ( void ) <nl> devices = *(( u32 *) obj -> buffer . pointer ); <nl> } else if ( obj -> type == ACPI_TYPE_INTEGER ) { <nl> devices = ( u32 ) obj -> integer . value ; <nl> + } else { <nl> + kfree ( out . pointer ); <nl> + return AE_ERROR ; <nl> } <nl> } else { <nl> kfree ( out . pointer );
mmm include / linux / hid . h <nl> ppp include / linux / hid . h <nl> struct hid_collection { <nl> struct hid_usage { <nl> unsigned hid ; /* hid usage code */ <nl> unsigned collection_index ; /* index into collection array */ <nl> + unsigned usage_index ; /* index into usage array */ <nl> /* hidinput data */ <nl> __u16 code ; /* input driver code */ <nl> __u8 type ; /* input driver type */mmm drivers / hid / hid - core . c <nl> ppp drivers / hid / hid - core . c <nl> struct hid_collection { <nl> struct hid_usage { <nl> unsigned hid ; /* hid usage code */ <nl> unsigned collection_index ; /* index into collection array */ <nl> + unsigned usage_index ; /* index into usage array */ <nl> /* hidinput data */ <nl> __u16 code ; /* input driver code */ <nl> __u8 type ; /* input driver type */ <nl> EXPORT_SYMBOL_GPL ( hid_register_report ); <nl> static struct hid_field * hid_register_field ( struct hid_report * report , unsigned usages , unsigned values ) <nl> { <nl> struct hid_field * field ; <nl> + int i ; <nl>  <nl> if ( report -> maxfield == HID_MAX_FIELDS ) { <nl> hid_err ( report -> device , " too many fields in report \ n "); <nl> static struct hid_field * hid_register_field ( struct hid_report * report , unsigned <nl> field -> value = ( s32 *)( field -> usage + usages ); <nl> field -> report = report ; <nl>  <nl> + for ( i = 0 ; i < usages ; i ++) <nl> + field -> usage [ i ]. usage_index = i ; <nl> + <nl> return field ; <nl> } <nl> 
mmm fs / exec . c <nl> ppp fs / exec . c <nl> static int __bprm_mm_init ( struct linux_binprm * bprm ) <nl> if (! vma ) <nl> return - ENOMEM ; <nl>  <nl> - down_write (& mm -> mmap_sem ); <nl> + if ( down_write_killable (& mm -> mmap_sem )) { <nl> + err = - EINTR ; <nl> + goto err_free ; <nl> + } <nl> vma -> vm_mm = mm ; <nl>  <nl> /* <nl> static int __bprm_mm_init ( struct linux_binprm * bprm ) <nl> return 0 ; <nl> err : <nl> up_write (& mm -> mmap_sem ); <nl> + err_free : <nl> bprm -> vma = NULL ; <nl> kmem_cache_free ( vm_area_cachep , vma ); <nl> return err ; <nl> int setup_arg_pages ( struct linux_binprm * bprm , <nl> bprm -> loader -= stack_shift ; <nl> bprm -> exec -= stack_shift ; <nl>  <nl> - down_write (& mm -> mmap_sem ); <nl> + if ( down_write_killable (& mm -> mmap_sem )) <nl> + return - EINTR ; <nl> + <nl> vm_flags = VM_STACK_FLAGS ; <nl>  <nl> /*
mmm drivers / gpu / drm / i915 / i915_drv . h <nl> ppp drivers / gpu / drm / i915 / i915_drv . h <nl> struct drm_i915_file_private { <nl>  <nl> # define HAS_FORCE_WAKE ( dev ) ( INTEL_INFO ( dev )-> has_force_wake ) <nl>  <nl> -# define HAS_L3_GPU_CACHE ( dev ) ( IS_IVYBRIDGE ( dev )) <nl> +# define HAS_L3_GPU_CACHE ( dev ) ( IS_IVYBRIDGE ( dev ) || IS_HASWELL ( dev )) <nl>  <nl> # include " i915_trace . h " <nl> 
mmm net / sctp / sm_statefuns . c <nl> ppp net / sctp / sm_statefuns . c <nl> sctp_disposition_t sctp_sf_do_5_2_4_dupcook ( struct net * net , <nl> } <nl>  <nl> /* Delete the tempory new association . */ <nl> - sctp_add_cmd_sf ( commands , SCTP_CMD_NEW_ASOC , SCTP_ASOC ( new_asoc )); <nl> + sctp_add_cmd_sf ( commands , SCTP_CMD_SET_ASOC , SCTP_ASOC ( new_asoc )); <nl> sctp_add_cmd_sf ( commands , SCTP_CMD_DELETE_TCB , SCTP_NULL ()); <nl>  <nl> /* Restore association pointer to provide SCTP command interpeter
mmm drivers / gpu / drm / msm / msm_gem . c <nl> ppp drivers / gpu / drm / msm / msm_gem . c <nl> void msm_gem_free_object ( struct drm_gem_object * obj ) <nl> if ( msm_obj -> pages ) <nl> drm_free_large ( msm_obj -> pages ); <nl>  <nl> + drm_prime_gem_destroy ( obj , msm_obj -> sgt ); <nl> } else { <nl> vunmap ( msm_obj -> vaddr ); <nl> put_pages ( obj );
mmm drivers / media / video / em28xx / em28xx - video . c <nl> ppp drivers / media / video / em28xx / em28xx - video . c <nl> static int em28xx_init_dev ( struct em28xx ** devhandle , struct usb_device * udev , <nl>  <nl> dev -> udev = udev ; <nl> mutex_init (& dev -> lock ); <nl> + mutex_init (& dev -> ctrl_urb_lock ); <nl> spin_lock_init (& dev -> slock ); <nl> init_waitqueue_head (& dev -> open ); <nl> init_waitqueue_head (& dev -> wait_frame );mmm drivers / media / video / em28xx / em28xx - core . c <nl> ppp drivers / media / video / em28xx / em28xx - core . c <nl> static int em28xx_init_dev ( struct em28xx ** devhandle , struct usb_device * udev , <nl>  <nl> dev -> udev = udev ; <nl> mutex_init (& dev -> lock ); <nl> + mutex_init (& dev -> ctrl_urb_lock ); <nl> spin_lock_init (& dev -> slock ); <nl> init_waitqueue_head (& dev -> open ); <nl> init_waitqueue_head (& dev -> wait_frame ); <nl> int em28xx_read_reg_req_len ( struct em28xx * dev , u8 req , u16 reg , <nl>  <nl> em28xx_regdbg (" req =% 02x , reg =% 02x ", req , reg ); <nl>  <nl> + mutex_lock (& dev -> ctrl_urb_lock ); <nl> ret = usb_control_msg ( dev -> udev , usb_rcvctrlpipe ( dev -> udev , 0 ), req , <nl> USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE , <nl> 0x0000 , reg , dev -> urb_buf , len , HZ ); <nl> if ( ret < 0 ) { <nl> if ( reg_debug ) <nl> printk (" failed !\ n "); <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl> return ret ; <nl> } <nl>  <nl> if ( len ) <nl> memcpy ( buf , dev -> urb_buf , len ); <nl>  <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl> + <nl> if ( reg_debug ) { <nl> printk ("% 02x values : ", ret ); <nl> for ( byte = 0 ; byte < len ; byte ++) <nl> int em28xx_read_reg_req ( struct em28xx * dev , u8 req , u16 reg ) <nl>  <nl> em28xx_regdbg (" req =% 02x , reg =% 02x :", req , reg ); <nl>  <nl> + mutex_lock (& dev -> ctrl_urb_lock ); <nl> ret = usb_control_msg ( dev -> udev , usb_rcvctrlpipe ( dev -> udev , 0 ), req , <nl> USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE , <nl> 0x0000 , reg , dev -> urb_buf , 1 , HZ ); <nl> + val = dev -> urb_buf [ 0 ]; <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl> + <nl> if ( ret < 0 ) { <nl> printk (" failed !\ n "); <nl> return ret ; <nl> } <nl>  <nl> - val = dev -> urb_buf [ 0 ]; <nl> - <nl> if ( reg_debug ) <nl> printk ("% 02x \ n ", ( unsigned char ) val ); <nl>  <nl> int em28xx_write_regs_req ( struct em28xx * dev , u8 req , u16 reg , char * buf , <nl> printk ("\ n "); <nl> } <nl>  <nl> + mutex_lock (& dev -> ctrl_urb_lock ); <nl> memcpy ( dev -> urb_buf , buf , len ); <nl> ret = usb_control_msg ( dev -> udev , usb_sndctrlpipe ( dev -> udev , 0 ), req , <nl> USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE , <nl> 0x0000 , reg , dev -> urb_buf , len , HZ ); <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl>  <nl> if ( dev -> wait_after_write ) <nl> msleep ( dev -> wait_after_write );mmm drivers / media / video / em28xx / em28xx . h <nl> ppp drivers / media / video / em28xx / em28xx . h <nl> static int em28xx_init_dev ( struct em28xx ** devhandle , struct usb_device * udev , <nl>  <nl> dev -> udev = udev ; <nl> mutex_init (& dev -> lock ); <nl> + mutex_init (& dev -> ctrl_urb_lock ); <nl> spin_lock_init (& dev -> slock ); <nl> init_waitqueue_head (& dev -> open ); <nl> init_waitqueue_head (& dev -> wait_frame ); <nl> int em28xx_read_reg_req_len ( struct em28xx * dev , u8 req , u16 reg , <nl>  <nl> em28xx_regdbg (" req =% 02x , reg =% 02x ", req , reg ); <nl>  <nl> + mutex_lock (& dev -> ctrl_urb_lock ); <nl> ret = usb_control_msg ( dev -> udev , usb_rcvctrlpipe ( dev -> udev , 0 ), req , <nl> USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE , <nl> 0x0000 , reg , dev -> urb_buf , len , HZ ); <nl> if ( ret < 0 ) { <nl> if ( reg_debug ) <nl> printk (" failed !\ n "); <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl> return ret ; <nl> } <nl>  <nl> if ( len ) <nl> memcpy ( buf , dev -> urb_buf , len ); <nl>  <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl> + <nl> if ( reg_debug ) { <nl> printk ("% 02x values : ", ret ); <nl> for ( byte = 0 ; byte < len ; byte ++) <nl> int em28xx_read_reg_req ( struct em28xx * dev , u8 req , u16 reg ) <nl>  <nl> em28xx_regdbg (" req =% 02x , reg =% 02x :", req , reg ); <nl>  <nl> + mutex_lock (& dev -> ctrl_urb_lock ); <nl> ret = usb_control_msg ( dev -> udev , usb_rcvctrlpipe ( dev -> udev , 0 ), req , <nl> USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE , <nl> 0x0000 , reg , dev -> urb_buf , 1 , HZ ); <nl> + val = dev -> urb_buf [ 0 ]; <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl> + <nl> if ( ret < 0 ) { <nl> printk (" failed !\ n "); <nl> return ret ; <nl> } <nl>  <nl> - val = dev -> urb_buf [ 0 ]; <nl> - <nl> if ( reg_debug ) <nl> printk ("% 02x \ n ", ( unsigned char ) val ); <nl>  <nl> int em28xx_write_regs_req ( struct em28xx * dev , u8 req , u16 reg , char * buf , <nl> printk ("\ n "); <nl> } <nl>  <nl> + mutex_lock (& dev -> ctrl_urb_lock ); <nl> memcpy ( dev -> urb_buf , buf , len ); <nl> ret = usb_control_msg ( dev -> udev , usb_sndctrlpipe ( dev -> udev , 0 ), req , <nl> USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE , <nl> 0x0000 , reg , dev -> urb_buf , len , HZ ); <nl> + mutex_unlock (& dev -> ctrl_urb_lock ); <nl>  <nl> if ( dev -> wait_after_write ) <nl> msleep ( dev -> wait_after_write ); <nl> struct em28xx { <nl>  <nl> /* locks */ <nl> struct mutex lock ; <nl> + struct mutex ctrl_urb_lock ; /* protects urb_buf */ <nl> /* spinlock_t queue_lock ; */ <nl> struct list_head inqueue , outqueue ; <nl> wait_queue_head_t open , wait_frame , wait_stream ;
mmm sound / soc / codecs / arizona . c <nl> ppp sound / soc / codecs / arizona . c <nl> int arizona_set_sysclk ( struct snd_soc_codec * codec , int clk_id , <nl> case 147456000 : <nl> val |= 6 << ARIZONA_SYSCLK_FREQ_SHIFT ; <nl> break ; <nl> + case 0 : <nl> + dev_dbg ( arizona -> dev , "% s cleared \ n ", name ); <nl> + * clk = freq ; <nl> + return 0 ; <nl> default : <nl> return - EINVAL ; <nl> } <nl> static int arizona_startup ( struct snd_pcm_substream * substream , <nl> return 0 ; <nl> } <nl>  <nl> + if ( base_rate == 0 ) <nl> + return 0 ; <nl> + <nl> if ( base_rate % 8000 ) <nl> constraint = & arizona_44k1_constraint ; <nl> else
mmm drivers / infiniband / hw / mlx4 / cm . c <nl> ppp drivers / infiniband / hw / mlx4 / cm . c <nl> static struct id_map_entry * <nl> id_map_alloc ( struct ib_device * ibdev , int slave_id , u32 sl_cm_id ) <nl> { <nl> int ret ; <nl> - static int next_id ; <nl> struct id_map_entry * ent ; <nl> struct mlx4_ib_sriov * sriov = & to_mdev ( ibdev )-> sriov ; <nl>  <nl> id_map_alloc ( struct ib_device * ibdev , int slave_id , u32 sl_cm_id ) <nl> idr_preload ( GFP_KERNEL ); <nl> spin_lock (& to_mdev ( ibdev )-> sriov . id_map_lock ); <nl>  <nl> - ret = idr_alloc (& sriov -> pv_id_table , ent , next_id , 0 , GFP_NOWAIT ); <nl> + ret = idr_alloc_cyclic (& sriov -> pv_id_table , ent , 0 , 0 , GFP_NOWAIT ); <nl> if ( ret >= 0 ) { <nl> - next_id = max ( ret + 1 , 0 ); <nl> ent -> pv_cm_id = ( u32 ) ret ; <nl> sl_id_map_add ( ibdev , ent ); <nl> list_add_tail (& ent -> list , & sriov -> cm_list );
mmm drivers / media / usb / ttusb - dec / ttusbdecfe . c <nl> ppp drivers / media / usb / ttusb - dec / ttusbdecfe . c <nl> static int ttusbdecfe_dvbs_diseqc_send_master_cmd ( struct dvb_frontend * fe , struc <nl> 0x00 , 0x00 , 0x00 , 0x00 , <nl> 0x00 , 0x00 }; <nl>  <nl> + if ( cmd -> msg_len > sizeof ( b ) - 4 ) <nl> + return - EINVAL ; <nl> + <nl> memcpy (& b [ 4 ], cmd -> msg , cmd -> msg_len ); <nl>  <nl> state -> config -> send_command ( fe , 0x72 ,
mmm include / net / cipso_ipv4 . h <nl> ppp include / net / cipso_ipv4 . h <nl> static inline int cipso_v4_validate ( const struct sk_buff * skb , <nl> unsigned char err_offset = 0 ; <nl> u8 opt_len = opt [ 1 ]; <nl> u8 opt_iter ; <nl> + u8 tag_len ; <nl>  <nl> if ( opt_len < 8 ) { <nl> err_offset = 1 ; <nl> static inline int cipso_v4_validate ( const struct sk_buff * skb , <nl> } <nl>  <nl> for ( opt_iter = 6 ; opt_iter < opt_len ;) { <nl> - if ( opt [ opt_iter + 1 ] > ( opt_len - opt_iter )) { <nl> + tag_len = opt [ opt_iter + 1 ]; <nl> + if (( tag_len == 0 ) || ( opt [ opt_iter + 1 ] > ( opt_len - opt_iter ))) { <nl> err_offset = opt_iter + 1 ; <nl> goto out ; <nl> } <nl> - opt_iter += opt [ opt_iter + 1 ]; <nl> + opt_iter += tag_len ; <nl> } <nl>  <nl> out :
mmm net / rds / rdma . c <nl> ppp net / rds / rdma . c <nl> static int __rds_rdma_map ( struct rds_sock * rs , struct rds_get_mr_args * args , <nl> long i ; <nl> int ret ; <nl>  <nl> - if ( rs -> rs_bound_addr == 0 ) { <nl> + if ( rs -> rs_bound_addr == 0 || ! rs -> rs_transport ) { <nl> ret = - ENOTCONN ; /* XXX not a great errno */ <nl> goto out ; <nl> }
mmm drivers / gpu / drm / radeon / kv_dpm . c <nl> ppp drivers / gpu / drm / radeon / kv_dpm . c <nl> void kv_dpm_powergate_uvd ( struct radeon_device * rdev , bool gate ) <nl> pi -> uvd_power_gated = gate ; <nl>  <nl> if ( gate ) { <nl> - uvd_v1_0_stop ( rdev ); <nl> - cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , false ); <nl> + if ( pi -> caps_uvd_pg ) { <nl> + uvd_v1_0_stop ( rdev ); <nl> + cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , false ); <nl> + } <nl> kv_update_uvd_dpm ( rdev , gate ); <nl> if ( pi -> caps_uvd_pg ) <nl> kv_notify_message_to_smu ( rdev , PPSMC_MSG_UVDPowerOFF ); <nl> } else { <nl> - if ( pi -> caps_uvd_pg ) <nl> + if ( pi -> caps_uvd_pg ) { <nl> kv_notify_message_to_smu ( rdev , PPSMC_MSG_UVDPowerON ); <nl> - uvd_v4_2_resume ( rdev ); <nl> - uvd_v1_0_start ( rdev ); <nl> - cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , true ); <nl> + uvd_v4_2_resume ( rdev ); <nl> + uvd_v1_0_start ( rdev ); <nl> + cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , true ); <nl> + } <nl> kv_update_uvd_dpm ( rdev , gate ); <nl> } <nl> }
mmm net / wireless / reg . c <nl> ppp net / wireless / reg . c <nl> struct reg_beacon { <nl> struct ieee80211_channel chan ; <nl> }; <nl>  <nl> + static void reg_todo ( struct work_struct * work ); <nl> + static DECLARE_WORK ( reg_work , reg_todo ); <nl> + <nl> /* We keep a static world regulatory domain in case of the absence of CRDA */ <nl> static const struct ieee80211_regdomain world_regdom = { <nl> . n_reg_rules = 5 , <nl> static void reg_todo ( struct work_struct * work ) <nl> reg_process_pending_beacon_hints (); <nl> } <nl>  <nl> - static DECLARE_WORK ( reg_work , reg_todo ); <nl> - <nl> static void queue_regulatory_request ( struct regulatory_request * request ) <nl> { <nl> if ( isalpha ( request -> alpha2 [ 0 ]))
mmm fs / cifs / cifs_dfs_ref . c <nl> ppp fs / cifs / cifs_dfs_ref . c <nl> char * cifs_compose_mount_options ( const char * sb_mountdata , <nl> * string to the length of the original string to allow for worst case . <nl> */ <nl> md_len = strlen ( sb_mountdata ) + INET6_ADDRSTRLEN ; <nl> - mountdata = kzalloc ( md_len + 1 , GFP_KERNEL ); <nl> + mountdata = kzalloc ( md_len + sizeof (" ip =") + 1 , GFP_KERNEL ); <nl> if ( mountdata == NULL ) { <nl> rc = - ENOMEM ; <nl> goto compose_mount_options_err ;
mmm drivers / lguest / lg . h <nl> ppp drivers / lguest / lg . h <nl> struct lg_cpu { <nl> unsigned long regs_page ; <nl> struct lguest_regs * regs ; <nl>  <nl> + struct lguest_pages * last_pages ; <nl> + <nl> int cpu_pgd ; /* which pgd this cpu is currently using */ <nl>  <nl> /* If a hypercall was asked for , this points to the arguments . */ <nl> struct lguest <nl>  <nl> /* Bitmap of what has changed : see CHANGED_ * above . */ <nl> int changed ; <nl> - struct lguest_pages * last_pages ; <nl>  <nl> struct pgdir pgdirs [ 4 ]; <nl> mmm drivers / lguest / lguest_user . c <nl> ppp drivers / lguest / lguest_user . c <nl> struct lg_cpu { <nl> unsigned long regs_page ; <nl> struct lguest_regs * regs ; <nl>  <nl> + struct lguest_pages * last_pages ; <nl> + <nl> int cpu_pgd ; /* which pgd this cpu is currently using */ <nl>  <nl> /* If a hypercall was asked for , this points to the arguments . */ <nl> struct lguest <nl>  <nl> /* Bitmap of what has changed : see CHANGED_ * above . */ <nl> int changed ; <nl> - struct lguest_pages * last_pages ; <nl>  <nl> struct pgdir pgdirs [ 4 ]; <nl>  <nl> static int lg_cpu_start ( struct lg_cpu * cpu , unsigned id , unsigned long start_ip ) <nl> * reference , it is destroyed before close () is called . */ <nl> cpu -> mm = get_task_mm ( cpu -> tsk ); <nl>  <nl> + /* We remember which CPU ' s pages this Guest used last , for optimization <nl> + * when the same Guest runs on the same CPU twice . */ <nl> + cpu -> last_pages = NULL ; <nl> + <nl> return 0 ; <nl> } <nl>  <nl> static int initialize ( struct file * file , const unsigned long __user * input ) <nl> if ( err ) <nl> goto free_regs ; <nl>  <nl> - /* We remember which CPU ' s pages this Guest used last , for optimization <nl> - * when the same Guest runs on the same CPU twice . */ <nl> - lg -> last_pages = NULL ; <nl> - <nl> /* We keep our " struct lguest " in the file ' s private_data . */ <nl> file -> private_data = lg ; <nl> mmm drivers / lguest / x86 / core . c <nl> ppp drivers / lguest / x86 / core . c <nl> struct lg_cpu { <nl> unsigned long regs_page ; <nl> struct lguest_regs * regs ; <nl>  <nl> + struct lguest_pages * last_pages ; <nl> + <nl> int cpu_pgd ; /* which pgd this cpu is currently using */ <nl>  <nl> /* If a hypercall was asked for , this points to the arguments . */ <nl> struct lguest <nl>  <nl> /* Bitmap of what has changed : see CHANGED_ * above . */ <nl> int changed ; <nl> - struct lguest_pages * last_pages ; <nl>  <nl> struct pgdir pgdirs [ 4 ]; <nl>  <nl> static int lg_cpu_start ( struct lg_cpu * cpu , unsigned id , unsigned long start_ip ) <nl> * reference , it is destroyed before close () is called . */ <nl> cpu -> mm = get_task_mm ( cpu -> tsk ); <nl>  <nl> + /* We remember which CPU ' s pages this Guest used last , for optimization <nl> + * when the same Guest runs on the same CPU twice . */ <nl> + cpu -> last_pages = NULL ; <nl> + <nl> return 0 ; <nl> } <nl>  <nl> static int initialize ( struct file * file , const unsigned long __user * input ) <nl> if ( err ) <nl> goto free_regs ; <nl>  <nl> - /* We remember which CPU ' s pages this Guest used last , for optimization <nl> - * when the same Guest runs on the same CPU twice . */ <nl> - lg -> last_pages = NULL ; <nl> - <nl> /* We keep our " struct lguest " in the file ' s private_data . */ <nl> file -> private_data = lg ; <nl>  <nl> static void copy_in_guest_info ( struct lg_cpu * cpu , struct lguest_pages * pages ) <nl> * same Guest we ran last time ( and that Guest hasn ' t run anywhere else <nl> * meanwhile ). If that ' s not the case , we pretend everything in the <nl> * Guest has changed . */ <nl> - if ( __get_cpu_var ( last_cpu ) != cpu || lg -> last_pages != pages ) { <nl> + if ( __get_cpu_var ( last_cpu ) != cpu || cpu -> last_pages != pages ) { <nl> __get_cpu_var ( last_cpu ) = cpu ; <nl> - lg -> last_pages = pages ; <nl> + cpu -> last_pages = pages ; <nl> lg -> changed = CHANGED_ALL ; <nl> } <nl> 
mmm drivers / block / floppy . c <nl> ppp drivers / block / floppy . c <nl> static void setup_format_params ( int track ) <nl> raw_cmd -> kernel_data = floppy_track_buffer ; <nl> raw_cmd -> length = 4 * F_SECT_PER_TRACK ; <nl>  <nl> + if (! F_SECT_PER_TRACK ) <nl> + return ; <nl> + <nl> /* allow for about 30ms for data transport per track */ <nl> head_shift = ( F_SECT_PER_TRACK + 5 ) / 6 ; <nl>  <nl> static int set_geometry ( unsigned int cmd , struct floppy_struct * g , <nl> /* sanity checking for parameters . */ <nl> if ( g -> sect <= 0 || <nl> g -> head <= 0 || <nl> + /* check for zero in F_SECT_PER_TRACK */ <nl> + ( unsigned char )(( g -> sect << 2 ) >> FD_SIZECODE ( g )) == 0 || <nl> g -> track <= 0 || g -> track > UDP -> tracks >> STRETCH ( g ) || <nl> /* check if reserved bits are set */ <nl> ( g -> stretch & ~( FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK )) != 0 )
mmm drivers / net / ethernet / broadcom / cnic . c <nl> ppp drivers / net / ethernet / broadcom / cnic . c <nl> static int cnic_start_hw ( struct cnic_dev * dev ) <nl> return 0 ; <nl>  <nl> err1 : <nl> - cp -> free_resc ( dev ); <nl> + if ( ethdev -> drv_state & CNIC_DRV_STATE_HANDLES_IRQ ) <nl> + cp -> stop_hw ( dev ); <nl> + else <nl> + cp -> free_resc ( dev ); <nl> pci_dev_put ( dev -> pcidev ); <nl> return err ; <nl> }
mmm drivers / scsi / sg . c <nl> ppp drivers / scsi / sg . c <nl> sg_common_write ( Sg_fd * sfp , Sg_request * srp , <nl> return k ; /* probably out of space --> ENOMEM */ <nl> } <nl> if ( atomic_read (& sdp -> detaching )) { <nl> - if ( srp -> bio ) <nl> + if ( srp -> bio ) { <nl> + if ( srp -> rq -> cmd != srp -> rq -> __cmd ) <nl> + kfree ( srp -> rq -> cmd ); <nl> + <nl> blk_end_request_all ( srp -> rq , - EIO ); <nl> + srp -> rq = NULL ; <nl> + } <nl> + <nl> sg_finish_rem_req ( srp ); <nl> return - ENODEV ; <nl> }
mmm drivers / net / wireless / orinoco_cs . c <nl> ppp drivers / net / wireless / orinoco_cs . c <nl> static struct pcmcia_device_id orinoco_cs_ids [] = { <nl> PCMCIA_DEVICE_PROD_ID12 (" Cabletron ", " RoamAbout 802 . 11 DS ", 0x32d445f5 , 0xedeffd90 ), <nl> PCMCIA_DEVICE_PROD_ID12 (" corega K . K .", " Wireless LAN PCC - 11 ", 0x5261440f , 0xa6405584 ), <nl> PCMCIA_DEVICE_PROD_ID12 (" corega K . K .", " Wireless LAN PCCA - 11 ", 0x5261440f , 0xdf6115f9 ), <nl> + PCMCIA_DEVICE_PROD_ID12 (" corega_K . K .", " Wireless_LAN_PCCB - 11 ", 0x29e33311 , 0xee7a27ae ), <nl> PCMCIA_DEVICE_PROD_ID12 (" D ", " Link DRC - 650 11Mbps WLAN Card ", 0x71b18589 , 0xf144e3ac ), <nl> PCMCIA_DEVICE_PROD_ID12 (" D ", " Link DWL - 650 11Mbps WLAN Card ", 0x71b18589 , 0xb6f1b0ab ), <nl> PCMCIA_DEVICE_PROD_ID12 (" ELSA ", " AirLancer MC - 11 ", 0x4507a33a , 0xef54f0e3 ),
mmm drivers / staging / serqt_usb2 / serqt_usb2 . c <nl> ppp drivers / staging / serqt_usb2 / serqt_usb2 . c <nl> static void qt_read_bulk_callback ( struct urb * urb ) <nl> if ( port_paranoia_check ( port , __func__ ) != 0 ) { <nl> dbg ("% s - port_paranoia_check , exiting \ n ", __func__ ); <nl> qt_port -> ReadBulkStopped = 1 ; <nl> - return ; <nl> + goto exit ; <nl> } <nl>  <nl> if (! serial ) { <nl> dbg ("% s - bad serial pointer , exiting \ n ", __func__ ); <nl> - return ; <nl> + goto exit ; <nl> } <nl> if ( qt_port -> closePending == 1 ) { <nl> /* Were closing , stop reading */ <nl> dbg ("% s - ( qt_port -> closepending == 1 \ n ", __func__ ); <nl> qt_port -> ReadBulkStopped = 1 ; <nl> - return ; <nl> + goto exit ; <nl> } <nl>  <nl> /* <nl> static void qt_read_bulk_callback ( struct urb * urb ) <nl> */ <nl> if ( qt_port -> RxHolding == 1 ) { <nl> qt_port -> ReadBulkStopped = 1 ; <nl> - return ; <nl> + goto exit ; <nl> } <nl>  <nl> if ( urb -> status ) { <nl> static void qt_read_bulk_callback ( struct urb * urb ) <nl>  <nl> dbg ("% s - nonzero read bulk status received : % d \ n ", <nl> __func__ , urb -> status ); <nl> - return ; <nl> + goto exit ; <nl> } <nl>  <nl> if ( tty && RxCount ) { <nl> static void qt_read_bulk_callback ( struct urb * urb ) <nl> } <nl>  <nl> schedule_work (& port -> work ); <nl> + exit : <nl> + tty_kref_put ( tty ); <nl> } <nl>  <nl> /* <nl> static void qt_block_until_empty ( struct tty_struct * tty , <nl> } <nl> } <nl>  <nl> - static void qt_close ( struct usb_serial_port * port ) <nl> + static void qt_close ( struct usb_serial_port * port ) <nl> { <nl> struct usb_serial * serial = port -> serial ; <nl> struct quatech_port * qt_port ; <nl> static void qt_close ( struct usb_serial_port * port ) <nl> /* wait up to for transmitter to empty */ <nl> if ( serial -> dev ) <nl> qt_block_until_empty ( tty , qt_port ); <nl> + tty_kref_put ( tty ); <nl>  <nl> /* Close uart channel */ <nl> status = qt_close_channel ( serial , index );
mmm drivers / usb / host / ohci - sm501 . c <nl> ppp drivers / usb / host / ohci - sm501 . c <nl> static int ohci_hcd_sm501_drv_remove ( struct platform_device * pdev ) <nl> static int ohci_sm501_suspend ( struct platform_device * pdev , pm_message_t msg ) <nl> { <nl> struct device * dev = & pdev -> dev ; <nl> - struct ohci_hcd * ohci = hcd_to_ohci ( platform_get_drvdata ( pdev )); <nl> + struct usb_hcd * hcd = platform_get_drvdata ( pdev ); <nl> + struct ohci_hcd * ohci = hcd_to_ohci ( hcd ); <nl> + bool do_wakeup = device_may_wakeup ( dev ); <nl> + int ret ; <nl>  <nl> if ( time_before ( jiffies , ohci -> next_statechange )) <nl> msleep ( 5 ); <nl> ohci -> next_statechange = jiffies ; <nl>  <nl> + ret = ohci_suspend ( hcd , do_wakeup ); <nl> + if ( ret ) <nl> + return ret ; <nl> + <nl> sm501_unit_power ( dev -> parent , SM501_GATE_USB_HOST , 0 ); <nl> - return 0 ; <nl> + return ret ; <nl> } <nl>  <nl> static int ohci_sm501_resume ( struct platform_device * pdev )
mmm drivers / gpu / drm / etnaviv / etnaviv_gpu . c <nl> ppp drivers / gpu / drm / etnaviv / etnaviv_gpu . c <nl> int etnaviv_gpu_submit ( struct etnaviv_gpu * gpu , <nl> goto out_pm_put ; <nl> } <nl>  <nl> + mutex_lock (& gpu -> lock ); <nl> + <nl> fence = etnaviv_gpu_fence_alloc ( gpu ); <nl> if (! fence ) { <nl> event_free ( gpu , event ); <nl> int etnaviv_gpu_submit ( struct etnaviv_gpu * gpu , <nl> goto out_pm_put ; <nl> } <nl>  <nl> - mutex_lock (& gpu -> lock ); <nl> - <nl> gpu -> event [ event ]. fence = fence ; <nl> submit -> fence = fence -> seqno ; <nl> gpu -> active_fence = submit -> fence ;
mmm drivers / staging / rtl8188eu / hal / usb_halinit . c <nl> ppp drivers / staging / rtl8188eu / hal / usb_halinit . c <nl> void rtl8188eu_set_hal_ops ( struct adapter * adapt ) <nl>  <nl>  <nl> adapt -> HalData = kzalloc ( sizeof ( struct hal_data_8188e ), GFP_KERNEL ); <nl> - if ( adapt -> HalData == NULL ) <nl> + if (! adapt -> HalData ) <nl> DBG_88E (" cant not alloc memory for HAL DATA \ n "); <nl>  <nl> halfunc -> hal_power_on = rtl8188eu_InitPowerOn ;
mmm drivers / char / virtio_console . c <nl> ppp drivers / char / virtio_console . c <nl> static ssize_t port_fops_write ( struct file * filp , const char __user * ubuf , <nl> if ( ret < 0 ) <nl> return ret ; <nl> } <nl> + /* Port got hot - unplugged . */ <nl> + if (! port -> guest_connected ) <nl> + return - ENODEV ; <nl>  <nl> count = min (( size_t )( 32 * 1024 ), count ); <nl> 
mmm drivers / net / hamradio / mkiss . c <nl> ppp drivers / net / hamradio / mkiss . c <nl> static int mkiss_ioctl ( struct tty_struct * tty , struct file * file , <nl> unsigned int cmd , unsigned long arg ) <nl> { <nl> struct mkiss * ax = mkiss_get ( tty ); <nl> - struct net_device * dev = ax -> dev ; <nl> + struct net_device * dev ; <nl> unsigned int tmp , err ; <nl>  <nl> /* First make sure we ' re connected . */ <nl> if ( ax == NULL ) <nl> return - ENXIO ; <nl> + dev = ax -> dev ; <nl>  <nl> switch ( cmd ) { <nl> case SIOCGIFNAME :
mmm drivers / media / dvb / dvb - core / dvbdev . c <nl> ppp drivers / media / dvb / dvb - core / dvbdev . c <nl> static int dvb_device_open ( struct inode * inode , struct file * file ) <nl> file -> private_data = dvbdev ; <nl> old_fops = file -> f_op ; <nl> file -> f_op = fops_get ( dvbdev -> fops ); <nl> + if ( file -> f_op == NULL ) { <nl> + file -> f_op = old_fops ; <nl> + goto fail ; <nl> + } <nl> if ( file -> f_op -> open ) <nl> err = file -> f_op -> open ( inode , file ); <nl> if ( err ) { <nl> static int dvb_device_open ( struct inode * inode , struct file * file ) <nl> unlock_kernel (); <nl> return err ; <nl> } <nl> + fail : <nl> up_read (& minor_rwsem ); <nl> unlock_kernel (); <nl> return - ENODEV ;mmm sound / core / sound . c <nl> ppp sound / core / sound . c <nl> static int dvb_device_open ( struct inode * inode , struct file * file ) <nl> file -> private_data = dvbdev ; <nl> old_fops = file -> f_op ; <nl> file -> f_op = fops_get ( dvbdev -> fops ); <nl> + if ( file -> f_op == NULL ) { <nl> + file -> f_op = old_fops ; <nl> + goto fail ; <nl> + } <nl> if ( file -> f_op -> open ) <nl> err = file -> f_op -> open ( inode , file ); <nl> if ( err ) { <nl> static int dvb_device_open ( struct inode * inode , struct file * file ) <nl> unlock_kernel (); <nl> return err ; <nl> } <nl> + fail : <nl> up_read (& minor_rwsem ); <nl> unlock_kernel (); <nl> return - ENODEV ; <nl> static int __snd_open ( struct inode * inode , struct file * file ) <nl> } <nl> old_fops = file -> f_op ; <nl> file -> f_op = fops_get ( mptr -> f_ops ); <nl> + if ( file -> f_op == NULL ) { <nl> + file -> f_op = old_fops ; <nl> + return - ENODEV ; <nl> + } <nl> if ( file -> f_op -> open ) <nl> err = file -> f_op -> open ( inode , file ); <nl> if ( err ) {mmm drivers / gpu / drm / drm_fops . c <nl> ppp drivers / gpu / drm / drm_fops . c <nl> static int dvb_device_open ( struct inode * inode , struct file * file ) <nl> file -> private_data = dvbdev ; <nl> old_fops = file -> f_op ; <nl> file -> f_op = fops_get ( dvbdev -> fops ); <nl> + if ( file -> f_op == NULL ) { <nl> + file -> f_op = old_fops ; <nl> + goto fail ; <nl> + } <nl> if ( file -> f_op -> open ) <nl> err = file -> f_op -> open ( inode , file ); <nl> if ( err ) { <nl> static int dvb_device_open ( struct inode * inode , struct file * file ) <nl> unlock_kernel (); <nl> return err ; <nl> } <nl> + fail : <nl> up_read (& minor_rwsem ); <nl> unlock_kernel (); <nl> return - ENODEV ; <nl> static int __snd_open ( struct inode * inode , struct file * file ) <nl> } <nl> old_fops = file -> f_op ; <nl> file -> f_op = fops_get ( mptr -> f_ops ); <nl> + if ( file -> f_op == NULL ) { <nl> + file -> f_op = old_fops ; <nl> + return - ENODEV ; <nl> + } <nl> if ( file -> f_op -> open ) <nl> err = file -> f_op -> open ( inode , file ); <nl> if ( err ) { <nl> int drm_stub_open ( struct inode * inode , struct file * filp ) <nl>  <nl> old_fops = filp -> f_op ; <nl> filp -> f_op = fops_get (& dev -> driver -> fops ); <nl> + if ( filp -> f_op == NULL ) { <nl> + filp -> f_op = old_fops ; <nl> + goto out ; <nl> + } <nl> if ( filp -> f_op -> open && ( err = filp -> f_op -> open ( inode , filp ))) { <nl> fops_put ( filp -> f_op ); <nl> filp -> f_op = fops_get ( old_fops );
mmm net / core / rtnetlink . c <nl> ppp net / core / rtnetlink . c <nl> static bool link_dump_filtered ( struct net_device * dev , <nl> return false ; <nl> } <nl>  <nl> - static struct net * get_target_net ( struct sk_buff * skb , int netnsid ) <nl> + static struct net * get_target_net ( struct sock * sk , int netnsid ) <nl> { <nl> struct net * net ; <nl>  <nl> - net = get_net_ns_by_id ( sock_net ( skb -> sk ), netnsid ); <nl> + net = get_net_ns_by_id ( sock_net ( sk ), netnsid ); <nl> if (! net ) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> /* For now , the caller is required to have CAP_NET_ADMIN in <nl> * the user namespace owning the target net ns . <nl> */ <nl> - if (! netlink_ns_capable ( skb , net -> user_ns , CAP_NET_ADMIN )) { <nl> + if (! sk_ns_capable ( sk , net -> user_ns , CAP_NET_ADMIN )) { <nl> put_net ( net ); <nl> return ERR_PTR (- EACCES ); <nl> } <nl> static int rtnl_dump_ifinfo ( struct sk_buff * skb , struct netlink_callback * cb ) <nl> ifla_policy , NULL ) >= 0 ) { <nl> if ( tb [ IFLA_IF_NETNSID ]) { <nl> netnsid = nla_get_s32 ( tb [ IFLA_IF_NETNSID ]); <nl> - tgt_net = get_target_net ( skb , netnsid ); <nl> + tgt_net = get_target_net ( skb -> sk , netnsid ); <nl> if ( IS_ERR ( tgt_net )) { <nl> tgt_net = net ; <nl> netnsid = - 1 ; <nl> static int rtnl_getlink ( struct sk_buff * skb , struct nlmsghdr * nlh , <nl>  <nl> if ( tb [ IFLA_IF_NETNSID ]) { <nl> netnsid = nla_get_s32 ( tb [ IFLA_IF_NETNSID ]); <nl> - tgt_net = get_target_net ( skb , netnsid ); <nl> + tgt_net = get_target_net ( NETLINK_CB ( skb ). sk , netnsid ); <nl> if ( IS_ERR ( tgt_net )) <nl> return PTR_ERR ( tgt_net ); <nl> }
mmm drivers / staging / comedi / drivers / unioxx5 . c <nl> ppp drivers / staging / comedi / drivers / unioxx5 . c <nl> static int __unioxx5_subdev_init ( struct comedi_device * dev , <nl> return - ENOMEM ; <nl>  <nl> ret = __comedi_request_region ( dev , iobase , UNIOXX5_SIZE ); <nl> - if ( ret ) <nl> + if ( ret ) { <nl> + kfree ( usp ); <nl> return ret ; <nl> + } <nl> usp -> usp_iobase = iobase ; <nl>  <nl> /* defining modules types */
mmm drivers / soc / tegra / pmc . c <nl> ppp drivers / soc / tegra / pmc . c <nl> static int tegra_io_pad_prepare ( enum tegra_io_pad id , unsigned long * request , <nl> } <nl>  <nl> rate = clk_get_rate ( pmc -> clk ); <nl> + if (! rate ) <nl> + return - ENODEV ; <nl>  <nl> tegra_pmc_writel ( DPD_SAMPLE_ENABLE , DPD_SAMPLE ); <nl> 
mmm drivers / net / ethernet / atheros / atlx / atl2 . c <nl> ppp drivers / net / ethernet / atheros / atlx / atl2 . c <nl> static int atl2_probe ( struct pci_dev * pdev , const struct pci_device_id * ent ) <nl>  <nl> err = - EIO ; <nl>  <nl> - netdev -> hw_features = NETIF_F_SG | NETIF_F_HW_VLAN_CTAG_RX ; <nl> + netdev -> hw_features = NETIF_F_HW_VLAN_CTAG_RX ; <nl> netdev -> features |= ( NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX ); <nl>  <nl> /* Init PHY as early as possible due to power saving issue */
mmm drivers / net / ethernet / intel / ixgbe / ixgbe_main . c <nl> ppp drivers / net / ethernet / intel / ixgbe / ixgbe_main . c <nl> static void ixgbe_tx_map ( struct ixgbe_ring * tx_ring , <nl> tx_buffer_info -> dma = dma ; <nl>  <nl> tx_desc -> read . buffer_addr = cpu_to_le64 ( dma + offset ); <nl> + if ( unlikely ( skb -> no_fcs )) <nl> + cmd_type &= ~( cpu_to_le32 ( IXGBE_ADVTXD_DCMD_IFCS )); <nl> tx_desc -> read . cmd_type_len = cmd_type | cpu_to_le32 ( size ); <nl> tx_desc -> read . olinfo_status = olinfo_status ; <nl>  <nl> static int __devinit ixgbe_probe ( struct pci_dev * pdev , <nl> netdev -> vlan_features |= NETIF_F_SG ; <nl>  <nl> netdev -> priv_flags |= IFF_UNICAST_FLT ; <nl> + netdev -> priv_flags |= IFF_SUPP_NOFCS ; <nl>  <nl> if ( adapter -> flags & IXGBE_FLAG_SRIOV_ENABLED ) <nl> adapter -> flags &= ~( IXGBE_FLAG_RSS_ENABLED |
mmm drivers / cpufreq / cpufreq . c <nl> ppp drivers / cpufreq / cpufreq . c <nl> static int cpufreq_online ( unsigned int cpu ) <nl> if ( new_policy ) { <nl> /* related_cpus should at least include policy -> cpus . */ <nl> cpumask_copy ( policy -> related_cpus , policy -> cpus ); <nl> - /* Clear mask of registered CPUs */ <nl> - cpumask_clear ( policy -> real_cpus ); <nl> } <nl>  <nl> /*
mmm drivers / staging / sm750fb / sm750 . c <nl> ppp drivers / staging / sm750fb / sm750 . c <nl> static int lynxfb_ops_cursor ( struct fb_info * info , struct fb_cursor * fbcursor ) <nl> } <nl>  <nl> cursor -> disable ( cursor ); <nl> - if ( fbcursor -> set & FB_CUR_SETSIZE ) { <nl> + if ( fbcursor -> set & FB_CUR_SETSIZE ) <nl> cursor -> setSize ( cursor , fbcursor -> image . width , fbcursor -> image . height ); <nl> - } <nl>  <nl> if ( fbcursor -> set & FB_CUR_SETPOS ) { <nl> cursor -> setPos ( cursor , fbcursor -> image . dx - info -> var . xoffset , <nl> static int lynxfb_ops_cursor ( struct fb_info * info , struct fb_cursor * fbcursor ) <nl> fbcursor -> mask ); <nl> } <nl>  <nl> - if ( fbcursor -> enable ) { <nl> + if ( fbcursor -> enable ) <nl> cursor -> enable ( cursor ); <nl> - } <nl>  <nl> return 0 ; <nl> } <nl> static void lynxfb_ops_fillrect ( struct fb_info * info , const struct fb_fillrect * <nl> unsigned int base , pitch , Bpp , rop ; <nl> u32 color ; <nl>  <nl> - if ( info -> state != FBINFO_STATE_RUNNING ) { <nl> + if ( info -> state != FBINFO_STATE_RUNNING ) <nl> return ; <nl> - } <nl>  <nl> par = info -> par ; <nl> share = par -> share ;
mmm arch / openrisc / mm / init . c <nl> ppp arch / openrisc / mm / init . c <nl> static void __init map_ram ( void ) <nl> set_pmd ( pme , __pmd ( _KERNPG_TABLE + __pa ( pte ))); <nl>  <nl> /* Fill the newly allocated page with PTE ' S */ <nl> - for ( j = 0 ; p < e && j < PTRS_PER_PGD ; <nl> + for ( j = 0 ; p < e && j < PTRS_PER_PTE ; <nl> v += PAGE_SIZE , p += PAGE_SIZE , j ++, pte ++) { <nl> if ( v >= ( u32 ) _e_kernel_ro || <nl> v < ( u32 ) _s_kernel_ro )mmm arch / openrisc / include / asm / pgtable . h <nl> ppp arch / openrisc / include / asm / pgtable . h <nl> static void __init map_ram ( void ) <nl> set_pmd ( pme , __pmd ( _KERNPG_TABLE + __pa ( pte ))); <nl>  <nl> /* Fill the newly allocated page with PTE ' S */ <nl> - for ( j = 0 ; p < e && j < PTRS_PER_PGD ; <nl> + for ( j = 0 ; p < e && j < PTRS_PER_PTE ; <nl> v += PAGE_SIZE , p += PAGE_SIZE , j ++, pte ++) { <nl> if ( v >= ( u32 ) _e_kernel_ro || <nl> v < ( u32 ) _s_kernel_ro ) <nl> extern void paging_init ( void ); <nl> */ <nl> # define PTRS_PER_PTE ( 1UL << ( PAGE_SHIFT - 2 )) <nl>  <nl> -# define PTRS_PER_PGD ( 1UL << ( PAGE_SHIFT - 2 )) <nl> +# define PTRS_PER_PGD ( 1UL << ( 32 - PGDIR_SHIFT )) <nl>  <nl> /* calculate how many PGD entries a user - level program can use <nl> * the first mappable virtual address is 0
mmm drivers / usb / mon / mon_text . c <nl> ppp drivers / usb / mon / mon_text . c <nl> int __init mon_text_init ( void ) <nl> { <nl> struct dentry * mondir ; <nl>  <nl> - mondir = debugfs_create_dir (" usbmon ", NULL ); <nl> + mondir = debugfs_create_dir (" usbmon ", usb_debug_root ); <nl> if ( IS_ERR ( mondir )) { <nl> printk ( KERN_NOTICE TAG ": debugfs is not available \ n "); <nl> return - ENODEV ;
mmm drivers / net / ethernet / intel / ixgbe / ixgbe_x550 . c <nl> ppp drivers / net / ethernet / intel / ixgbe / ixgbe_x550 . c <nl> static s32 ixgbe_setup_kr_x550em ( struct ixgbe_hw * hw ) <nl> if ( hw -> phy . autoneg_advertised & IXGBE_LINK_SPEED_2_5GB_FULL ) <nl> return 0 ; <nl>  <nl> + if ( ixgbe_check_reset_blocked ( hw )) <nl> + return 0 ; <nl> + <nl> return ixgbe_setup_kr_speed_x550em ( hw , hw -> phy . autoneg_advertised ); <nl> } <nl> 
mmm fs / btrfs / file . c <nl> ppp fs / btrfs / file . c <nl> int btrfs_add_inode_defrag ( struct btrfs_trans_handle * trans , <nl> spin_lock (& root -> fs_info -> defrag_inodes_lock ); <nl> if (! BTRFS_I ( inode )-> in_defrag ) <nl> __btrfs_add_inode_defrag ( inode , defrag ); <nl> + else <nl> + kfree ( defrag ); <nl> spin_unlock (& root -> fs_info -> defrag_inodes_lock ); <nl> return 0 ; <nl> }
mmm drivers / infiniband / hw / ipath / ipath_rc . c <nl> ppp drivers / infiniband / hw / ipath / ipath_rc . c <nl> static int do_rc_ack ( struct ipath_qp * qp , u32 aeth , u32 psn , int opcode , <nl> /* If this is a partial ACK , reset the retransmit timer . */ <nl> if ( qp -> s_last != qp -> s_tail ) { <nl> spin_lock (& dev -> pending_lock ); <nl> - list_add_tail (& qp -> timerwait , <nl> - & dev -> pending [ dev -> pending_index ]); <nl> + if ( list_empty (& qp -> timerwait )) <nl> + list_add_tail (& qp -> timerwait , <nl> + & dev -> pending [ dev -> pending_index ]); <nl> spin_unlock (& dev -> pending_lock ); <nl> /* <nl> * If we get a partial ACK for a resent operation ,
mmm net / ipv4 / netfilter / nf_flow_table_ipv4 . c <nl> ppp net / ipv4 / netfilter / nf_flow_table_ipv4 . c <nl> static int nf_flow_dnat_ip ( const struct flow_offload * flow , struct sk_buff * skb , <nl> default : <nl> return - 1 ; <nl> } <nl> + csum_replace4 (& iph -> check , addr , new_addr ); <nl>  <nl> return nf_flow_nat_ip_l4proto ( skb , iph , thoff , addr , new_addr ); <nl> }
mmm drivers / gpu / drm / i915 / intel_display . c <nl> ppp drivers / gpu / drm / i915 / intel_display . c <nl> int intel_get_load_detect_pipe ( struct drm_connector * connector , <nl> */ <nl> if (! crtc ) { <nl> DRM_DEBUG_KMS (" no pipe available for load - detect \ n "); <nl> + ret = - ENODEV ; <nl> goto fail ; <nl> } <nl>  <nl> int intel_get_load_detect_pipe ( struct drm_connector * connector , <nl> DRM_DEBUG_KMS (" reusing fbdev for load - detection framebuffer \ n "); <nl> if ( IS_ERR ( fb )) { <nl> DRM_DEBUG_KMS (" failed to allocate framebuffer for load - detection \ n "); <nl> + ret = PTR_ERR ( fb ); <nl> goto fail ; <nl> } <nl> 
mmm drivers / rpmsg / rpmsg_core . c <nl> ppp drivers / rpmsg / rpmsg_core . c <nl> static ssize_t modalias_show ( struct device * dev , <nl> struct device_attribute * attr , char * buf ) <nl> { <nl> struct rpmsg_device * rpdev = to_rpmsg_device ( dev ); <nl> + ssize_t len ; <nl> + <nl> + len = of_device_modalias ( dev , buf , PAGE_SIZE ); <nl> + if ( len != - ENODEV ) <nl> + return len ; <nl>  <nl> return sprintf ( buf , RPMSG_DEVICE_MODALIAS_FMT "\ n ", rpdev -> id . name ); <nl> } <nl> static int rpmsg_dev_match ( struct device * dev , struct device_driver * drv ) <nl> static int rpmsg_uevent ( struct device * dev , struct kobj_uevent_env * env ) <nl> { <nl> struct rpmsg_device * rpdev = to_rpmsg_device ( dev ); <nl> + int ret ; <nl> + <nl> + ret = of_device_uevent_modalias ( dev , env ); <nl> + if ( ret != - ENODEV ) <nl> + return ret ; <nl>  <nl> return add_uevent_var ( env , " MODALIAS =" RPMSG_DEVICE_MODALIAS_FMT , <nl> rpdev -> id . name );
mmm drivers / bluetooth / hci_bcm . c <nl> ppp drivers / bluetooth / hci_bcm . c <nl> static int bcm_close ( struct hci_uart * hu ) <nl> if ( IS_ENABLED ( CONFIG_PM ) && bdev -> irq > 0 ) { <nl> devm_free_irq ( bdev -> dev , bdev -> irq , bdev ); <nl> device_init_wakeup ( bdev -> dev , false ); <nl> + pm_runtime_disable ( bdev -> dev ); <nl> } <nl>  <nl> bcm_gpio_set_power ( bdev , false ); <nl> - pm_runtime_disable ( bdev -> dev ); <nl> pm_runtime_set_suspended ( bdev -> dev ); <nl> } <nl> mutex_unlock (& bcm_device_lock );
mmm drivers / usb / net / usbnet . c <nl> ppp drivers / usb / net / usbnet . c <nl> static int blan_mdlm_bind ( struct usbnet * dev , struct usb_interface * intf ) <nl> } <nl> /* expect bcdVersion 1 . 0 , ignore */ <nl> if ( memcmp (& desc -> bGUID , blan_guid , 16 ) <nl> - && memcmp (& desc -> bGUID , blan_guid , 16 ) ) { <nl> + && memcmp (& desc -> bGUID , safe_guid , 16 ) ) { <nl> /* hey , this one might _really_ be MDLM ! */ <nl> dev_dbg (& intf -> dev , " MDLM guid \ n "); <nl> goto bad_desc ;
mmm drivers / gpu / drm / atmel - hlcdc / atmel_hlcdc_dc . c <nl> ppp drivers / gpu / drm / atmel - hlcdc / atmel_hlcdc_dc . c <nl> static int atmel_hlcdc_dc_atomic_commit ( struct drm_device * dev , <nl> dc -> commit . pending = true ; <nl> spin_unlock (& dc -> commit . wait . lock ); <nl>  <nl> - if ( ret ) { <nl> - kfree ( commit ); <nl> - goto error ; <nl> - } <nl> + if ( ret ) <nl> + goto err_free ; <nl>  <nl> - /* Swap the state , this is the point of no return . */ <nl> - drm_atomic_helper_swap_state ( state , true ); <nl> + /* We have our own synchronization through the commit lock . */ <nl> + BUG_ON ( drm_atomic_helper_swap_state ( state , false ) < 0 ); <nl>  <nl> + /* Swap state succeeded , this is the point of no return . */ <nl> drm_atomic_state_get ( state ); <nl> if ( async ) <nl> queue_work ( dc -> wq , & commit -> work ); <nl> static int atmel_hlcdc_dc_atomic_commit ( struct drm_device * dev , <nl>  <nl> return 0 ; <nl>  <nl> + err_free : <nl> + kfree ( commit ); <nl> error : <nl> drm_atomic_helper_cleanup_planes ( dev , state ); <nl> return ret ;
mmm fs / btrfs / ioctl . c <nl> ppp fs / btrfs / ioctl . c <nl> static int btrfs_extent_same ( struct inode * src , u64 loff , u64 olen , <nl> inode_lock ( src ); <nl>  <nl> ret = extent_same_check_offsets ( src , loff , & len , olen ); <nl> + if ( ret ) <nl> + goto out_unlock ; <nl> + ret = extent_same_check_offsets ( src , dst_loff , & len , olen ); <nl> if ( ret ) <nl> goto out_unlock ; <nl> 
mmm drivers / staging / android / ion / ion_system_heap . c <nl> ppp drivers / staging / android / ion / ion_system_heap . c <nl> static struct page_info * alloc_largest_available ( struct ion_system_heap * heap , <nl> struct page_info * info ; <nl> int i ; <nl>  <nl> + info = kmalloc ( sizeof ( struct page_info ), GFP_KERNEL ); <nl> + if (! info ) <nl> + return NULL ; <nl> + <nl> for ( i = 0 ; i < num_orders ; i ++) { <nl> if ( size < order_to_size ( orders [ i ])) <nl> continue ; <nl> static struct page_info * alloc_largest_available ( struct ion_system_heap * heap , <nl> if (! page ) <nl> continue ; <nl>  <nl> - info = kmalloc ( sizeof ( struct page_info ), GFP_KERNEL ); <nl> info -> page = page ; <nl> info -> order = orders [ i ]; <nl> return info ; <nl> } <nl> + kfree ( info ); <nl> + <nl> return NULL ; <nl> } <nl> 
mmm crypto / shash . c <nl> ppp crypto / shash . c <nl> static int shash_update_unaligned ( struct shash_desc * desc , const u8 * data , <nl> u8 buf [ shash_align_buffer_size ( unaligned_len , alignmask )] <nl> __attribute__ (( aligned )); <nl>  <nl> + if ( unaligned_len > len ) <nl> + unaligned_len = len ; <nl> + <nl> memcpy ( buf , data , unaligned_len ); <nl>  <nl> return shash -> update ( desc , buf , unaligned_len ) ?:
mmm drivers / gpu / drm / exynos / exynos_drm_dmabuf . c <nl> ppp drivers / gpu / drm / exynos / exynos_drm_dmabuf . c <nl> struct dma_buf * exynos_dmabuf_prime_export ( struct drm_device * drm_dev , <nl> struct exynos_drm_gem_obj * exynos_gem_obj = to_exynos_gem_obj ( obj ); <nl>  <nl> return dma_buf_export ( exynos_gem_obj , & exynos_dmabuf_ops , <nl> - exynos_gem_obj -> base . size , 0600 ); <nl> + exynos_gem_obj -> base . size , flags ); <nl> } <nl>  <nl> struct drm_gem_object * exynos_dmabuf_prime_import ( struct drm_device * drm_dev ,
mmm drivers / md / raid1 . c <nl> ppp drivers / md / raid1 . c <nl> int md_raid1_congested ( struct mddev * mddev , int bits ) <nl> return 1 ; <nl>  <nl> rcu_read_lock (); <nl> - for ( i = 0 ; i < conf -> raid_disks ; i ++) { <nl> + for ( i = 0 ; i < conf -> raid_disks * 2 ; i ++) { <nl> struct md_rdev * rdev = rcu_dereference ( conf -> mirrors [ i ]. rdev ); <nl> if ( rdev && ! test_bit ( Faulty , & rdev -> flags )) { <nl> struct request_queue * q = bdev_get_queue ( rdev -> bdev );
mmm fs / namespace . c <nl> ppp fs / namespace . c <nl> void __detach_mounts ( struct dentry * dentry ) <nl>  <nl> namespace_lock (); <nl> mp = lookup_mountpoint ( dentry ); <nl> - if (! mp ) <nl> + if ( IS_ERR_OR_NULL ( mp )) <nl> goto out_unlock ; <nl>  <nl> lock_mount_hash ();
mmm fs / isofs / rock . c <nl> ppp fs / isofs / rock . c <nl> struct rock_state { <nl> int cont_size ; <nl> int cont_extent ; <nl> int cont_offset ; <nl> + int cont_loops ; <nl> struct inode * inode ; <nl> }; <nl>  <nl> static void init_rock_state ( struct rock_state * rs , struct inode * inode ) <nl> rs -> inode = inode ; <nl> } <nl>  <nl> +/* Maximum number of Rock Ridge continuation entries */ <nl> +# define RR_MAX_CE_ENTRIES 32 <nl> + <nl> /* <nl> * Returns 0 if the caller should continue scanning , 1 if the scan must end <nl> * and - ve on error . <nl> static int rock_continue ( struct rock_state * rs ) <nl> goto out ; <nl> } <nl> ret = - EIO ; <nl> + if (++ rs -> cont_loops >= RR_MAX_CE_ENTRIES ) <nl> + goto out ; <nl> bh = sb_bread ( rs -> inode -> i_sb , rs -> cont_extent ); <nl> if ( bh ) { <nl> memcpy ( rs -> buffer , bh -> b_data + rs -> cont_offset ,
mmm lib / mpi / mpi - pow . c <nl> ppp lib / mpi / mpi - pow . c <nl> int mpi_powm ( MPI res , MPI base , MPI exp , MPI mod ) <nl> if (! esize ) { <nl> /* Exponent is zero , result is 1 mod MOD , i . e ., 1 or 0 <nl> * depending on if MOD equals 1 . */ <nl> - rp [ 0 ] = 1 ; <nl> res -> nlimbs = ( msize == 1 && mod -> d [ 0 ] == 1 ) ? 0 : 1 ; <nl> + if ( res -> nlimbs ) { <nl> + if ( mpi_resize ( res , 1 ) < 0 ) <nl> + goto enomem ; <nl> + rp = res -> d ; <nl> + rp [ 0 ] = 1 ; <nl> + } <nl> res -> sign = 0 ; <nl> goto leave ; <nl> }
mmm net / wireless / radiotap . c <nl> ppp net / wireless / radiotap . c <nl> int ieee80211_radiotap_iterator_init ( <nl> struct ieee80211_radiotap_header * radiotap_header , <nl> int max_length , const struct ieee80211_radiotap_vendor_namespaces * vns ) <nl> { <nl> + /* check the radiotap header can actually be present */ <nl> + if ( max_length < sizeof ( struct ieee80211_radiotap_header )) <nl> + return - EINVAL ; <nl> + <nl> /* Linux only supports version 0 radiotap format */ <nl> if ( radiotap_header -> it_version ) <nl> return - EINVAL ; <nl> int ieee80211_radiotap_iterator_init ( <nl> */ <nl>  <nl> if (( unsigned long ) iterator -> _arg - <nl> - ( unsigned long ) iterator -> _rtheader > <nl> + ( unsigned long ) iterator -> _rtheader + <nl> + sizeof ( uint32_t ) > <nl> ( unsigned long ) iterator -> _max_length ) <nl> return - EINVAL ; <nl> }
mmm tools / perf / util / symbol . c <nl> ppp tools / perf / util / symbol . c <nl> static const char * const vmlinux_paths_upd [] = { <nl> "/ boot / vmlinux -% s ", <nl> "/ usr / lib / debug / boot / vmlinux -% s ", <nl> "/ lib / modules /% s / build / vmlinux ", <nl> - "/ usr / lib / debug / lib / modules /% s / vmlinux " <nl> + "/ usr / lib / debug / lib / modules /% s / vmlinux ", <nl> + "/ usr / lib / debug / boot / vmlinux -% s . debug " <nl> }; <nl>  <nl> static int vmlinux_path__add ( const char * new_entry )
mmm drivers / staging / rtl8188eu / core / rtw_efuse . c <nl> ppp drivers / staging / rtl8188eu / core / rtw_efuse . c <nl> int Efuse_PgPacketRead ( struct adapter * pAdapter , u8 offset , u8 * data ) <nl> u8 hoffset = 0 , hworden = 0 ; <nl> u8 tmpidx = 0 ; <nl> u8 tmpdata [ 8 ]; <nl> - u8 max_section = 0 ; <nl> u8 tmp_header = 0 ; <nl>  <nl> - EFUSE_GetEfuseDefinition ( pAdapter , EFUSE_WIFI , TYPE_EFUSE_MAX_SECTION , ( void *)& max_section ); <nl> - <nl> if (! data ) <nl> return false ; <nl> - if ( offset > max_section ) <nl> + if ( offset > EFUSE_MAX_SECTION_88E ) <nl> return false ; <nl>  <nl> memset ( data , 0xff , sizeof ( u8 ) * PGPKT_DATA_SIZE );
mmm fs / btrfs / backref . c <nl> ppp fs / btrfs / backref . c <nl> static int find_parent_nodes ( struct btrfs_trans_handle * trans , <nl> } <nl> ret = find_extent_in_eb ( eb , bytenr , <nl> * extent_item_pos , & eie ); <nl> - ref -> inode_list = eie ; <nl> free_extent_buffer ( eb ); <nl> + if ( ret < 0 ) <nl> + goto out ; <nl> + ref -> inode_list = eie ; <nl> } <nl> ret = ulist_add_merge ( refs , ref -> parent , <nl> ( uintptr_t ) ref -> inode_list ,
mmm fs / dax . c <nl> ppp fs / dax . c <nl> static int copy_user_dax ( struct block_device * bdev , struct dax_device * dax_dev , <nl> static void * dax_insert_mapping_entry ( struct address_space * mapping , <nl> struct vm_fault * vmf , <nl> void * entry , sector_t sector , <nl> - unsigned long flags ) <nl> + unsigned long flags , bool dirty ) <nl> { <nl> struct radix_tree_root * page_tree = & mapping -> page_tree ; <nl> void * new_entry ; <nl> pgoff_t index = vmf -> pgoff ; <nl>  <nl> - if ( vmf -> flags & FAULT_FLAG_WRITE ) <nl> + if ( dirty ) <nl> __mark_inode_dirty ( mapping -> host , I_DIRTY_PAGES ); <nl>  <nl> if ( dax_is_zero_entry ( entry ) && !( flags & RADIX_DAX_ZERO_PAGE )) { <nl> static void * dax_insert_mapping_entry ( struct address_space * mapping , <nl> entry = new_entry ; <nl> } <nl>  <nl> - if ( vmf -> flags & FAULT_FLAG_WRITE ) <nl> + if ( dirty ) <nl> radix_tree_tag_set ( page_tree , index , PAGECACHE_TAG_DIRTY ); <nl>  <nl> spin_unlock_irq (& mapping -> tree_lock ); <nl> static int dax_load_hole ( struct address_space * mapping , void * entry , <nl> } <nl>  <nl> entry2 = dax_insert_mapping_entry ( mapping , vmf , entry , 0 , <nl> - RADIX_DAX_ZERO_PAGE ); <nl> + RADIX_DAX_ZERO_PAGE , false ); <nl> if ( IS_ERR ( entry2 )) { <nl> ret = VM_FAULT_SIGBUS ; <nl> goto out ; <nl> static int dax_iomap_pte_fault ( struct vm_fault * vmf , pfn_t * pfnp , <nl>  <nl> entry = dax_insert_mapping_entry ( mapping , vmf , entry , <nl> dax_iomap_sector (& iomap , pos ), <nl> - 0 ); <nl> + 0 , write ); <nl> if ( IS_ERR ( entry )) { <nl> error = PTR_ERR ( entry ); <nl> goto error_finish_iomap ; <nl> static int dax_pmd_load_hole ( struct vm_fault * vmf , struct iomap * iomap , <nl> goto fallback ; <nl>  <nl> ret = dax_insert_mapping_entry ( mapping , vmf , entry , 0 , <nl> - RADIX_DAX_PMD | RADIX_DAX_ZERO_PAGE ); <nl> + RADIX_DAX_PMD | RADIX_DAX_ZERO_PAGE , false ); <nl> if ( IS_ERR ( ret )) <nl> goto fallback ; <nl>  <nl> static int dax_iomap_pmd_fault ( struct vm_fault * vmf , pfn_t * pfnp , <nl>  <nl> entry = dax_insert_mapping_entry ( mapping , vmf , entry , <nl> dax_iomap_sector (& iomap , pos ), <nl> - RADIX_DAX_PMD ); <nl> + RADIX_DAX_PMD , write ); <nl> if ( IS_ERR ( entry )) <nl> goto finish_iomap ; <nl> 
mmm drivers / iio / industrialio - buffer . c <nl> ppp drivers / iio / industrialio - buffer . c <nl> int iio_buffer_register ( struct iio_dev * indio_dev , <nl> if ( channels ) { <nl> /* new magic */ <nl> for ( i = 0 ; i < num_channels ; i ++) { <nl> + if ( channels [ i ]. scan_index < 0 ) <nl> + continue ; <nl> + <nl> /* Establish necessary mask length */ <nl> if ( channels [ i ]. scan_index > <nl> ( int ) indio_dev -> masklength - 1 )
mmm drivers / net / wireless / ti / wlcore / cmd . c <nl> ppp drivers / net / wireless / ti / wlcore / cmd . c <nl> static int __wlcore_cmd_send ( struct wl1271 * wl , u16 id , void * buf , <nl> id != CMD_STOP_FWLOGGER )) <nl> return - EIO ; <nl>  <nl> + if ( WARN_ON_ONCE ( len < sizeof (* cmd ))) <nl> + return - EIO ; <nl> + <nl> cmd = buf ; <nl> cmd -> id = cpu_to_le16 ( id ); <nl> cmd -> status = 0 ; <nl> int wlcore_cmd_configure_failsafe ( struct wl1271 * wl , u16 id , void * buf , <nl>  <nl> wl1271_debug ( DEBUG_CMD , " cmd configure (% d )", id ); <nl>  <nl> + if ( WARN_ON_ONCE ( len < sizeof (* acx ))) <nl> + return - EIO ; <nl> + <nl> acx -> id = cpu_to_le16 ( id ); <nl>  <nl> /* payload length , does not include any headers */
mmm drivers / media / video / gspca / ov519 . c <nl> ppp drivers / media / video / gspca / ov519 . c <nl> static int sd_config ( struct gspca_dev * gspca_dev , <nl> break ; <nl> } <nl> sd -> brightness = BRIGHTNESS_DEF ; <nl> - sd -> contrast = CONTRAST_DEF ; <nl> + if ( sd -> sensor == SEN_OV6630 || sd -> sensor == SEN_OV66308AF ) <nl> + sd -> contrast = 200 ; /* The default is too low for the ov6630 */ <nl> + else <nl> + sd -> contrast = CONTRAST_DEF ; <nl> sd -> colors = COLOR_DEF ; <nl> sd -> hflip = HFLIP_DEF ; <nl> sd -> vflip = VFLIP_DEF ;
mmm fs / btrfs / send . c <nl> ppp fs / btrfs / send . c <nl> long btrfs_ioctl_send ( struct file * mnt_file , void __user * arg_ ) <nl> goto out ; <nl> } <nl>  <nl> + if ( arg -> clone_sources_count > <nl> + ULLONG_MAX / sizeof (* arg -> clone_sources )) { <nl> + ret = - EINVAL ; <nl> + goto out ; <nl> + } <nl> + <nl> if (! access_ok ( VERIFY_READ , arg -> clone_sources , <nl> sizeof (* arg -> clone_sources ) * <nl> arg -> clone_sources_count )) {
mmm drivers / infiniband / core / uverbs_ioctl . c <nl> ppp drivers / infiniband / core / uverbs_ioctl . c <nl> static int uverbs_validate_kernel_mandatory ( const struct uverbs_method_spec * met <nl> return - EINVAL ; <nl> } <nl>  <nl> + for (; i < method_spec -> num_buckets ; i ++) { <nl> + struct uverbs_attr_spec_hash * attr_spec_bucket = <nl> + method_spec -> attr_buckets [ i ]; <nl> + <nl> + if (! bitmap_empty ( attr_spec_bucket -> mandatory_attrs_bitmask , <nl> + attr_spec_bucket -> num_attrs )) <nl> + return - EINVAL ; <nl> + } <nl> + <nl> return 0 ; <nl> } <nl> 
mmm drivers / infiniband / hw / mlx5 / main . c <nl> ppp drivers / infiniband / hw / mlx5 / main . c <nl> static int get_port_caps ( struct mlx5_ib_dev * dev ) <nl> struct ib_device_attr * dprops = NULL ; <nl> struct ib_port_attr * pprops = NULL ; <nl> struct mlx5_general_caps * gen ; <nl> - int err = 0 ; <nl> + int err = - ENOMEM ; <nl> int port ; <nl>  <nl> gen = & dev -> mdev -> caps . gen ;
mmm fs / btrfs / free - space - cache . c <nl> ppp fs / btrfs / free - space - cache . c <nl> void btrfs_dump_free_space ( struct btrfs_block_group_cache * block_group , <nl>  <nl> for ( n = rb_first (& ctl -> free_space_offset ); n ; n = rb_next ( n )) { <nl> info = rb_entry ( n , struct btrfs_free_space , offset_index ); <nl> - if ( info -> bytes >= bytes ) <nl> + if ( info -> bytes >= bytes && ! block_group -> ro ) <nl> count ++; <nl> printk ( KERN_CRIT " entry offset % llu , bytes % llu , bitmap % s \ n ", <nl> ( unsigned long long ) info -> offset ,
mmm drivers / staging / wilc1000 / linux_mon . c <nl> ppp drivers / staging / wilc1000 / linux_mon . c <nl> static int mon_mgmt_tx ( struct net_device * dev , const u8 * buf , size_t len ) <nl> mgmt_tx -> buff = kmalloc ( len , GFP_ATOMIC ); <nl> if ( mgmt_tx -> buff == NULL ) { <nl> PRINT_ER (" Failed to allocate memory for mgmt_tx buff \ n "); <nl> + kfree ( mgmt_tx ); <nl> return WILC_FAIL ; <nl>  <nl> }mmm drivers / staging / wilc1000 / wilc_wfi_cfgoperations . c <nl> ppp drivers / staging / wilc1000 / wilc_wfi_cfgoperations . c <nl> static int mon_mgmt_tx ( struct net_device * dev , const u8 * buf , size_t len ) <nl> mgmt_tx -> buff = kmalloc ( len , GFP_ATOMIC ); <nl> if ( mgmt_tx -> buff == NULL ) { <nl> PRINT_ER (" Failed to allocate memory for mgmt_tx buff \ n "); <nl> + kfree ( mgmt_tx ); <nl> return WILC_FAIL ; <nl>  <nl> } <nl> int WILC_WFI_mgmt_tx ( struct wiphy * wiphy , <nl> mgmt_tx -> buff = WILC_MALLOC ( buf_len ); <nl> if ( mgmt_tx -> buff == NULL ) { <nl> PRINT_ER (" Failed to allocate memory for mgmt_tx buff \ n "); <nl> + kfree ( mgmt_tx ); <nl> return WILC_FAIL ; <nl> } <nl> memcpy ( mgmt_tx -> buff , buf , len );
mmm drivers / block / drbd / drbd_main . c <nl> ppp drivers / block / drbd / drbd_main . c <nl> static void after_state_ch ( struct drbd_conf * mdev , union drbd_state os , <nl> drbd_free_bc ( mdev -> ldev ); <nl> mdev -> ldev = NULL ;); <nl>  <nl> - if ( mdev -> md_io_tmpp ) <nl> + if ( mdev -> md_io_tmpp ) { <nl> __free_page ( mdev -> md_io_tmpp ); <nl> + mdev -> md_io_tmpp = NULL ; <nl> + } <nl> } <nl>  <nl> /* Disks got bigger while they were detached */
mmm fs / xfs / xfs_attr_inactive . c <nl> ppp fs / xfs / xfs_attr_inactive . c <nl> xfs_attr_inactive ( <nl> */ <nl> xfs_trans_ijoin ( trans , dp , 0 ); <nl>  <nl> - /* invalidate and truncate the attribute fork extents */ <nl> - if ( dp -> i_d . di_aformat != XFS_DINODE_FMT_LOCAL ) { <nl> + /* <nl> + * Invalidate and truncate the attribute fork extents . Make sure the <nl> + * fork actually has attributes as otherwise the invalidation has no <nl> + * blocks to read and returns an error . In this case , just do the fork <nl> + * removal below . <nl> + */ <nl> + if ( xfs_inode_hasattr ( dp ) && <nl> + dp -> i_d . di_aformat != XFS_DINODE_FMT_LOCAL ) { <nl> error = xfs_attr3_root_inactive (& trans , dp ); <nl> if ( error ) <nl> goto out_cancel ;
mmm net / batman - adv / bat_debugfs . c <nl> ppp net / batman - adv / bat_debugfs . c <nl> int debug_log ( struct bat_priv * bat_priv , char * fmt , ...) <nl>  <nl> va_start ( args , fmt ); <nl> vscnprintf ( tmp_log_buf , sizeof ( tmp_log_buf ), fmt , args ); <nl> - fdebug_log ( bat_priv -> debug_log , "[% 10u ] % s ", <nl> + fdebug_log ( bat_priv -> debug_log , "[% 10lu ] % s ", <nl> ( jiffies / HZ ), tmp_log_buf ); <nl> va_end ( args ); <nl> 
mmm mm / pagewalk . c <nl> ppp mm / pagewalk . c <nl> int walk_page_range ( unsigned long start , unsigned long end , <nl> vma = vma -> vm_next ; <nl>  <nl> err = walk_page_test ( start , next , walk ); <nl> - if ( err > 0 ) <nl> + if ( err > 0 ) { <nl> + /* <nl> + * positive return values are purely for <nl> + * controlling the pagewalk , so should never <nl> + * be passed to the callers . <nl> + */ <nl> + err = 0 ; <nl> continue ; <nl> + } <nl> if ( err < 0 ) <nl> break ; <nl> }
mmm arch / x86 / kernel / topology . c <nl> ppp arch / x86 / kernel / topology . c <nl> int __ref _debug_hotplug_cpu ( int cpu , int action ) <nl> ret = cpu_down ( cpu ); <nl> if (! ret ) { <nl> pr_info (" CPU % u is now offline \ n ", cpu ); <nl> + dev -> offline = true ; <nl> kobject_uevent (& dev -> kobj , KOBJ_OFFLINE ); <nl> } else <nl> pr_debug (" Can ' t offline CPU % d .\ n ", cpu ); <nl> break ; <nl> case 1 : <nl> ret = cpu_up ( cpu ); <nl> - if (! ret ) <nl> + if (! ret ) { <nl> + dev -> offline = false ; <nl> kobject_uevent (& dev -> kobj , KOBJ_ONLINE ); <nl> - else <nl> + } else { <nl> pr_debug (" Can ' t online CPU % d .\ n ", cpu ); <nl> + } <nl> break ; <nl> default : <nl> ret = - EINVAL ;
mmm drivers / gpu / drm / i915 / intel_guc . c <nl> ppp drivers / gpu / drm / i915 / intel_guc . c <nl> int intel_guc_send_mmio ( struct intel_guc * guc , const u32 * action , u32 len , <nl> " ret =% d status = 0x % 08X response = 0x % 08X \ n ", <nl> action [ 0 ], ret , status , <nl> I915_READ ( SOFT_SCRATCH ( 15 ))); <nl> - } else { <nl> - /* Use data from the GuC response as our return value */ <nl> - ret = INTEL_GUC_MSG_TO_DATA ( status ); <nl> + goto out ; <nl> } <nl>  <nl> + if ( response_buf ) { <nl> + int count = min ( response_buf_size , guc -> send_regs . count - 1 ); <nl> + <nl> + for ( i = 0 ; i < count ; i ++) <nl> + response_buf [ i ] = I915_READ ( guc_send_reg ( guc , i + 1 )); <nl> + } <nl> + <nl> + /* Use data from the GuC response as our return value */ <nl> + ret = INTEL_GUC_MSG_TO_DATA ( status ); <nl> + <nl> + out : <nl> intel_uncore_forcewake_put ( dev_priv , guc -> send_regs . fw_domains ); <nl> mutex_unlock (& guc -> send_mutex ); <nl> 
mmm drivers / tty / serial / amba - pl011 . c <nl> ppp drivers / tty / serial / amba - pl011 . c <nl> static void pl011_dma_probe_initcall ( struct device * dev , struct uart_amba_port * <nl> dmaengine_slave_config ( chan , & rx_conf ); <nl> uap -> dmarx . chan = chan ; <nl>  <nl> - if ( plat -> dma_rx_poll_enable ) { <nl> + if ( plat && plat -> dma_rx_poll_enable ) { <nl> /* Set poll rate if specified . */ <nl> if ( plat -> dma_rx_poll_rate ) { <nl> uap -> dmarx . auto_poll_rate = false ;
mmm drivers / platform / x86 / peaq - wmi . c <nl> ppp drivers / platform / x86 / peaq - wmi . c <nl> static void peaq_wmi_poll ( struct input_polled_dev * dev ) <nl> } <nl>  <nl> /* Some other devices ( Shuttle XS35 ) use the same WMI GUID for other purposes */ <nl> - static const struct dmi_system_id peaq_dmi_table [] = { <nl> + static const struct dmi_system_id peaq_dmi_table [] __initconst = { <nl> { <nl> . matches = { <nl> DMI_MATCH ( DMI_SYS_VENDOR , " PEAQ "), <nl> static int __init peaq_wmi_init ( void ) <nl>  <nl> static void __exit peaq_wmi_exit ( void ) <nl> { <nl> - if (! dmi_check_system ( peaq_dmi_table )) <nl> - return ; <nl> - <nl> - if (! wmi_has_guid ( PEAQ_DOLBY_BUTTON_GUID )) <nl> - return ; <nl> - <nl> input_unregister_polled_device ( peaq_poll_dev ); <nl> } <nl> 
mmm drivers / isdn / i4l / isdn_ppp . c <nl> ppp drivers / isdn / i4l / isdn_ppp . c <nl> static struct sk_buff * isdn_ppp_decompress ( struct sk_buff * skb , struct ippp_struc <nl> rsparm . maxdlen = IPPP_RESET_MAXDATABYTES ; <nl>  <nl> skb_out = dev_alloc_skb ( is -> mru + PPP_HDRLEN ); <nl> + if (! skb_out ) { <nl> + kfree_skb ( skb ); <nl> + printk ( KERN_ERR " ippp : decomp memory allocation failure \ n "); <nl> + return NULL ; <nl> + } <nl> len = ipc -> decompress ( stat , skb , skb_out , & rsparm ); <nl> kfree_skb ( skb ); <nl> if ( len <= 0 ) {
mmm drivers / media / i2c / tvp5150 . c <nl> ppp drivers / media / i2c / tvp5150 . c <nl> static int tvp5150_fill_fmt ( struct v4l2_subdev * sd , <nl> struct v4l2_mbus_framefmt * f ; <nl> struct tvp5150 * decoder = to_tvp5150 ( sd ); <nl>  <nl> - if (! format || format -> pad ) <nl> + if (! format || ( format -> pad != DEMOD_PAD_VID_OUT )) <nl> return - EINVAL ; <nl>  <nl> f = & format -> format ;
mmm sound / soc / codecs / wm5102 . c <nl> ppp sound / soc / codecs / wm5102 . c <nl> static int wm5102_sysclk_ev ( struct snd_soc_dapm_widget * w , <nl> struct snd_kcontrol * kcontrol , int event ) <nl> { <nl> struct snd_soc_codec * codec = w -> codec ; <nl> - struct arizona * arizona = dev_get_drvdata ( codec -> dev ); <nl> + struct arizona * arizona = dev_get_drvdata ( codec -> dev -> parent ); <nl> struct regmap * regmap = codec -> control_data ; <nl> const struct reg_default * patch = NULL ; <nl> int i , patch_size ;
mmm Documentation / lguest / lguest . c <nl> ppp Documentation / lguest / lguest . c <nl> struct virtqueue <nl> /* Remember the arguments to the program so we can " reboot " */ <nl> static char ** main_args ; <nl>  <nl> -/* Since guest is UP and we don ' t run at the same time , we don ' t need barriers . <nl> - * But I include them in the code in case others copy it . */ <nl> -# define wmb () <nl> +/* We have to be careful with barriers : our devices are all run in separate <nl> + * threads and so we need to make sure that changes visible to the Guest happen <nl> + * in precise order . */ <nl> +# define wmb () __asm__ __volatile__ ("" : : : " memory ") <nl>  <nl> /* Convert an iovec element to the given type . <nl> *
mmm drivers / scsi / sr_ioctl . c <nl> ppp drivers / scsi / sr_ioctl . c <nl> int sr_do_ioctl ( Scsi_CD * cd , struct packet_command * cgc ) <nl> struct scsi_device * SDev ; <nl> struct scsi_sense_hdr sshdr ; <nl> int result , err = 0 , retries = 0 ; <nl> + unsigned char sense_buffer [ SCSI_SENSE_BUFFERSIZE ], * senseptr = NULL ; <nl>  <nl> SDev = cd -> device ; <nl>  <nl> + if ( cgc -> sense ) <nl> + senseptr = sense_buffer ; <nl> + <nl> retry : <nl> if (! scsi_block_when_processing_errors ( SDev )) { <nl> err = - ENODEV ; <nl> int sr_do_ioctl ( Scsi_CD * cd , struct packet_command * cgc ) <nl> } <nl>  <nl> result = scsi_execute ( SDev , cgc -> cmd , cgc -> data_direction , <nl> - cgc -> buffer , cgc -> buflen , <nl> - ( unsigned char *) cgc -> sense , & sshdr , <nl> + cgc -> buffer , cgc -> buflen , senseptr , & sshdr , <nl> cgc -> timeout , IOCTL_RETRIES , 0 , 0 , NULL ); <nl>  <nl> + if ( cgc -> sense ) <nl> + memcpy ( cgc -> sense , sense_buffer , sizeof (* cgc -> sense )); <nl> + <nl> /* Minimal error checking . Ignore cases we know about , and report the rest . */ <nl> if ( driver_byte ( result ) != 0 ) { <nl> switch ( sshdr . sense_key ) {
mmm drivers / iommu / intel - iommu . c <nl> ppp drivers / iommu / intel - iommu . c <nl> static int domain_context_mapping_one ( struct dmar_domain * domain , <nl> if ( context_copied ( context )) { <nl> u16 did_old = context_domain_id ( context ); <nl>  <nl> - if ( did_old >= 0 && did_old < cap_ndoms ( iommu -> cap )) <nl> + if ( did_old >= 0 && did_old < cap_ndoms ( iommu -> cap )) { <nl> iommu -> flush . flush_context ( iommu , did_old , <nl> ((( u16 ) bus ) << 8 ) | devfn , <nl> DMA_CCMD_MASK_NOBIT , <nl> DMA_CCMD_DEVICE_INVL ); <nl> + iommu -> flush . flush_iotlb ( iommu , did_old , 0 , 0 , <nl> + DMA_TLB_DSI_FLUSH ); <nl> + } <nl> } <nl>  <nl> pgd = domain -> pgd ;
mmm drivers / gpu / drm / i915 / intel_lrc . c <nl> ppp drivers / gpu / drm / i915 / intel_lrc . c <nl> void intel_lrc_irq_handler ( struct intel_engine_cs * ring ) <nl>  <nl> spin_unlock (& ring -> execlist_lock ); <nl>  <nl> - WARN ( submit_contexts > 2 , " More than two context complete events ?\ n "); <nl> + if ( unlikely ( submit_contexts > 2 )) <nl> + DRM_ERROR (" More than two context complete events ?\ n "); <nl> + <nl> ring -> next_context_status_buffer = write_pointer % GEN8_CSB_ENTRIES ; <nl>  <nl> /* Update the read pointer to the old write pointer . Manual ringbuffer
mmm net / xfrm / xfrm_user . c <nl> ppp net / xfrm / xfrm_user . c <nl> static int xfrm_del_sa ( struct sk_buff * skb , struct nlmsghdr * nlh , <nl>  <nl> static void copy_to_user_state ( struct xfrm_state * x , struct xfrm_usersa_info * p ) <nl> { <nl> + memset ( p , 0 , sizeof (* p )); <nl> memcpy (& p -> id , & x -> id , sizeof ( p -> id )); <nl> memcpy (& p -> sel , & x -> sel , sizeof ( p -> sel )); <nl> memcpy (& p -> lft , & x -> lft , sizeof ( p -> lft ));
mmm arch / powerpc / mm / pgtable - radix . c <nl> ppp arch / powerpc / mm / pgtable - radix . c <nl> void radix__mark_rodata_ro ( void ) <nl> { <nl> unsigned long start , end ; <nl>  <nl> + /* <nl> + * mark_rodata_ro () will mark itself as ! writable at some point . <nl> + * Due to DD1 workaround in radix__pte_update (), we ' ll end up with <nl> + * an invalid pte and the system will crash quite severly . <nl> + */ <nl> + if ( cpu_has_feature ( CPU_FTR_POWER9_DD1 )) { <nl> + pr_warn (" Warning : Unable to mark rodata read only on P9 DD1 \ n "); <nl> + return ; <nl> + } <nl> + <nl> start = ( unsigned long ) _stext ; <nl> end = ( unsigned long ) __init_begin ; <nl> 
mmm drivers / net / ethernet / xilinx / ll_temac_main . c <nl> ppp drivers / net / ethernet / xilinx / ll_temac_main . c <nl> void temac_indirect_out32 ( struct temac_local * lp , int reg , u32 value ) <nl> return ; <nl> temac_iow ( lp , XTE_LSW0_OFFSET , value ); <nl> temac_iow ( lp , XTE_CTL0_OFFSET , CNTLREG_WRITE_ENABLE_MASK | reg ); <nl> + temac_indirect_busywait ( lp ); <nl> } <nl>  <nl> /**
mmm fs / ext2 / ialloc . c <nl> ppp fs / ext2 / ialloc . c <nl> struct inode * ext2_new_inode ( struct inode * dir , umode_t mode , <nl>  <nl> for ( i = 0 ; i < sbi -> s_groups_count ; i ++) { <nl> gdp = ext2_get_group_desc ( sb , group , & bh2 ); <nl> + if (! gdp ) { <nl> + if (++ group == sbi -> s_groups_count ) <nl> + group = 0 ; <nl> + continue ; <nl> + } <nl> brelse ( bitmap_bh ); <nl> bitmap_bh = read_inode_bitmap ( sb , group ); <nl> if (! bitmap_bh ) {
mmm drivers / uwb / drp . c <nl> ppp drivers / uwb / drp . c <nl> static void uwb_drp_handle_alien_drp ( struct uwb_rc * rc , struct uwb_ie_drp * drp_i <nl>  <nl> /* alloc and initialize new uwb_cnflt_alien */ <nl> cnflt = kzalloc ( sizeof ( struct uwb_cnflt_alien ), GFP_KERNEL ); <nl> - if (! cnflt ) <nl> + if (! cnflt ) { <nl> dev_err ( dev , " failed to alloc uwb_cnflt_alien struct \ n "); <nl> + return ; <nl> + } <nl> + <nl> INIT_LIST_HEAD (& cnflt -> rc_node ); <nl> init_timer (& cnflt -> timer ); <nl> cnflt -> timer . function = uwb_cnflt_timer ;
mmm drivers / scsi / qla2xxx / qla_isr . c <nl> ppp drivers / scsi / qla2xxx / qla_isr . c <nl> qla25xx_process_bidir_status_iocb ( scsi_qla_host_t * vha , void * pkt , <nl> bsg_job -> reply_len = sizeof ( struct fc_bsg_reply ); <nl> /* Always return DID_OK , bsg will send the vendor specific response <nl> * in this case only */ <nl> - sp -> done ( sp , DID_OK << 6 ); <nl> + sp -> done ( sp , DID_OK << 16 ); <nl>  <nl> } <nl> 
mmm drivers / pnp / pnpacpi / rsparser . c <nl> ppp drivers / pnp / pnpacpi / rsparser . c <nl> static void pnpacpi_encode_ext_irq ( struct acpi_resource * resource , <nl> resource -> data . extended_irq . triggering = triggering ; <nl> resource -> data . extended_irq . polarity = polarity ; <nl> if ( triggering == ACPI_EDGE_SENSITIVE ) <nl> - resource -> data . irq . sharable = ACPI_EXCLUSIVE ; <nl> + resource -> data . extended_irq . sharable = ACPI_EXCLUSIVE ; <nl> else <nl> - resource -> data . irq . sharable = ACPI_SHARED ; <nl> + resource -> data . extended_irq . sharable = ACPI_SHARED ; <nl> resource -> data . extended_irq . interrupt_count = 1 ; <nl> resource -> data . extended_irq . interrupts [ 0 ] = p -> start ; <nl> }
mmm drivers / net / ethernet / calxeda / xgmac . c <nl> ppp drivers / net / ethernet / calxeda / xgmac . c <nl> static int xgmac_hw_init ( struct net_device * dev ) <nl> DMA_BUS_MODE_FB | DMA_BUS_MODE_ATDS | DMA_BUS_MODE_AAL ; <nl> writel ( value , ioaddr + XGMAC_DMA_BUS_MODE ); <nl>  <nl> - /* Enable interrupts */ <nl> - writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_STATUS ); <nl> - writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_INTR_ENA ); <nl> + writel ( 0 , ioaddr + XGMAC_DMA_INTR_ENA ); <nl>  <nl> /* Mask power mgt interrupt */ <nl> writel ( XGMAC_INT_STAT_PMTIM , ioaddr + XGMAC_INT_STAT ); <nl> static int xgmac_open ( struct net_device * dev ) <nl> napi_enable (& priv -> napi ); <nl> netif_start_queue ( dev ); <nl>  <nl> + /* Enable interrupts */ <nl> + writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_STATUS ); <nl> + writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_INTR_ENA ); <nl> + <nl> return 0 ; <nl> } <nl> 
mmm sound / soc / intel / skylake / skl - sst . c <nl> ppp sound / soc / intel / skylake / skl - sst . c <nl> static int skl_unload_module ( struct sst_dsp * ctx , u16 mod_id ) <nl> dev_err ( ctx -> dev , " Module bad usage cnt !:% d \ n ", usage_cnt ); <nl> return - EIO ; <nl> } <nl> + <nl> + /* if module is used by others return , no need to unload */ <nl> + if ( usage_cnt > 0 ) <nl> + return 0 ; <nl> + <nl> ret = skl_ipc_unload_modules (& skl -> ipc , <nl> SKL_NUM_MODULES , & mod_id ); <nl> if ( ret < 0 ) {
mmm drivers / mtd / ubi / vtbl . c <nl> ppp drivers / mtd / ubi / vtbl . c <nl> static int init_volumes ( struct ubi_device * ubi , const struct ubi_scan_info * si , <nl> if ( ubi -> autoresize_vol_id != - 1 ) { <nl> ubi_err (" more then one auto - resize volume (% d " <nl> " and % d )", ubi -> autoresize_vol_id , i ); <nl> + kfree ( vol ); <nl> return - EINVAL ; <nl> } <nl> 
mmm drivers / scsi / aic7xxx / aic7xxx_osm . c <nl> ppp drivers / scsi / aic7xxx / aic7xxx_osm . c <nl> ahc_send_async ( struct ahc_softc * ahc , char channel , <nl> spi_period ( starget ) = tinfo -> curr . period ; <nl> spi_width ( starget ) = tinfo -> curr . width ; <nl> spi_offset ( starget ) = tinfo -> curr . offset ; <nl> - spi_dt ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_DT_REQ ; <nl> - spi_qas ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_QAS_REQ ; <nl> - spi_iu ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_IU_REQ ; <nl> + spi_dt ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_DT_REQ ? 1 : 0 ; <nl> + spi_qas ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_QAS_REQ ? 1 : 0 ; <nl> + spi_iu ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_IU_REQ ? 1 : 0 ; <nl> spi_display_xfer_agreement ( starget ); <nl> break ; <nl> } <nl> static void ahc_linux_set_dt ( struct scsi_target * starget , int dt ) <nl> if ( dt ) { <nl> period = 9 ; /* 12 . 5ns is the only period valid for DT */ <nl> ppr_options |= MSG_EXT_PPR_DT_REQ ; <nl> - } else if ( period == 9 ) <nl> + } else if ( period == 9 ) { <nl> period = 10 ; /* if resetting DT , period must be >= 25ns */ <nl> + ppr_options &= ~ MSG_EXT_PPR_DT_REQ ; <nl> + } <nl>  <nl> ahc_compile_devinfo (& devinfo , shost -> this_id , starget -> id , 0 , <nl> starget -> channel + ' A ', ROLE_INITIATOR );
mmm fs / btrfs / ioctl . c <nl> ppp fs / btrfs / ioctl . c <nl> static noinline long btrfs_ioctl_clone ( struct file * file , unsigned long srcfd , <nl> btrfs_wait_ordered_range ( src , off , len ); <nl> } <nl>  <nl> + /* truncate page cache pages from target inode range */ <nl> + truncate_inode_pages_range (& inode -> i_data , off , <nl> + ALIGN ( off + len , PAGE_CACHE_SIZE ) - 1 ); <nl> + <nl> /* clone data */ <nl> key . objectid = btrfs_ino ( src ); <nl> key . type = BTRFS_EXTENT_DATA_KEY ;
mmm kernel / trace / trace . c <nl> ppp kernel / trace / trace . c <nl> static ssize_t tracing_splice_read_pipe ( struct file * filp , <nl> . partial = partial_def , <nl> . nr_pages = 0 , /* This gets updated below . */ <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & tracing_pipe_buf_ops , <nl> . spd_release = tracing_spd_release_pipe , <nl> }; <nl> tracing_buffers_splice_read ( struct file * file , loff_t * ppos , <nl> . pages = pages_def , <nl> . partial = partial_def , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & buffer_pipe_buf_ops , <nl> . spd_release = buffer_spd_release , <nl> };mmm kernel / relay . c <nl> ppp kernel / relay . c <nl> static ssize_t tracing_splice_read_pipe ( struct file * filp , <nl> . partial = partial_def , <nl> . nr_pages = 0 , /* This gets updated below . */ <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & tracing_pipe_buf_ops , <nl> . spd_release = tracing_spd_release_pipe , <nl> }; <nl> tracing_buffers_splice_read ( struct file * file , loff_t * ppos , <nl> . pages = pages_def , <nl> . partial = partial_def , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & buffer_pipe_buf_ops , <nl> . spd_release = buffer_spd_release , <nl> }; <nl> static ssize_t subbuf_splice_actor ( struct file * in , <nl> . nr_pages = 0 , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> . partial = partial , <nl> - . flags = flags , <nl> . ops = & relay_pipe_buf_ops , <nl> . spd_release = relay_page_release , <nl> };mmm include / linux / splice . h <nl> ppp include / linux / splice . h <nl> static ssize_t tracing_splice_read_pipe ( struct file * filp , <nl> . partial = partial_def , <nl> . nr_pages = 0 , /* This gets updated below . */ <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & tracing_pipe_buf_ops , <nl> . spd_release = tracing_spd_release_pipe , <nl> }; <nl> tracing_buffers_splice_read ( struct file * file , loff_t * ppos , <nl> . pages = pages_def , <nl> . partial = partial_def , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & buffer_pipe_buf_ops , <nl> . spd_release = buffer_spd_release , <nl> }; <nl> static ssize_t subbuf_splice_actor ( struct file * in , <nl> . nr_pages = 0 , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> . partial = partial , <nl> - . flags = flags , <nl> . ops = & relay_pipe_buf_ops , <nl> . spd_release = relay_page_release , <nl> }; <nl> struct splice_pipe_desc { <nl> struct partial_page * partial ; /* pages [] may not be contig */ <nl> int nr_pages ; /* number of populated pages in map */ <nl> unsigned int nr_pages_max ; /* pages [] & partial [] arrays size */ <nl> - unsigned int flags ; /* splice flags */ <nl> const struct pipe_buf_operations * ops ;/* ops associated with output pipe */ <nl> void (* spd_release )( struct splice_pipe_desc *, unsigned int ); <nl> };mmm net / core / skbuff . c <nl> ppp net / core / skbuff . c <nl> static ssize_t tracing_splice_read_pipe ( struct file * filp , <nl> . partial = partial_def , <nl> . nr_pages = 0 , /* This gets updated below . */ <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & tracing_pipe_buf_ops , <nl> . spd_release = tracing_spd_release_pipe , <nl> }; <nl> tracing_buffers_splice_read ( struct file * file , loff_t * ppos , <nl> . pages = pages_def , <nl> . partial = partial_def , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> - . flags = flags , <nl> . ops = & buffer_pipe_buf_ops , <nl> . spd_release = buffer_spd_release , <nl> }; <nl> static ssize_t subbuf_splice_actor ( struct file * in , <nl> . nr_pages = 0 , <nl> . nr_pages_max = PIPE_DEF_BUFFERS , <nl> . partial = partial , <nl> - . flags = flags , <nl> . ops = & relay_pipe_buf_ops , <nl> . spd_release = relay_page_release , <nl> }; <nl> struct splice_pipe_desc { <nl> struct partial_page * partial ; /* pages [] may not be contig */ <nl> int nr_pages ; /* number of populated pages in map */ <nl> unsigned int nr_pages_max ; /* pages [] & partial [] arrays size */ <nl> - unsigned int flags ; /* splice flags */ <nl> const struct pipe_buf_operations * ops ;/* ops associated with output pipe */ <nl> void (* spd_release )( struct splice_pipe_desc *, unsigned int ); <nl> }; <nl> int skb_splice_bits ( struct sk_buff * skb , struct sock * sk , unsigned int offset , <nl> . pages = pages , <nl> . partial = partial , <nl> . nr_pages_max = MAX_SKB_FRAGS , <nl> - . flags = flags , <nl> . ops = & nosteal_pipe_buf_ops , <nl> . spd_release = sock_spd_release , <nl> };
mmm drivers / net / wireless / wl12xx / wl1271_spi . c <nl> ppp drivers / net / wireless / wl12xx / wl1271_spi . c <nl> static void wl1271_spi_reset ( struct wl1271 * wl ) <nl> spi_message_add_tail (& t , & m ); <nl>  <nl> spi_sync ( wl_to_spi ( wl ), & m ); <nl> + kfree ( cmd ); <nl>  <nl> wl1271_dump ( DEBUG_SPI , " spi reset -> ", cmd , WSPI_INIT_CMD_LEN ); <nl> } <nl> static void wl1271_spi_init ( struct wl1271 * wl ) <nl> spi_message_add_tail (& t , & m ); <nl>  <nl> spi_sync ( wl_to_spi ( wl ), & m ); <nl> + kfree ( cmd ); <nl>  <nl> wl1271_dump ( DEBUG_SPI , " spi init -> ", cmd , WSPI_INIT_CMD_LEN ); <nl> }
mmm net / xfrm / xfrm_user . c <nl> ppp net / xfrm / xfrm_user . c <nl> static inline int xfrm_replay_verify_len ( struct xfrm_replay_state_esn * replay_es <nl> up = nla_data ( rp ); <nl> ulen = xfrm_replay_state_esn_len ( up ); <nl>  <nl> - if ( nla_len ( rp ) < ulen || xfrm_replay_state_esn_len ( replay_esn ) != ulen ) <nl> + /* Check the overall length and the internal bitmap length to avoid <nl> + * potential overflow . */ <nl> + if ( nla_len ( rp ) < ulen || <nl> + xfrm_replay_state_esn_len ( replay_esn ) != ulen || <nl> + replay_esn -> bmp_len != up -> bmp_len ) <nl> return - EINVAL ; <nl>  <nl> if ( up -> replay_window > up -> bmp_len * sizeof ( __u32 ) * 8 )
mmm arch / powerpc / sysdev / qe_lib / ucc . c <nl> ppp arch / powerpc / sysdev / qe_lib / ucc . c <nl> int ucc_set_qe_mux_rxtx ( int ucc_num , enum qe_clock clock , enum comm_dir mode ) <nl> case QE_CLK18 : source = 8 ; break ; <nl> case QE_CLK7 : source = 9 ; break ; <nl> case QE_CLK8 : source = 10 ; break ; <nl> + case QE_CLK16 : source = 11 ; break ; <nl> default : source = - 1 ; break ; <nl> } <nl> break ; <nl> int ucc_set_qe_mux_rxtx ( int ucc_num , enum qe_clock clock , enum comm_dir mode ) <nl> case QE_CLK22 : source = 8 ; break ; <nl> case QE_CLK7 : source = 9 ; break ; <nl> case QE_CLK8 : source = 10 ; break ; <nl> + case QE_CLK16 : source = 11 ; break ; <nl> default : source = - 1 ; break ; <nl> } <nl> break ;
mmm drivers / staging / rtl8192u / r819xU_firmware . c <nl> ppp drivers / staging / rtl8192u / r819xU_firmware . c <nl> bool fw_download_code ( struct net_device * dev , u8 * code_virtual_address , u32 buff <nl> * add 4 to avoid packet appending overflow . <nl> * */ <nl> skb = dev_alloc_skb ( USB_HWDESC_HEADER_LEN + frag_length + 4 ); <nl> + if (! skb ) <nl> + return false ; <nl> memcpy (( unsigned char *)( skb -> cb ),& dev , sizeof ( dev )); <nl> tcb_desc = ( cb_desc *)( skb -> cb + MAX_DEV_ADDR_SIZE ); <nl> tcb_desc -> queue_index = TXCMD_QUEUE ;
mmm drivers / scsi / aacraid / linit . c <nl> ppp drivers / scsi / aacraid / linit . c <nl> static long aac_compat_do_ioctl ( struct aac_dev * dev , unsigned cmd , unsigned long <nl> static int aac_compat_ioctl ( struct scsi_device * sdev , int cmd , void __user * arg ) <nl> { <nl> struct aac_dev * dev = ( struct aac_dev *) sdev -> host -> hostdata ; <nl> + if (! capable ( CAP_SYS_RAWIO )) <nl> + return - EPERM ; <nl> return aac_compat_do_ioctl ( dev , cmd , ( unsigned long ) arg ); <nl> } <nl> 
mmm drivers / net / wireless / intel / iwlwifi / pcie / tx - gen2 . c <nl> ppp drivers / net / wireless / intel / iwlwifi / pcie / tx - gen2 . c <nl> int iwl_trans_pcie_dyn_txq_alloc ( struct iwl_trans * trans , <nl> rsp = ( void *) hcmd . resp_pkt -> data ; <nl> qid = le16_to_cpu ( rsp -> queue_number ); <nl>  <nl> - if ( qid > ARRAY_SIZE ( trans_pcie -> txq )) { <nl> + if ( qid >= ARRAY_SIZE ( trans_pcie -> txq )) { <nl> WARN_ONCE ( 1 , " queue index % d unsupported ", qid ); <nl> ret = - EIO ; <nl> goto error_free_resp ;
mmm net / xfrm / xfrm_policy . c <nl> ppp net / xfrm / xfrm_policy . c <nl> static int xfrm_expand_policies ( const struct flowi * fl , u16 family , <nl> * num_xfrms = 0 ; <nl> return 0 ; <nl> } <nl> - if ( IS_ERR ( pols [ 0 ])) <nl> + if ( IS_ERR ( pols [ 0 ])) { <nl> + * num_pols = 0 ; <nl> return PTR_ERR ( pols [ 0 ]); <nl> + } <nl>  <nl> * num_xfrms = pols [ 0 ]-> xfrm_nr ; <nl>  <nl> static int xfrm_expand_policies ( const struct flowi * fl , u16 family , <nl> if ( pols [ 1 ]) { <nl> if ( IS_ERR ( pols [ 1 ])) { <nl> xfrm_pols_put ( pols , * num_pols ); <nl> + * num_pols = 0 ; <nl> return PTR_ERR ( pols [ 1 ]); <nl> } <nl> (* num_pols )++;
mmm net / netfilter / nft_hash . c <nl> ppp net / netfilter / nft_hash . c <nl> static int nft_hash_init ( const struct nft_ctx * ctx , <nl> if (! tb [ NFTA_HASH_SREG ] || <nl> ! tb [ NFTA_HASH_DREG ] || <nl> ! tb [ NFTA_HASH_LEN ] || <nl> - ! tb [ NFTA_HASH_SEED ] || <nl> ! tb [ NFTA_HASH_MODULUS ]) <nl> return - EINVAL ; <nl>  <nl> static int nft_hash_init ( const struct nft_ctx * ctx , <nl> if ( priv -> offset + priv -> modulus - 1 < priv -> offset ) <nl> return - EOVERFLOW ; <nl>  <nl> - priv -> seed = ntohl ( nla_get_be32 ( tb [ NFTA_HASH_SEED ])); <nl> + if ( tb [ NFTA_HASH_SEED ]) <nl> + priv -> seed = ntohl ( nla_get_be32 ( tb [ NFTA_HASH_SEED ])); <nl> + else <nl> + get_random_bytes (& priv -> seed , sizeof ( priv -> seed )); <nl>  <nl> return nft_validate_register_load ( priv -> sreg , len ) && <nl> nft_validate_register_store ( ctx , priv -> dreg , NULL ,
mmm drivers / md / bcache / super . c <nl> ppp drivers / md / bcache / super . c <nl> static void cache_set_flush ( struct closure * cl ) <nl> struct btree * b ; <nl> unsigned i ; <nl>  <nl> + if (! c ) <nl> + closure_return ( cl ); <nl> + <nl> bch_cache_accounting_destroy (& c -> accounting ); <nl>  <nl> kobject_put (& c -> internal );
mmm drivers / mfd / stm32 - timers . c <nl> ppp drivers / mfd / stm32 - timers . c <nl> static int stm32_timers_probe ( struct platform_device * pdev ) <nl> return of_platform_populate ( pdev -> dev . of_node , NULL , NULL , & pdev -> dev ); <nl> } <nl>  <nl> + static int stm32_timers_remove ( struct platform_device * pdev ) <nl> +{ <nl> + of_platform_depopulate (& pdev -> dev ); <nl> + <nl> + return 0 ; <nl> +} <nl> + <nl> static const struct of_device_id stm32_timers_of_match [] = { <nl> { . compatible = " st , stm32 - timers ", }, <nl> { /* end node */ }, <nl> MODULE_DEVICE_TABLE ( of , stm32_timers_of_match ); <nl>  <nl> static struct platform_driver stm32_timers_driver = { <nl> . probe = stm32_timers_probe , <nl> + . remove = stm32_timers_remove , <nl> . driver = { <nl> . name = " stm32 - timers ", <nl> . of_match_table = stm32_timers_of_match ,
mmm drivers / gpu / drm / drm_crtc . c <nl> ppp drivers / gpu / drm / drm_crtc . c <nl> void drm_mode_config_reset ( struct drm_device * dev ) <nl> if ( encoder -> funcs -> reset ) <nl> encoder -> funcs -> reset ( encoder ); <nl>  <nl> + mutex_lock (& dev -> mode_config . mutex ); <nl> drm_for_each_connector ( connector , dev ) { <nl> connector -> status = connector_status_unknown ; <nl>  <nl> if ( connector -> funcs -> reset ) <nl> connector -> funcs -> reset ( connector ); <nl> } <nl> + mutex_unlock (& dev -> mode_config . mutex ); <nl> } <nl> EXPORT_SYMBOL ( drm_mode_config_reset ); <nl> 
mmm drivers / net / wireless / iwlwifi / dvm / power . c <nl> ppp drivers / net / wireless / iwlwifi / dvm / power . c <nl> # include " commands . h " <nl> # include " power . h " <nl>  <nl> - static bool force_cam ; <nl> + static bool force_cam = true ; <nl> module_param ( force_cam , bool , 0644 ); <nl> MODULE_PARM_DESC ( force_cam , " force continuously aware mode ( no power saving at all )"); <nl> 
mmm drivers / net / netxen / netxen_nic_init . c <nl> ppp drivers / net / netxen / netxen_nic_init . c <nl> static inline int do_rom_fast_write_words ( struct netxen_adapter * adapter , <nl> while ( 1 ) { <nl> int data1 ; <nl>  <nl> - do_rom_fast_read ( adapter , addridx , & data1 ); <nl> + ret = do_rom_fast_read ( adapter , addridx , & data1 ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> + <nl> if ( data1 == data ) <nl> break ; <nl> 
mmm net / bridge / br_netfilter . c <nl> ppp net / bridge / br_netfilter . c <nl> static int br_parse_ip_options ( struct sk_buff * skb ) <nl> goto drop ; <nl> } <nl>  <nl> - /* Zero out the CB buffer if no options present */ <nl> - if ( iph -> ihl == 5 ) { <nl> - memset ( IPCB ( skb ), 0 , sizeof ( struct inet_skb_parm )); <nl> + memset ( IPCB ( skb ), 0 , sizeof ( struct inet_skb_parm )); <nl> + if ( iph -> ihl == 5 ) <nl> return 0 ; <nl> - } <nl>  <nl> opt -> optlen = iph -> ihl * 4 - sizeof ( struct iphdr ); <nl> if ( ip_options_compile ( dev_net ( dev ), opt , skb ))
mmm drivers / spi / spi - imx . c <nl> ppp drivers / spi / spi - imx . c <nl> static int spi_imx_dma_transfer ( struct spi_imx_data * spi_imx , <nl> tx -> sgl , tx -> nents , DMA_MEM_TO_DEV , <nl> DMA_PREP_INTERRUPT | DMA_CTRL_ACK ); <nl> if (! desc_tx ) <nl> - goto no_dma ; <nl> + goto tx_nodma ; <nl>  <nl> desc_tx -> callback = spi_imx_dma_tx_callback ; <nl> desc_tx -> callback_param = ( void *) spi_imx ; <nl> static int spi_imx_dma_transfer ( struct spi_imx_data * spi_imx , <nl> rx -> sgl , rx -> nents , DMA_DEV_TO_MEM , <nl> DMA_PREP_INTERRUPT | DMA_CTRL_ACK ); <nl> if (! desc_rx ) <nl> - goto no_dma ; <nl> + goto rx_nodma ; <nl>  <nl> desc_rx -> callback = spi_imx_dma_rx_callback ; <nl> desc_rx -> callback_param = ( void *) spi_imx ; <nl> static int spi_imx_dma_transfer ( struct spi_imx_data * spi_imx , <nl>  <nl> return ret ; <nl>  <nl> - no_dma : <nl> + rx_nodma : <nl> + dmaengine_terminate_all ( master -> dma_tx ); <nl> + tx_nodma : <nl> pr_warn_once ("% s % s : DMA not available , falling back to PIO \ n ", <nl> dev_driver_string (& master -> dev ), <nl> dev_name (& master -> dev ));
mmm drivers / scsi / libfc / fc_exch . c <nl> ppp drivers / scsi / libfc / fc_exch . c <nl> static struct fc_exch * fc_exch_em_alloc ( struct fc_lport * lport , <nl> * EM is selected when a NULL match function pointer is encountered <nl> * or when a call to a match function returns true . <nl> */ <nl> - static inline struct fc_exch * fc_exch_alloc ( struct fc_lport * lport , <nl> - struct fc_frame * fp ) <nl> + static struct fc_exch * fc_exch_alloc ( struct fc_lport * lport , <nl> + struct fc_frame * fp ) <nl> { <nl> struct fc_exch_mgr_anchor * ema ; <nl> + struct fc_exch * ep ; <nl>  <nl> - list_for_each_entry ( ema , & lport -> ema_list , ema_list ) <nl> - if (! ema -> match || ema -> match ( fp )) <nl> - return fc_exch_em_alloc ( lport , ema -> mp ); <nl> + list_for_each_entry ( ema , & lport -> ema_list , ema_list ) { <nl> + if (! ema -> match || ema -> match ( fp )) { <nl> + ep = fc_exch_em_alloc ( lport , ema -> mp ); <nl> + if ( ep ) <nl> + return ep ; <nl> + } <nl> + } <nl> return NULL ; <nl> } <nl> 
mmm fs / autofs4 / expire . c <nl> ppp fs / autofs4 / expire . c <nl> static int autofs4_tree_busy ( struct vfsmount * mnt , <nl> struct autofs_info * ino = autofs4_dentry_ino ( p ); <nl> unsigned int ino_count = atomic_read (& ino -> count ); <nl>  <nl> + /* <nl> + * Clean stale dentries below that have not been <nl> + * invalidated after a mount fail during lookup <nl> + */ <nl> + d_invalidate ( p ); <nl> + <nl> /* allow for dget above and top is already dgot */ <nl> if ( p == top ) <nl> ino_count += 2 ;
mmm net / netfilter / ipvs / ip_vs_core . c <nl> ppp net / netfilter / ipvs / ip_vs_core . c <nl> static inline bool is_new_conn_expected ( const struct ip_vs_conn * cp , <nl> switch ( cp -> protocol ) { <nl> case IPPROTO_TCP : <nl> return ( cp -> state == IP_VS_TCP_S_TIME_WAIT ) || <nl> + ( cp -> state == IP_VS_TCP_S_CLOSE ) || <nl> (( conn_reuse_mode & 2 ) && <nl> ( cp -> state == IP_VS_TCP_S_FIN_WAIT ) && <nl> ( cp -> flags & IP_VS_CONN_F_NOOUTPUT ));
mmm drivers / hwmon / applesmc . c <nl> ppp drivers / hwmon / applesmc . c <nl> static const char * temperature_sensors_sets [][ 36 ] = { <nl> /* Set 5 : iMac */ <nl> { " TC0D ", " TA0P ", " TG0P ", " TG0D ", " TG0H ", " TH0P ", " Tm0P ", " TO0P ", <nl> " Tp0C ", NULL }, <nl> +/* Set 6 : Macbook3 set */ <nl> + { " TB0T ", " TC0D ", " TC0P ", " TM0P ", " TN0P ", " TTF0 ", " TW0P ", " Th0H ", <nl> + " Th0S ", " Th1H ", NULL }, <nl> }; <nl>  <nl> /* List of keys used to read / write fan speeds */ <nl> static __initdata struct dmi_match_data applesmc_dmi_data [] = { <nl> { . accelerometer = 0 , . light = 0 , . temperature_set = 4 }, <nl> /* iMac : temperature set 5 */ <nl> { . accelerometer = 0 , . light = 0 , . temperature_set = 5 }, <nl> +/* MacBook3 : accelerometer and temperature set 6 */ <nl> + { . accelerometer = 1 , . light = 0 , . temperature_set = 6 }, <nl> }; <nl>  <nl> /* Note that DMI_MATCH (...," MacBook ") will match " MacBookPro1 , 1 ". <nl> static __initdata struct dmi_system_id applesmc_whitelist [] = { <nl> DMI_MATCH ( DMI_BOARD_VENDOR ," Apple "), <nl> DMI_MATCH ( DMI_PRODUCT_NAME ," MacBookPro ") }, <nl> ( void *)& applesmc_dmi_data [ 0 ]}, <nl> - { applesmc_dmi_match , " Apple MacBook ", { <nl> + { applesmc_dmi_match , " Apple MacBook ( v2 )", { <nl> DMI_MATCH ( DMI_BOARD_VENDOR ," Apple "), <nl> DMI_MATCH ( DMI_PRODUCT_NAME ," MacBook2 ") }, <nl> ( void *)& applesmc_dmi_data [ 1 ]}, <nl> + { applesmc_dmi_match , " Apple MacBook ( v3 )", { <nl> + DMI_MATCH ( DMI_BOARD_VENDOR ," Apple "), <nl> + DMI_MATCH ( DMI_PRODUCT_NAME ," MacBook3 ") }, <nl> + ( void *)& applesmc_dmi_data [ 6 ]}, <nl> { applesmc_dmi_match , " Apple MacBook ", { <nl> DMI_MATCH ( DMI_BOARD_VENDOR ," Apple "), <nl> DMI_MATCH ( DMI_PRODUCT_NAME ," MacBook ") },
mmm drivers / video / atmel_lcdfb . c <nl> ppp drivers / video / atmel_lcdfb . c <nl> static int atmel_lcdfb_check_var ( struct fb_var_screeninfo * var , <nl> var -> transp . offset = var -> transp . length = 0 ; <nl> var -> xoffset = var -> yoffset = 0 ; <nl>  <nl> + if ( info -> fix . smem_len ) { <nl> + unsigned int smem_len = ( var -> xres_virtual * var -> yres_virtual <nl> + * (( var -> bits_per_pixel + 7 ) / 8 )); <nl> + if ( smem_len > info -> fix . smem_len ) <nl> + return - EINVAL ; <nl> + } <nl> + <nl> /* Saturate vertical and horizontal timings at maximum values */ <nl> var -> vsync_len = min_t ( u32 , var -> vsync_len , <nl> ( ATMEL_LCDC_VPW >> ATMEL_LCDC_VPW_OFFSET ) + 1 );
mmm drivers / infiniband / hw / ocrdma / ocrdma_verbs . c <nl> ppp drivers / infiniband / hw / ocrdma / ocrdma_verbs . c <nl> int ocrdma_arm_cq ( struct ib_cq * ibcq , enum ib_cq_notify_flags cq_flags ) <nl> if ( cq -> first_arm ) { <nl> ocrdma_ring_cq_db ( dev , cq_id , arm_needed , sol_needed , 0 ); <nl> cq -> first_arm = false ; <nl> - goto skip_defer ; <nl> } <nl> - cq -> deferred_arm = true ; <nl>  <nl> - skip_defer : <nl> + cq -> deferred_arm = true ; <nl> cq -> deferred_sol = sol_needed ; <nl> spin_unlock_irqrestore (& cq -> cq_lock , flags ); <nl> 
mmm arch / x86 / xen / grant - table . c <nl> ppp arch / x86 / xen / grant - table . c <nl> static int __init xlated_setup_gnttab_pages ( void ) <nl> rc = arch_gnttab_map_shared ( pfns , nr_grant_frames , nr_grant_frames , <nl> & xen_auto_xlat_grant_frames . vaddr ); <nl>  <nl> - kfree ( pages ); <nl> if ( rc ) { <nl> pr_warn ("% s Couldn ' t map % ld pfns rc :% d \ n ", __func__ , <nl> nr_grant_frames , rc ); <nl> free_xenballooned_pages ( nr_grant_frames , pages ); <nl> + kfree ( pages ); <nl> kfree ( pfns ); <nl> return rc ; <nl> } <nl> + kfree ( pages ); <nl>  <nl> xen_auto_xlat_grant_frames . pfn = pfns ; <nl> xen_auto_xlat_grant_frames . count = nr_grant_frames ;
mmm net / bluetooth / rfcomm / tty . c <nl> ppp net / bluetooth / rfcomm / tty . c <nl> static int rfcomm_get_dev_list ( void __user * arg ) <nl>  <nl> size = sizeof (* dl ) + dev_num * sizeof (* di ); <nl>  <nl> - dl = kmalloc ( size , GFP_KERNEL ); <nl> + dl = kzalloc ( size , GFP_KERNEL ); <nl> if (! dl ) <nl> return - ENOMEM ; <nl> 
mmm drivers / ide / ide - atapi . c <nl> ppp drivers / ide / ide - atapi . c <nl> ide_startstop_t ide_issue_pc ( ide_drive_t * drive , unsigned int timeout , <nl> { <nl> struct ide_atapi_pc * pc = drive -> pc ; <nl> ide_hwif_t * hwif = drive -> hwif ; <nl> + u32 tf_flags ; <nl> u16 bcount ; <nl> u8 scsi = !!( drive -> dev_flags & IDE_DFLAG_SCSI ); <nl>  <nl> ide_startstop_t ide_issue_pc ( ide_drive_t * drive , unsigned int timeout , <nl> if (! drive -> dma ) <nl> pc -> flags &= ~ PC_FLAG_DMA_OK ; <nl>  <nl> - ide_pktcmd_tf_load ( drive , scsi ? 0 : IDE_TFLAG_OUT_DEVICE , bcount , <nl> - drive -> dma ); <nl> + if ( scsi ) <nl> + tf_flags = 0 ; <nl> + else if ( drive -> media == ide_cdrom || drive -> media == ide_optical ) <nl> + tf_flags = IDE_TFLAG_OUT_NSECT | IDE_TFLAG_OUT_LBAL ; <nl> + else <nl> + tf_flags = IDE_TFLAG_OUT_DEVICE ; <nl> + <nl> + ide_pktcmd_tf_load ( drive , tf_flags , bcount , drive -> dma ); <nl>  <nl> /* Issue the packet command */ <nl> if ( drive -> atapi_flags & IDE_AFLAG_DRQ_INTERRUPT ) {
mmm include / linux / mm . h <nl> ppp include / linux / mm . h <nl> static inline bool is_pci_p2pdma_page ( const struct page * page ) <nl> } <nl> # endif /* CONFIG_DEV_PAGEMAP_OPS */ <nl>  <nl> +/* 127 : arbitrary random number , small enough to assemble well */ <nl> +# define page_ref_zero_or_close_to_overflow ( page ) \ <nl> + (( unsigned int ) page_ref_count ( page ) + 127u <= 127u ) <nl> + <nl> static inline void get_page ( struct page * page ) <nl> { <nl> page = compound_head ( page ); <nl> static inline void get_page ( struct page * page ) <nl> * Getting a normal page or the head of a compound page <nl> * requires to already have an elevated page -> _refcount . <nl> */ <nl> - VM_BUG_ON_PAGE ( page_ref_count ( page ) <= 0 , page ); <nl> + VM_BUG_ON_PAGE ( page_ref_zero_or_close_to_overflow ( page ), page ); <nl> page_ref_inc ( page ); <nl> } <nl> 
mmm fs / nfsd / nfs4xdr . c <nl> ppp fs / nfsd / nfs4xdr . c <nl> nfsd4_encode_getdeviceinfo ( struct nfsd4_compoundres * resp , __be32 nfserr , <nl> struct nfsd4_getdeviceinfo * gdev ) <nl> { <nl> struct xdr_stream * xdr = & resp -> xdr ; <nl> - const struct nfsd4_layout_ops * ops = <nl> - nfsd4_layout_ops [ gdev -> gd_layout_type ]; <nl> + const struct nfsd4_layout_ops * ops ; <nl> u32 starting_len = xdr -> buf -> len , needed_len ; <nl> __be32 * p ; <nl>  <nl> nfsd4_encode_getdeviceinfo ( struct nfsd4_compoundres * resp , __be32 nfserr , <nl>  <nl> /* If maxcount is 0 then just update notifications */ <nl> if ( gdev -> gd_maxcount != 0 ) { <nl> + ops = nfsd4_layout_ops [ gdev -> gd_layout_type ]; <nl> nfserr = ops -> encode_getdeviceinfo ( xdr , gdev ); <nl> if ( nfserr ) { <nl> /* <nl> nfsd4_encode_layoutget ( struct nfsd4_compoundres * resp , __be32 nfserr , <nl> struct nfsd4_layoutget * lgp ) <nl> { <nl> struct xdr_stream * xdr = & resp -> xdr ; <nl> - const struct nfsd4_layout_ops * ops = <nl> - nfsd4_layout_ops [ lgp -> lg_layout_type ]; <nl> + const struct nfsd4_layout_ops * ops ; <nl> __be32 * p ; <nl>  <nl> dprintk ("% s : err % d \ n ", __func__ , nfserr ); <nl> nfsd4_encode_layoutget ( struct nfsd4_compoundres * resp , __be32 nfserr , <nl> * p ++ = cpu_to_be32 ( lgp -> lg_seg . iomode ); <nl> * p ++ = cpu_to_be32 ( lgp -> lg_layout_type ); <nl>  <nl> + ops = nfsd4_layout_ops [ lgp -> lg_layout_type ]; <nl> nfserr = ops -> encode_layoutget ( xdr , lgp ); <nl> out : <nl> kfree ( lgp -> lg_content );
mmm drivers / net / ixgb / ixgb_main . c <nl> ppp drivers / net / ixgb / ixgb_main . c <nl> ixgb_restore_vlan ( struct ixgb_adapter * adapter ) <nl>  <nl> static void ixgb_netpoll ( struct net_device * dev ) <nl> { <nl> - struct ixgb_adapter * adapter = dev -> priv ; <nl> + struct ixgb_adapter * adapter = netdev_priv ( dev ); <nl>  <nl> disable_irq ( adapter -> pdev -> irq ); <nl> ixgb_intr ( adapter -> pdev -> irq , dev , NULL );
mmm ipc / mqueue . c <nl> ppp ipc / mqueue . c <nl> static int do_mq_notify ( mqd_t mqdes , const struct sigevent * notification ) <nl>  <nl> timeo = MAX_SCHEDULE_TIMEOUT ; <nl> ret = netlink_attachskb ( sock , nc , & timeo , NULL ); <nl> - if ( ret == 1 ) <nl> + if ( ret == 1 ) { <nl> + sock = NULL ; <nl> goto retry ; <nl> + } <nl> if ( ret ) { <nl> sock = NULL ; <nl> nc = NULL ;
mmm sound / soc / codecs / wm8903 . c <nl> ppp sound / soc / codecs / wm8903 . c <nl> static int wm8903_probe ( struct snd_soc_codec * codec ) <nl> /* power down chip */ <nl> static int wm8903_remove ( struct snd_soc_codec * codec ) <nl> { <nl> + struct wm8903_priv * wm8903 = snd_soc_codec_get_drvdata ( codec ); <nl> + <nl> wm8903_free_gpio ( codec ); <nl> wm8903_set_bias_level ( codec , SND_SOC_BIAS_OFF ); <nl> + if ( wm8903 -> irq ) <nl> + free_irq ( wm8903 -> irq , codec ); <nl> + <nl> return 0 ; <nl> } <nl> 
mmm net / netfilter / ipset / ip_set_core . c <nl> ppp net / netfilter / ipset / ip_set_core . c <nl> ip_set_net_exit ( struct net * net ) <nl>  <nl> inst -> is_deleted = true ; /* flag for ip_set_nfnl_put */ <nl>  <nl> + nfnl_lock ( NFNL_SUBSYS_IPSET ); <nl> for ( i = 0 ; i < inst -> ip_set_max ; i ++) { <nl> set = ip_set ( inst , i ); <nl> if ( set ) { <nl> ip_set_net_exit ( struct net * net ) <nl> ip_set_destroy_set ( set ); <nl> } <nl> } <nl> + nfnl_unlock ( NFNL_SUBSYS_IPSET ); <nl> kfree ( rcu_dereference_protected ( inst -> ip_set_list , 1 )); <nl> } <nl> 
mmm drivers / net / wireless / microchip / wilc1000 / cfg80211 . c <nl> ppp drivers / net / wireless / microchip / wilc1000 / cfg80211 . c <nl> static inline void wilc_wfi_cfg_parse_ch_attr ( u8 * buf , u32 len , u8 sta_ch ) <nl> if ( index + sizeof (* e ) + attr_size > len ) <nl> return ; <nl>  <nl> - if ( e -> attr_type == IEEE80211_P2P_ATTR_CHANNEL_LIST ) <nl> + if ( e -> attr_type == IEEE80211_P2P_ATTR_CHANNEL_LIST && <nl> + attr_size >= ( sizeof ( struct wilc_attr_ch_list ) - sizeof (* e ))) <nl> ch_list_idx = index ; <nl> else if ( e -> attr_type == IEEE80211_P2P_ATTR_OPER_CHANNEL && <nl> attr_size == ( sizeof ( struct wilc_attr_oper_ch ) - sizeof (* e )))
mmm net / openvswitch / flow . c <nl> ppp net / openvswitch / flow . c <nl> static void stats_read ( struct flow_stats * stats , <nl> unsigned long * used , __be16 * tcp_flags ) <nl> { <nl> spin_lock (& stats -> lock ); <nl> - if ( time_after ( stats -> used , * used )) <nl> + if (!* used || time_after ( stats -> used , * used )) <nl> * used = stats -> used ; <nl> * tcp_flags |= stats -> tcp_flags ; <nl> ovs_stats -> n_packets += stats -> packet_count ;
mmm drivers / infiniband / hw / mlx4 / qp . c <nl> ppp drivers / infiniband / hw / mlx4 / qp . c <nl> static struct ib_qp * _mlx4_ib_create_qp_rss ( struct ib_pd * pd , <nl> return ERR_PTR (- EFAULT ); <nl> } <nl>  <nl> + if ( memchr_inv ( ucmd . reserved , 0 , sizeof ( ucmd . reserved ))) <nl> + return ERR_PTR (- EOPNOTSUPP ); <nl> + <nl> if ( ucmd . comp_mask || ucmd . reserved1 ) <nl> return ERR_PTR (- EOPNOTSUPP ); <nl> 
mmm kernel / ucount . c <nl> ppp kernel / ucount . c <nl> struct ucounts * alloc_ucounts ( struct user_namespace * ns , kuid_t uid ) <nl> kfree ( new ); <nl> } else { <nl> hlist_add_head (& new -> node , hashent ); <nl> + get_user_ns ( new -> ns ); <nl> spin_unlock_irq (& ucounts_lock ); <nl> return new ; <nl> } <nl> void put_ucounts ( struct ucounts * ucounts ) <nl> if ( atomic_dec_and_lock_irqsave (& ucounts -> count , & ucounts_lock , flags )) { <nl> hlist_del_init (& ucounts -> node ); <nl> spin_unlock_irqrestore (& ucounts_lock , flags ); <nl> + put_user_ns ( ucounts -> ns ); <nl> kfree ( ucounts ); <nl> } <nl> }
mmm fs / btrfs / inode . c <nl> ppp fs / btrfs / inode . c <nl> int btrfs_check_free_space ( struct btrfs_root * root , u64 num_required , <nl> int ret = 0 ; <nl>  <nl> if ( for_del ) <nl> - thresh = ( total * 90 ) / 100 ; <nl> + thresh = total * 90 ; <nl> else <nl> - thresh = ( total * 85 ) / 100 ; <nl> + thresh = total * 85 ; <nl> + <nl> + do_div ( thresh , 100 ); <nl>  <nl> spin_lock (& root -> fs_info -> delalloc_lock ); <nl> if ( used + root -> fs_info -> delalloc_bytes + num_required > thresh ) <nl> static int btrfs_ioctl_resize ( struct btrfs_root * root , void __user * arg ) <nl> ret = - EFBIG ; <nl> goto out_unlock ; <nl> } <nl> - new_size = ( new_size / root -> sectorsize ) * root -> sectorsize ; <nl> + <nl> + do_div ( new_size , root -> sectorsize ); <nl> + new_size *= root -> sectorsize ; <nl>  <nl> printk (" new size is % Lu \ n ", new_size ); <nl> if ( new_size > old_size ) {mmm fs / btrfs / extent - tree . c <nl> ppp fs / btrfs / extent - tree . c <nl> int btrfs_check_free_space ( struct btrfs_root * root , u64 num_required , <nl> int ret = 0 ; <nl>  <nl> if ( for_del ) <nl> - thresh = ( total * 90 ) / 100 ; <nl> + thresh = total * 90 ; <nl> else <nl> - thresh = ( total * 85 ) / 100 ; <nl> + thresh = total * 85 ; <nl> + <nl> + do_div ( thresh , 100 ); <nl>  <nl> spin_lock (& root -> fs_info -> delalloc_lock ); <nl> if ( used + root -> fs_info -> delalloc_bytes + num_required > thresh ) <nl> static int btrfs_ioctl_resize ( struct btrfs_root * root , void __user * arg ) <nl> ret = - EFBIG ; <nl> goto out_unlock ; <nl> } <nl> - new_size = ( new_size / root -> sectorsize ) * root -> sectorsize ; <nl> + <nl> + do_div ( new_size , root -> sectorsize ); <nl> + new_size *= root -> sectorsize ; <nl>  <nl> printk (" new size is % Lu \ n ", new_size ); <nl> if ( new_size > old_size ) { <nl> int btrfs_grow_extent_tree ( struct btrfs_trans_handle * trans , <nl> u64 nr = 0 ; <nl> u64 cur_byte ; <nl> u64 old_size ; <nl> + unsigned long rem ; <nl> struct btrfs_block_group_cache * cache ; <nl> struct btrfs_block_group_item * item ; <nl> struct btrfs_fs_info * info = root -> fs_info ; <nl> int btrfs_grow_extent_tree ( struct btrfs_trans_handle * trans , <nl> struct btrfs_block_group_item ); <nl>  <nl> btrfs_set_disk_block_group_used ( leaf , item , 0 ); <nl> - if ( nr % 3 ) { <nl> + div_long_long_rem ( nr , 3 , & rem ); <nl> + if ( rem ) { <nl> btrfs_set_disk_block_group_flags ( leaf , item , <nl> BTRFS_BLOCK_GROUP_DATA ); <nl> } else {
mmm drivers / tty / serial / arc_uart . c <nl> ppp drivers / tty / serial / arc_uart . c <nl> static int arc_serial_probe ( struct platform_device * pdev ) <nl> if ( dev_id < 0 ) <nl> dev_id = 0 ; <nl>  <nl> + if ( dev_id >= ARRAY_SIZE ( arc_uart_ports )) { <nl> + dev_err (& pdev -> dev , " serial % d out of range \ n ", dev_id ); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> uart = & arc_uart_ports [ dev_id ]; <nl> port = & uart -> port ; <nl> 
mmm drivers / net / wireless / wl12xx / main . c <nl> ppp drivers / net / wireless / wl12xx / main . c <nl> static struct platform_device wl1271_device = { <nl> }, <nl> }; <nl>  <nl> + static DEFINE_MUTEX ( wl_list_mutex ); <nl> static LIST_HEAD ( wl_list ); <nl>  <nl> static int wl1271_dev_notify ( struct notifier_block * me , unsigned long what , <nl> static int wl1271_dev_notify ( struct notifier_block * me , unsigned long what , <nl> return NOTIFY_DONE ; <nl>  <nl> wl_temp = hw -> priv ; <nl> + mutex_lock (& wl_list_mutex ); <nl> list_for_each_entry ( wl , & wl_list , list ) { <nl> if ( wl == wl_temp ) <nl> break ; <nl> } <nl> + mutex_unlock (& wl_list_mutex ); <nl> if ( wl != wl_temp ) <nl> return NOTIFY_DONE ; <nl>  <nl> static int wl1271_op_add_interface ( struct ieee80211_hw * hw , <nl> out : <nl> mutex_unlock (& wl -> mutex ); <nl>  <nl> + mutex_lock (& wl_list_mutex ); <nl> if (! ret ) <nl> list_add (& wl -> list , & wl_list ); <nl> + mutex_unlock (& wl_list_mutex ); <nl>  <nl> return ret ; <nl> } <nl> static void __wl1271_op_remove_interface ( struct wl1271 * wl ) <nl>  <nl> wl1271_info (" down "); <nl>  <nl> + mutex_lock (& wl_list_mutex ); <nl> list_del (& wl -> list ); <nl> + mutex_unlock (& wl_list_mutex ); <nl>  <nl> WARN_ON ( wl -> state != WL1271_STATE_ON ); <nl> 
mmm drivers / pinctrl / pinctrl - amd . c <nl> ppp drivers / pinctrl / pinctrl - amd . c <nl> static struct irq_chip amd_gpio_irqchip = { <nl> . irq_set_type = amd_gpio_irq_set_type , <nl> }; <nl>  <nl> - static void amd_gpio_irq_handler ( unsigned int irq , struct irq_desc * desc ) <nl> + static void amd_gpio_irq_handler ( unsigned int __irq , struct irq_desc * desc ) <nl> { <nl> + unsigned int irq = irq_desc_get_irq ( desc ); <nl> u32 i ; <nl> u32 off ; <nl> u32 reg ;
mmm fs / partitions / efi . c <nl> ppp fs / partitions / efi . c <nl> static int is_gpt_valid ( struct parsed_partitions * state , u64 lba , <nl> goto fail ; <nl> } <nl>  <nl> + /* Check that sizeof_partition_entry has the correct value */ <nl> + if ( le32_to_cpu ((* gpt )-> sizeof_partition_entry ) != sizeof ( gpt_entry )) { <nl> + pr_debug (" GUID Partitition Entry Size check failed .\ n "); <nl> + goto fail ; <nl> + } <nl> + <nl> if (!(* ptes = alloc_read_gpt_entries ( state , * gpt ))) <nl> goto fail ; <nl> 
mmm drivers / usb / dwc3 / dwc3 - qcom . c <nl> ppp drivers / usb / dwc3 / dwc3 - qcom . c <nl> static int dwc3_qcom_acpi_register_core ( struct platform_device * pdev ) <nl> qcom -> dwc3 -> dev . coherent_dma_mask = dev -> coherent_dma_mask ; <nl>  <nl> child_res = kcalloc ( 2 , sizeof (* child_res ), GFP_KERNEL ); <nl> - if (! child_res ) <nl> + if (! child_res ) { <nl> + platform_device_put ( qcom -> dwc3 ); <nl> return - ENOMEM ; <nl> + } <nl>  <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> if (! res ) { <nl> static int dwc3_qcom_acpi_register_core ( struct platform_device * pdev ) <nl> if ( ret ) { <nl> dev_err (& pdev -> dev , " failed to add device \ n "); <nl> device_remove_software_node (& qcom -> dwc3 -> dev ); <nl> + goto out ; <nl> } <nl> + kfree ( child_res ); <nl> + return 0 ; <nl>  <nl> out : <nl> + platform_device_put ( qcom -> dwc3 ); <nl> kfree ( child_res ); <nl> return ret ; <nl> }
mmm include / linux / init_task . h <nl> ppp include / linux / init_task . h <nl> extern struct cred init_cred ; <nl> [ PIDTYPE_PGID ] = INIT_PID_LINK ( PIDTYPE_PGID ), \ <nl> [ PIDTYPE_SID ] = INIT_PID_LINK ( PIDTYPE_SID ), \ <nl> }, \ <nl> + . thread_group = LIST_HEAD_INIT ( tsk . thread_group ), \ <nl> . dirties = INIT_PROP_LOCAL_SINGLE ( dirties ), \ <nl> INIT_IDS \ <nl> INIT_PERF_EVENTS ( tsk ) \
mmm drivers / usb / dwc2 / gadget . c <nl> ppp drivers / usb / dwc2 / gadget . c <nl> static int dwc2_hsotg_process_req_feature ( struct dwc2_hsotg * hsotg , <nl> switch ( recip ) { <nl> case USB_RECIP_DEVICE : <nl> switch ( wValue ) { <nl> + case USB_DEVICE_REMOTE_WAKEUP : <nl> + hsotg -> remote_wakeup_allowed = 1 ; <nl> + break ; <nl> + <nl> case USB_DEVICE_TEST_MODE : <nl> if (( wIndex & 0xff ) != 0 ) <nl> return - EINVAL ; <nl> int dwc2_gadget_init ( struct dwc2_hsotg * hsotg ) <nl> hsotg -> gadget . max_speed = USB_SPEED_HIGH ; <nl> hsotg -> gadget . ops = & dwc2_hsotg_gadget_ops ; <nl> hsotg -> gadget . name = dev_name ( dev ); <nl> + hsotg -> remote_wakeup_allowed = 0 ; <nl>  <nl> if ( hsotg -> params . lpm ) <nl> hsotg -> gadget . lpm_capable = true ;mmm drivers / usb / dwc2 / core . h <nl> ppp drivers / usb / dwc2 / core . h <nl> static int dwc2_hsotg_process_req_feature ( struct dwc2_hsotg * hsotg , <nl> switch ( recip ) { <nl> case USB_RECIP_DEVICE : <nl> switch ( wValue ) { <nl> + case USB_DEVICE_REMOTE_WAKEUP : <nl> + hsotg -> remote_wakeup_allowed = 1 ; <nl> + break ; <nl> + <nl> case USB_DEVICE_TEST_MODE : <nl> if (( wIndex & 0xff ) != 0 ) <nl> return - EINVAL ; <nl> int dwc2_gadget_init ( struct dwc2_hsotg * hsotg ) <nl> hsotg -> gadget . max_speed = USB_SPEED_HIGH ; <nl> hsotg -> gadget . ops = & dwc2_hsotg_gadget_ops ; <nl> hsotg -> gadget . name = dev_name ( dev ); <nl> + hsotg -> remote_wakeup_allowed = 0 ; <nl>  <nl> if ( hsotg -> params . lpm ) <nl> hsotg -> gadget . lpm_capable = true ; <nl> struct dwc2_hregs_backup { <nl> * @ ctrl_req : Request for EP0 control packets . <nl> * @ ep0_state : EP0 control transfers state <nl> * @ test_mode : USB test mode requested by the host <nl> + * @ remote_wakeup_allowed : True if device is allowed to wake - up host by <nl> + * remote - wakeup signalling <nl> * @ setup_desc_dma : EP0 setup stage desc chain DMA address <nl> * @ setup_desc : EP0 setup stage desc chain pointer <nl> * @ ctrl_in_desc_dma : EP0 IN data phase desc chain DMA address <nl> struct dwc2_hsotg { <nl> struct usb_gadget gadget ; <nl> unsigned int enabled : 1 ; <nl> unsigned int connected : 1 ; <nl> + unsigned int remote_wakeup_allowed : 1 ; <nl> struct dwc2_hsotg_ep * eps_in [ MAX_EPS_CHANNELS ]; <nl> struct dwc2_hsotg_ep * eps_out [ MAX_EPS_CHANNELS ]; <nl> # endif /* CONFIG_USB_DWC2_PERIPHERAL || CONFIG_USB_DWC2_DUAL_ROLE */
mmm arch / x86 / kvm / paging_tmpl . h <nl> ppp arch / x86 / kvm / paging_tmpl . h <nl> static int FNAME ( walk_addr_generic )( struct guest_walker * walker , <nl> } <nl>  <nl> ptep_user = ( pt_element_t __user *)(( void *) host_addr + offset ); <nl> - if ( unlikely ( copy_from_user (& pte , ptep_user , sizeof ( pte )))) { <nl> + if ( unlikely ( __copy_from_user (& pte , ptep_user , sizeof ( pte )))) { <nl> present = false ; <nl> break ; <nl> }mmm virt / kvm / kvm_main . c <nl> ppp virt / kvm / kvm_main . c <nl> static int FNAME ( walk_addr_generic )( struct guest_walker * walker , <nl> } <nl>  <nl> ptep_user = ( pt_element_t __user *)(( void *) host_addr + offset ); <nl> - if ( unlikely ( copy_from_user (& pte , ptep_user , sizeof ( pte )))) { <nl> + if ( unlikely ( __copy_from_user (& pte , ptep_user , sizeof ( pte )))) { <nl> present = false ; <nl> break ; <nl> } <nl> int __kvm_set_memory_region ( struct kvm * kvm , <nl> goto out ; <nl> if ( mem -> guest_phys_addr & ( PAGE_SIZE - 1 )) <nl> goto out ; <nl> - if ( user_alloc && ( mem -> userspace_addr & ( PAGE_SIZE - 1 ))) <nl> + /* We can read the guest memory with __xxx_user () later on . */ <nl> + if ( user_alloc && <nl> + (( mem -> userspace_addr & ( PAGE_SIZE - 1 )) || <nl> + ! access_ok ( VERIFY_WRITE , mem -> userspace_addr , mem -> memory_size ))) <nl> goto out ; <nl> if ( mem -> slot >= KVM_MEMORY_SLOTS + KVM_PRIVATE_MEM_SLOTS ) <nl> goto out ; <nl> int kvm_read_guest_page ( struct kvm * kvm , gfn_t gfn , void * data , int offset , <nl> addr = gfn_to_hva ( kvm , gfn ); <nl> if ( kvm_is_error_hva ( addr )) <nl> return - EFAULT ; <nl> - r = copy_from_user ( data , ( void __user *) addr + offset , len ); <nl> + r = __copy_from_user ( data , ( void __user *) addr + offset , len ); <nl> if ( r ) <nl> return - EFAULT ; <nl> return 0 ;
mmm drivers / media / video / gspca / gspca . c <nl> ppp drivers / media / video / gspca / gspca . c <nl> void gspca_frame_add ( struct gspca_dev * gspca_dev , <nl> } else { <nl> switch ( gspca_dev -> last_packet_type ) { <nl> case DISCARD_PACKET : <nl> - if ( packet_type == LAST_PACKET ) <nl> + if ( packet_type == LAST_PACKET ) { <nl> gspca_dev -> last_packet_type = packet_type ; <nl> + gspca_dev -> image = NULL ; <nl> + gspca_dev -> image_len = 0 ; <nl> + } <nl> return ; <nl> case LAST_PACKET : <nl> return ;
mmm arch / arm / mach - pxa / magician . c <nl> ppp arch / arm / mach - pxa / magician . c <nl> static void samsung_lcd_power ( int on , struct fb_var_screeninfo * si ) <nl> gpio_set_value ( GPIO75_MAGICIAN_SAMSUNG_POWER , 1 ); <nl> else <nl> gpio_set_value ( EGPIO_MAGICIAN_LCD_POWER , 1 ); <nl> - mdelay ( 10 ); <nl> + mdelay ( 6 ); <nl> gpio_set_value ( GPIO106_MAGICIAN_LCD_DCDC_NRESET , 1 ); <nl> - mdelay ( 10 ); <nl> + mdelay ( 6 ); /* Avdd -> Voff > 5ms */ <nl> gpio_set_value ( GPIO104_MAGICIAN_LCD_VOFF_EN , 1 ); <nl> - mdelay ( 30 ); <nl> + mdelay ( 16 ); /* Voff -> Von >( 5 + 10 ) ms */ <nl> gpio_set_value ( GPIO105_MAGICIAN_LCD_VON_EN , 1 ); <nl> - mdelay ( 10 ); <nl> } else { <nl> - mdelay ( 10 ); <nl> gpio_set_value ( GPIO105_MAGICIAN_LCD_VON_EN , 0 ); <nl> - mdelay ( 30 ); <nl> + mdelay ( 16 ); <nl> gpio_set_value ( GPIO104_MAGICIAN_LCD_VOFF_EN , 0 ); <nl> - mdelay ( 10 ); <nl> + mdelay ( 6 ); <nl> gpio_set_value ( GPIO106_MAGICIAN_LCD_DCDC_NRESET , 0 ); <nl> - mdelay ( 10 ); <nl> + mdelay ( 6 ); <nl> if ( system_rev < 3 ) <nl> gpio_set_value ( GPIO75_MAGICIAN_SAMSUNG_POWER , 0 ); <nl> else
mmm sound / soc / codecs / sgtl5000 . c <nl> ppp sound / soc / codecs / sgtl5000 . c <nl> static int sgtl5000_set_clock ( struct snd_soc_codec * codec , int frame_rate ) <nl> } else { <nl> dev_err ( codec -> dev , <nl> " PLL not supported in slave mode \ n "); <nl> + dev_err ( codec -> dev , "% d ratio is not supported . " <nl> + " SYS_MCLK needs to be 256 , 384 or 512 * fs \ n ", <nl> + sgtl5000 -> sysclk / sys_fs ); <nl> return - EINVAL ; <nl> } <nl> }
mmm sound / soc / soc - cache . c <nl> ppp sound / soc / soc - cache . c <nl> static int snd_soc_8_16_write ( struct snd_soc_codec * codec , unsigned int reg , <nl> data [ 1 ] = ( value >> 8 ) & 0xff ; <nl> data [ 2 ] = value & 0xff ; <nl>  <nl> - if (! snd_soc_codec_volatile_register ( codec , reg )) <nl> - reg_cache [ reg ] = value ; <nl> + if (! snd_soc_codec_volatile_register ( codec , reg ) <nl> + && reg < codec -> driver -> reg_cache_size ) <nl> + reg_cache [ reg ] = value ; <nl>  <nl> if ( codec -> cache_only ) { <nl> codec -> cache_sync = 1 ;
mmm drivers / net / wireless / rtlwifi / pci . c <nl> ppp drivers / net / wireless / rtlwifi / pci . c <nl> static bool _rtl_pci_find_adapter ( struct pci_dev * pdev , <nl> pci_read_config_byte ( pdev , 0x8 , & revisionid ); <nl> pci_read_config_word ( pdev , 0x3C , & irqline ); <nl>  <nl> + /* PCI ID 0x10ec : 0x8192 occurs for both RTL8192E , which uses <nl> + * r8192e_pci , and RTL8192SE , which uses this driver . If the <nl> + * revision ID is RTL_PCI_REVISION_ID_8192PCIE ( 0x01 ), then <nl> + * the correct driver is r8192e_pci , thus this routine should <nl> + * return false . <nl> + */ <nl> + if ( deviceid == RTL_PCI_8192SE_DID && <nl> + revisionid == RTL_PCI_REVISION_ID_8192PCIE ) <nl> + return false ; <nl> + <nl> if ( deviceid == RTL_PCI_8192_DID || <nl> deviceid == RTL_PCI_0044_DID || <nl> deviceid == RTL_PCI_0047_DID || <nl> int __devinit rtl_pci_probe ( struct pci_dev * pdev , <nl> pci_write_config_byte ( pdev , 0x04 , 0x07 ); <nl>  <nl> /* find adapter */ <nl> - _rtl_pci_find_adapter ( pdev , hw ); <nl> + if (! _rtl_pci_find_adapter ( pdev , hw )) <nl> + goto fail3 ; <nl>  <nl> /* Init IO handler */ <nl> _rtl_pci_io_handler_init (& pdev -> dev , hw );
mmm drivers / char / ipmi / ipmi_devintf . c <nl> ppp drivers / char / ipmi / ipmi_devintf . c <nl> static long compat_ipmi_ioctl ( struct file * filep , unsigned int cmd , <nl> struct ipmi_recv __user * precv64 ; <nl> struct ipmi_recv recv64 ; <nl>  <nl> + memset (& recv64 , 0 , sizeof ( recv64 )); <nl> if ( get_compat_ipmi_recv (& recv64 , compat_ptr ( arg ))) <nl> return - EFAULT ; <nl> 
mmm kernel / cgroup . c <nl> ppp kernel / cgroup . c <nl> int cgroup_add_legacy_cftypes ( struct cgroup_subsys * ss , struct cftype * cfts ) <nl> { <nl> struct cftype * cft ; <nl>  <nl> - for ( cft = cfts ; cft && cft -> name [ 0 ] != '\ 0 '; cft ++) <nl> - cft -> flags |= __CFTYPE_NOT_ON_DFL ; <nl> + /* <nl> + * If legacy_flies_on_dfl , we want to show the legacy files on the <nl> + * dfl hierarchy but iff the target subsystem hasn ' t been updated <nl> + * for the dfl hierarchy yet . <nl> + */ <nl> + if (! cgroup_legacy_files_on_dfl || <nl> + ss -> dfl_cftypes != ss -> legacy_cftypes ) { <nl> + for ( cft = cfts ; cft && cft -> name [ 0 ] != '\ 0 '; cft ++) <nl> + cft -> flags |= __CFTYPE_NOT_ON_DFL ; <nl> + } <nl> + <nl> return cgroup_add_cftypes ( ss , cfts ); <nl> } <nl> 
mmm drivers / block / nbd . c <nl> ppp drivers / block / nbd . c <nl> static void nbd_config_put ( struct nbd_device * nbd ) <nl> } <nl> kfree ( config -> socks ); <nl> } <nl> + kfree ( nbd -> config ); <nl> nbd -> config = NULL ; <nl>  <nl> nbd -> tag_set . timeout = 0 ;
mmm drivers / nvme / host / core . c <nl> ppp drivers / nvme / host / core . c <nl> static void nvme_init_integrity ( struct nvme_ns * ns ) <nl> { <nl> struct blk_integrity integrity ; <nl>  <nl> + memset (& integrity , 0 , sizeof ( integrity )); <nl> switch ( ns -> pi_type ) { <nl> case NVME_NS_DPS_PI_TYPE3 : <nl> integrity . profile = & t10_pi_type3_crc ;
mmm drivers / net / phy / dp83640 . c <nl> ppp drivers / net / phy / dp83640 . c <nl> static int ptp_dp83640_enable ( struct ptp_clock_info * ptp , <nl> event_num = EXT_EVENT + index ; <nl> evnt = EVNT_WR | ( event_num & EVNT_SEL_MASK ) << EVNT_SEL_SHIFT ; <nl> if ( on ) { <nl> - gpio_num = gpio_tab [ EXTTS0_GPIO + index ]; <nl> + gpio_num = 1 + ptp_find_pin ( clock -> ptp_clock , <nl> + PTP_PF_EXTTS , index ); <nl> + if ( gpio_num < 1 ) <nl> + return - EINVAL ; <nl> evnt |= ( gpio_num & EVNT_GPIO_MASK ) << EVNT_GPIO_SHIFT ; <nl> if ( rq -> extts . flags & PTP_FALLING_EDGE ) <nl> evnt |= EVNT_FALL ;
mmm drivers / gpu / drm / i915 / gvt / kvmgt . c <nl> ppp drivers / gpu / drm / i915 / gvt / kvmgt . c <nl> static int kvmgt_write_protect_add ( unsigned long handle , u64 gfn ) <nl>  <nl> idx = srcu_read_lock (& kvm -> srcu ); <nl> slot = gfn_to_memslot ( kvm , gfn ); <nl> + if (! slot ) { <nl> + srcu_read_unlock (& kvm -> srcu , idx ); <nl> + return - EINVAL ; <nl> + } <nl>  <nl> spin_lock (& kvm -> mmu_lock ); <nl>  <nl> static int kvmgt_write_protect_remove ( unsigned long handle , u64 gfn ) <nl>  <nl> idx = srcu_read_lock (& kvm -> srcu ); <nl> slot = gfn_to_memslot ( kvm , gfn ); <nl> + if (! slot ) { <nl> + srcu_read_unlock (& kvm -> srcu , idx ); <nl> + return - EINVAL ; <nl> + } <nl>  <nl> spin_lock (& kvm -> mmu_lock ); <nl> 
mmm net / netlink / af_netlink . c <nl> ppp net / netlink / af_netlink . c <nl> static struct pernet_operations __net_initdata netlink_net_ops = { <nl>  <nl> static int __init netlink_proto_init ( void ) <nl> { <nl> - struct sk_buff * dummy_skb ; <nl> int i ; <nl> unsigned long limit ; <nl> unsigned int order ; <nl> static int __init netlink_proto_init ( void ) <nl> if ( err != 0 ) <nl> goto out ; <nl>  <nl> - BUILD_BUG_ON ( sizeof ( struct netlink_skb_parms ) > sizeof ( dummy_skb -> cb )); <nl> + BUILD_BUG_ON ( sizeof ( struct netlink_skb_parms ) > FIELD_SIZEOF ( struct sk_buff , cb )); <nl>  <nl> nl_table = kcalloc ( MAX_LINKS , sizeof (* nl_table ), GFP_KERNEL ); <nl> if (! nl_table )
mmm drivers / staging / wilc1000 / host_interface . c <nl> ppp drivers / staging / wilc1000 / host_interface . c <nl> int wilc_deinit ( struct wilc_vif * vif ) <nl>  <nl> if ( hif_drv -> usr_scan_req . scan_result ) { <nl> hif_drv -> usr_scan_req . scan_result ( SCAN_EVENT_ABORTED , NULL , <nl> - hif_drv -> usr_scan_req . arg , NULL ); <nl> + hif_drv -> usr_scan_req . arg , <nl> + NULL ); <nl> hif_drv -> usr_scan_req . scan_result = NULL ; <nl> } <nl>  <nl> int wilc_del_allstation ( struct wilc_vif * vif , u8 mac_addr [][ ETH_ALEN ]) <nl>  <nl> for ( i = 0 ; i < MAX_NUM_STA ; i ++) { <nl> if ( memcmp ( mac_addr [ i ], zero_addr , ETH_ALEN )) { <nl> - memcpy ( del_all_sta_info -> del_all_sta [ i ], mac_addr [ i ], ETH_ALEN ); <nl> + memcpy ( del_all_sta_info -> del_all_sta [ i ], mac_addr [ i ], <nl> + ETH_ALEN ); <nl> assoc_sta ++; <nl> } <nl> }
mmm kernel / torture . c <nl> ppp kernel / torture . c <nl> static int torture_shutdown_notify ( struct notifier_block * unused1 , <nl> unsigned long unused2 , void * unused3 ) <nl> { <nl> mutex_lock (& fullstop_mutex ); <nl> - if ( fullstop == FULLSTOP_DONTSTOP ) <nl> + if ( fullstop == FULLSTOP_DONTSTOP ) { <nl> + VERBOSE_TOROUT_STRING (" Unscheduled system shutdown detected "); <nl> fullstop = FULLSTOP_SHUTDOWN ; <nl> - else <nl> + } else { <nl> pr_warn (" Concurrent rmmod and shutdown illegal !\ n "); <nl> + } <nl> mutex_unlock (& fullstop_mutex ); <nl> return NOTIFY_DONE ; <nl> }
mmm drivers / net / wireless / brcm80211 / brcmfmac / wl_cfg80211 . c <nl> ppp drivers / net / wireless / brcm80211 / brcmfmac / wl_cfg80211 . c <nl> static int brcmf_enable_bw40_2g ( struct brcmf_cfg80211_info * cfg ) <nl>  <nl> ch . band = BRCMU_CHAN_BAND_2G ; <nl> ch . bw = BRCMU_CHAN_BW_40 ; <nl> + ch . sb = BRCMU_CHAN_SB_NONE ; <nl> ch . chnum = 0 ; <nl> cfg -> d11inf . encchspec (& ch ); <nl>  <nl> static int brcmf_enable_bw40_2g ( struct brcmf_cfg80211_info * cfg ) <nl>  <nl> brcmf_update_bw40_channel_flag (& band -> channels [ j ], & ch ); <nl> } <nl> + kfree ( pbuf ); <nl> } <nl> return err ; <nl> }
mmm sound / soc / omap / omap - pcm . c <nl> ppp sound / soc / omap / omap - pcm . c <nl> static int omap_pcm_new ( struct snd_soc_pcm_runtime * rtd ) <nl> } <nl>  <nl> out : <nl> + /* free preallocated buffers in case of error */ <nl> + if ( ret ) <nl> + omap_pcm_free_dma_buffers ( pcm ); <nl> + <nl> return ret ; <nl> } <nl> 
mmm drivers / net / pcmcia / 3c589_cs . c <nl> ppp drivers / net / pcmcia / 3c589_cs . c <nl> struct el3_private { <nl> spinlock_t lock ; <nl> }; <nl>  <nl> - static const char * if_names [] = { " auto ", " 10baseT ", " 10base2 ", " AUI " }; <nl> + static const char * if_names [] = { " auto ", " 10base2 ", " 10baseT ", " AUI " }; <nl>  <nl> /*====================================================================*/ <nl> 
mmm drivers / input / keyboard / tegra - kbc . c <nl> ppp drivers / input / keyboard / tegra - kbc . c <nl> static int tegra_kbc_start ( struct tegra_kbc * kbc ) <nl> /* Reset the KBC controller to clear all previous status .*/ <nl> reset_control_assert ( kbc -> rst ); <nl> udelay ( 100 ); <nl> - reset_control_assert ( kbc -> rst ); <nl> + reset_control_deassert ( kbc -> rst ); <nl> udelay ( 100 ); <nl>  <nl> tegra_kbc_config_pins ( kbc );
mmm drivers / usb / serial / cp210x . c <nl> ppp drivers / usb / serial / cp210x . c <nl> static const struct usb_device_id id_table [] = { <nl> { USB_DEVICE ( 0x10C4 , 0x8341 ) }, /* Siemens MC35PU GPRS Modem */ <nl> { USB_DEVICE ( 0x10C4 , 0x8382 ) }, /* Cygnal Integrated Products , Inc . */ <nl> { USB_DEVICE ( 0x10C4 , 0x83A8 ) }, /* Amber Wireless AMB2560 */ <nl> + { USB_DEVICE ( 0x10C4 , 0x83D8 ) }, /* DekTec DTA Plus VHF / UHF Booster / Attenuator */ <nl> { USB_DEVICE ( 0x10C4 , 0x8411 ) }, /* Kyocera GPS Module */ <nl> + { USB_DEVICE ( 0x10C4 , 0x8418 ) }, /* IRZ Automation Teleport SG - 10 GSM / GPRS Modem */ <nl> { USB_DEVICE ( 0x10C4 , 0x846E ) }, /* BEI USB Sensor Interface ( VCP ) */ <nl> { USB_DEVICE ( 0x10C4 , 0x8477 ) }, /* Balluff RFID */ <nl> { USB_DEVICE ( 0x10C4 , 0xEA60 ) }, /* Silicon Labs factory default */
mmm drivers / tty / serial / pch_uart . c <nl> ppp drivers / tty / serial / pch_uart . c <nl> static struct eg20t_port * pch_uart_init_port ( struct pci_dev * pdev , <nl> int fifosize , base_baud ; <nl> int port_type ; <nl> struct pch_uart_driver_data * board ; <nl> + const char * board_name ; <nl>  <nl> board = & drv_dat [ id -> driver_data ]; <nl> port_type = board -> port_type ; <nl> static struct eg20t_port * pch_uart_init_port ( struct pci_dev * pdev , <nl> base_baud = 1843200 ; /* 1 . 8432MHz */ <nl>  <nl> /* quirk for CM - iTC board */ <nl> - if ( strstr ( dmi_get_system_info ( DMI_BOARD_NAME ), " CM - iTC ")) <nl> + board_name = dmi_get_system_info ( DMI_BOARD_NAME ); <nl> + if ( board_name && strstr ( board_name , " CM - iTC ")) <nl> base_baud = 192000000 ; /* 192 . 0MHz */ <nl>  <nl> switch ( port_type ) {
mmm drivers / media / video / saa7134 / saa7134 - dvb . c <nl> ppp drivers / media / video / saa7134 / saa7134 - dvb . c <nl> static int dvb_init ( struct saa7134_dev * dev ) <nl> dev -> dvb . frontend = dvb_attach ( mt352_attach , & avermedia_777 , <nl> & dev -> i2c_adap ); <nl> if ( dev -> dvb . frontend ) { <nl> - dvb_attach ( dvb_pll_attach , dev -> dvb . frontend , 0x61 , <nl> - NULL , DVB_PLL_PHILIPS_TD1316 ); <nl> + dvb_attach ( simple_tuner_attach , dev -> dvb . frontend , <nl> + & dev -> i2c_adap , 0x61 , <nl> + TUNER_PHILIPS_TD1316 ); <nl> } <nl> break ; <nl> case SAA7134_BOARD_MD7134 :
mmm drivers / net / can / usb / gs_usb . c <nl> ppp drivers / net / can / usb / gs_usb . c <nl> static int gs_can_open ( struct net_device * netdev ) <nl> rc ); <nl>  <nl> usb_unanchor_urb ( urb ); <nl> + usb_free_urb ( urb ); <nl> break ; <nl> } <nl> 
mmm drivers / staging / rtl8192e / r8192E_cmdpkt . h <nl> ppp drivers / staging / rtl8192e / r8192E_cmdpkt . h <nl> # ifndef R819XUSB_CMDPKT_H <nl> # define R819XUSB_CMDPKT_H <nl> # define CMPK_RX_TX_FB_SIZE sizeof ( struct cmpk_txfb ) <nl> -# define CMPK_TX_SET_CONFIG_SIZE sizeof ( cmpk_set_cfg_t ) <nl> -# define CMPK_BOTH_QUERY_CONFIG_SIZE sizeof ( cmpk_set_cfg_t ) <nl> +# define CMPK_TX_SET_CONFIG_SIZE sizeof ( struct cmpk_set_cfg ) <nl> +# define CMPK_BOTH_QUERY_CONFIG_SIZE sizeof ( struct cmpk_set_cfg ) <nl> # define CMPK_RX_TX_STS_SIZE sizeof ( cmpk_tx_status_t ) <nl> # define CMPK_RX_DBG_MSG_SIZE sizeof ( cmpk_rx_dbginfo_t ) <nl> # define CMPK_TX_RAHIS_SIZE sizeof ( cmpk_tx_rahis_t ) <nl> struct cmpk_intr_sta { <nl> };//; <nl>  <nl>  <nl> - typedef struct tag_cmd_pkt_set_configuration <nl> -{ <nl> + struct cmpk_set_cfg { <nl> u8 element_id ; <nl> u8 length ; <nl> u16 reserve1 ; <nl> typedef struct tag_cmd_pkt_set_configuration <nl> u8 cfg_offset ; <nl> u32 value ; <nl> u32 mask ; <nl> -} cmpk_set_cfg_t ; <nl> +};//; <nl>  <nl> -# define cmpk_query_cfg_t cmpk_set_cfg_t <nl> +# define cmpk_query_cfg_t struct cmpk_set_cfg <nl>  <nl> typedef struct tag_tx_stats_feedback <nl> {
mmm kernel / sysctl . c <nl> ppp kernel / sysctl . c <nl> static int do_proc_douintvec_minmax_conv ( unsigned long * lvalp , <nl> if ( write ) { <nl> unsigned int val = * lvalp ; <nl>  <nl> + if (* lvalp > UINT_MAX ) <nl> + return - EINVAL ; <nl> + <nl> if (( param -> min && * param -> min > val ) || <nl> ( param -> max && * param -> max < val )) <nl> return - ERANGE ; <nl>  <nl> - if (* lvalp > UINT_MAX ) <nl> - return - EINVAL ; <nl> * valp = val ; <nl> } else { <nl> unsigned int val = * valp ; <nl> static int do_proc_dopipe_max_size_conv ( unsigned long * lvalp , <nl> struct do_proc_dopipe_max_size_conv_param * param = data ; <nl>  <nl> if ( write ) { <nl> - unsigned int val = round_pipe_size (* lvalp ); <nl> + unsigned int val ; <nl>  <nl> + if (* lvalp > UINT_MAX ) <nl> + return - EINVAL ; <nl> + <nl> + val = round_pipe_size (* lvalp ); <nl> if ( val == 0 ) <nl> return - EINVAL ; <nl>  <nl> if ( param -> min && * param -> min > val ) <nl> return - ERANGE ; <nl>  <nl> - if (* lvalp > UINT_MAX ) <nl> - return - EINVAL ; <nl> - <nl> * valp = val ; <nl> } else { <nl> unsigned int val = * valp ;
mmm drivers / scsi / ibmvscsi / ibmvscsi . c <nl> ppp drivers / scsi / ibmvscsi / ibmvscsi . c <nl> static int ibmvscsi_probe ( struct vio_dev * vdev , const struct vio_device_id * id ) <nl> host -> max_lun = 8 ; <nl> host -> max_id = max_id ; <nl> host -> max_channel = max_channel ; <nl> + host -> max_cmd_len = 16 ; <nl>  <nl> if ( scsi_add_host ( hostdata -> host , hostdata -> dev )) <nl> goto add_host_failed ;
mmm drivers / scsi / qla2xxx / qla_tmpl . c <nl> ppp drivers / scsi / qla2xxx / qla_tmpl . c <nl> qla27xx_fwdt_entry_t270 ( struct scsi_qla_host * vha , <nl> qla27xx_write_reg ( reg , 0xc0 , addr | 0x80000000 , buf ); <nl> qla27xx_insert32 ( addr , buf , len ); <nl> qla27xx_read_off ( reg , 0xc4 , buf , len ); <nl> - addr ++; <nl> + addr += sizeof ( uint32_t ); <nl> } <nl>  <nl> return false ;
mmm kernel / futex . c <nl> ppp kernel / futex . c <nl> static int futex_requeue ( u32 __user * uaddr1 , unsigned int flags , <nl> struct futex_q * this , * next ; <nl> DEFINE_WAKE_Q ( wake_q ); <nl>  <nl> + if ( nr_wake < 0 || nr_requeue < 0 ) <nl> + return - EINVAL ; <nl> + <nl> /* <nl> * When PI not supported : return - ENOSYS if requeue_pi is true , <nl> * consequently the compiler knows requeue_pi is always false past
mmm drivers / media / v4l2 - core / v4l2 - async . c <nl> ppp drivers / media / v4l2 - core / v4l2 - async . c <nl> int v4l2_async_notifier_register ( struct v4l2_device * v4l2_dev , <nl> struct v4l2_async_subdev * asd ; <nl> int i ; <nl>  <nl> - if (! notifier -> num_subdevs || notifier -> num_subdevs > V4L2_MAX_SUBDEVS ) <nl> + if (! v4l2_dev || ! notifier -> num_subdevs || <nl> + notifier -> num_subdevs > V4L2_MAX_SUBDEVS ) <nl> return - EINVAL ; <nl>  <nl> notifier -> v4l2_dev = v4l2_dev ;
mmm fs / nfs / super . c <nl> ppp fs / nfs / super . c <nl> static int nfs_statfs ( struct dentry * dentry , struct kstatfs * buf ) <nl> goto out_err ; <nl>  <nl> error = server -> nfs_client -> rpc_ops -> statfs ( server , fh , & res ); <nl> + if ( unlikely ( error == - ESTALE )) { <nl> + struct dentry * pd_dentry ; <nl>  <nl> + pd_dentry = dget_parent ( dentry ); <nl> + if ( pd_dentry != NULL ) { <nl> + nfs_zap_caches ( pd_dentry -> d_inode ); <nl> + dput ( pd_dentry ); <nl> + } <nl> + } <nl> nfs_free_fattr ( res . fattr ); <nl> if ( error < 0 ) <nl> goto out_err ;
mmm fs / cifs / cifsacl . c <nl> ppp fs / cifs / cifsacl . c <nl> static int parse_sid ( struct cifs_sid * psid , char * end_of_acl ) <nl> return - EINVAL ; <nl> } <nl>  <nl> - if ( psid -> num_subauth ) { <nl> # ifdef CONFIG_CIFS_DEBUG2 <nl> + if ( psid -> num_subauth ) { <nl> int i ; <nl> cFYI ( 1 , " SID revision % d num_auth % d ", <nl> psid -> revision , psid -> num_subauth ); <nl> static int parse_sid ( struct cifs_sid * psid , char * end_of_acl ) <nl> num auths and therefore go off the end */ <nl> cFYI ( 1 , " RID 0x % x ", <nl> le32_to_cpu ( psid -> sub_auth [ psid -> num_subauth - 1 ])); <nl> -# endif <nl> } <nl> +# endif <nl>  <nl> return 0 ; <nl> }
mmm drivers / usb / gadget / fsl_qe_udc . c <nl> ppp drivers / usb / gadget / fsl_qe_udc . c <nl> static int qe_ep_enable ( struct usb_ep * _ep , <nl> ep = container_of ( _ep , struct qe_ep , ep ); <nl>  <nl> /* catch various bogus parameters */ <nl> - if (! _ep || ! desc || ep -> ep . desc || _ep -> name == ep_name [ 0 ] || <nl> + if (! _ep || ! desc || _ep -> name == ep_name [ 0 ] || <nl> ( desc -> bDescriptorType != USB_DT_ENDPOINT )) <nl> return - EINVAL ; <nl> 
mmm drivers / net / sis190 . c <nl> ppp drivers / net / sis190 . c <nl> static int __mdio_read ( struct net_device * dev , int phy_id , int reg ) <nl> return mdio_read ( tp -> mmio_addr , phy_id , reg ); <nl> } <nl>  <nl> + static u16 mdio_read_latched ( void __iomem * ioaddr , int phy_id , int reg ) <nl> +{ <nl> + mdio_read ( ioaddr , phy_id , reg ); <nl> + return mdio_read ( ioaddr , phy_id , reg ); <nl> +} <nl> + <nl> static u16 __devinit sis190_read_eeprom ( void __iomem * ioaddr , u32 reg ) <nl> { <nl> u16 data = 0xffff ; <nl> static void sis190_phy_task ( void * data ) <nl> if ( val & BMCR_RESET ) { <nl> // FIXME : needlessly high ? -- FR 02 / 07 / 2005 <nl> mod_timer (& tp -> timer , jiffies + HZ / 10 ); <nl> - } else if (!( mdio_read ( ioaddr , phy_id , MII_BMSR ) & BMSR_ANEGCOMPLETE )) { <nl> + } else if (!( mdio_read_latched ( ioaddr , phy_id , MII_BMSR ) & <nl> + BMSR_ANEGCOMPLETE )) { <nl> net_link ( tp , KERN_WARNING "% s : PHY reset until link up .\ n ", <nl> dev -> name ); <nl> mdio_write ( ioaddr , phy_id , MII_BMCR , val | BMCR_RESET );
mmm drivers / net / wireless / brcm80211 / brcmfmac / firmware . c <nl> ppp drivers / net / wireless / brcm80211 / brcmfmac / firmware . c <nl> struct nvram_parser { <nl> bool multi_dev_v2 ; <nl> }; <nl>  <nl> +/** <nl> + * is_nvram_char () - check if char is a valid one for NVRAM entry <nl> + * <nl> + * It accepts all printable ASCII chars except for '#' which opens a comment . <nl> + * Please note that ' ' ( space ) while accepted is not a valid key name char . <nl> + */ <nl> static bool is_nvram_char ( char c ) <nl> { <nl> /* comment marker excluded */ <nl> static bool is_nvram_char ( char c ) <nl> return false ; <nl>  <nl> /* key and value may have any other readable character */ <nl> - return ( c > 0x20 && c < 0x7f ); <nl> + return ( c >= 0x20 && c < 0x7f ); <nl> } <nl>  <nl> static bool is_whitespace ( char c ) <nl> static enum nvram_parser_state brcmf_nvram_handle_key ( struct nvram_parser * nvp ) <nl> nvp -> multi_dev_v1 = true ; <nl> if ( strncmp (& nvp -> fwnv -> data [ nvp -> entry ], " pcie /", 5 ) == 0 ) <nl> nvp -> multi_dev_v2 = true ; <nl> - } else if (! is_nvram_char ( c )) { <nl> + } else if (! is_nvram_char ( c ) || c == ' ') { <nl> brcmf_dbg ( INFO , " warning : ln =% d : col =% d : '=' expected , skip invalid key entry \ n ", <nl> nvp -> line , nvp -> column ); <nl> return COMMENT ;
mmm sound / core / seq_device . c <nl> ppp sound / core / seq_device . c <nl> void snd_seq_device_load_drivers ( void ) <nl> flush_work (& autoload_work ); <nl> } <nl> EXPORT_SYMBOL ( snd_seq_device_load_drivers ); <nl> +# define cancel_autoload_drivers () cancel_work_sync (& autoload_work ) <nl> # else <nl> # define queue_autoload_drivers () /* NOP */ <nl> +# define cancel_autoload_drivers () /* NOP */ <nl> # endif <nl>  <nl> /* <nl> static int snd_seq_device_dev_free ( struct snd_device * device ) <nl> { <nl> struct snd_seq_device * dev = device -> device_data ; <nl>  <nl> + cancel_autoload_drivers (); <nl> put_device (& dev -> dev ); <nl> return 0 ; <nl> }
mmm arch / x86 / kvm / x86 . c <nl> ppp arch / x86 / kvm / x86 . c <nl> EXPORT_SYMBOL_GPL ( kvm_inject_realmode_interrupt ); <nl>  <nl> static int handle_emulation_failure ( struct kvm_vcpu * vcpu ) <nl> { <nl> + int r = EMULATE_DONE ; <nl> + <nl> ++ vcpu -> stat . insn_emulation_fail ; <nl> trace_kvm_emulate_insn_failed ( vcpu ); <nl> - vcpu -> run -> exit_reason = KVM_EXIT_INTERNAL_ERROR ; <nl> - vcpu -> run -> internal . suberror = KVM_INTERNAL_ERROR_EMULATION ; <nl> - vcpu -> run -> internal . ndata = 0 ; <nl> + if (! is_guest_mode ( vcpu )) { <nl> + vcpu -> run -> exit_reason = KVM_EXIT_INTERNAL_ERROR ; <nl> + vcpu -> run -> internal . suberror = KVM_INTERNAL_ERROR_EMULATION ; <nl> + vcpu -> run -> internal . ndata = 0 ; <nl> + r = EMULATE_FAIL ; <nl> + } <nl> kvm_queue_exception ( vcpu , UD_VECTOR ); <nl> - return EMULATE_FAIL ; <nl> + <nl> + return r ; <nl> } <nl>  <nl> static bool reexecute_instruction ( struct kvm_vcpu * vcpu , gva_t gva )
mmm drivers / gpu / drm / drm_edid . c <nl> ppp drivers / gpu / drm / drm_edid . c <nl> drm_mode_std ( struct drm_connector * connector , struct edid * edid , <nl> * secondary GTF curve . Please don ' t do that . <nl> */ <nl> mode = drm_gtf_mode ( dev , hsize , vsize , vrefresh_rate , 0 , 0 ); <nl> + if (! mode ) <nl> + return NULL ; <nl> if ( drm_mode_hsync ( mode ) > drm_gtf2_hbreak ( edid )) { <nl> drm_mode_destroy ( dev , mode ); <nl> mode = drm_gtf_mode_complex ( dev , hsize , vsize , <nl> drm_gtf_modes_for_range ( struct drm_connector * connector , struct edid * edid , <nl> for ( i = 0 ; i < num_extra_modes ; i ++) { <nl> const struct minimode * m = & extra_modes [ i ]; <nl> newmode = drm_gtf_mode ( dev , m -> w , m -> h , m -> r , 0 , 0 ); <nl> + if (! newmode ) <nl> + return modes ; <nl>  <nl> if (! mode_in_range ( newmode , edid , timing )) { <nl> drm_mode_destroy ( dev , newmode ); <nl> drm_cvt_modes_for_range ( struct drm_connector * connector , struct edid * edid , <nl> for ( i = 0 ; i < num_extra_modes ; i ++) { <nl> const struct minimode * m = & extra_modes [ i ]; <nl> newmode = drm_cvt_mode ( dev , m -> w , m -> h , m -> r , rb , 0 , 0 ); <nl> + if (! newmode ) <nl> + return modes ; <nl>  <nl> if (! mode_in_range ( newmode , edid , timing )) { <nl> drm_mode_destroy ( dev , newmode );
mmm drivers / net / ethernet / qlogic / qlcnic / qlcnic_main . c <nl> ppp drivers / net / ethernet / qlogic / qlcnic / qlcnic_main . c <nl> static int qlcnic_82xx_setup_intr ( struct qlcnic_adapter * adapter ) <nl> qlcnic_disable_multi_tx ( adapter ); <nl>  <nl> err = qlcnic_enable_msi_legacy ( adapter ); <nl> - if (! err ) <nl> + if ( err ) <nl> return err ; <nl> } <nl> }
mmm fs / nfs / super . c <nl> ppp fs / nfs / super . c <nl> static int nfs_parse_mount_options ( char * raw , <nl> string = match_strdup ( args ); <nl> if ( string == NULL ) <nl> goto out_nomem ; <nl> + kfree ( mnt -> client_address ); <nl> mnt -> client_address = string ; <nl> break ; <nl> case Opt_mounthost : <nl> string = match_strdup ( args ); <nl> if ( string == NULL ) <nl> goto out_nomem ; <nl> + kfree ( mnt -> mount_server . hostname ); <nl> mnt -> mount_server . hostname = string ; <nl> break ; <nl> case Opt_mountaddr :
mmm drivers / mtd / chips / cfi_util . c <nl> ppp drivers / mtd / chips / cfi_util . c <nl> int __xipram cfi_qry_mode_on ( uint32_t base , struct map_info * map , <nl> cfi_send_gen_cmd ( 0xAA , 0x5555 , base , map , cfi , cfi -> device_type , NULL ); <nl> cfi_send_gen_cmd ( 0x55 , 0x2AAA , base , map , cfi , cfi -> device_type , NULL ); <nl> cfi_send_gen_cmd ( 0x98 , 0x5555 , base , map , cfi , cfi -> device_type , NULL ); <nl> + if ( cfi_qry_present ( map , base , cfi )) <nl> + return 1 ; <nl> + /* SST 39VF640xB */ <nl> + cfi_send_gen_cmd ( 0xF0 , 0 , base , map , cfi , cfi -> device_type , NULL ); <nl> + cfi_send_gen_cmd ( 0xAA , 0x555 , base , map , cfi , cfi -> device_type , NULL ); <nl> + cfi_send_gen_cmd ( 0x55 , 0x2AA , base , map , cfi , cfi -> device_type , NULL ); <nl> + cfi_send_gen_cmd ( 0x98 , 0x555 , base , map , cfi , cfi -> device_type , NULL ); <nl> if ( cfi_qry_present ( map , base , cfi )) <nl> return 1 ; <nl> /* QRY not found */
mmm arch / x86 / kernel / cpu / perf_event . c <nl> ppp arch / x86 / kernel / cpu / perf_event . c <nl> static inline void x86_assign_hw_event ( struct perf_event * event , <nl> hwc -> event_base = 0 ; <nl> } else if ( hwc -> idx >= X86_PMC_IDX_FIXED ) { <nl> hwc -> config_base = MSR_ARCH_PERFMON_FIXED_CTR_CTRL ; <nl> - hwc -> event_base = MSR_ARCH_PERFMON_FIXED_CTR0 ; <nl> + hwc -> event_base = MSR_ARCH_PERFMON_FIXED_CTR0 + ( hwc -> idx - X86_PMC_IDX_FIXED ); <nl> } else { <nl> hwc -> config_base = x86_pmu_config_addr ( hwc -> idx ); <nl> hwc -> event_base = x86_pmu_event_addr ( hwc -> idx );
mmm drivers / usb / gadget / fsl_udc_core . c <nl> ppp drivers / usb / gadget / fsl_udc_core . c <nl> static int __exit fsl_udc_remove ( struct platform_device * pdev ) <nl> if (! udc_controller ) <nl> return - ENODEV ; <nl>  <nl> - usb_del_gadget_udc (& udc_controller -> gadget ); <nl> udc_controller -> done = & done ; <nl> + usb_del_gadget_udc (& udc_controller -> gadget ); <nl>  <nl> fsl_udc_clk_release (); <nl> 
mmm io_uring / msg_ring . c <nl> ppp io_uring / msg_ring . c <nl> int io_msg_ring ( struct io_kiocb * req , unsigned int issue_flags ) <nl> req_set_fail ( req ); <nl> io_req_set_res ( req , ret , 0 ); <nl> /* put file to avoid an attempt to IOPOLL the req */ <nl> - io_put_file ( req -> file ); <nl> + if (!( req -> flags & REQ_F_FIXED_FILE )) <nl> + io_put_file ( req -> file ); <nl> req -> file = NULL ; <nl> return IOU_OK ; <nl> }
mmm drivers / input / evdev . c <nl> ppp drivers / input / evdev . c <nl> static long evdev_do_ioctl ( struct file * file , unsigned int cmd , <nl> return - EFAULT ; <nl>  <nl> error = input_ff_upload ( dev , & effect , file ); <nl> + if ( error ) <nl> + return error ; <nl>  <nl> if ( put_user ( effect . id , &((( struct ff_effect __user *) p )-> id ))) <nl> return - EFAULT ; <nl>  <nl> - return error ; <nl> + return 0 ; <nl> } <nl>  <nl> /* Multi - number variable - length handlers */
mmm drivers / misc / fastrpc . c <nl> ppp drivers / misc / fastrpc . c <nl> static int fastrpc_dma_buf_attach ( struct dma_buf * dmabuf , <nl> FASTRPC_PHYS ( buffer -> phys ), buffer -> size ); <nl> if ( ret < 0 ) { <nl> dev_err ( buffer -> dev , " failed to get scatterlist from DMA API \ n "); <nl> + kfree ( a ); <nl> return - EINVAL ; <nl> } <nl> 
mmm drivers / net / bonding / bond_main . c <nl> ppp drivers / net / bonding / bond_main . c <nl> int bond_enslave ( struct net_device * bond_dev , struct net_device * slave_dev ) <nl> write_unlock_bh (& bond -> curr_slave_lock ); <nl> read_unlock (& bond -> lock ); <nl> } <nl> + slave_disable_netpoll ( new_slave ); <nl>  <nl> err_close : <nl> slave_dev -> priv_flags &= ~ IFF_BONDING ;
mmm drivers / kvm / mmu . c <nl> ppp drivers / kvm / mmu . c <nl> void kvm_mmu_pte_write ( struct kvm_vcpu * vcpu , gpa_t gpa , <nl> unsigned pte_size ; <nl> unsigned page_offset ; <nl> unsigned misaligned ; <nl> + unsigned quadrant ; <nl> int level ; <nl> int flooded = 0 ; <nl> int npte ; <nl> void kvm_mmu_pte_write ( struct kvm_vcpu * vcpu , gpa_t gpa , <nl> page_offset <<= 1 ; <nl> npte = 2 ; <nl> } <nl> + quadrant = page_offset >> PAGE_SHIFT ; <nl> page_offset &= ~ PAGE_MASK ; <nl> + if ( quadrant != page -> role . quadrant ) <nl> + continue ; <nl> } <nl> spte = __va ( page -> page_hpa ); <nl> spte += page_offset / sizeof (* spte );
mmm drivers / net / wireless / iwlwifi / mvm / power . c <nl> ppp drivers / net / wireless / iwlwifi / mvm / power . c <nl> static void iwl_mvm_power_build_cmd ( struct iwl_mvm * mvm , <nl> cmd -> flags |= cpu_to_le16 ( POWER_FLAGS_POWER_SAVE_ENA_MSK ); <nl>  <nl> if (! vif -> bss_conf . ps || iwl_mvm_vif_low_latency ( mvmvif ) || <nl> - ! mvmvif -> pm_enabled || iwl_mvm_tdls_sta_count ( mvm , vif )) <nl> + ! mvmvif -> pm_enabled ) <nl> return ; <nl>  <nl> cmd -> flags |= cpu_to_le16 ( POWER_FLAGS_POWER_MANAGEMENT_ENA_MSK ); <nl> static void iwl_mvm_power_set_pm ( struct iwl_mvm * mvm , <nl> if ( vifs -> ap_vif ) <nl> ap_mvmvif = iwl_mvm_vif_from_mac80211 ( vifs -> ap_vif ); <nl>  <nl> + /* don ' t allow PM if any TDLS stations exist */ <nl> + if ( iwl_mvm_tdls_sta_count ( mvm , NULL )) <nl> + return ; <nl> + <nl> /* enable PM on bss if bss stand alone */ <nl> if ( vifs -> bss_active && ! vifs -> p2p_active && ! vifs -> ap_active ) { <nl> bss_mvmvif -> pm_enabled = true ;
mmm drivers / media / video / tlg2300 / pd - video . c <nl> ppp drivers / media / video / tlg2300 / pd - video . c <nl> int alloc_bulk_urbs_generic ( struct urb ** urb_array , int num , <nl> int buf_size , gfp_t gfp_flags , <nl> usb_complete_t complete_fn , void * context ) <nl> { <nl> - struct urb * urb ; <nl> - void * mem ; <nl> - int i ; <nl> + int i = 0 ; <nl>  <nl> - for ( i = 0 ; i < num ; i ++) { <nl> - urb = usb_alloc_urb ( 0 , gfp_flags ); <nl> + for (; i < num ; i ++) { <nl> + void * mem ; <nl> + struct urb * urb = usb_alloc_urb ( 0 , gfp_flags ); <nl> if ( urb == NULL ) <nl> return i ; <nl>  <nl> mem = usb_alloc_coherent ( udev , buf_size , gfp_flags , <nl> & urb -> transfer_dma ); <nl> - if ( mem == NULL ) <nl> + if ( mem == NULL ) { <nl> + usb_free_urb ( urb ); <nl> return i ; <nl> + } <nl>  <nl> usb_fill_bulk_urb ( urb , udev , usb_rcvbulkpipe ( udev , ep_addr ), <nl> mem , buf_size , complete_fn , context );
mmm sound / pci / hda / patch_analog . c <nl> ppp sound / pci / hda / patch_analog . c <nl> static struct hda_verb ad1988_spdif_init_verbs [] = { <nl> { } <nl> }; <nl>  <nl> + static struct hda_verb ad1988_spdif_in_init_verbs [] = { <nl> + /* unmute SPDIF input pin */ <nl> + { 0x1c , AC_VERB_SET_AMP_GAIN_MUTE , AMP_IN_UNMUTE ( 0 )}, <nl> + { } <nl> +}; <nl> + <nl> /* AD1989 has no ADC -> SPDIF route */ <nl> static struct hda_verb ad1989_spdif_init_verbs [] = { <nl> /* SPDIF - 1 out pin */ <nl> static int patch_ad1988 ( struct hda_codec * codec ) <nl> ad1988_spdif_init_verbs ; <nl> } <nl> } <nl> - if ( spec -> dig_in_nid && codec -> vendor_id < 0x11d4989a ) <nl> + if ( spec -> dig_in_nid && codec -> vendor_id < 0x11d4989a ) { <nl> spec -> mixers [ spec -> num_mixers ++] = ad1988_spdif_in_mixers ; <nl> + spec -> init_verbs [ spec -> num_init_verbs ++] = <nl> + ad1988_spdif_in_init_verbs ; <nl> + } <nl>  <nl> codec -> patch_ops = ad198x_patch_ops ; <nl> switch ( board_config ) {
mmm drivers / net / bonding / bond_main . c <nl> ppp drivers / net / bonding / bond_main . c <nl> static u16 bond_select_queue ( struct net_device * dev , struct sk_buff * skb ) <nl> { <nl> /* <nl> * This helper function exists to help dev_pick_tx get the correct <nl> - * destination queue . Using a helper function skips the a call to <nl> + * destination queue . Using a helper function skips a call to <nl> * skb_tx_hash and will put the skbs in the queue we expect on their <nl> * way down to the bonding driver . <nl> */ <nl> - return skb -> queue_mapping ; <nl> + u16 txq = skb_rx_queue_recorded ( skb ) ? skb_get_rx_queue ( skb ) : 0 ; <nl> + <nl> + if ( unlikely ( txq >= dev -> real_num_tx_queues )) { <nl> + do <nl> + txq -= dev -> real_num_tx_queues ; <nl> + while ( txq >= dev -> real_num_tx_queues ); <nl> + } <nl> + return txq ; <nl> } <nl>  <nl> static netdev_tx_t bond_start_xmit ( struct sk_buff * skb , struct net_device * dev )
mmm drivers / staging / xgifb / XGI_main_26 . c <nl> ppp drivers / staging / xgifb / XGI_main_26 . c <nl> static int xgifb_probe ( struct pci_dev * pdev , <nl>  <nl> if ( xgifb_info -> mode_idx < 0 ) { <nl> dev_err (& pdev -> dev , " No supported video mode found \ n "); <nl> + ret = - EINVAL ; <nl> goto error_1 ; <nl> } <nl> 
mmm drivers / staging / speakup / kobjects . c <nl> ppp drivers / staging / speakup / kobjects . c <nl> static ssize_t synth_store ( struct kobject * kobj , struct kobj_attribute * attr , <nl> len = strlen ( buf ); <nl> if ( len < 2 || len > 9 ) <nl> return - EINVAL ; <nl> - strncpy ( new_synth_name , buf , len ); <nl> + memcpy ( new_synth_name , buf , len ); <nl> if ( new_synth_name [ len - 1 ] == '\ n ') <nl> len --; <nl> new_synth_name [ len ] = '\ 0 '; <nl> static ssize_t punc_store ( struct kobject * kobj , struct kobj_attribute * attr , <nl> return - EINVAL ; <nl> } <nl>  <nl> - strncpy ( punc_buf , buf , x ); <nl> + memcpy ( punc_buf , buf , x ); <nl>  <nl> while ( x && punc_buf [ x - 1 ] == '\ n ') <nl> x --;
mmm drivers / regulator / pwm - regulator . c <nl> ppp drivers / regulator / pwm - regulator . c <nl> static int pwm_regulator_probe ( struct platform_device * pdev ) <nl> return ret ; <nl> } <nl>  <nl> - /* <nl> - * FIXME : pwm_apply_args () should be removed when switching to the <nl> - * atomic PWM API . <nl> - */ <nl> - pwm_apply_args ( drvdata -> pwm ); <nl> + ret = pwm_adjust_config ( drvdata -> pwm ); <nl> + if ( ret ) <nl> + return ret ; <nl>  <nl> regulator = devm_regulator_register (& pdev -> dev , <nl> & drvdata -> desc , & config );
mmm drivers / staging / lustre / lustre / obdclass / obd_config . c <nl> ppp drivers / staging / lustre / lustre / obdclass / obd_config . c <nl> int class_process_proc_param ( char * prefix , struct lprocfs_vars * lvars , <nl>  <nl> oldfs = get_fs (); <nl> set_fs ( KERNEL_DS ); <nl> - rc = var -> fops -> write (& fakefile , sval , <nl> + rc = var -> fops -> write (& fakefile , <nl> + ( const char __user *) sval , <nl> vallen , NULL ); <nl> set_fs ( oldfs ); <nl> }
mmm drivers / staging / imx - drm / imx - drm - core . c <nl> ppp drivers / staging / imx - drm / imx - drm - core . c <nl> int imx_drm_add_crtc ( struct drm_crtc * crtc , <nl>  <nl> mutex_lock (& imxdrm -> mutex ); <nl>  <nl> + /* <nl> + * The vblank arrays are dimensioned by MAX_CRTC - we can ' t <nl> + * pass IDs greater than this to those functions . <nl> + */ <nl> + if ( imxdrm -> pipes >= MAX_CRTC ) { <nl> + ret = - EINVAL ; <nl> + goto err_busy ; <nl> + } <nl> + <nl> if ( imxdrm -> drm -> open_count ) { <nl> ret = - EBUSY ; <nl> goto err_busy ;
mmm include / net / udp . h <nl> ppp include / net / udp . h <nl> static inline int copy_linear_skb ( struct sk_buff * skb , int len , int off , <nl> { <nl> int n , copy = len - off ; <nl>  <nl> + if ( copy < 0 ) <nl> + return - EINVAL ; <nl> n = copy_to_iter ( skb -> data + off , copy , to ); <nl> if ( n == copy ) <nl> return 0 ;
mmm drivers / gpio / gpio - mb86s7x . c <nl> ppp drivers / gpio / gpio - mb86s7x . c <nl> static int mb86s70_gpio_request ( struct gpio_chip * gc , unsigned gpio ) <nl> spin_lock_irqsave (& gchip -> lock , flags ); <nl>  <nl> val = readl ( gchip -> base + PFR ( gpio )); <nl> + if (!( val & OFFSET ( gpio ))) { <nl> + spin_unlock_irqrestore (& gchip -> lock , flags ); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> val &= ~ OFFSET ( gpio ); <nl> writel ( val , gchip -> base + PFR ( gpio )); <nl> 
mmm fs / fuse / inode . c <nl> ppp fs / fuse / inode . c <nl> static int fuse_fill_super ( struct super_block * sb , void * data , int silent ) <nl> err_put_root : <nl> dput ( root_dentry ); <nl> err_put_conn : <nl> + bdi_destroy (& fc -> bdi ); <nl> fuse_conn_put ( fc ); <nl> err_fput : <nl> fput ( file );
mmm sound / core / control . c <nl> ppp sound / core / control . c <nl> int snd_ctl_add ( struct snd_card * card , struct snd_kcontrol * kcontrol ) <nl> { <nl> struct snd_ctl_elem_id id ; <nl> unsigned int idx ; <nl> + unsigned int count ; <nl> int err = - EINVAL ; <nl>  <nl> if (! kcontrol ) <nl> int snd_ctl_add ( struct snd_card * card , struct snd_kcontrol * kcontrol ) <nl> card -> controls_count += kcontrol -> count ; <nl> kcontrol -> id . numid = card -> last_numid + 1 ; <nl> card -> last_numid += kcontrol -> count ; <nl> + count = kcontrol -> count ; <nl> up_write (& card -> controls_rwsem ); <nl> - for ( idx = 0 ; idx < kcontrol -> count ; idx ++, id . index ++, id . numid ++) <nl> + for ( idx = 0 ; idx < count ; idx ++, id . index ++, id . numid ++) <nl> snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_ADD , & id ); <nl> return 0 ; <nl>  <nl> int snd_ctl_replace ( struct snd_card * card , struct snd_kcontrol * kcontrol , <nl> bool add_on_replace ) <nl> { <nl> struct snd_ctl_elem_id id ; <nl> + unsigned int count ; <nl> unsigned int idx ; <nl> struct snd_kcontrol * old ; <nl> int ret ; <nl> int snd_ctl_replace ( struct snd_card * card , struct snd_kcontrol * kcontrol , <nl> card -> controls_count += kcontrol -> count ; <nl> kcontrol -> id . numid = card -> last_numid + 1 ; <nl> card -> last_numid += kcontrol -> count ; <nl> + count = kcontrol -> count ; <nl> up_write (& card -> controls_rwsem ); <nl> - for ( idx = 0 ; idx < kcontrol -> count ; idx ++, id . index ++, id . numid ++) <nl> + for ( idx = 0 ; idx < count ; idx ++, id . index ++, id . numid ++) <nl> snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_ADD , & id ); <nl> return 0 ; <nl>  <nl> static int snd_ctl_elem_write ( struct snd_card * card , struct snd_ctl_file * file , <nl> result = kctl -> put ( kctl , control ); <nl> } <nl> if ( result > 0 ) { <nl> + struct snd_ctl_elem_id id = control -> id ; <nl> up_read (& card -> controls_rwsem ); <nl> - snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_VALUE , <nl> - & control -> id ); <nl> + snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_VALUE , & id ); <nl> return 0 ; <nl> } <nl> } <nl> static int snd_ctl_tlv_ioctl ( struct snd_ctl_file * file , <nl> } <nl> err = kctl -> tlv . c ( kctl , op_flag , tlv . length , _tlv -> tlv ); <nl> if ( err > 0 ) { <nl> + struct snd_ctl_elem_id id = kctl -> id ; <nl> up_read (& card -> controls_rwsem ); <nl> - snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_TLV , & kctl -> id ); <nl> + snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_TLV , & id ); <nl> return 0 ; <nl> } <nl> } else {
mmm net / mpls / af_mpls . c <nl> ppp net / mpls / af_mpls . c <nl> static int mpls_dev_sysctl_register ( struct net_device * dev , <nl> free : <nl> kfree ( table ); <nl> out : <nl> + mdev -> sysctl = NULL ; <nl> return - ENOBUFS ; <nl> } <nl>  <nl> static void mpls_dev_sysctl_unregister ( struct net_device * dev , <nl> struct net * net = dev_net ( dev ); <nl> struct ctl_table * table ; <nl>  <nl> + if (! mdev -> sysctl ) <nl> + return ; <nl> + <nl> table = mdev -> sysctl -> ctl_table_arg ; <nl> unregister_net_sysctl_table ( mdev -> sysctl ); <nl> kfree ( table );
mmm net / rxrpc / conn_service . c <nl> ppp net / rxrpc / conn_service . c <nl> struct rxrpc_connection * rxrpc_find_service_conn_rcu ( struct rxrpc_peer * peer , <nl> else if ( conn -> proto . index_key > k . index_key ) <nl> p = rcu_dereference_raw ( p -> rb_right ); <nl> else <nl> - goto done ; <nl> + break ; <nl> conn = NULL ; <nl> } <nl> } while ( need_seqretry (& peer -> service_conn_lock , seq )); <nl>  <nl> - done : <nl> done_seqretry (& peer -> service_conn_lock , seq ); <nl> _leave (" = % d ", conn ? conn -> debug_id : - 1 ); <nl> return conn ;
mmm drivers / net / wireless / ath / ath6kl / sdio . c <nl> ppp drivers / net / wireless / ath / ath6kl / sdio . c <nl> struct ath6kl_sdio { <nl> # define CMD53_ARG_FIXED_ADDRESS 0 <nl> # define CMD53_ARG_INCR_ADDRESS 1 <nl>  <nl> + static int ath6kl_sdio_config ( struct ath6kl * ar ); <nl> + <nl> static inline struct ath6kl_sdio * ath6kl_sdio_priv ( struct ath6kl * ar ) <nl> { <nl> return ar -> hif_priv ; <nl> static int ath6kl_sdio_power_on ( struct ath6kl * ar ) <nl> */ <nl> msleep ( 10 ); <nl>  <nl> + ret = ath6kl_sdio_config ( ar ); <nl> + if ( ret ) { <nl> + ath6kl_err (" Failed to config sdio : % d \ n ", ret ); <nl> + goto out ; <nl> + } <nl> + <nl> ar_sdio -> is_disabled = false ; <nl>  <nl> + out : <nl> return ret ; <nl> } <nl> 
mmm net / sctp / ipv6 . c <nl> ppp net / sctp / ipv6 . c <nl> static struct sock * sctp_v6_create_accept_sk ( struct sock * sk , <nl> newnp = inet6_sk ( newsk ); <nl>  <nl> memcpy ( newnp , np , sizeof ( struct ipv6_pinfo )); <nl> + newnp -> ipv6_mc_list = NULL ; <nl> + newnp -> ipv6_ac_list = NULL ; <nl> + newnp -> ipv6_fl_list = NULL ; <nl>  <nl> rcu_read_lock (); <nl> opt = rcu_dereference ( np -> opt );
mmm drivers / net / r8169 . c <nl> ppp drivers / net / r8169 . c <nl> static const int multicast_filter_limit = 32 ; <nl> # define RX_DMA_BURST 6 /* Maximum PCI burst , ' 6 ' is 1024 */ <nl> # define TX_DMA_BURST 6 /* Maximum PCI burst , ' 6 ' is 1024 */ <nl> # define EarlyTxThld 0x3F /* 0x3F means NO early transmit */ <nl> -# define RxPacketMaxSize 0x3FE8 /* 16K - 1 - ETH_HLEN - VLAN - CRC ... */ <nl> # define SafeMtu 0x1c20 /* ... actually life sucks beyond ~ 7k */ <nl> # define InterFrameGap 0x03 /* 3 means InterFrameGap = the shortest one */ <nl>  <nl> static u16 rtl_rw_cpluscmd ( void __iomem * ioaddr ) <nl> return cmd ; <nl> } <nl>  <nl> - static void rtl_set_rx_max_size ( void __iomem * ioaddr ) <nl> + static void rtl_set_rx_max_size ( void __iomem * ioaddr , unsigned int rx_buf_sz ) <nl> { <nl> /* Low hurts . Let ' s disable the filtering . */ <nl> - RTL_W16 ( RxMaxSize , 16383 ); <nl> + RTL_W16 ( RxMaxSize , rx_buf_sz ); <nl> } <nl>  <nl> static void rtl8169_set_magic_reg ( void __iomem * ioaddr , unsigned mac_version ) <nl> static void rtl_hw_start_8169 ( struct net_device * dev ) <nl>  <nl> RTL_W8 ( EarlyTxThres , EarlyTxThld ); <nl>  <nl> - rtl_set_rx_max_size ( ioaddr ); <nl> + rtl_set_rx_max_size ( ioaddr , tp -> rx_buf_sz ); <nl>  <nl> if (( tp -> mac_version == RTL_GIGA_MAC_VER_01 ) || <nl> ( tp -> mac_version == RTL_GIGA_MAC_VER_02 ) || <nl> static void rtl_hw_start_8168 ( struct net_device * dev ) <nl>  <nl> RTL_W8 ( EarlyTxThres , EarlyTxThld ); <nl>  <nl> - rtl_set_rx_max_size ( ioaddr ); <nl> + rtl_set_rx_max_size ( ioaddr , tp -> rx_buf_sz ); <nl>  <nl> tp -> cp_cmd |= RTL_R16 ( CPlusCmd ) | PktCntrDisable | INTT_1 ; <nl>  <nl> static void rtl_hw_start_8101 ( struct net_device * dev ) <nl>  <nl> RTL_W8 ( EarlyTxThres , EarlyTxThld ); <nl>  <nl> - rtl_set_rx_max_size ( ioaddr ); <nl> + rtl_set_rx_max_size ( ioaddr , tp -> rx_buf_sz ); <nl>  <nl> tp -> cp_cmd |= rtl_rw_cpluscmd ( ioaddr ) | PCIMulRW ; <nl> 
mmm virt / kvm / arm / vgic . c <nl> ppp virt / kvm / arm / vgic . c <nl> bool kvm_vgic_map_is_active ( struct kvm_vcpu * vcpu , struct irq_phys_map * map ) <nl> return true ; <nl> } <nl>  <nl> - return dist_active_irq ( vcpu ); <nl> + return vgic_irq_is_active ( vcpu , map -> virt_irq ); <nl> } <nl>  <nl> /*
mmm net / ipv4 / tcp_input . c <nl> ppp net / ipv4 / tcp_input . c <nl> int tcp_rcv_state_process ( struct sock * sk , struct sk_buff * skb , <nl> goto discard ; <nl>  <nl> if ( th -> syn ) { <nl> + if ( th -> fin ) <nl> + goto discard ; <nl> if ( icsk -> icsk_af_ops -> conn_request ( sk , skb ) < 0 ) <nl> return 1 ; <nl> 
mmm drivers / acpi / events / evgpe . c <nl> ppp drivers / acpi / events / evgpe . c <nl> acpi_ev_gpe_dispatch ( struct acpi_gpe_event_info * gpe_event_info , u32 gpe_number ) <nl>  <nl> ACPI_FUNCTION_TRACE ( ev_gpe_dispatch ); <nl>  <nl> + acpi_gpe_count ++; <nl> + <nl> /* <nl> * If edge - triggered , clear the GPE status bit now . Note that <nl> * level - triggered events are cleared after the GPE is serviced .mmm drivers / acpi / utilities / utglobal . c <nl> ppp drivers / acpi / utilities / utglobal . c <nl> acpi_ev_gpe_dispatch ( struct acpi_gpe_event_info * gpe_event_info , u32 gpe_number ) <nl>  <nl> ACPI_FUNCTION_TRACE ( ev_gpe_dispatch ); <nl>  <nl> + acpi_gpe_count ++; <nl> + <nl> /* <nl> * If edge - triggered , clear the GPE status bit now . Note that <nl> * level - triggered events are cleared after the GPE is serviced . <nl> void acpi_ut_init_globals ( void ) <nl>  <nl> /* GPE support */ <nl>  <nl> + acpi_gpe_count = 0 ; <nl> acpi_gbl_gpe_xrupt_list_head = NULL ; <nl> acpi_gbl_gpe_fadt_blocks [ 0 ] = NULL ; <nl> acpi_gbl_gpe_fadt_blocks [ 1 ] = NULL ; <nl> void acpi_ut_init_globals ( void ) <nl>  <nl> ACPI_EXPORT_SYMBOL ( acpi_dbg_level ) <nl> ACPI_EXPORT_SYMBOL ( acpi_dbg_layer ) <nl> + ACPI_EXPORT_SYMBOL ( acpi_gpe_count )mmm include / acpi / acglobal . h <nl> ppp include / acpi / acglobal . h <nl> acpi_ev_gpe_dispatch ( struct acpi_gpe_event_info * gpe_event_info , u32 gpe_number ) <nl>  <nl> ACPI_FUNCTION_TRACE ( ev_gpe_dispatch ); <nl>  <nl> + acpi_gpe_count ++; <nl> + <nl> /* <nl> * If edge - triggered , clear the GPE status bit now . Note that <nl> * level - triggered events are cleared after the GPE is serviced . <nl> void acpi_ut_init_globals ( void ) <nl>  <nl> /* GPE support */ <nl>  <nl> + acpi_gpe_count = 0 ; <nl> acpi_gbl_gpe_xrupt_list_head = NULL ; <nl> acpi_gbl_gpe_fadt_blocks [ 0 ] = NULL ; <nl> acpi_gbl_gpe_fadt_blocks [ 1 ] = NULL ; <nl> void acpi_ut_init_globals ( void ) <nl>  <nl> ACPI_EXPORT_SYMBOL ( acpi_dbg_level ) <nl> ACPI_EXPORT_SYMBOL ( acpi_dbg_layer ) <nl> + ACPI_EXPORT_SYMBOL ( acpi_gpe_count ) <nl> extern u32 acpi_dbg_layer ; <nl>  <nl> extern u32 acpi_gbl_nesting_level ; <nl>  <nl> +/* Event counters */ <nl> + <nl> + ACPI_EXTERN u32 acpi_gpe_count ; <nl> + <nl> /* Support for dynamic control method tracing mechanism */ <nl>  <nl> ACPI_EXTERN u32 acpi_gbl_original_dbg_level ;
mmm net / netfilter / nf_tables_netdev . c <nl> ppp net / netfilter / nf_tables_netdev . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> };mmm net / netfilter / nf_tables_inet . c <nl> ppp net / netfilter / nf_tables_inet . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl> mmm net / netfilter / nf_tables_api . c <nl> ppp net / netfilter / nf_tables_api . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> static int nft_chain_parse_hook ( struct net * net , <nl> return - EINVAL ; <nl>  <nl> hook -> num = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_HOOKNUM ])); <nl> - if ( hook -> num >= afi -> nhooks ) <nl> - return - EINVAL ; <nl> - <nl> hook -> priority = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_PRIORITY ])); <nl>  <nl> type = chain_type [ afi -> family ][ NFT_CHAIN_T_DEFAULT ]; <nl> static int nf_tables_flowtable_parse_hook ( const struct nft_ctx * ctx , <nl> return - EINVAL ; <nl>  <nl> hooknum = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_NUM ])); <nl> - if ( hooknum >= ctx -> afi -> nhooks ) <nl> + if ( hooknum != NF_NETDEV_INGRESS ) <nl> return - EINVAL ; <nl>  <nl> priority = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_PRIORITY ]));mmm net / ipv4 / netfilter / nf_tables_ipv4 . c <nl> ppp net / ipv4 / netfilter / nf_tables_ipv4 . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> static int nft_chain_parse_hook ( struct net * net , <nl> return - EINVAL ; <nl>  <nl> hook -> num = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_HOOKNUM ])); <nl> - if ( hook -> num >= afi -> nhooks ) <nl> - return - EINVAL ; <nl> - <nl> hook -> priority = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_PRIORITY ])); <nl>  <nl> type = chain_type [ afi -> family ][ NFT_CHAIN_T_DEFAULT ]; <nl> static int nf_tables_flowtable_parse_hook ( const struct nft_ctx * ctx , <nl> return - EINVAL ; <nl>  <nl> hooknum = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_NUM ])); <nl> - if ( hooknum >= ctx -> afi -> nhooks ) <nl> + if ( hooknum != NF_NETDEV_INGRESS ) <nl> return - EINVAL ; <nl>  <nl> priority = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_PRIORITY ])); <nl> static unsigned int nft_do_chain_ipv4 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv4 __read_mostly = { <nl> . family = NFPROTO_IPV4 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl> mmm net / ipv4 / netfilter / nf_tables_arp . c <nl> ppp net / ipv4 / netfilter / nf_tables_arp . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> static int nft_chain_parse_hook ( struct net * net , <nl> return - EINVAL ; <nl>  <nl> hook -> num = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_HOOKNUM ])); <nl> - if ( hook -> num >= afi -> nhooks ) <nl> - return - EINVAL ; <nl> - <nl> hook -> priority = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_PRIORITY ])); <nl>  <nl> type = chain_type [ afi -> family ][ NFT_CHAIN_T_DEFAULT ]; <nl> static int nf_tables_flowtable_parse_hook ( const struct nft_ctx * ctx , <nl> return - EINVAL ; <nl>  <nl> hooknum = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_NUM ])); <nl> - if ( hooknum >= ctx -> afi -> nhooks ) <nl> + if ( hooknum != NF_NETDEV_INGRESS ) <nl> return - EINVAL ; <nl>  <nl> priority = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_PRIORITY ])); <nl> static unsigned int nft_do_chain_ipv4 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv4 __read_mostly = { <nl> . family = NFPROTO_IPV4 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> nft_do_chain_arp ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_arp __read_mostly = { <nl> . family = NFPROTO_ARP , <nl> - . nhooks = NF_ARP_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl> mmm include / net / netfilter / nf_tables . h <nl> ppp include / net / netfilter / nf_tables . h <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> static int nft_chain_parse_hook ( struct net * net , <nl> return - EINVAL ; <nl>  <nl> hook -> num = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_HOOKNUM ])); <nl> - if ( hook -> num >= afi -> nhooks ) <nl> - return - EINVAL ; <nl> - <nl> hook -> priority = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_PRIORITY ])); <nl>  <nl> type = chain_type [ afi -> family ][ NFT_CHAIN_T_DEFAULT ]; <nl> static int nf_tables_flowtable_parse_hook ( const struct nft_ctx * ctx , <nl> return - EINVAL ; <nl>  <nl> hooknum = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_NUM ])); <nl> - if ( hooknum >= ctx -> afi -> nhooks ) <nl> + if ( hooknum != NF_NETDEV_INGRESS ) <nl> return - EINVAL ; <nl>  <nl> priority = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_PRIORITY ])); <nl> static unsigned int nft_do_chain_ipv4 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv4 __read_mostly = { <nl> . family = NFPROTO_IPV4 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> nft_do_chain_arp ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_arp __read_mostly = { <nl> . family = NFPROTO_ARP , <nl> - . nhooks = NF_ARP_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> enum nft_af_flags { <nl> * <nl> * @ list : used internally <nl> * @ family : address family <nl> - * @ nhooks : number of hooks in this family <nl> * @ owner : module owner <nl> * @ tables : used internally <nl> * @ flags : family flags <nl> enum nft_af_flags { <nl> struct nft_af_info { <nl> struct list_head list ; <nl> int family ; <nl> - unsigned int nhooks ; <nl> struct module * owner ; <nl> struct list_head tables ; <nl> u32 flags ;mmm net / ipv6 / netfilter / nf_tables_ipv6 . c <nl> ppp net / ipv6 / netfilter / nf_tables_ipv6 . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> static int nft_chain_parse_hook ( struct net * net , <nl> return - EINVAL ; <nl>  <nl> hook -> num = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_HOOKNUM ])); <nl> - if ( hook -> num >= afi -> nhooks ) <nl> - return - EINVAL ; <nl> - <nl> hook -> priority = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_PRIORITY ])); <nl>  <nl> type = chain_type [ afi -> family ][ NFT_CHAIN_T_DEFAULT ]; <nl> static int nf_tables_flowtable_parse_hook ( const struct nft_ctx * ctx , <nl> return - EINVAL ; <nl>  <nl> hooknum = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_NUM ])); <nl> - if ( hooknum >= ctx -> afi -> nhooks ) <nl> + if ( hooknum != NF_NETDEV_INGRESS ) <nl> return - EINVAL ; <nl>  <nl> priority = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_PRIORITY ])); <nl> static unsigned int nft_do_chain_ipv4 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv4 __read_mostly = { <nl> . family = NFPROTO_IPV4 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> nft_do_chain_arp ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_arp __read_mostly = { <nl> . family = NFPROTO_ARP , <nl> - . nhooks = NF_ARP_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> enum nft_af_flags { <nl> * <nl> * @ list : used internally <nl> * @ family : address family <nl> - * @ nhooks : number of hooks in this family <nl> * @ owner : module owner <nl> * @ tables : used internally <nl> * @ flags : family flags <nl> enum nft_af_flags { <nl> struct nft_af_info { <nl> struct list_head list ; <nl> int family ; <nl> - unsigned int nhooks ; <nl> struct module * owner ; <nl> struct list_head tables ; <nl> u32 flags ; <nl> static unsigned int nft_do_chain_ipv6 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv6 __read_mostly = { <nl> . family = NFPROTO_IPV6 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl> mmm net / bridge / netfilter / nf_tables_bridge . c <nl> ppp net / bridge / netfilter / nf_tables_bridge . c <nl> nft_do_chain_netdev ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_netdev __read_mostly = { <nl> . family = NFPROTO_NETDEV , <nl> - . nhooks = NF_NETDEV_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> . flags = NFT_AF_NEEDS_DEV , <nl> }; <nl> static unsigned int nft_do_chain_inet ( void * priv , struct sk_buff * skb , <nl>  <nl> static struct nft_af_info nft_af_inet __read_mostly = { <nl> . family = NFPROTO_INET , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> static int nft_chain_parse_hook ( struct net * net , <nl> return - EINVAL ; <nl>  <nl> hook -> num = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_HOOKNUM ])); <nl> - if ( hook -> num >= afi -> nhooks ) <nl> - return - EINVAL ; <nl> - <nl> hook -> priority = ntohl ( nla_get_be32 ( ha [ NFTA_HOOK_PRIORITY ])); <nl>  <nl> type = chain_type [ afi -> family ][ NFT_CHAIN_T_DEFAULT ]; <nl> static int nf_tables_flowtable_parse_hook ( const struct nft_ctx * ctx , <nl> return - EINVAL ; <nl>  <nl> hooknum = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_NUM ])); <nl> - if ( hooknum >= ctx -> afi -> nhooks ) <nl> + if ( hooknum != NF_NETDEV_INGRESS ) <nl> return - EINVAL ; <nl>  <nl> priority = ntohl ( nla_get_be32 ( tb [ NFTA_FLOWTABLE_HOOK_PRIORITY ])); <nl> static unsigned int nft_do_chain_ipv4 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv4 __read_mostly = { <nl> . family = NFPROTO_IPV4 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> nft_do_chain_arp ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_arp __read_mostly = { <nl> . family = NFPROTO_ARP , <nl> - . nhooks = NF_ARP_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> enum nft_af_flags { <nl> * <nl> * @ list : used internally <nl> * @ family : address family <nl> - * @ nhooks : number of hooks in this family <nl> * @ owner : module owner <nl> * @ tables : used internally <nl> * @ flags : family flags <nl> enum nft_af_flags { <nl> struct nft_af_info { <nl> struct list_head list ; <nl> int family ; <nl> - unsigned int nhooks ; <nl> struct module * owner ; <nl> struct list_head tables ; <nl> u32 flags ; <nl> static unsigned int nft_do_chain_ipv6 ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_ipv6 __read_mostly = { <nl> . family = NFPROTO_IPV6 , <nl> - . nhooks = NF_INET_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl>  <nl> nft_do_chain_bridge ( void * priv , <nl>  <nl> static struct nft_af_info nft_af_bridge __read_mostly = { <nl> . family = NFPROTO_BRIDGE , <nl> - . nhooks = NF_BR_NUMHOOKS , <nl> . owner = THIS_MODULE , <nl> }; <nl> 
mmm kernel / printk . c <nl> ppp kernel / printk . c <nl> asmlinkage int printk ( const char * fmt , ...) <nl> return r ; <nl> } <nl>  <nl> +/* cpu currently holding logbuf_lock */ <nl> + static volatile unsigned int printk_cpu = UINT_MAX ; <nl> + <nl> asmlinkage int vprintk ( const char * fmt , va_list args ) <nl> { <nl> unsigned long flags ; <nl> asmlinkage int vprintk ( const char * fmt , va_list args ) <nl> static char printk_buf [ 1024 ]; <nl> static int log_level_unknown = 1 ; <nl>  <nl> - if ( unlikely ( oops_in_progress )) <nl> + preempt_disable (); <nl> + if ( unlikely ( oops_in_progress ) && printk_cpu == smp_processor_id ()) <nl> + /* If a crash is occurring during printk () on this CPU , <nl> + * make sure we can ' t deadlock */ <nl> zap_locks (); <nl>  <nl> /* This stops the holder of console_sem just where we want him */ <nl> spin_lock_irqsave (& logbuf_lock , flags ); <nl> + printk_cpu = smp_processor_id (); <nl>  <nl> /* Emit the output into the temporary buffer */ <nl> printed_len = vscnprintf ( printk_buf , sizeof ( printk_buf ), fmt , args ); <nl> asmlinkage int vprintk ( const char * fmt , va_list args ) <nl> * CPU until it is officially up . We shouldn ' t be calling into <nl> * random console drivers on a CPU which doesn ' t exist yet .. <nl> */ <nl> + printk_cpu = UINT_MAX ; <nl> spin_unlock_irqrestore (& logbuf_lock , flags ); <nl> goto out ; <nl> } <nl> asmlinkage int vprintk ( const char * fmt , va_list args ) <nl> * We own the drivers . We can drop the spinlock and let <nl> * release_console_sem () print the text <nl> */ <nl> + printk_cpu = UINT_MAX ; <nl> spin_unlock_irqrestore (& logbuf_lock , flags ); <nl> console_may_schedule = 0 ; <nl> release_console_sem (); <nl> asmlinkage int vprintk ( const char * fmt , va_list args ) <nl> * allows the semaphore holder to proceed and to call the <nl> * console drivers with the output which we just produced . <nl> */ <nl> + printk_cpu = UINT_MAX ; <nl> spin_unlock_irqrestore (& logbuf_lock , flags ); <nl> } <nl> out : <nl> + preempt_enable (); <nl> return printed_len ; <nl> } <nl> EXPORT_SYMBOL ( printk );
mmm tools / objtool / check . c <nl> ppp tools / objtool / check . c <nl> static bool ignore_unreachable_insn ( struct instruction * insn ) <nl> if ( is_kasan_insn ( insn ) || is_ubsan_insn ( insn )) <nl> return true ; <nl>  <nl> - if ( insn -> type == INSN_JUMP_UNCONDITIONAL && insn -> jump_dest ) { <nl> - insn = insn -> jump_dest ; <nl> - continue ; <nl> + if ( insn -> type == INSN_JUMP_UNCONDITIONAL ) { <nl> + if ( insn -> jump_dest && <nl> + insn -> jump_dest -> func == insn -> func ) { <nl> + insn = insn -> jump_dest ; <nl> + continue ; <nl> + } <nl> + <nl> + break ; <nl> } <nl>  <nl> if ( insn -> offset + insn -> len >= insn -> func -> offset + insn -> func -> len ) <nl> break ; <nl> + <nl> insn = list_next_entry ( insn , list ); <nl> } <nl> 
mmm net / netfilter / nf_conntrack_netlink . c <nl> ppp net / netfilter / nf_conntrack_netlink . c <nl> ctnetlink_setup_nat ( struct nf_conn * ct , const struct nlattr * const cda []) <nl> # ifdef CONFIG_NF_NAT_NEEDED <nl> int ret ; <nl>  <nl> + if (! cda [ CTA_NAT_DST ] && ! cda [ CTA_NAT_SRC ]) <nl> + return 0 ; <nl> + <nl> ret = ctnetlink_parse_nat_setup ( ct , NF_NAT_MANIP_DST , <nl> cda [ CTA_NAT_DST ]); <nl> if ( ret < 0 )
mmm net / nfc / llcp / sock . c <nl> ppp net / nfc / llcp / sock . c <nl> static int llcp_sock_getname ( struct socket * sock , struct sockaddr * uaddr , <nl> struct nfc_llcp_sock * llcp_sock = nfc_llcp_sock ( sk ); <nl> DECLARE_SOCKADDR ( struct sockaddr_nfc_llcp *, llcp_addr , uaddr ); <nl>  <nl> + if ( llcp_sock == NULL || llcp_sock -> dev == NULL ) <nl> + return - EBADFD ; <nl> + <nl> pr_debug ("% p % d % d % d \ n ", sk , llcp_sock -> target_idx , <nl> llcp_sock -> dsap , llcp_sock -> ssap ); <nl> 
mmm drivers / gpu / drm / amd / display / amdgpu_dm / amdgpu_dm . c <nl> ppp drivers / gpu / drm / amd / display / amdgpu_dm / amdgpu_dm . c <nl> fill_stream_properties_from_drm_display_mode ( struct dc_stream_state * stream , <nl> const struct drm_connector * connector ) <nl> { <nl> struct dc_crtc_timing * timing_out = & stream -> timing ; <nl> + const struct drm_display_info * info = & connector -> display_info ; <nl>  <nl> memset ( timing_out , 0 , sizeof ( struct dc_crtc_timing )); <nl>  <nl> fill_stream_properties_from_drm_display_mode ( struct dc_stream_state * stream , <nl> timing_out -> v_border_top = 0 ; <nl> timing_out -> v_border_bottom = 0 ; <nl> /* TODO : un - hardcode */ <nl> - <nl> - if (( connector -> display_info . color_formats & DRM_COLOR_FORMAT_YCRCB444 ) <nl> + if ( drm_mode_is_420_only ( info , mode_in ) <nl> + && stream -> sink -> sink_signal == SIGNAL_TYPE_HDMI_TYPE_A ) <nl> + timing_out -> pixel_encoding = PIXEL_ENCODING_YCBCR420 ; <nl> + else if (( connector -> display_info . color_formats & DRM_COLOR_FORMAT_YCRCB444 ) <nl> && stream -> sink -> sink_signal == SIGNAL_TYPE_HDMI_TYPE_A ) <nl> timing_out -> pixel_encoding = PIXEL_ENCODING_YCBCR444 ; <nl> else
mmm fs / isofs / export . c <nl> ppp fs / isofs / export . c <nl> isofs_export_encode_fh ( struct inode * inode , <nl> len = 3 ; <nl> fh32 [ 0 ] = ei -> i_iget5_block ; <nl> fh16 [ 2 ] = ( __u16 ) ei -> i_iget5_offset ; /* fh16 [ sic ] */ <nl> + fh16 [ 3 ] = 0 ; /* avoid leaking uninitialized data */ <nl> fh32 [ 2 ] = inode -> i_generation ; <nl> if ( parent ) { <nl> struct iso_inode_info * eparent ;
mmm arch / mips / math - emu / cp1emu . c <nl> ppp arch / mips / math - emu / cp1emu . c <nl> int mm_isBranchInstr ( struct pt_regs * regs , struct mm_decoded_insn dec_insn , <nl> unsigned int fcr31 ; <nl> unsigned int bit ; <nl>  <nl> + if (! cpu_has_mmips ) <nl> + return 0 ; <nl> + <nl> switch ( insn . mm_i_format . opcode ) { <nl> case mm_pool32a_op : <nl> if (( insn . mm_i_format . simmediate & MM_POOL32A_MINOR_MASK ) ==
mmm drivers / macintosh / via - cuda . c <nl> ppp drivers / macintosh / via - cuda . c <nl> cuda_poll ( void ) <nl> } <nl> EXPORT_SYMBOL ( cuda_poll ); <nl>  <nl> +# define ARRAY_FULL ( a , p ) (( p ) - ( a ) == ARRAY_SIZE ( a )) <nl> + <nl> static irqreturn_t <nl> cuda_interrupt ( int irq , void * arg ) <nl> { <nl> cuda_interrupt ( int irq , void * arg ) <nl> break ; <nl>  <nl> case reading : <nl> - * reply_ptr ++ = in_8 (& via [ SR ]); <nl> + if ( reading_reply ? ARRAY_FULL ( current_req -> reply , reply_ptr ) <nl> + : ARRAY_FULL ( cuda_rbuf , reply_ptr )) <nl> + ( void ) in_8 (& via [ SR ]); <nl> + else <nl> + * reply_ptr ++ = in_8 (& via [ SR ]); <nl> if (! TREQ_asserted ( status )) { <nl> /* that ' s all folks */ <nl> negate_TIP_and_TACK ();
mmm kernel / trace / trace_events . c <nl> ppp kernel / trace / trace_events . c <nl> int trace_define_field ( struct ftrace_event_call * call , char * type , <nl> { <nl> struct ftrace_event_field * field ; <nl>  <nl> - field = kmalloc ( sizeof (* field ), GFP_KERNEL ); <nl> + field = kzalloc ( sizeof (* field ), GFP_KERNEL ); <nl> if (! field ) <nl> goto err ; <nl> + <nl> field -> name = kstrdup ( name , GFP_KERNEL ); <nl> if (! field -> name ) <nl> goto err ; <nl> + <nl> field -> type = kstrdup ( type , GFP_KERNEL ); <nl> if (! field -> type ) <nl> goto err ; <nl> + <nl> field -> offset = offset ; <nl> field -> size = size ; <nl> list_add (& field -> link , & call -> fields ); <nl>  <nl> return 0 ; <nl> + <nl> err : <nl> if ( field ) { <nl> kfree ( field -> name ); <nl> kfree ( field -> type ); <nl> } <nl> kfree ( field ); <nl> + <nl> return - ENOMEM ; <nl> } <nl> 
mmm drivers / media / video / saa7134 / saa7134 - input . c <nl> ppp drivers / media / video / saa7134 / saa7134 - input . c <nl> int saa7134_input_init1 ( struct saa7134_dev * dev ) <nl> mask_keyup = 0x400000 ; <nl> polling = 50 ; // ms <nl> break ; <nl> + case SAA7134_BOARD_VIDEOMATE_DVBT_300 : <nl> + ir_codes = videomate_tv_pvr_codes ; <nl> + mask_keycode = 0x003F00 ; <nl> + mask_keyup = 0x040000 ; <nl> + break ; <nl> } <nl> if ( NULL == ir_codes ) { <nl> printk ("% s : Oops : IR config error [ card =% d ]\ n ",mmm drivers / media / video / saa7134 / saa7134 - cards . c <nl> ppp drivers / media / video / saa7134 / saa7134 - cards . c <nl> int saa7134_input_init1 ( struct saa7134_dev * dev ) <nl> mask_keyup = 0x400000 ; <nl> polling = 50 ; // ms <nl> break ; <nl> + case SAA7134_BOARD_VIDEOMATE_DVBT_300 : <nl> + ir_codes = videomate_tv_pvr_codes ; <nl> + mask_keycode = 0x003F00 ; <nl> + mask_keyup = 0x040000 ; <nl> + break ; <nl> } <nl> if ( NULL == ir_codes ) { <nl> printk ("% s : Oops : IR config error [ card =% d ]\ n ", <nl> int saa7134_board_init1 ( struct saa7134_dev * dev ) <nl> /* case SAA7134_BOARD_SABRENT_SBTTVFM : */ /* not finished yet */ <nl> case SAA7134_BOARD_VIDEOMATE_TV_PVR : <nl> case SAA7134_BOARD_VIDEOMATE_TV_GOLD_PLUSII : <nl> + case SAA7134_BOARD_VIDEOMATE_DVBT_300 : <nl> case SAA7134_BOARD_MANLI_MTV001 : <nl> case SAA7134_BOARD_MANLI_MTV002 : <nl> case SAA7134_BOARD_BEHOLD_409FM :
mmm security / keys / key . c <nl> ppp security / keys / key . c <nl> static inline void key_alloc_serial ( struct key * key ) <nl> key -> serial = 2 ; <nl> key_serial_next = key -> serial + 1 ; <nl>  <nl> - if (! parent -> rb_parent ) <nl> + if (! rb_parent ( parent )) <nl> p = & key_serial_tree . rb_node ; <nl> - else if ( parent -> rb_parent -> rb_left == parent ) <nl> - p = & parent -> rb_parent -> rb_left ; <nl> + else if ( rb_parent ( parent )-> rb_left == parent ) <nl> + p = &( rb_parent ( parent )-> rb_left ); <nl> else <nl> - p = & parent -> rb_parent -> rb_right ; <nl> + p = &( rb_parent ( parent )-> rb_right ); <nl>  <nl> parent = rb_next ( parent ); <nl> if (! parent )
mmm drivers / net / ethernet / intel / i40e / i40e_main . c <nl> ppp drivers / net / ethernet / intel / i40e / i40e_main . c <nl> static void i40e_link_event ( struct i40e_pf * pf ) <nl> { <nl> bool new_link , old_link ; <nl> struct i40e_vsi * vsi = pf -> vsi [ pf -> lan_vsi ]; <nl> + u8 new_link_speed , old_link_speed ; <nl>  <nl> /* set this to force the get_link_status call to refresh state */ <nl> pf -> hw . phy . get_link_info = true ; <nl>  <nl> old_link = ( pf -> hw . phy . link_info_old . link_info & I40E_AQ_LINK_UP ); <nl> new_link = i40e_get_link_status (& pf -> hw ); <nl> + old_link_speed = pf -> hw . phy . link_info_old . link_speed ; <nl> + new_link_speed = pf -> hw . phy . link_info . link_speed ; <nl>  <nl> if ( new_link == old_link && <nl> + new_link_speed == old_link_speed && <nl> ( test_bit ( __I40E_DOWN , & vsi -> state ) || <nl> new_link == netif_carrier_ok ( vsi -> netdev ))) <nl> return ;
mmm drivers / acpi / bus . c <nl> ppp drivers / acpi / bus . c <nl> int acpi_device_set_power ( struct acpi_device * device , int state ) <nl> int result = 0 ; <nl> acpi_status status = AE_OK ; <nl> char object_name [ 5 ] = { ' _ ', ' P ', ' S ', ' 0 ' + state , '\ 0 ' }; <nl> + bool cut_power = false ; <nl>  <nl> if (! device || ( state < ACPI_STATE_D0 ) || ( state > ACPI_STATE_D3_COLD )) <nl> return - EINVAL ; <nl> int acpi_device_set_power ( struct acpi_device * device , int state ) <nl> return - ENODEV ; <nl> } <nl>  <nl> - /* For D3cold we should execute _PS3 , not _PS4 . */ <nl> - if ( state == ACPI_STATE_D3_COLD ) <nl> + /* For D3cold we should first transition into D3hot . */ <nl> + if ( state == ACPI_STATE_D3_COLD <nl> + && device -> power . states [ ACPI_STATE_D3_COLD ]. flags . os_accessible ) { <nl> + state = ACPI_STATE_D3_HOT ; <nl> object_name [ 3 ] = ' 3 '; <nl> + cut_power = true ; <nl> + } <nl>  <nl> /* <nl> * Transition Power <nl> int acpi_device_set_power ( struct acpi_device * device , int state ) <nl> } <nl> } <nl>  <nl> + if ( cut_power ) <nl> + result = acpi_power_transition ( device , ACPI_STATE_D3_COLD ); <nl> + <nl> end : <nl> if ( result ) <nl> printk ( KERN_WARNING PREFIX
mmm arch / powerpc / kernel / pci_64 . c <nl> ppp arch / powerpc / kernel / pci_64 . c <nl> long sys_pciconfig_iobase ( long which , unsigned long in_bus , <nl> unsigned long in_devfn ) <nl> { <nl> struct pci_controller * hose ; <nl> - struct pci_bus * bus = NULL ; <nl> + struct pci_bus * tmp_bus , * bus = NULL ; <nl> struct device_node * hose_node ; <nl>  <nl> /* Argh ! Please forgive me for that hack , but that ' s the <nl> long sys_pciconfig_iobase ( long which , unsigned long in_bus , <nl> * used on pre - domains setup . We return the first match <nl> */ <nl>  <nl> - list_for_each_entry ( bus , & pci_root_buses , node ) { <nl> - if ( in_bus >= bus -> number && in_bus <= bus -> busn_res . end ) <nl> + list_for_each_entry ( tmp_bus , & pci_root_buses , node ) { <nl> + if ( in_bus >= tmp_bus -> number && <nl> + in_bus <= tmp_bus -> busn_res . end ) { <nl> + bus = tmp_bus ; <nl> break ; <nl> - bus = NULL ; <nl> + } <nl> } <nl> if ( bus == NULL || bus -> dev . of_node == NULL ) <nl> return - ENODEV ;
mmm drivers / i2c / busses / i2c - omap . c <nl> ppp drivers / i2c / busses / i2c - omap . c <nl> static int omap_i2c_init ( struct omap_i2c_dev * dev ) <nl> * to get longer filter period for better noise suppression . <nl> * The filter is iclk ( fclk for HS ) period . <nl> */ <nl> - if ( dev -> speed > 400 || cpu_is_omap_2430 ()) <nl> + if ( dev -> speed > 400 || cpu_is_omap2430 ()) <nl> internal_clk = 19200 ; <nl> else if ( dev -> speed > 100 ) <nl> internal_clk = 9600 ;
mmm sound / usb / usbaudio . c <nl> ppp sound / usb / usbaudio . c <nl> static int check_hw_params_convention ( struct snd_usb_substream * subs ) <nl>  <nl> channels = kcalloc ( MAX_MASK , sizeof ( u32 ), GFP_KERNEL ); <nl> rates = kcalloc ( MAX_MASK , sizeof ( u32 ), GFP_KERNEL ); <nl> + if (! channels || ! rates ) <nl> + goto __out ; <nl>  <nl> list_for_each ( p , & subs -> fmt_list ) { <nl> struct audioformat * f ;
mmm drivers / staging / comedi / drivers / ni_660x . c <nl> ppp drivers / staging / comedi / drivers / ni_660x . c <nl> static int ni_660x_request_mite_channel ( struct comedi_device * dev , <nl> struct mite_channel * mite_chan ; <nl>  <nl> spin_lock_irqsave (& devpriv -> mite_channel_lock , flags ); <nl> - BUG_ON ( counter -> mite_chan ); <nl> mite_chan = mite_request_channel ( devpriv -> mite , <nl> mite_ring ( devpriv , counter )); <nl> if (! mite_chan ) {
mmm drivers / net / tun . c <nl> ppp drivers / net / tun . c <nl> static int tun_set_iff ( struct net * net , struct file * file , struct ifreq * ifr ) <nl>  <nl> err_detach : <nl> tun_detach_all ( dev ); <nl> + /* register_netdevice () already called tun_free_netdev () */ <nl> + goto err_free_dev ; <nl> + <nl> err_free_flow : <nl> tun_flow_uninit ( tun ); <nl> security_tun_dev_free_security ( tun -> security );
mmm drivers / staging / unisys / visorchannel / visorchannel_funcs . c <nl> ppp drivers / staging / unisys / visorchannel / visorchannel_funcs . c <nl> visorchannel_read ( VISORCHANNEL * channel , ulong offset , <nl> int rc = visor_memregion_read ( channel -> memregion , offset , <nl> local , nbytes ); <nl> if (( rc >= 0 ) && ( offset == 0 ) && <nl> - ( nbytes >= sizeof ( struct channel_header ))) { <nl> + ( nbytes >= sizeof ( struct channel_header ))) { <nl> memcpy (& channel -> chan_hdr , local , <nl> sizeof ( struct channel_header )); <nl> } <nl> safe_sig_queue_validate ( struct signal_queue_header * psafe_sqh , <nl> punsafe_sqh -> tail = * ptail ; <nl>  <nl> ERRDRV (" safe_sig_queue_validate : head = 0x % x , tail = 0x % x , MaxSlots = 0x % x ", <nl> - * phead , * ptail , psafe_sqh -> max_slots ); <nl> + * phead , * ptail , psafe_sqh -> max_slots ); <nl> return 0 ; <nl> } <nl> return 1 ; <nl> visorchannel_debug ( VISORCHANNEL * channel , int nQueues , <nl> struct signal_queue_header q ; <nl>  <nl> errcode = visorchannel_read ( channel , <nl> - off + phdr -> ch_space_offset + <nl> - ( i * sizeof ( q )), <nl> - & q , sizeof ( q )); <nl> + off + <nl> + phdr -> ch_space_offset + <nl> + ( i * sizeof ( q )), <nl> + & q , sizeof ( q )); <nl> if ( errcode < 0 ) { <nl> seq_printf ( seq , <nl> " failed to read signal queue #% d from channel @ 0x %- 16 . 16Lx errcode =% d \ n ",
mmm net / wireless / nl80211 . c <nl> ppp net / wireless / nl80211 . c <nl> static int nl80211_start_radar_detection ( struct sk_buff * skb , <nl> if ( err ) <nl> return err ; <nl>  <nl> + if ( netif_carrier_ok ( dev )) <nl> + return - EBUSY ; <nl> + <nl> if ( wdev -> cac_started ) <nl> return - EBUSY ; <nl> 
mmm drivers / gpu / drm / radeon / radeon_display . c <nl> ppp drivers / gpu / drm / radeon / radeon_display . c <nl> bool radeon_crtc_scaling_mode_fixup ( struct drm_crtc * crtc , <nl> radeon_crtc -> rmx_type = radeon_encoder -> rmx_type ; <nl> else <nl> radeon_crtc -> rmx_type = RMX_OFF ; <nl> - src_v = crtc -> mode . vdisplay ; <nl> - dst_v = radeon_crtc -> native_mode . vdisplay ; <nl> - src_h = crtc -> mode . hdisplay ; <nl> - dst_h = radeon_crtc -> native_mode . vdisplay ; <nl> /* copy native mode */ <nl> memcpy (& radeon_crtc -> native_mode , <nl> & radeon_encoder -> native_mode , <nl> sizeof ( struct drm_display_mode )); <nl> + src_v = crtc -> mode . vdisplay ; <nl> + dst_v = radeon_crtc -> native_mode . vdisplay ; <nl> + src_h = crtc -> mode . hdisplay ; <nl> + dst_h = radeon_crtc -> native_mode . hdisplay ; <nl>  <nl> /* fix up for overscan on hdmi */ <nl> if ( ASIC_IS_AVIVO ( rdev ) &&
mmm fs / cifs / smb2ops . c <nl> ppp fs / cifs / smb2ops . c <nl> smb2_query_symlink ( const unsigned int xid , struct cifs_tcon * tcon , <nl> & resp_buftype ); <nl> if (! rc || ! err_iov . iov_base ) { <nl> rc = - ENOENT ; <nl> - goto querty_exit ; <nl> + goto free_path ; <nl> } <nl>  <nl> err_buf = err_iov . iov_base ; <nl> smb2_query_symlink ( const unsigned int xid , struct cifs_tcon * tcon , <nl>  <nl> querty_exit : <nl> free_rsp_buf ( resp_buftype , err_buf ); <nl> + free_path : <nl> kfree ( utf16_path ); <nl> return rc ; <nl> }
mmm mm / compaction . c <nl> ppp mm / compaction . c <nl> static isolate_migrate_t isolate_migratepages ( struct zone * zone , <nl> low_pfn = isolate_migratepages_block ( cc , low_pfn , end_pfn , <nl> isolate_mode ); <nl>  <nl> - if (! low_pfn || cc -> contended ) <nl> + if (! low_pfn || cc -> contended ) { <nl> + acct_isolated ( zone , cc ); <nl> return ISOLATE_ABORT ; <nl> + } <nl>  <nl> /* <nl> * Either we isolated something and proceed with migration . Or
mmm drivers / video / amba - clcd . c <nl> ppp drivers / video / amba - clcd . c <nl> static int clcdfb_register ( struct clcd_fb * fb ) <nl>  <nl> fb_set_var (& fb -> fb , & fb -> fb . var ); <nl>  <nl> - printk ( KERN_INFO " CLCD : % s hardware , % s display \ n ", <nl> - fb -> board -> name , fb -> panel -> mode . name ); <nl> + dev_info (& fb -> dev -> dev , "% s hardware , % s display \ n ", <nl> + fb -> board -> name , fb -> panel -> mode . name ); <nl>  <nl> ret = register_framebuffer (& fb -> fb ); <nl> if ( ret == 0 ) <nl> static int clcdfb_probe ( struct amba_device * dev , struct amba_id * id ) <nl> fb -> dev = dev ; <nl> fb -> board = board ; <nl>  <nl> + dev_info (& fb -> dev -> dev , " PL % 03x rev % u at 0x % 08llx \ n ", <nl> + amba_part ( dev ), amba_rev ( dev ), <nl> + ( unsigned long long ) dev -> res . start ); <nl> + <nl> ret = fb -> board -> setup ( fb ); <nl> if ( ret ) <nl> goto free_fb ;
mmm drivers / infiniband / ulp / ipoib / ipoib_main . c <nl> ppp drivers / infiniband / ulp / ipoib / ipoib_main . c <nl> static void unicast_arp_send ( struct sk_buff * skb , struct net_device * dev , <nl> skb_push ( skb , sizeof * phdr ); <nl> __skb_queue_tail (& path -> queue , skb ); <nl>  <nl> - if ( path_rec_start ( dev , path )) { <nl> + if (! path -> query && path_rec_start ( dev , path )) { <nl> spin_unlock_irqrestore (& priv -> lock , flags ); <nl> path_free ( dev , path ); <nl> return ;
mmm drivers / gpu / drm / i915 / intel_ringbuffer . c <nl> ppp drivers / gpu / drm / i915 / intel_ringbuffer . c <nl> intel_ring_alloc_request ( struct intel_engine_cs * ring ) <nl> return - ENOMEM ; <nl>  <nl> kref_init (& request -> ref ); <nl> + request -> ring = ring ; <nl>  <nl> ret = i915_gem_get_seqno ( ring -> dev , & request -> seqno ); <nl> if ( ret ) {mmm drivers / gpu / drm / i915 / intel_lrc . c <nl> ppp drivers / gpu / drm / i915 / intel_lrc . c <nl> intel_ring_alloc_request ( struct intel_engine_cs * ring ) <nl> return - ENOMEM ; <nl>  <nl> kref_init (& request -> ref ); <nl> + request -> ring = ring ; <nl>  <nl> ret = i915_gem_get_seqno ( ring -> dev , & request -> seqno ); <nl> if ( ret ) { <nl> static int logical_ring_alloc_request ( struct intel_engine_cs * ring , <nl> } <nl>  <nl> kref_init (& request -> ref ); <nl> + request -> ring = ring ; <nl>  <nl> ret = i915_gem_get_seqno ( ring -> dev , & request -> seqno ); <nl> if ( ret ) {mmm drivers / gpu / drm / i915 / i915_gem . c <nl> ppp drivers / gpu / drm / i915 / i915_gem . c <nl> intel_ring_alloc_request ( struct intel_engine_cs * ring ) <nl> return - ENOMEM ; <nl>  <nl> kref_init (& request -> ref ); <nl> + request -> ring = ring ; <nl>  <nl> ret = i915_gem_get_seqno ( ring -> dev , & request -> seqno ); <nl> if ( ret ) { <nl> static int logical_ring_alloc_request ( struct intel_engine_cs * ring , <nl> } <nl>  <nl> kref_init (& request -> ref ); <nl> + request -> ring = ring ; <nl>  <nl> ret = i915_gem_get_seqno ( ring -> dev , & request -> seqno ); <nl> if ( ret ) { <nl> int __i915_add_request ( struct intel_engine_cs * ring , <nl> return ret ; <nl> } <nl>  <nl> - request -> ring = ring ; <nl> request -> head = request_start ; <nl> request -> tail = request_ring_position ; <nl> 
mmm drivers / input / touchscreen / sur40 . c <nl> ppp drivers / input / touchscreen / sur40 . c <nl> static int sur40_probe ( struct usb_interface * interface , <nl> sur40 -> alloc_ctx = vb2_dma_sg_init_ctx ( sur40 -> dev ); <nl> if ( IS_ERR ( sur40 -> alloc_ctx )) { <nl> dev_err ( sur40 -> dev , " Can ' t allocate buffer context "); <nl> + error = PTR_ERR ( sur40 -> alloc_ctx ); <nl> goto err_unreg_v4l2 ; <nl> } <nl> 
mmm drivers / staging / goldfish / goldfish_audio . c <nl> ppp drivers / staging / goldfish / goldfish_audio . c <nl> static int goldfish_audio_probe ( struct platform_device * pdev ) <nl> return 0 ; <nl>  <nl> err_misc_register_failed : <nl> + free_irq ( data -> irq , data ); <nl> err_request_irq_failed : <nl> dma_free_coherent (& pdev -> dev , COMBINED_BUFFER_SIZE , <nl> data -> buffer_virt , data -> buffer_phys );
mmm kernel / module . c <nl> ppp kernel / module . c <nl> static noinline struct module * load_module ( void __user * umod , <nl> free_unload : <nl> module_unload_free ( mod ); <nl> # if defined ( CONFIG_MODULE_UNLOAD ) && defined ( CONFIG_SMP ) <nl> - free_init : <nl> percpu_modfree ( mod -> refptr ); <nl> + free_init : <nl> # endif <nl> module_free ( mod , mod -> module_init ); <nl> free_core :
mmm arch / arm / kernel / sched_clock . c <nl> ppp arch / arm / kernel / sched_clock . c <nl> static unsigned long long notrace cyc_to_sched_clock ( u32 cyc , u32 mask ) <nl> u64 epoch_ns ; <nl> u32 epoch_cyc ; <nl>  <nl> - if ( cd . suspended ) <nl> - return cd . epoch_ns ; <nl> - <nl> /* <nl> * Load the epoch_cyc and epoch_ns atomically . We do this by <nl> * ensuring that we always write epoch_cyc , epoch_ns and <nl> unsigned long long __read_mostly (* sched_clock_func )( void ) = sched_clock_32 ; <nl>  <nl> unsigned long long notrace sched_clock ( void ) <nl> { <nl> + if ( cd . suspended ) <nl> + return cd . epoch_ns ; <nl> + <nl> return sched_clock_func (); <nl> } <nl> 
mmm drivers / lightnvm / pblk . h <nl> ppp drivers / lightnvm / pblk . h <nl> struct pblk { <nl>  <nl> int min_write_pgs ; /* Minimum amount of pages required by controller */ <nl> int max_write_pgs ; /* Maximum amount of pages supported by controller */ <nl> - int pgs_in_buffer ; /* Number of pages that need to be held in buffer to <nl> - * guarantee successful reads . <nl> - */ <nl>  <nl> sector_t capacity ; /* Device capacity when bad blocks are subtracted */ <nl> mmm drivers / lightnvm / pblk - init . c <nl> ppp drivers / lightnvm / pblk - init . c <nl> struct pblk { <nl>  <nl> int min_write_pgs ; /* Minimum amount of pages required by controller */ <nl> int max_write_pgs ; /* Maximum amount of pages supported by controller */ <nl> - int pgs_in_buffer ; /* Number of pages that need to be held in buffer to <nl> - * guarantee successful reads . <nl> - */ <nl>  <nl> sector_t capacity ; /* Device capacity when bad blocks are subtracted */ <nl>  <nl> static int pblk_rwb_init ( struct pblk * pblk ) <nl> struct pblk_rb_entry * entries ; <nl> unsigned long nr_entries , buffer_size ; <nl> unsigned int power_size , power_seg_sz ; <nl> + int pgs_in_buffer ; <nl>  <nl> - if ( write_buffer_size && ( write_buffer_size > pblk -> pgs_in_buffer )) <nl> + pgs_in_buffer = max ( geo -> mw_cunits , geo -> ws_opt ) * geo -> all_luns ; <nl> + <nl> + if ( write_buffer_size && ( write_buffer_size > pgs_in_buffer )) <nl> buffer_size = write_buffer_size ; <nl> else <nl> - buffer_size = pblk -> pgs_in_buffer ; <nl> + buffer_size = pgs_in_buffer ; <nl>  <nl> nr_entries = pblk_rb_calculate_size ( buffer_size ); <nl>  <nl> static int pblk_core_init ( struct pblk * pblk ) <nl> atomic64_set (& pblk -> nr_flush , 0 ); <nl> pblk -> nr_flush_rst = 0 ; <nl>  <nl> - pblk -> pgs_in_buffer = geo -> mw_cunits * geo -> all_luns ; <nl> - <nl> pblk -> min_write_pgs = geo -> ws_opt * ( geo -> csecs / PAGE_SIZE ); <nl> max_write_ppas = pblk -> min_write_pgs * geo -> all_luns ; <nl> pblk -> max_write_pgs = min_t ( int , max_write_ppas , NVM_MAX_VLBA );
mmm sound / soc / davinci / davinci - mcasp . c <nl> ppp sound / soc / davinci / davinci - mcasp . c <nl> static int davinci_mcasp_set_dai_fmt ( struct snd_soc_dai * cpu_dai , <nl> int ret = 0 ; <nl> u32 data_delay ; <nl> bool fs_pol_rising ; <nl> + bool inv_fs = false ; <nl>  <nl> pm_runtime_get_sync ( mcasp -> dev ); <nl> switch ( fmt & SND_SOC_DAIFMT_FORMAT_MASK ) { <nl> static int davinci_mcasp_set_dai_fmt ( struct snd_soc_dai * cpu_dai , <nl> /* No delay after FS */ <nl> data_delay = 0 ; <nl> break ; <nl> - default : <nl> + case SND_SOC_DAIFMT_I2S : <nl> /* configure a full - word SYNC pulse ( LRCLK ) */ <nl> mcasp_set_bits ( mcasp , DAVINCI_MCASP_TXFMCTL_REG , FSXDUR ); <nl> mcasp_set_bits ( mcasp , DAVINCI_MCASP_RXFMCTL_REG , FSRDUR ); <nl>  <nl> /* 1st data bit occur one ACLK cycle after the frame sync */ <nl> data_delay = 1 ; <nl> + /* FS need to be inverted */ <nl> + inv_fs = true ; <nl> break ; <nl> + default : <nl> + ret = - EINVAL ; <nl> + goto out ; <nl> } <nl>  <nl> mcasp_mod_bits ( mcasp , DAVINCI_MCASP_TXFMT_REG , FSXDLY ( data_delay ), <nl> static int davinci_mcasp_set_dai_fmt ( struct snd_soc_dai * cpu_dai , <nl> goto out ; <nl> } <nl>  <nl> + if ( inv_fs ) <nl> + fs_pol_rising = ! fs_pol_rising ; <nl> + <nl> if ( fs_pol_rising ) { <nl> mcasp_clr_bits ( mcasp , DAVINCI_MCASP_TXFMCTL_REG , FSXPOL ); <nl> mcasp_clr_bits ( mcasp , DAVINCI_MCASP_RXFMCTL_REG , FSRPOL );
mmm crypto / crypto_user_base . c <nl> ppp crypto / crypto_user_base . c <nl> static int crypto_report ( struct sk_buff * in_skb , struct nlmsghdr * in_nlh , <nl> drop_alg : <nl> crypto_mod_put ( alg ); <nl>  <nl> - if ( err ) <nl> + if ( err ) { <nl> + kfree_skb ( skb ); <nl> return err ; <nl> + } <nl>  <nl> return nlmsg_unicast ( net -> crypto_nlsk , skb , NETLINK_CB ( in_skb ). portid ); <nl> }
mmm drivers / infiniband / hw / mthca / mthca_qp . c <nl> ppp drivers / infiniband / hw / mthca / mthca_qp . c <nl> int mthca_alloc_qp ( struct mthca_dev * dev , <nl> } <nl>  <nl> static void mthca_lock_cqs ( struct mthca_cq * send_cq , struct mthca_cq * recv_cq ) <nl> + __acquires (& send_cq -> lock ) __acquires (& recv_cq -> lock ) <nl> { <nl> - if ( send_cq == recv_cq ) <nl> + if ( send_cq == recv_cq ) { <nl> spin_lock_irq (& send_cq -> lock ); <nl> - else if ( send_cq -> cqn < recv_cq -> cqn ) { <nl> + __acquire (& recv_cq -> lock ); <nl> + } else if ( send_cq -> cqn < recv_cq -> cqn ) { <nl> spin_lock_irq (& send_cq -> lock ); <nl> spin_lock_nested (& recv_cq -> lock , SINGLE_DEPTH_NESTING ); <nl> } else { <nl> static void mthca_lock_cqs ( struct mthca_cq * send_cq , struct mthca_cq * recv_cq ) <nl> } <nl>  <nl> static void mthca_unlock_cqs ( struct mthca_cq * send_cq , struct mthca_cq * recv_cq ) <nl> + __releases (& send_cq -> lock ) __releases (& recv_cq -> lock ) <nl> { <nl> - if ( send_cq == recv_cq ) <nl> + if ( send_cq == recv_cq ) { <nl> + __release (& recv_cq -> lock ); <nl> spin_unlock_irq (& send_cq -> lock ); <nl> - else if ( send_cq -> cqn < recv_cq -> cqn ) { <nl> + } else if ( send_cq -> cqn < recv_cq -> cqn ) { <nl> spin_unlock (& recv_cq -> lock ); <nl> spin_unlock_irq (& send_cq -> lock ); <nl> } else {
mmm tools / perf / util / sort . c <nl> ppp tools / perf / util / sort . c <nl> static int hist_entry__srcline_snprintf ( struct hist_entry * self , char * bf , <nl> if ( path != NULL ) <nl> goto out_path ; <nl>  <nl> + if (! self -> ms . map ) <nl> + goto out_ip ; <nl> + <nl> snprintf ( cmd , sizeof ( cmd ), " addr2line - e % s % 016 " PRIx64 , <nl> self -> ms . map -> dso -> long_name , self -> ip ); <nl> fp = popen ( cmd , " r ");
mmm sound / pci / hda / patch_sigmatel . c <nl> ppp sound / pci / hda / patch_sigmatel . c <nl> static const struct snd_pci_quirk stac92hd73xx_cfg_tbl [] = { <nl> SND_PCI_QUIRK ( PCI_VENDOR_ID_DELL , 0x02bd , <nl> " Dell Studio 1557 ", STAC_DELL_M6_DMIC ), <nl> SND_PCI_QUIRK ( PCI_VENDOR_ID_DELL , 0x02fe , <nl> - " Dell Studio XPS 1645 ", STAC_DELL_M6_BOTH ), <nl> + " Dell Studio XPS 1645 ", STAC_DELL_M6_DMIC ), <nl> SND_PCI_QUIRK ( PCI_VENDOR_ID_DELL , 0x0413 , <nl> " Dell Studio 1558 ", STAC_DELL_M6_DMIC ), <nl> {} /* terminator */
mmm src / src_parser . c <nl> ppp src / src_parser . c <nl> static int src_parser_trans_stage_1_2_3 ( const int tmp_fd , const char * src , const <nl> ( PBUF_TMP_PREV_CHAR ( pbuf ) == ' ' || PBUF_TMP_PREV_CHAR ( pbuf ) == '\ t ' || <nl> PBUF_TMP_PREV_CHAR ( pbuf ) == '\ n ')) { <nl> pbuf . f_indx ++; <nl> - } else if ( pbuf . tmp_indx && <nl> + } else if ( pbuf . tmp_indx && <nl> ( PBUF_TMP_PREV_CHAR ( pbuf ) == '\\')) { <nl> pbuf . tmp_indx --; <nl> pbuf . f_indx ++; <nl> static int src_parser_trans_stage_1_2_3 ( const int tmp_fd , const char * src , const <nl> continue ; <nl>  <nl> case '\\': <nl> + p_buf_write_tmp (& pbuf , tmp_fd ); <nl> p_buf_push_tmp_char (& pbuf , '\\'); <nl> continue ; <nl>  <nl> case '/': <nl> + p_buf_write_tmp (& pbuf , tmp_fd ); <nl> p_buf_push_tmp_char (& pbuf , '/'); <nl> continue ; <nl> 
mmm ssdpd . c <nl> ppp ssdpd . c <nl> static void ssdp_recv ( int sd ) <nl> ssize_t len ; <nl> struct sockaddr sa ; <nl> socklen_t salen ; <nl> - char buf [ MAX_PKT_SIZE ]; <nl> + char buf [ MAX_PKT_SIZE + 1 ]; <nl>  <nl> memset ( buf , 0 , sizeof ( buf )); <nl> - len = recvfrom ( sd , buf , sizeof ( buf ), MSG_DONTWAIT , & sa , & salen ); <nl> + len = recvfrom ( sd , buf , sizeof ( buf ) - 1 , MSG_DONTWAIT , & sa , & salen ); <nl> if ( len > 0 ) { <nl> - buf [ len ] = 0 ; <nl> - <nl> if ( sa . sa_family != AF_INET ) <nl> return ; <nl> 
mmm src / ftpcmd . c <nl> ppp src / ftpcmd . c <nl> static void handle_PORT ( ctrl_t * ctrl , char * str ) <nl>  <nl> /* Convert PORT command ' s argument to IP address + port */ <nl> sscanf ( str , "% d ,% d ,% d ,% d ,% d ,% d ", & a , & b , & c , & d , & e , & f ); <nl> - sprintf ( addr , "% d .% d .% d .% d ", a , b , c , d ); <nl> + snprintf ( addr , sizeof ( addr ), "% d .% d .% d .% d ", a , b , c , d ); <nl>  <nl> /* Check IPv4 address using inet_aton (), throw away converted result */ <nl> if (! inet_aton ( addr , &( sin . sin_addr ))) {
mmm src / common . c <nl> ppp src / common . c <nl> check : <nl> strlcat ( rpath , name , sizeof ( rpath )); <nl> } <nl>  <nl> - if (! chrooted && strncmp ( dir , home , strlen ( home ))) { <nl> + if (! chrooted && strncmp ( rpath , home , strlen ( home ))) { <nl> DBG (" Failed non - chroot dir :% s vs home :% s ", dir , home ); <nl> return NULL ; <nl> }
mmm src / statement . cc <nl> ppp src / statement . cc <nl> template < class T > Values :: Field * <nl> return new Values :: Float ( pos , source . ToNumber (). DoubleValue ()); <nl> } <nl> else if ( source . IsObject ()) { <nl> - std :: string val = source . ToString (). Utf8Value (); <nl> + Napi :: String napiVal = source . ToString (); <nl> + // Check whether toString returned a value that is not undefined . <nl> + if ( napiVal . Type () == 0 ) { <nl> + return NULL ; <nl> + } <nl> + <nl> + std :: string val = napiVal . Utf8Value (); <nl> return new Values :: Text ( pos , val . length (), val . c_str ()); <nl> } <nl> else {
mmm unix / Xvnc / programs / Xserver / hw / vnc / auth . c <nl> ppp unix / Xvnc / programs / Xserver / hw / vnc / auth . c <nl> Bool rfbOptPamAuth ( void ) <nl>  <nl> for ( s = secTypes ; s -> name != NULL ; s ++) { <nl> if ((! strcmp ( s -> name , " unixlogin ") || <nl> - ! strcmp (& s -> name [ strlen ( s -> name ) - 5 ], " plain ")) && s -> enabled ) <nl> + strstr ( s -> name , " plain ")) && s -> enabled ) <nl> return TRUE ; <nl> } <nl> mmm unix / Xvnc / programs / Xserver / hw / vnc / rfbserver . c <nl> ppp unix / Xvnc / programs / Xserver / hw / vnc / rfbserver . c <nl> Bool rfbOptPamAuth ( void ) <nl>  <nl> for ( s = secTypes ; s -> name != NULL ; s ++) { <nl> if ((! strcmp ( s -> name , " unixlogin ") || <nl> - ! strcmp (& s -> name [ strlen ( s -> name ) - 5 ], " plain ")) && s -> enabled ) <nl> + strstr ( s -> name , " plain ")) && s -> enabled ) <nl> return TRUE ; <nl> } <nl>  <nl> static void rfbProcessClientNormalMessage ( rfbClientPtr cl ) <nl>  <nl> flags = Swap32IfLE ( msg . f . flags ); <nl>  <nl> - READ ( data , msg . f . length ) <nl> - <nl> - if ( msg . f . length > sizeof ( data )) <nl> + if ( msg . f . length > sizeof ( data )) { <nl> rfbLog (" Ignoring fence . Payload of % d bytes is too large .\ n ", <nl> msg . f . length ); <nl> - else <nl> + SKIP ( msg . f . length ) <nl> + } else { <nl> + READ ( data , msg . f . length ) <nl> HandleFence ( cl , flags , msg . f . length , data ); <nl> + } <nl> + <nl> return ; <nl> } <nl> 
mmm net / nfs . c <nl> ppp net / nfs . c <nl> static int nfs_lookup_reply ( uchar * pkt , unsigned len ) <nl> } <nl>  <nl> if ( supported_nfs_versions & NFSV2_FLAG ) { <nl> + if ((( uchar *)&( rpc_pkt . u . reply . data [ 0 ]) - ( uchar *)(& rpc_pkt ) + NFS_FHSIZE ) > len ) <nl> + return - NFS_RPC_DROP ; <nl> memcpy ( filefh , rpc_pkt . u . reply . data + 1 , NFS_FHSIZE ); <nl> } else { /* NFSV3_FLAG */ <nl> filefh3_length = ntohl ( rpc_pkt . u . reply . data [ 1 ]); <nl> if ( filefh3_length > NFS3_FHSIZE ) <nl> filefh3_length = NFS3_FHSIZE ; <nl> + if ((( uchar *)&( rpc_pkt . u . reply . data [ 0 ]) - ( uchar *)(& rpc_pkt ) + filefh3_length ) > len ) <nl> + return - NFS_RPC_DROP ; <nl> memcpy ( filefh , rpc_pkt . u . reply . data + 2 , filefh3_length ); <nl> } <nl> 
mmm common / fdt_region . c <nl> ppp common / fdt_region . c <nl> int fdt_find_regions ( const void * fdt , char * const inc [], int inc_count , <nl> int depth = - 1 ; <nl> int want = 0 ; <nl> int base = fdt_off_dt_struct ( fdt ); <nl> + bool expect_end = false ; <nl>  <nl> end = path ; <nl> * end = '\ 0 '; <nl> int fdt_find_regions ( const void * fdt , char * const inc [], int inc_count , <nl> tag = fdt_next_tag ( fdt , offset , & nextoffset ); <nl> stop_at = nextoffset ; <nl>  <nl> + /* If we see two root nodes , something is wrong */ <nl> + if ( expect_end && tag != FDT_END ) <nl> + return - FDT_ERR_BADLAYOUT ; <nl> + <nl> switch ( tag ) { <nl> case FDT_PROP : <nl> include = want >= 2 ; <nl> int fdt_find_regions ( const void * fdt , char * const inc [], int inc_count , <nl> if ( depth == FDT_MAX_DEPTH ) <nl> return - FDT_ERR_BADSTRUCTURE ; <nl> name = fdt_get_name ( fdt , offset , & len ); <nl> + <nl> + /* The root node must have an empty name */ <nl> + if (! depth && * name ) <nl> + return - FDT_ERR_BADLAYOUT ; <nl> if ( end - path + 2 + len >= path_len ) <nl> return - FDT_ERR_NOSPACE ; <nl> if ( end != path + 1 ) <nl> int fdt_find_regions ( const void * fdt , char * const inc [], int inc_count , <nl> while ( end > path && *-- end != '/') <nl> ; <nl> * end = '\ 0 '; <nl> + if ( depth == - 1 ) <nl> + expect_end = true ; <nl> break ; <nl>  <nl> case FDT_END :
mmm v4l2loopback . c <nl> ppp v4l2loopback . c <nl> static int vidioc_querycap ( struct file * file , void * priv , <nl> __u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE ; <nl>  <nl> strlcpy ( cap -> driver , " v4l2 loopback ", sizeof ( cap -> driver )); <nl> - snprintf ( cap -> card , labellen , dev -> card_label ); <nl> + snprintf ( cap -> card , labellen , "% s ", dev -> card_label ); <nl> snprintf ( cap -> bus_info , sizeof ( cap -> bus_info ), <nl> " platform : v4l2loopback -% 03d ", device_nr ); <nl>  <nl> static int v4l2_loopback_add ( struct v4l2_loopback_config * conf , int * ret_nr ) <nl> } <nl>  <nl> MARK (); <nl> - snprintf ( dev -> vdev -> name , sizeof ( dev -> vdev -> name ), dev -> card_label ); <nl> + snprintf ( dev -> vdev -> name , sizeof ( dev -> vdev -> name ), "% s ", dev -> card_label ); <nl>  <nl> vdev_priv -> device_nr = nr ; <nl> 
mmm core / master . c <nl> ppp core / master . c <nl> static void master_check_listen_queue () { <nl> if ( uwsgi_sock -> queue > load ) { <nl> load = uwsgi_sock -> queue ; <nl> } <nl> - if ( uwsgi_sock -> queue >= uwsgi_sock -> max_queue ) { <nl> + if ( uwsgi_sock -> queue > 0 && uwsgi_sock -> queue >= uwsgi_sock -> max_queue ) { <nl> uwsgi_log_verbose ("*** uWSGI listen queue of socket \"% s \" ( fd : % d ) full !!! (% llu /% llu ) ***\ n ", uwsgi_sock -> name , uwsgi_sock -> fd , ( unsigned long long ) uwsgi_sock -> queue , ( unsigned long long ) uwsgi_sock -> max_queue ); <nl> uwsgi . shared -> options [ UWSGI_OPTION_BACKLOG_ERRORS ]++; <nl> }
mmm plugins / python / tracebacker . c <nl> ppp plugins / python / tracebacker . c <nl> void * uwsgi_python_tracebacker_thread ( void * foobar ) { <nl> uwsgi . no_defer_accept = current_defer_accept ; <nl>  <nl> PyObject * traceback_module = PyImport_ImportModule (" traceback "); <nl> - if (! traceback_module ) return NULL ; <nl> + if (! traceback_module ) { <nl> + free ( str_wid ); <nl> + free ( sock_path ); <nl> + close ( fd ); <nl> + return NULL ; <nl> + } <nl> PyObject * traceback_dict = PyModule_GetDict ( traceback_module ); <nl> PyObject * extract_stack = PyDict_GetItemString ( traceback_dict , " extract_stack "); <nl> 
mmm core / alarm . c <nl> ppp core / alarm . c <nl> static void uwsgi_alarm_thread_loop ( struct uwsgi_thread * ut ) { <nl> long ptr = 0 ; <nl> memcpy (& ptr , buf , sizeof ( long )); <nl> struct uwsgi_alarm_instance * uai = ( struct uwsgi_alarm_instance *) ptr ; <nl> - if (! uai ) return ; <nl> + if (! uai ) <nl> + break ; <nl> uwsgi_alarm_run ( uai , msg , msg_size ); <nl> } <nl> } <nl> } <nl> + free ( buf ); <nl> } <nl>  <nl> // initialize alarms , instances and log regexps
mmm plugins / rawrouter / rawrouter . c <nl> ppp plugins / rawrouter / rawrouter . c <nl> static struct uwsgi_option rawrouter_options [] = { <nl> {" rawrouter - ss ", required_argument , 0 , " run the rawrouter stats server ", uwsgi_opt_set_str , & urr . cr . stats_server , 0 }, <nl> {" rawrouter - harakiri ", required_argument , 0 , " enable rawrouter harakiri ", uwsgi_opt_set_int , & urr . cr . harakiri , 0 }, <nl>  <nl> - {" rawrouter - xclient ", no_argument , 0 , " use the xclient protocol to pass the client addres ", uwsgi_opt_true , & urr . xclient , 0 }, <nl> + {" rawrouter - xclient ", no_argument , 0 , " use the xclient protocol to pass the client address ", uwsgi_opt_true , & urr . xclient , 0 }, <nl>  <nl> {" rawrouter - buffer - size ", required_argument , 0 , " set internal buffer size ( default : page size )", uwsgi_opt_set_64bit , & urr . cr . buffer_size , 0 }, <nl> 
mmm plugins / stats_pusher_statsd / plugin . c <nl> ppp plugins / stats_pusher_statsd / plugin . c <nl> # include < uwsgi . h > <nl>  <nl> +/* <nl> + <nl> + this is a stats pusher plugin for the statsd server : <nl> + <nl> +-- stats - push statsd : address [, prefix ] <nl> + <nl> + example : <nl> + <nl> +-- stats - push statsd : 127 . 0 . 0 . 1 : 8125 , myinstance <nl> + <nl> + it is pretty minimal , but will be extended after the 2 . 0 metric subsystem will be released <nl> + <nl> +*/ <nl> + <nl> extern struct uwsgi_server uwsgi ; <nl>  <nl> +// configuration of a statsd node <nl> struct statsd_node { <nl> int fd ; <nl> union uwsgi_sockaddr addr ;
mmm uwsgi . c <nl> ppp uwsgi . c <nl> int uwsgi_start ( void * v_argv ) { <nl> } <nl>  <nl> uwsgi_add_sockets_to_queue ( uwsgi . async_queue ); <nl> - } <nl>  <nl> - uwsgi . rb_async_timeouts = uwsgi_init_rb_timer (); <nl> + uwsgi . rb_async_timeouts = uwsgi_init_rb_timer (); <nl>  <nl> - uwsgi . async_queue_unused = uwsgi_malloc ( sizeof ( struct wsgi_request *) * uwsgi . async ); <nl> + uwsgi . async_queue_unused = uwsgi_malloc ( sizeof ( struct wsgi_request *) * uwsgi . async ); <nl>  <nl> - for ( i = 0 ; i < uwsgi . async ; i ++) { <nl> - uwsgi . async_queue_unused [ i ] = uwsgi . wsgi_requests [ i ]; <nl> - } <nl> + for ( i = 0 ; i < uwsgi . async ; i ++) { <nl> + uwsgi . async_queue_unused [ i ] = uwsgi . wsgi_requests [ i ]; <nl> + } <nl>  <nl> - uwsgi . async_queue_unused_ptr = uwsgi . async - 1 ; <nl> + uwsgi . async_queue_unused_ptr = uwsgi . async - 1 ; <nl> + } <nl> # endif <nl>  <nl> 
mmm core / utils . c <nl> ppp core / utils . c <nl> void uwsgi_uuid ( char * buf ) { <nl> int uwsgi_uuid_cmp ( char * x , char * y ) { <nl> int i ; <nl> for ( i = 0 ; i < 36 ; i ++) { <nl> - if ( x [ i ] > y [ i ]) { <nl> - return 1 ; <nl> + if ( x [ i ] != y [ i ]) { <nl> + if ( x [ i ] > y [ i ]) { <nl> + return 1 ; <nl> + } <nl> + return 0 ; <nl> } <nl> } <nl> return 0 ;
mmm plugins / gevent / gevent . c <nl> ppp plugins / gevent / gevent . c <nl> PyObject * py_uwsgi_gevent_graceful ( PyObject * self , PyObject * args ) { <nl>  <nl> void uwsgi_gevent_gbcw () { <nl>  <nl> - uwsgi_log ("... The work of process % d is done . Seeya !\ n ", getpid ()); <nl> - <nl> py_uwsgi_gevent_graceful ( NULL , NULL ); <nl> + <nl> + uwsgi_log ("... The work of process % d is done . Seeya !\ n ", getpid ()); <nl> + exit ( 0 ); <nl> } <nl>  <nl> struct wsgi_request * uwsgi_gevent_current_wsgi_req ( void ) {
mmm plugins / pypy / pypy_plugin . c <nl> ppp plugins / pypy / pypy_plugin . c <nl> static void uwsgi_pypy_onload () { <nl> # ifdef UWSGI_PYPY_HOME <nl> upypy . home = UWSGI_PYPY_HOME ; <nl> # endif <nl> + uwsgi . has_threads = 1 ; <nl> } <nl>  <nl> static int uwsgi_pypy_mule ( char * opt ) {
mmm plugins / python / pyloader . c <nl> ppp plugins / python / pyloader . c <nl> PyObject * uwsgi_file_loader ( void * arg1 ) { <nl> Py_DECREF ( wsgi_file_dict ); <nl> Py_DECREF ( wsgi_file_module ); <nl> free ( py_filename ); <nl> - uwsgi_log ( " unable to find \" application \" callable in file % s \ n ", filename ); <nl> + uwsgi_log ( " unable to find \"% s \" callable in file % s \ n ", callable , filename ); <nl> return NULL ; <nl> } <nl>  <nl> if (! PyFunction_Check ( wsgi_file_callable ) && ! PyCallable_Check ( wsgi_file_callable )) { <nl> - uwsgi_log ( "\" application \" must be a callable object in file % s \ n ", filename ); <nl> + uwsgi_log ( "\"% s \" must be a callable object in file % s \ n ", callable , filename ); <nl> Py_DECREF ( wsgi_file_callable ); <nl> Py_DECREF ( wsgi_file_dict ); <nl> Py_DECREF ( wsgi_file_module );
mmm plugins / stats_pusher_statsd / plugin . c <nl> ppp plugins / stats_pusher_statsd / plugin . c <nl> struct uwsgi_stats_pusher_statsd { <nl>  <nl> static struct uwsgi_option stats_pusher_statsd_options [] = { <nl> {" statsd - no - workers ", no_argument , 0 , " disable generation of single worker metrics ", uwsgi_opt_true , & u_stats_pusher_statsd . no_workers , 0 }, <nl> - {" statsd - all - gauges ", no_argument , 0 , " push all metrics to statsd as gauges ", uwsgi_opt_true , & u_stats_pusher_statsd . all_gauges , 0 } <nl> + {" statsd - all - gauges ", no_argument , 0 , " push all metrics to statsd as gauges ", uwsgi_opt_true , & u_stats_pusher_statsd . all_gauges , 0 }, <nl> + UWSGI_END_OF_OPTIONS <nl> }; <nl>  <nl> // configuration of a statsd node
mmm core / logging . c <nl> ppp core / logging . c <nl> void logto ( char * logfile ) { <nl> uwsgi . logfile = logfile ; <nl>  <nl> if ( uwsgi . chmod_logfile_value ) { <nl> - if ( chmod ( uwsgi . logfile , uwsgi . chmod_logfile_value )) { <nl> - uwsgi_error (" chmod ()"); <nl> + if ( fchmod ( fd , uwsgi . chmod_logfile_value )) { <nl> + uwsgi_error (" fchmod ()"); <nl> } <nl> } <nl> }
mmm core / io . c <nl> ppp core / io . c <nl> static char * uwsgi_scheme_section ( char * url , size_t * size , int add_zero ) { <nl> } <nl>  <nl> struct uwsgi_string_list * uwsgi_register_scheme ( char * name , char * (* func )( char *, size_t *, int )) { <nl> - struct uwsgi_string_list * usl = uwsgi_string_new_list (& uwsgi . schemes , name ); <nl> + struct uwsgi_string_list * usl = NULL ; <nl> + uwsgi_foreach ( usl , uwsgi . schemes ) { <nl> + if (! strcmp ( usl -> value , name )) goto found ; <nl> + } <nl> + <nl> + usl = uwsgi_string_new_list (& uwsgi . schemes , name ); <nl> + <nl> + found : <nl> usl -> custom_ptr = func ; <nl> return usl ; <nl> }
mmm core / legion . c <nl> ppp core / legion . c <nl> static void legions_check_nodes_step2 () { <nl> memcpy ( best_uuid , node -> uuid , 36 ); <nl> } <nl> // go on if i am not an arbiter <nl> - else if ( ul -> valor > 0 ) { <nl> - // no potential Lord is available , i will propose myself <nl> - // but only if i am not suspended ... <nl> - if ( uwsgi_now () > ul -> suspended_til ) { <nl> - best_valor = ul -> valor ; <nl> - memcpy ( best_uuid , ul -> uuid , 36 ); <nl> - i_am_the_best = 1 ; <nl> - } <nl> + // no potential Lord is available , i will propose myself <nl> + // but only if i am not suspended ... <nl> + else if ( ul -> valor > 0 && uwsgi_now () > ul -> suspended_til ) { <nl> + best_valor = ul -> valor ; <nl> + memcpy ( best_uuid , ul -> uuid , 36 ); <nl> + i_am_the_best = 1 ; <nl> } <nl> else { <nl> // empty lord
mmm plugins / http / http . c <nl> ppp plugins / http / http . c <nl> int http_parse ( struct http_session * h_session ) { <nl> hv = hv -> next ; <nl> } <nl>  <nl> + // security check <nl> + if ( c >= MAX_HTTP_VEC - 4 ) { <nl> + uwsgi_log (" too much headers in request . skipping it .\ n "); <nl> + return 0 ; <nl> + } <nl> + <nl> return c ; <nl>  <nl> }
mmm master . c <nl> ppp master . c <nl> int master_loop ( char ** argv , char ** environ ) { <nl>  <nl> # endif <nl> } <nl> - kill ( uwsgi . workers [ i ]. pid , SIGUSR2 ); <nl> - // allow SIGUSR2 to be delivered <nl> - sleep ( 1 ); <nl> - kill ( uwsgi . workers [ i ]. pid , SIGKILL ); <nl> + <nl> + if ( uwsgi . workers [ i ]. pid > 0 ) { <nl> + kill ( uwsgi . workers [ i ]. pid , SIGUSR2 ); <nl> + // allow SIGUSR2 to be delivered <nl> + sleep ( 1 ); <nl> + kill ( uwsgi . workers [ i ]. pid , SIGKILL ); <nl> + } <nl> // to avoid races <nl> uwsgi . workers [ i ]. harakiri = 0 ; <nl> } <nl> int master_loop ( char ** argv , char ** environ ) { <nl> if ( uwsgi . workers [ uwsgi . mywid ]. cheaped == 1 ) { <nl> uwsgi . workers [ uwsgi . mywid ]. pid = 0 ; <nl> uwsgi_log (" uWSGI worker % d cheaped .\ n ", uwsgi . mywid ); <nl> + uwsgi . workers [ uwsgi . mywid ]. harakiri = 0 ; <nl> continue ; <nl> } <nl> gettimeofday (& last_respawn , NULL );
mmm master . c <nl> ppp master . c <nl> void master_loop ( char ** argv , char ** environ ) { <nl> // checking logsize <nl> if ( uwsgi . logfile ) { <nl> uwsgi . shared -> logsize = lseek ( 2 , 0 , SEEK_CUR ); <nl> - if ( uwsgi . shared -> logsize > 4096 ) { <nl> + if ( uwsgi . shared -> logsize > 8192 ) { <nl> uwsgi_log (" logsize : % d \ n ", uwsgi . shared -> logsize ); <nl> + char * new_logfile = uwsgi_malloc ( strlen ( uwsgi . logfile ) + 14 + 1 ); <nl> + memset ( new_logfile , 0 , strlen ( uwsgi . logfile ) + 14 + 1 ); <nl> + if (! rename ( uwsgi . logfile , new_logfile )) { <nl> + // close 2 , reopen logfile dup ' it and gracefully reload workers ; <nl> + } <nl> + free ( new_logfile ); <nl> } <nl> } <nl> 
mmm core / master_utils . c <nl> ppp core / master_utils . c <nl> int uwsgi_calc_cheaper ( void ) { <nl> ignore_algo = 1 ; <nl> } <nl> uwsgi . cheaper_fifo_delta = 0 ; <nl> + goto safe ; <nl> } <nl>  <nl> // if cheaper limits wants to change worker count , then skip cheaper algo <nl> int uwsgi_calc_cheaper ( void ) { <nl> needed_workers = 0 ; <nl> } <nl>  <nl> + safe : <nl> if ( needed_workers > 0 ) { <nl> for ( i = 1 ; i <= uwsgi . numproc ; i ++) { <nl> if ( uwsgi . workers [ i ]. cheaped == 1 && uwsgi . workers [ i ]. pid == 0 ) {
mmm plugins / v8 / v8_commonjs . cc <nl> ppp plugins / v8 / v8_commonjs . cc <nl> static v8 :: Handle < v8 :: Value > uwsgi_v8_commonjs_require ( const v8 :: Arguments & <nl> free ( tmp_filename ); <nl> return ret ; <nl> } <nl> + free ( tmp_filename ); <nl> } <nl> - free ( tmp_filename ); <nl> usl = usl -> next ; <nl> } <nl> }
mmm uwsgi . c <nl> ppp uwsgi . c <nl> int uwsgi_start ( void * v_argv ) { <nl> # ifndef __OpenBSD__ <nl>  <nl> if ( uwsgi . rl . rlim_max > 0 ) { <nl> + uwsgi . rl . rlim_cur = uwsgi . rl . rlim_max ; <nl> uwsgi_log (" limiting address space of processes ...\ n "); <nl> if ( setrlimit ( RLIMIT_AS , & uwsgi . rl )) { <nl> uwsgi_error (" setrlimit ()");
mmm core / cache . c <nl> ppp core / cache . c <nl> extern struct uwsgi_server uwsgi ; <nl>  <nl> static void cache_full ( struct uwsgi_cache * uc ) { <nl> uint64_t i ; <nl> + int force_clear = 0 ; <nl>  <nl> if (! uc -> ignore_full ) { <nl> if ( uc -> purge_lru ) <nl> static void cache_full ( struct uwsgi_cache * uc ) { <nl>  <nl> // we do not need locking here ! <nl> if ( uc -> sweep_on_full ) { <nl> + uint64_t removed = 0 ; <nl> uint64_t now = ( uint64_t ) uwsgi_now (); <nl> if ( uc -> next_scan <= now ) { <nl> uc -> next_scan = now + uc -> sweep_on_full ; <nl> for ( i = 1 ; i < uc -> max_items ; i ++) { <nl> struct uwsgi_cache_item * uci = cache_item ( i ); <nl> if ( uci -> expires > 0 && uci -> expires <= now ) { <nl> - uwsgi_cache_del2 ( uc , NULL , 0 , i , 0 ); <nl> + if (! uwsgi_cache_del2 ( uc , NULL , 0 , i , 0 )) { <nl> + removed ++; <nl> + } <nl> } <nl> } <nl> + if ( removed == 0 ) { <nl> + force_clear = 1 ; <nl> + } <nl> } <nl> } <nl>  <nl> - if ( uc -> clear_on_full ) { <nl> + if ( uc -> clear_on_full || force_clear ) { <nl> for ( i = 1 ; i < uc -> max_items ; i ++) { <nl> uwsgi_cache_del2 ( uc , NULL , 0 , i , 0 ); <nl> }
mmm plugins / alarm_xmpp / gloox . cc <nl> ppp plugins / alarm_xmpp / gloox . cc <nl> class Jabbo : public ConnectionListener { <nl> p = strtok_r ( NULL , ",", & ctx ); <nl> } <nl>  <nl> + full_jid = jab_username ; <nl> + <nl> JID jid ( jab_username ); <nl> client = new Client ( jid , jab_password ); <nl> client -> registerConnectionListener ( this ); <nl> class Jabbo : public ConnectionListener { <nl> event_queue_add_fd_read ( u_thread -> queue , fd ); <nl> event_queue_add_fd_read ( u_thread -> queue , u_thread -> pipe [ 1 ]); <nl> u_connected = 1 ; <nl> - uwsgi_log ("[ uwsgi - alarm - xmpp ] connected to the XMPP server \ n "); <nl> + uwsgi_log_alarm ("- xmpp ] (% s ) connected to the XMPP server \ n ", full_jid ); <nl> } <nl>  <nl> virtual void onDisconnect ( ConnectionError e ) { <nl> - uwsgi_log ("[ uwsgi - alarm - xmpp ] trying reconnect to the XMPP server ...\ n "); <nl> + uwsgi_log_alarm ("- xmpp ] (% s ) trying reconnect to the XMPP server ...\ n ", full_jid ); <nl> if ( u_connected ) { <nl> // no need to remove it as it is already closed ... <nl> // event_queue_del_fd ( u_thread -> queue , fd , event_queue_read ()); <nl> class Jabbo : public ConnectionListener { <nl> } <nl>  <nl> virtual void onResourceBindError ( const Error * error ) { <nl> - uwsgi_log ("[ uwsgi - alarm - xmpp ] onResourceBindError (): % s \ n ", error -> text (). c_str ()); <nl> + uwsgi_log_alarm ("- xmpp ] (% s ) onResourceBindError (): % s \ n ", full_jid , error -> text (). c_str ()); <nl> client -> disconnect (); <nl> } <nl>  <nl> virtual void onSessionCreateError ( const Error * error ) { <nl> - uwsgi_log ("[ uwsgi - alarm - xmpp ] onSessionCreateError (): % s \ n ", error -> text (). c_str ()); <nl> + uwsgi_log_alarm ("- xmpp ] (% s ) onSessionCreateError (): % s \ n ", full_jid , error -> text (). c_str ()); <nl> client -> disconnect (); <nl> } <nl>  <nl> class Jabbo : public ConnectionListener { <nl> } <nl>  <nl> Client * client ; <nl> + char * full_jid ; <nl> int fd ; <nl> int u_connected ; <nl> struct uwsgi_thread * u_thread ;
mmm core / emperor . c <nl> ppp core / emperor . c <nl> static int on_demand_bind ( char * socket_name ) { <nl> goto error ; <nl> } <nl>  <nl> + if (! is_tcp ) { <nl> + if ( chmod ( socket_name , 0666 )) { <nl> + goto error ; <nl> + } <nl> + } <nl> + <nl> if ( listen ( fd , uwsgi . listen_queue ) != 0 ) { <nl> goto error ; <nl> }
mmm plugins / alarm_curl / alarm_curl_plugin . c <nl> ppp plugins / alarm_curl / alarm_curl_plugin . c <nl> static void uwsgi_alarm_curl_to ( CURL * curl , CURLoption option , char * arg , struct <nl> p = strtok_r ( NULL , ",", & ctx ); <nl> } <nl> curl_easy_setopt ( curl , option , list ); <nl> + free ( items ); <nl> } <nl> # endif <nl>  <nl> static void uwsgi_alarm_curl_loop ( struct uwsgi_thread * ut ) { <nl> exit ( 1 ); <nl> } <nl>  <nl> + free ( opts ); <nl> + <nl> for (;;) { <nl> int ret = event_queue_wait ( ut -> queue , - 1 , & interesting_fd ); <nl> if ( ret < 0 ) return ;
mmm core / legion . c <nl> ppp core / legion . c <nl> next : <nl> } <nl>  <nl> // this must be called only by the master !!! <nl> - if ( uwsgi . mywid > 0 ) return ; <nl> + if (! uwsgi . workers ) return ; <nl> + if ( uwsgi . workers [ 0 ]. pid != getpid ()) return ; <nl> uwsgi_legion_announce_death (); <nl> } <nl> 
mmm uwsgi . c <nl> ppp uwsgi . c <nl> void uwsgi_opt_set_placeholder ( char * opt , char * value , void * none ) { <nl>  <nl> p [ 0 ] = 0 ; <nl> add_exported_option ( uwsgi_str ( value ), p + 1 , 1 ); <nl> - p [ 1 ] = '='; <nl> + p [ 0 ] = '='; <nl>  <nl> } <nl> 
mmm plugins / mongrel2 / mongrel2 . c <nl> ppp plugins / mongrel2 / mongrel2 . c <nl> static void mongrel2_connect () { <nl> } <nl> char * responder = strchr ( uwsgi_sock -> name , ','); <nl> if (! responder ) { <nl> - uwsgi_log (" invalid zeromq address \ n "); <nl> + uwsgi_log (" invalid zeromq address : % s \ n ", uwsgi_sock -> name ); <nl> exit ( 1 ); <nl> } <nl> uwsgi_sock -> receiver = uwsgi_concat2n ( uwsgi_sock -> name , responder - uwsgi_sock -> name , "", 0 );
mmm uwsgi . c <nl> ppp uwsgi . c <nl> void reap_them_all ( int signum ) { <nl> } <nl>  <nl> for ( i = 0 ; i < uwsgi . mules_cnt ; i ++) { <nl> + if (! uwsgi . mules ) break ; <nl> if ( uwsgi . mules [ i ]. pid > 0 ) <nl> kill ( uwsgi . mules [ i ]. pid , SIGKILL ); <nl> }
mmm uwsgi . c <nl> ppp uwsgi . c <nl> int main ( int argc , char * argv [], char * envp []) { <nl>  <nl> plugins_requested = getenv (" UWSGI_PLUGINS "); <nl> if ( plugins_requested ) { <nl> + plugins_requested = uwsgi_concat2 ( plugins_requested , ""); <nl> char * p = strtok ( plugins_requested , ","); <nl> while ( p != NULL ) { <nl> uwsgi_load_plugin (- 1 , p , NULL , 0 ); <nl> static int manage_base_opt ( int i , char * optarg ) { <nl> uwsgi . allowed_modifiers = optarg ; <nl> return 1 ; <nl> case LONG_ARGS_PLUGINS : <nl> - p = strtok ( optarg , ","); <nl> + p = strtok ( uwsgi_concat2 ( optarg , ""), ","); <nl> while ( p != NULL ) { <nl> # ifdef UWSGI_DEBUG <nl> uwsgi_debug (" loading plugin % s \ n ", p );
mmm plugins / http / http . c <nl> ppp plugins / http / http . c <nl> struct uwsgi_http { <nl> uint8_t modifier1 ; <nl> struct uwsgi_string_list * http_vars ; <nl> int manage_expect ; <nl> + <nl> + int raw_body ; <nl> + <nl> int keepalive ; <nl> # ifdef UWSGI_SSL <nl> int https_export_cert ; <nl> struct uwsgi_option http_options [] = { <nl> {" http - manage - expect ", no_argument , 0 , " manage the Expect HTTP request header ", uwsgi_opt_true , & uhttp . manage_expect , 0 }, <nl> {" http - keepalive ", no_argument , 0 , " support HTTP keepalive ( non - pipelined ) requests ( requires backend support )", uwsgi_opt_true , & uhttp . keepalive , 0 }, <nl>  <nl> + {" http - raw - body ", no_argument , 0 , " blindly send HTTP body to backends ( required for WebSockets and Icecast support )", uwsgi_opt_true , & uhttp . raw_body , 0 }, <nl> + <nl> {" http - use - code - string ", required_argument , 0 , " use code string as hostname -> server mapper for the http router ", uwsgi_opt_corerouter_cs , & uhttp , 0 }, <nl> {" http - use - socket ", optional_argument , 0 , " forward request to the specified uwsgi socket ", uwsgi_opt_corerouter_use_socket , & uhttp , 0 }, <nl> {" http - gracetime ", required_argument , 0 , " retry connections to dead static nodes after the specified amount of seconds ", uwsgi_opt_set_int , & uhttp . cr . static_node_gracetime , 0 }, <nl> To have a reliable implementation , we need to reset a bunch of values <nl> break ; <nl> } <nl>  <nl> + if ( cs -> post_cl == 0 && uhttp . raw_body ) goto raw ; <nl> + <nl> // avoid pipelined input <nl> if ( hs -> received_body >= cs -> post_cl ) { <nl> break ; <nl> To have a reliable implementation , we need to reset a bunch of values <nl> len = cs -> post_cl - hs -> received_body ; <nl> } <nl>  <nl> + raw : <nl> len = send ( cs -> instance_fd , bbuf , len , 0 ); <nl>  <nl> if ( len <= 0 ) {mmm plugins / python / uwsgi_pymodule . c <nl> ppp plugins / python / uwsgi_pymodule . c <nl> struct uwsgi_http { <nl> uint8_t modifier1 ; <nl> struct uwsgi_string_list * http_vars ; <nl> int manage_expect ; <nl> + <nl> + int raw_body ; <nl> + <nl> int keepalive ; <nl> # ifdef UWSGI_SSL <nl> int https_export_cert ; <nl> struct uwsgi_option http_options [] = { <nl> {" http - manage - expect ", no_argument , 0 , " manage the Expect HTTP request header ", uwsgi_opt_true , & uhttp . manage_expect , 0 }, <nl> {" http - keepalive ", no_argument , 0 , " support HTTP keepalive ( non - pipelined ) requests ( requires backend support )", uwsgi_opt_true , & uhttp . keepalive , 0 }, <nl>  <nl> + {" http - raw - body ", no_argument , 0 , " blindly send HTTP body to backends ( required for WebSockets and Icecast support )", uwsgi_opt_true , & uhttp . raw_body , 0 }, <nl> + <nl> {" http - use - code - string ", required_argument , 0 , " use code string as hostname -> server mapper for the http router ", uwsgi_opt_corerouter_cs , & uhttp , 0 }, <nl> {" http - use - socket ", optional_argument , 0 , " forward request to the specified uwsgi socket ", uwsgi_opt_corerouter_use_socket , & uhttp , 0 }, <nl> {" http - gracetime ", required_argument , 0 , " retry connections to dead static nodes after the specified amount of seconds ", uwsgi_opt_set_int , & uhttp . cr . static_node_gracetime , 0 }, <nl> To have a reliable implementation , we need to reset a bunch of values <nl> break ; <nl> } <nl>  <nl> + if ( cs -> post_cl == 0 && uhttp . raw_body ) goto raw ; <nl> + <nl> // avoid pipelined input <nl> if ( hs -> received_body >= cs -> post_cl ) { <nl> break ; <nl> To have a reliable implementation , we need to reset a bunch of values <nl> len = cs -> post_cl - hs -> received_body ; <nl> } <nl>  <nl> + raw : <nl> len = send ( cs -> instance_fd , bbuf , len , 0 ); <nl>  <nl> if ( len <= 0 ) { <nl> PyObject * py_uwsgi_unlock ( PyObject * self , PyObject * args ) { <nl> return Py_None ; <nl> } <nl>  <nl> + PyObject * py_uwsgi_connection_fd ( PyObject * self , PyObject * args ) { <nl> + struct wsgi_request * wsgi_req = current_wsgi_req (); <nl> + return PyInt_FromLong ( wsgi_req -> poll . fd ); <nl> +} <nl> + <nl> PyObject * py_uwsgi_embedded_data ( PyObject * self , PyObject * args ) { <nl>  <nl> char * name ; <nl> static PyMethodDef uwsgi_advanced_methods [] = { <nl> # endif <nl>  <nl> {" connect ", py_uwsgi_connect , METH_VARARGS , ""}, <nl> + {" connection_fd ", py_uwsgi_connection_fd , METH_VARARGS , ""}, <nl> {" is_connected ", py_uwsgi_is_connected , METH_VARARGS , ""}, <nl> {" send ", py_uwsgi_send , METH_VARARGS , ""}, <nl> {" recv ", py_uwsgi_recv , METH_VARARGS , ""},
mmm core / mount . c <nl> ppp core / mount . c <nl> int uwsgi_mount ( char * fs , char * what , char * where , char * flags , char * data ) { <nl> char * mflags = uwsgi_str ( flags ); <nl> char * p , * ctx = NULL ; <nl> uwsgi_foreach_token ( mflags , ",", p , ctx ) { <nl> + if ( strcmp ( p , " defaults ") == 0 ) <nl> + continue ; <nl> unsigned long flag = ( unsigned long ) uwsgi_mount_flag ( p ); <nl> if (! flag ) { <nl> uwsgi_log (" unknown mount flag \"% s \"\ n ", p ); <nl> int uwsgi_mount ( char * fs , char * what , char * where , char * flags , char * data ) { <nl> } <nl> mountflags |= flag ; <nl> } <nl> + if (!* fs ) fs = NULL ; <nl> free ( mflags ); <nl> parsed : <nl> # ifdef __linux__
mmm proto / http . c <nl> ppp proto / http . c <nl> static uint16_t http_add_uwsgi_header ( struct wsgi_request * wsgi_req , char * hh , i <nl> wsgi_req -> if_modified_since = val ; <nl> wsgi_req -> if_modified_since_len = vallen ; <nl> } <nl> + else if (! uwsgi_strncmp (" X_FORWARDED_SSL ", 15 , hh , keylen )) { <nl> + if ( vallen == 2 && val [ 0 ] == ' o ' && val [ 1 ] == ' n ') { <nl> + wsgi_req -> scheme = " https "; <nl> + wsgi_req -> scheme_len = 5 ; <nl> + } <nl> + } <nl> else if ( uwsgi . vhost_host && ! uwsgi_strncmp (" HOST ", 4 , hh , keylen )) { <nl> wsgi_req -> host = val ; <nl> wsgi_req -> host_len = vallen ;
mmm plugins / python / pyutils . c <nl> ppp plugins / python / pyutils . c <nl> void init_pyargv () { <nl> # endif <nl>  <nl> up . argc = 1 ; <nl> - char * tmp_ptr = uwsgi_str ( up . argv ); <nl> + if ( up . argv ) { <nl> + char * tmp_ptr = uwsgi_str ( up . argv ); <nl> # ifdef __sun__ <nl> // FIX THIS !!! <nl> ap = strtok ( tmp_ptr , " "); <nl> void init_pyargv () { <nl> } <nl> } <nl>  <nl> - free ( tmp_ptr ); <nl> + free ( tmp_ptr ); <nl> + } <nl>  <nl> # ifdef PYTHREE <nl> up . py_argv = uwsgi_calloc ( sizeof ( wchar_t *) * up . argc + 1 );
mmm apache2 / mod_uwsgi . c <nl> ppp apache2 / mod_uwsgi . c <nl> static int uwsgi_handler ( request_rec * r ) { <nl> } <nl> else { <nl> if ( r -> path_info ) { <nl> - ap_log_rerror ( APLOG_MARK , APLOG_ERR , 0 , r , " uwsgi : PATH_INFO : % s ", r -> path_info ); <nl> - vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " SCRIPT_NAME ", apr_pstrndup ( r -> pool , r -> uri , ( strlen ( r -> uri ) - strlen ( r -> path_info ) )) , & pkt_size ) ; <nl> - vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " PATH_INFO ", r -> path_info , & pkt_size ) ; <nl> + if ( strlen ( r -> path_info ) <= 0 ) { <nl> + vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " SCRIPT_NAME ", "", & pkt_size ) ; <nl> + vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " PATH_INFO ", r -> uri , & pkt_size ) ; <nl> + } <nl> + else { <nl> + vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " SCRIPT_NAME ", apr_pstrndup ( r -> pool , r -> uri , ( strlen ( r -> uri ) - strlen ( r -> path_info ) )) , & pkt_size ) ; <nl> + vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " PATH_INFO ", r -> path_info , & pkt_size ) ; <nl> + } <nl> } <nl> else { <nl> vecptr = uwsgi_add_var ( uwsgi_vars , vecptr , " SCRIPT_NAME ", "", & pkt_size ) ;
mmm core / uwsgi . c <nl> ppp core / uwsgi . c <nl> void * mem_collector ( void * foobar ) { <nl> uwsgi_log_verbose (" mem - collector thread started for worker % d \ n ", uwsgi . mywid ); <nl> for (;;) { <nl> sleep ( uwsgi . mem_collector_freq ); <nl> - uint64_t rss , vsz ; <nl> + uint64_t rss = 0 , vsz = 0 ; <nl> get_memusage (& rss , & vsz ); <nl> uwsgi . workers [ uwsgi . mywid ]. rss_size = rss ; <nl> uwsgi . workers [ uwsgi . mywid ]. vsz_size = vsz ;
mmm plugins / router_rewrite / router_rewrite . c <nl> ppp plugins / router_rewrite / router_rewrite . c <nl> static int uwsgi_routing_func_rewrite ( struct wsgi_request * wsgi_req , struct uwsg <nl> char * ptr = uwsgi_req_append ( wsgi_req , " PATH_INFO ", 9 , path_info , path_info_len ); <nl> if (! ptr ) goto clear ; <nl>  <nl> + free ( path_info ); <nl> + <nl> // set new path_info <nl> wsgi_req -> path_info = ptr ; <nl> wsgi_req -> path_info_len = path_info_len ;
mmm utils . c <nl> ppp utils . c <nl> void uwsgi_set_processname ( char * name ) { <nl> strncat ( uwsgi . orig_argv [ 0 ], uwsgi . procname_append , uwsgi . max_procname -( amount + 1 )); <nl> } <nl>  <nl> - memset ( uwsgi . orig_argv [ 0 ]+ amount + 1 , ' ', uwsgi . max_procname -( amount - 1 )); <nl> + // fill with spaces ... <nl> + memset ( uwsgi . orig_argv [ 0 ]+ amount + 1 , ' ', uwsgi . max_procname -( amount )); <nl> + // end with \ 0 <nl> + memset ( uwsgi . orig_argv [ 0 ]+ amount + 1 +( uwsgi . max_procname -( amount )), '\ 0 ', 1 ); <nl> + <nl> # elif defined ( __FreeBSD__ ) <nl> if ( uwsgi . procname_prefix ) { <nl> if (! uwsgi . procname_append ) {
mmm plugins / router_cache / router_cache . c <nl> ppp plugins / router_cache / router_cache . c <nl> error : <nl> if ( urcc -> key ) free ( urcc -> key ); <nl> if ( urcc -> name ) free ( urcc -> name ); <nl> if ( urcc -> expires_str ) free ( urcc -> expires_str ); <nl> + free ( urcc ); <nl> return - 1 ; <nl> } <nl> 
mmm plugins / cgi / cgi_plugin . c <nl> ppp plugins / cgi / cgi_plugin . c <nl> char * uwsgi_cgi_get_docroot ( char * path_info , uint16_t path_info_len , int * need_f <nl> } <nl>  <nl> if ( choosen_udd -> status == 0 ) { <nl> - char * tmp_udd = realpath ( path , NULL ); <nl> - if (! tmp_udd ) { <nl> + char * tmp_udd = uwsgi_malloc ( PATH_MAX + 1 ); <nl> + if (! realpath ( path , tmp_udd )) { <nl> return NULL ; <nl> } <nl> 
mmm core / utils . c <nl> ppp core / utils . c <nl> void uwsgi_write_pidfile_explicit ( char * pidfile_name , pid_t pid ) { <nl> } <nl>  <nl> char * uwsgi_expand_path ( char * dir , int dir_len , char * ptr ) { <nl> - char src [ PATH_MAX + 1 ]; <nl> - memcpy ( src , dir , dir_len ); <nl> - src [ dir_len ] = 0 ; <nl> + if ( dir_len > PATH_MAX ) <nl> + { <nl> + uwsgi_log (" invalid path size : % d ( max % d )\ n ", dir_len , PATH_MAX ); <nl> + return NULL ; <nl> + } <nl> + char * src = uwsgi_concat2n ( dir , dir_len , "", 0 ); <nl> char * dst = ptr ; <nl> if (! dst ) <nl> dst = uwsgi_malloc ( PATH_MAX + 1 ); <nl> char * uwsgi_expand_path ( char * dir , int dir_len , char * ptr ) { <nl> uwsgi_error_realpath ( src ); <nl> if (! ptr ) <nl> free ( dst ); <nl> + free ( src ); <nl> return NULL ; <nl> } <nl> + free ( src ); <nl> return dst ; <nl> } <nl> 
mmm core / cache . c <nl> ppp core / cache . c <nl> static uint64_t uwsgi_cache_find_free_blocks ( struct uwsgi_cache * uc , uint64_t ne <nl>  <nl> // ok we now have the start position , let ' s search for contiguous blocks <nl> uint8_t * bitmap = uc -> blocks_bitmap ; <nl> - uint64_t base = 0xffffffffffffffff ; <nl> + uint64_t base = 0xffffffffffffffffLLU ; <nl> uint8_t base_bit = 0 ; <nl> uint64_t j ; <nl> uint64_t found = 0 ; <nl> static uint64_t uwsgi_cache_find_free_blocks ( struct uwsgi_cache * uc , uint64_t ne <nl> // used block <nl> if ( num & i ) { <nl> found = 0 ; <nl> - base = 0xffffffffffffffff ; <nl> + base = 0xffffffffffffffffLLU ; <nl> base_bit = 0 ; <nl> } <nl> // free block <nl> else { <nl> - if ( base == 0xffffffffffffffff ) { <nl> + if ( base == 0xffffffffffffffffLLU ) { <nl> base = j ; <nl> base_bit = bit_pos ; <nl> } <nl> static uint64_t uwsgi_cache_find_free_blocks ( struct uwsgi_cache * uc , uint64_t ne <nl> if ( j >= need_to_scan ) { <nl> j = 0 ; <nl> found = 0 ; <nl> - base = 0xffffffffffffffff ; <nl> + base = 0xffffffffffffffffLLU ; <nl> base_bit = 0 ; <nl> } <nl> } <nl>  <nl>  <nl> // no more free blocks <nl> - return 0xffffffffffffffff ; <nl> + return 0xffffffffffffffffLLU ; <nl> } <nl>  <nl> static uint64_t cache_mark_blocks ( struct uwsgi_cache * uc , uint64_t index , uint64_t len ) { <nl> int uwsgi_cache_set2 ( struct uwsgi_cache * uc , char * key , uint16_t keylen , char * v <nl> else { <nl> uci -> first_block = uwsgi_cache_find_free_blocks ( uc , vallen ); <nl> // uwsgi_log (" first block = % llu \ n ", uci -> first_block ); <nl> - if ( uci -> first_block == 0xffffffffffffffff ) { <nl> + if ( uci -> first_block == 0xffffffffffffffffLLU ) { <nl> uwsgi_log ("*** DANGER cache \"% s \" is FULL !!! ***\ n ", uc -> name ); <nl> uc -> full ++; <nl> if ( rollback_mode == 0 ) { <nl> int uwsgi_cache_set2 ( struct uwsgi_cache * uc , char * key , uint16_t keylen , char * v <nl> // we have a special case here , as we need to find a new series of free blocks <nl> uint64_t old_first_block = uci -> first_block ; <nl> uci -> first_block = uwsgi_cache_find_free_blocks ( uc , vallen ); <nl> - if ( uci -> first_block == 0xffffffffffffffff ) { <nl> + if ( uci -> first_block == 0xffffffffffffffffLLU ) { <nl> uwsgi_log ("*** DANGER cache \"% s \" is FULL !!! ***\ n ", uc -> name ); <nl> uc -> full ++; <nl> uci -> first_block = old_first_block ;
mmm plugins / python / python_plugin . c <nl> ppp plugins / python / python_plugin . c <nl> void uwsgi_python_reset_random_seed () { <nl> void uwsgi_python_atexit () { <nl>  <nl> // if hijacked do not run atexit hooks <nl> + if ( uwsgi . workers [ uwsgi . mywid ]. hijacked ) <nl> + return ; <nl>  <nl> // this time we use this higher level function <nl> // as this code can be executed in a signal handler
mmm plugins / python / python_plugin . c <nl> ppp plugins / python / python_plugin . c <nl> void uwsgi_python_harakiri ( int wid ) { <nl> char * address = uwsgi_concat2 ( up . tracebacker , uwsgi_num2str ( wid )); <nl>  <nl> int fd = uwsgi_connect ( address , - 1 , 0 ); <nl> - for (;;) { <nl> + while ( fd >= 0 ) { <nl> int ret = uwsgi_waitfd ( fd , uwsgi . shared -> options [ UWSGI_OPTION_SOCKET_TIMEOUT ]); <nl> if ( ret <= 0 ) { <nl> break ;
mmm apache2 / mod_proxy_uwsgi . c <nl> ppp apache2 / mod_proxy_uwsgi . c <nl> static int uwsgi_response ( request_rec * r , proxy_conn_rec * backend , proxy_server_ <nl> ap_set_content_type ( r , apr_pstrdup ( r -> pool , buf )); <nl> } <nl>  <nl> - for (;;) { <nl> + int finish = 0 ; <nl> + while (! finish ) { <nl> rv = ap_get_brigade ( rp -> input_filters , bb , <nl> AP_MODE_READBYTES , mode , <nl> conf -> io_buffer_size ); <nl> static int uwsgi_response ( request_rec * r , proxy_conn_rec * backend , proxy_server_ <nl>  <nl> ap_proxy_buckets_lifetime_transform ( r , bb , pass_bb ); <nl>  <nl> - ap_pass_brigade ( r -> output_filters , pass_bb ); <nl> + // found the last brigade ? <nl> + if ( APR_BUCKET_IS_EOS ( APR_BRIGADE_LAST ( bb ))) finish = 1 ; <nl> + <nl> + if ( ap_pass_brigade ( r -> output_filters , pass_bb ) != APR_SUCCESS || c -> aborted ) { <nl> + finish = 1 ; <nl> + } <nl> + <nl> apr_brigade_cleanup ( bb ); <nl> apr_brigade_cleanup ( pass_bb ); <nl> }
mmm core / init . c <nl> ppp core / init . c <nl> void sanitize_args () { <nl>  <nl> /* here we try to choose if thunder lock is a good thing */ <nl> # ifdef UNBIT <nl> - if ( uwsgi . numproc > 1 ) { <nl> + if ( uwsgi . numproc > 1 && ! uwsgi . map_socket ) { <nl> uwsgi . use_thunder_lock = 1 ; <nl> } <nl> # endif
mmm core / emperor . c <nl> ppp core / emperor . c <nl> next : <nl> } <nl>  <nl> void uwsgi_emperor_simple_do_with_attrs ( struct uwsgi_emperor_scanner * ues , char * name , char * config , time_t ts , uid_t uid , gid_t gid , char * socket_name , struct uwsgi_dyn_dict * attrs ) { <nl> - if (! uwsgi_emperor_is_valid ( name )) <nl> + if (! uwsgi_emperor_is_valid ( name )) { <nl> + if ( attrs ) <nl> + uwsgi_dyn_dict_free (& attrs ); <nl> return ; <nl> + } <nl>  <nl> struct uwsgi_instance * ui_current = emperor_get ( name ); <nl>  <nl> if ( ui_current ) { <nl> + if ( ui_current -> attrs ) { <nl> + uwsgi_dyn_dict_free (& ui_current -> attrs ); <nl> + } <nl> + ui_current -> attrs = attrs ; <nl>  <nl> // skip in case the instance is going down ... <nl> if ( ui_current -> status > 0 )
mmm core / master_utils . c <nl> ppp core / master_utils . c <nl> struct uwsgi_stats * uwsgi_master_generate_stats () { <nl> uc = uc -> next ; <nl> } <nl>  <nl> + if ( uwsgi_stats_list_close ( us )) <nl> + goto end ; <nl> + <nl> if ( uwsgi_stats_comma ( us )) <nl> goto end ; <nl> }
mmm core / utils . c <nl> ppp core / utils . c <nl> char * uwsgi_chomp2 ( char * str ) { <nl>  <nl>  <nl> int uwsgi_tmpfd () { <nl> + int fd = - 1 ; <nl> char * tmpdir = getenv (" TMPDIR "); <nl> if (! tmpdir ) { <nl> tmpdir = "/ tmp "; <nl> } <nl> +# ifdef O_TMPFILE <nl> + fd = open ( tmpdir , O_TMPFILE | O_RDWR ); <nl> + if ( fd >= 0 ) { <nl> + return fd ; <nl> + } <nl> + // fallback to old style <nl> +# endif <nl> char * template = uwsgi_concat2 ( tmpdir , "/ uwsgiXXXXXX "); <nl> - int fd = mkstemp ( template ); <nl> + fd = mkstemp ( template ); <nl> unlink ( template ); <nl> free ( template ); <nl> return fd ;
mmm core / master_utils . c <nl> ppp core / master_utils . c <nl> int uwsgi_respawn_worker ( int wid ) { <nl> for ( i = 0 ; i < uwsgi . cores ; i ++) { <nl> uwsgi . workers [ uwsgi . mywid ]. cores [ i ]. in_request = 0 ; <nl> memset (& uwsgi . workers [ uwsgi . mywid ]. cores [ i ]. req , 0 , sizeof ( struct wsgi_request )); <nl> + memset ( uwsgi . workers [ uwsgi . mywid ]. cores [ i ]. buffer , 0 , sizeof ( struct uwsgi_header )); <nl> } <nl>  <nl> uwsgi_fixup_fds ( wid , 0 , NULL );
mmm uwsgi . h <nl> ppp uwsgi . h <nl> struct uwsgi_route_var { <nl> char * name ; <nl> uint16_t name_len ; <nl> char *(* func )( struct wsgi_request *, char *, uint16_t , uint16_t *); <nl> + int need_free ; <nl> struct uwsgi_route_var * next ; <nl> }; <nl> mmm core / routing . c <nl> ppp core / routing . c <nl> struct uwsgi_route_var { <nl> char * name ; <nl> uint16_t name_len ; <nl> char *(* func )( struct wsgi_request *, char *, uint16_t , uint16_t *); <nl> + int need_free ; <nl> struct uwsgi_route_var * next ; <nl> }; <nl>  <nl> struct uwsgi_buffer * uwsgi_routing_translate ( struct wsgi_request * wsgi_req , stru <nl> case 2 : <nl> if ( pass1 [ i ] == '}') { <nl> uint16_t vallen = 0 ; <nl> + int need_free = 0 ; <nl> char * value = NULL ; <nl> char * bracket = memchr ( key , '[', keylen ); <nl> if ( bracket && keylen > 0 && key [ keylen - 1 ] == ']') { <nl> struct uwsgi_route_var * urv = uwsgi_get_route_var ( key , bracket - key ); <nl> if ( urv ) { <nl> + need_free = urv -> need_free ; <nl> value = urv -> func ( wsgi_req , bracket + 1 , keylen - ( urv -> name_len + 2 ), & vallen ); <nl> } <nl> else { <nl> struct uwsgi_buffer * uwsgi_routing_translate ( struct wsgi_request * wsgi_req , stru <nl> value = uwsgi_get_var ( wsgi_req , key , keylen , & vallen ); <nl> } <nl> if ( value ) { <nl> - if ( uwsgi_buffer_append ( ub , value , vallen )) goto error ; <nl> + if ( uwsgi_buffer_append ( ub , value , vallen )) { <nl> + if ( need_free ) { <nl> + free ( value ); <nl> + } <nl> + goto error ; <nl> + } <nl> + if ( need_free ) { <nl> + free ( value ); <nl> + } <nl> } <nl> status = 0 ; <nl> key = NULL ;
mmm core / fork_server . c <nl> ppp core / fork_server . c <nl>  <nl> extern struct uwsgi_server uwsgi ; <nl>  <nl> +/* <nl> + <nl> + on connection retrieve the uid , gid and pid of the connecting process , in addition to up to 3 <nl> + file descriptors ( emperor pipe , emperor pipe_config , on_demand socket dup ()' ed to 0 ) <nl> + <nl> + if authorized , double fork , get the pid of the second child and exit () <nl> + its parent ( this will force the Emperor to became its subreaper ). <nl> + <nl> + from now on , we can consider the new child as a full - featured vassal <nl> + <nl> +*/ <nl> + <nl> void uwsgi_fork_server ( char * socket ) { <nl> int fd = bind_to_unix ( socket , uwsgi . listen_queue , uwsgi . chmod_socket , uwsgi . abstract_socket ); <nl> if ( fd < 0 ) exit ( 1 );
mmm plugins / emperor_amqp / amqp . c <nl> ppp plugins / emperor_amqp / amqp . c <nl> static char * amqp_simple_get_frame ( int fd , struct amqp_frame_header * fh ) { <nl> while ( len < fh -> size + 1 ) { <nl> rlen = recv ( fd , ptr , ( fh -> size + 1 )- len , 0 ); <nl> if ( rlen <= 0 ) { <nl> - if ( rlen < 0 ) <nl> + if ( rlen < 0 ) { <nl> uwsgi_error (" recv ()"); <nl> + } <nl> + free ( frame ); <nl> return NULL ; <nl> } <nl> len += rlen ;
mmm src / TopicTree . h <nl> ppp src / TopicTree . h <nl> private : <nl>  <nl> /* Should be getData and commit ? */ <nl> void publish ( Topic * iterator , size_t start , size_t stop , std :: string_view topic , std :: pair < std :: string_view , std :: string_view > message ) { <nl> - /* If we already have 64 triggered topics make sure to drain it here */ <nl> - if ( numTriggeredTopics == 64 ) { <nl> - drain (); <nl> - } <nl>  <nl> /* Iterate over all segments in given topic */ <nl> for (; stop != std :: string :: npos ; start = stop + 1 ) { <nl> private : <nl>  <nl> /* Add this topic to triggered */ <nl> if (! iterator -> terminatingWildcardChild -> triggered ) { <nl> + /* If we already have 64 triggered topics make sure to drain it here */ <nl> + if ( numTriggeredTopics == 64 ) { <nl> + drain (); <nl> + } <nl> + <nl> triggeredTopics [ numTriggeredTopics ++] = iterator -> terminatingWildcardChild ; <nl> iterator -> terminatingWildcardChild -> triggered = true ; <nl> } <nl> private : <nl>  <nl> /* Add this topic to triggered */ <nl> if (! iterator -> triggered ) { <nl> + /* If we already have 64 triggered topics make sure to drain it here */ <nl> + if ( numTriggeredTopics == 64 ) { <nl> + drain (); <nl> + } <nl> + <nl> triggeredTopics [ numTriggeredTopics ++] = iterator ; <nl> iterator -> triggered = true ; <nl> }
mmm uc . c <nl> ppp uc . c <nl> static bool split_region ( struct uc_struct * uc , MemoryRegion * mr , <nl>  <nl> QLIST_FOREACH ( block , & uc -> ram_list . blocks , next ) <nl> { <nl> - if ( block -> offset <= mr -> addr && <nl> + // block -> offset is the offset within ram_addr_t , not GPA <nl> + if ( block -> mr -> addr <= mr -> addr && <nl> block -> used_length >= ( mr -> end - mr -> addr )) { <nl> break ; <nl> }mmm qemu / accel / tcg / translate - all . c <nl> ppp qemu / accel / tcg / translate - all . c <nl> static bool split_region ( struct uc_struct * uc , MemoryRegion * mr , <nl>  <nl> QLIST_FOREACH ( block , & uc -> ram_list . blocks , next ) <nl> { <nl> - if ( block -> offset <= mr -> addr && <nl> + // block -> offset is the offset within ram_addr_t , not GPA <nl> + if ( block -> mr -> addr <= mr -> addr && <nl> block -> used_length >= ( mr -> end - mr -> addr )) { <nl> break ; <nl> } <nl> static void uc_invalidate_tb ( struct uc_struct * uc , uint64_t start_addr , size_t l <nl> { <nl> tb_page_addr_t start , end ; <nl>  <nl> - // GVA to GPA ( GPA -> HVA via page_find , HVA -> HPA via host mmu ) <nl> + // GVA to GPA <nl> + // ( GPA -> HVA via memory_region_get_ram_addr ( mr ) + GPA + block -> host , <nl> + // HVA -> HPA via host mmu ) <nl> start = get_page_addr_code ( uc -> cpu -> env_ptr , start_addr ) & ( target_ulong )(- 1 ); <nl>  <nl> // For 32bit target .
mmm auth_mellon_util . c <nl> ppp auth_mellon_util . c <nl> int am_check_url ( request_rec * r , const char * url ) <nl> " Control character detected in URL ."); <nl> return HTTP_BAD_REQUEST ; <nl> } <nl> + if (* i == '\\') { <nl> + /* Reject backslash character , as it can be used to bypass <nl> + * redirect URL validation . */ <nl> + AM_LOG_RERROR ( APLOG_MARK , APLOG_ERR , HTTP_BAD_REQUEST , r , <nl> + " Backslash character detected in URL ."); <nl> + return HTTP_BAD_REQUEST ; <nl> + } <nl> } <nl>  <nl> return OK ;
mmm management / univention - directory - notifier / src / callback . c <nl> ppp management / univention - directory - notifier / src / callback . c <nl> int data_on_connection ( int fd , callback_remove_handler remove ) <nl> p += strlen ( network_line ); <nl>  <nl>  <nl> - } else if ( ! strncmp ( network_line , " GET_DN ", strlen (" GET_DN ")) && msg_id != UINT32_MAX && network_client_get_version ( fd ) > 0 ) { <nl> + } else if ( ! strncmp ( network_line , " GET_DN ", strlen (" GET_DN ")) && msg_id != UINT32_MAX && version > PROTOCOL_UNKNOWN && version < PROTOCOL_3 ) { <nl>  <nl> univention_debug ( UV_DEBUG_TRANSFILE , UV_DEBUG_ALL , " RECV : GET_DN "); <nl> 
mmm src / modules / m_whois . c <nl> ppp src / modules / m_whois . c <nl> DLLFUNC int m_whois ( aClient * cptr , aClient * sptr , int parc , char * parv []) <nl> else <nl> strlcat ( buf , " a Local IRC Operator ", sizeof buf ); <nl> if ( buf [ 0 ]) <nl> - sendto_one ( sptr , <nl> - rpl_str ( RPL_WHOISOPERATOR ), me . name , <nl> - parv [ 0 ], name , buf ); <nl> + { <nl> + if ( IsOper ( sptr ) && MyClient ( acptr )) <nl> + sendto_one ( sptr , <nl> + ":% s 313 % s % s : is % s (% s )", me . name , <nl> + parv [ 0 ], name , buf , acptr -> user -> operlogin ); <nl> + else <nl> + sendto_one ( sptr , <nl> + rpl_str ( RPL_WHOISOPERATOR ), me . name , <nl> + parv [ 0 ], name , buf ); <nl> + } <nl> } <nl>  <nl> if ( IsHelpOp ( acptr ) && ! hideoper && ! user -> away )
mmm src / s_bsd . c <nl> ppp src / s_bsd . c <nl> int inetport ( ConfigItem_listen * listener , char * name , int port ) <nl> { <nl> int yes = 1 ; <nl>  <nl> - setsockopt ( listener -> fd , IPPROTO_TCP , TCP_DEFER_ACCEPT , & yes , sizeof ( int )); <nl> + ( void ) setsockopt ( listener -> fd , IPPROTO_TCP , TCP_DEFER_ACCEPT , & yes , sizeof ( int )); <nl> } <nl> # endif <nl> mmm src / s_misc . c <nl> ppp src / s_misc . c <nl> int inetport ( ConfigItem_listen * listener , char * name , int port ) <nl> { <nl> int yes = 1 ; <nl>  <nl> - setsockopt ( listener -> fd , IPPROTO_TCP , TCP_DEFER_ACCEPT , & yes , sizeof ( int )); <nl> + ( void ) setsockopt ( listener -> fd , IPPROTO_TCP , TCP_DEFER_ACCEPT , & yes , sizeof ( int )); <nl> } <nl> # endif <nl>  <nl> char text [ 2048 ]; <nl> return ; <nl> snprintf ( text , sizeof ( text ), "[ BUG ] operator count bug ! value in / lusers is '% d ', we counted '% d ', " <nl> " user ='% s ', userserver ='% s ', tag =% s . Corrected . ", <nl> - IRCstats . operators , counted , orig -> name ? orig -> name : "< null >", <nl> + IRCstats . operators , counted , orig -> name , <nl> orig -> srvptr ? orig -> srvptr -> name : "< null >", tag ? tag : "< null >"); <nl> # ifdef DEBUGMODE <nl> sendto_realops ("% s ", text );
mmm src / s_auth . c <nl> ppp src / s_auth . c <nl> void start_auth ( aClient * cptr ) <nl> sock . SIN_PORT = htons ( 113 ); <nl> sock . SIN_FAMILY = AFINET ; <nl>  <nl> - if ( connect ( cptr -> authfd , ( struct sockaddr *)& sock , <nl> - sizeof ( sock )) == - 1 && !( ERRNO == P_EINPROGRESS )) <nl> + if ( connect ( cptr -> authfd , ( struct sockaddr *)& sock , sizeof ( sock )) == - 1 && !( ERRNO == P_EWORKING )) <nl> { <nl> ircstp -> is_abad ++; <nl> /*
mmm src / modules / m_mode . c <nl> ppp src / modules / m_mode . c <nl> CMD_FUNC ( _m_umode ) <nl> case ' ': <nl> case '\ t ': <nl> break ; <nl> - case ' r ': <nl> case ' s ': <nl> if ( what == MODE_DEL ) { <nl> if ( parc >= 4 && sptr -> user -> snomask ) {
mmm src / s_conf . c <nl> ppp src / s_conf . c <nl> int _test_link ( ConfigFile * conf , ConfigEntry * ce ) <nl> } <nl> } <nl> } <nl> + else <nl> + { <nl> + config_error_unknown ( cep -> ce_fileptr -> cf_filename , <nl> + cep -> ce_varlinenum , " link ", cep -> ce_varname ); <nl> + errors ++; <nl> + continue ; <nl> + } <nl> } <nl>  <nl> if (! has_incoming && ! has_outgoing )
mmm src / win32 / gui . c <nl> ppp src / win32 / gui . c <nl> int CloseUnreal ( HWND hWnd ) <nl> return 0 ; <nl> else <nl> { <nl> - DestroyWindow ( hWnd ); <nl> - exit ( 0 ); <nl> + DestroyWindow ( hWnd ); <nl> + TerminateProcess ( GetCurrentProcess (), 0 ); <nl> + exit ( 0 ); /* in case previous fails ( possible ?) */ <nl> } <nl> } <nl> 
mmm src / modules / m_sasl . c <nl> ppp src / modules / m_sasl . c <nl> CMD_FUNC ( m_authenticate ) <nl> return 0 ; <nl> } <nl>  <nl> + if (( parv [ 1 ][ 0 ] == ':') || strchr ( parv [ 1 ], ' ')) <nl> + { <nl> + sendto_one ( sptr , err_str ( ERR_CANNOTDOCOMMAND ), me . name , "*", " AUTHENTICATE ", " Invalid parameter "); <nl> + return 0 ; <nl> + } <nl> + <nl> if ( strlen ( parv [ 1 ]) > 400 ) <nl> { <nl> sendto_one ( sptr , err_str ( ERR_SASLTOOLONG ), me . name , BadPtr ( sptr -> name ) ? "*" : sptr -> name );
mmm src / p_lx_elf . cpp <nl> ppp src / p_lx_elf . cpp <nl> bool PackLinuxElf32 :: canPack () <nl> if ( sec_strndx ) { <nl> unsigned const sh_name = get_te32 (& sec_strndx -> sh_name ); <nl> if ( Elf32_Shdr :: SHT_STRTAB != get_te32 (& sec_strndx -> sh_type ) <nl> - || ( u32_t ) file_size <= sh_name // FIXME : weak <nl> + || ( u32_t ) file_size <= ( sizeof (". shstrtab ") <nl> + + sh_name + ( shstrtab - ( const char *)& file_image [ 0 ])) <nl> || ( sh_name <nl> && 0 != strcmp (( char const *)". shstrtab ", & shstrtab [ sh_name ])) <nl> ) { <nl> - throwCantPack (" bad e_shstrndx "); <nl> + throwCantPack (" bad e_shstrtab "); <nl> } <nl> } <nl> } <nl> PackLinuxElf64 :: canPack () <nl> if ( sec_strndx ) { <nl> unsigned const sh_name = get_te32 (& sec_strndx -> sh_name ); <nl> if ( Elf64_Shdr :: SHT_STRTAB != get_te32 (& sec_strndx -> sh_type ) <nl> - || ( u32_t ) file_size <= sh_name // FIXME : weak <nl> + || ( u32_t ) file_size <= ( sizeof (". shstrtab ") <nl> + + sh_name + ( shstrtab - ( const char *)& file_image [ 0 ])) <nl> || ( sh_name <nl> && 0 != strcmp (( char const *)". shstrtab ", & shstrtab [ sh_name ])) <nl> ) { <nl> - throwCantPack (" bad e_shstrndx "); <nl> + throwCantPack (" bad e_shstrtab "); <nl> } <nl> } <nl> }
mmm src / p_tmt . cpp <nl> ppp src / p_tmt . cpp <nl> int PackTmt :: readFileHeader () { <nl> unsigned const imagesize = ih . imagesize ; <nl> unsigned const entry = ih . entry ; <nl> unsigned const relocsize = ih . relocsize ; <nl> - if (! imagesize || file_size <= imagesize || file_size <= entry || file_size <= relocsize ) { <nl> + if ( imagesize < sizeof ( ih ) || entry < sizeof ( ih ) || file_size <= imagesize || <nl> + file_size <= entry || file_size <= relocsize ) { <nl> printWarn ( getName (), " bad header ; imagesize =%# x entry =%# x relocsize =%# x ", imagesize , <nl> entry , relocsize ); <nl> return 0 ; <nl> void PackTmt :: pack ( OutputFile * fo ) { <nl> obuf . allocForCompression ( usize + rsize + 128 ); <nl>  <nl> MemBuffer mb_wrkmem ; <nl> - mb_wrkmem . alloc ( rsize + EXTRA_INFO ); // relocations <nl> + mb_wrkmem . alloc ( rsize + EXTRA_INFO + 4 ); // relocations + original entry point + relocsize <nl> SPAN_S_VAR ( upx_byte , wrkmem , mb_wrkmem ); <nl>  <nl> fi -> seek ( adam_offset + sizeof ( ih ), SEEK_SET ); <nl> void PackTmt :: pack ( OutputFile * fo ) { <nl> fi -> readx ( wrkmem + 4 , rsize ); <nl> const unsigned overlay = file_size - fi -> tell (); <nl>  <nl> - if ( find_le32 ( ibuf , 128 , get_le32 (" UPX ")) >= 0 ) <nl> + if ( find_le32 ( ibuf , UPX_MIN ( 128u , usize ), get_le32 (" UPX ")) >= 0 ) <nl> throwAlreadyPacked (); <nl> if ( rsize == 0 ) <nl> throwCantPack (" file is already compressed with another packer ");
mmm src / p_lx_elf . cpp <nl> ppp src / p_lx_elf . cpp <nl> PackLinuxElf32 :: PackLinuxElf32help1 ( InputFile * f ) <nl> e_phnum = get_te16 (& ehdri . e_phnum ); <nl> e_shnum = get_te16 (& ehdri . e_shnum ); <nl> unsigned const e_phentsize = get_te16 (& ehdri . e_phentsize ); <nl> - if ( ehdri . e_ident [ Elf32_Ehdr :: EI_CLASS ]!= Elf32_Ehdr :: ELFCLASS32 <nl> + if ( memcmp (( char const *)& ehdri , "\ x7f \ x45 \ x4c \ x46 ", 4 ) // "\ 177ELF " <nl> + || ehdri . e_ident [ Elf32_Ehdr :: EI_CLASS ]!= Elf32_Ehdr :: ELFCLASS32 <nl> || sizeof ( Elf32_Phdr ) != e_phentsize <nl> || ( Elf32_Ehdr :: ELFDATA2MSB == ehdri . e_ident [ Elf32_Ehdr :: EI_DATA ] <nl> && & N_BELE_RTP :: be_policy != bele ) <nl> PackLinuxElf64 :: PackLinuxElf64help1 ( InputFile * f ) <nl> e_phnum = get_te16 (& ehdri . e_phnum ); <nl> e_shnum = get_te16 (& ehdri . e_shnum ); <nl> unsigned const e_phentsize = get_te16 (& ehdri . e_phentsize ); <nl> - if ( ehdri . e_ident [ Elf64_Ehdr :: EI_CLASS ]!= Elf64_Ehdr :: ELFCLASS64 <nl> + if ( memcmp (( char const *)& ehdri , "\ x7f \ x45 \ x4c \ x46 ", 4 ) // "\ 177ELF " <nl> + || ehdri . e_ident [ Elf64_Ehdr :: EI_CLASS ]!= Elf64_Ehdr :: ELFCLASS64 <nl> || sizeof ( Elf64_Phdr ) != e_phentsize <nl> || ( Elf64_Ehdr :: ELFDATA2MSB == ehdri . e_ident [ Elf64_Ehdr :: EI_DATA ] <nl> && & N_BELE_RTP :: be_policy != bele ) <nl> PackLinuxElf64 :: invert_pt_dynamic ( Elf64_Dyn const * dynp , upx_uint64_t headway ) <nl> } <nl> if ( file_size <= dt_offsets [ n_off ]) { <nl> char msg [ 60 ]; snprintf ( msg , sizeof ( msg ), " bad DT_ {%# x } = %# x ( beyond EOF )", <nl> - dt_names [ k ], dt_offsets [ n_off ]); <nl> + k , dt_offsets [ n_off ]); <nl> throwCantPack ( msg ); <nl> } <nl> n_off += !! dt_offsets [ n_off ];
mmm src / UriCommon . c <nl> ppp src / UriCommon . c <nl>  <nl>  <nl> void URI_FUNC ( ResetUri )( URI_TYPE ( Uri ) * uri ) { <nl> + if ( uri == NULL ) { <nl> + return ; <nl> + } <nl> memset ( uri , 0 , sizeof ( URI_TYPE ( Uri ))); <nl> } <nl> 
mmm src / UriQuery . c <nl> ppp src / UriQuery . c <nl>  <nl>  <nl>  <nl> +# include < limits . h > <nl> + <nl> + <nl> + <nl> static int URI_FUNC ( ComposeQueryEngine )( URI_CHAR * dest , <nl> const URI_TYPE ( QueryList ) * queryList , <nl> int maxChars , int * charsWritten , int * charsRequired , <nl> int URI_FUNC ( ComposeQueryEngine )( URI_CHAR * dest , <nl> const URI_CHAR * const value = queryList -> value ; <nl> const int worstCase = ( normalizeBreaks == URI_TRUE ? 6 : 3 ); <nl> const int keyLen = ( key == NULL ) ? 0 : ( int ) URI_STRLEN ( key ); <nl> - const int keyRequiredChars = worstCase * keyLen ; <nl> + int keyRequiredChars ; <nl> const int valueLen = ( value == NULL ) ? 0 : ( int ) URI_STRLEN ( value ); <nl> - const int valueRequiredChars = worstCase * valueLen ; <nl> + int valueRequiredChars ; <nl> + <nl> + if (( keyLen >= INT_MAX / worstCase ) || ( valueLen >= INT_MAX / worstCase )) { <nl> + return URI_ERROR_OUTPUT_TOO_LARGE ; <nl> + } <nl> + keyRequiredChars = worstCase * keyLen ; <nl> + valueRequiredChars = worstCase * valueLen ; <nl>  <nl> if ( dest == NULL ) { <nl> (* charsRequired ) += ampersandLen + keyRequiredChars + (( value == NULL )
mmm tools / tiff2ps . c <nl> ppp tools / tiff2ps . c <nl> TIFF2PS ( FILE * fd , TIFF * tif , <nl> if (! generateEPSF && ( level2 || level3 )) { <nl> fprintf ( fd , <nl> " 1 dict begin / PageSize [ % f % f ] def currentdict end setpagedevice \ n ", <nl> - pw ? pw : ( rotate ? prh : prw ), <nl> - ph ? ph : ( rotate ? prw : prh )); <nl> + pw ? pw * PS_UNIT_SIZE : ( rotate ? prh : prw ), <nl> + ph ? ph * PS_UNIT_SIZE : ( rotate ? prw : prh )); <nl> fputs ( <nl> "<<\ n / Policies <<\ n / PageSize 3 \ n >>\ n >> setpagedevice \ n ", <nl> fd );
mmm libtiff / tif_dir . c <nl> ppp libtiff / tif_dir . c <nl> _TIFFVGetField ( TIFF * tif , ttag_t tag , va_list ap ) <nl> * va_arg ( ap , void **) = tv -> value ; <nl> ret_val = 1 ; <nl> } else { <nl> - int i ; <nl> + int j ; <nl> char * val = ( char *) tv -> value ; <nl>  <nl> - for ( i = 0 ; i < tv -> count ; <nl> - i ++, val += _TIFFDataSize ( fip -> field_type )) { <nl> + for ( j = 0 ; j < tv -> count ; <nl> + j ++, val += _TIFFDataSize ( tv -> info -> field_type )) { <nl> switch ( fip -> field_type ) { <nl> case TIFF_BYTE : <nl> case TIFF_UNDEFINED :
mmm libtiff / tif_pixarlog . c <nl> ppp libtiff / tif_pixarlog . c <nl> horizontalAccumulate8abgr ( uint16 * wp , int n , int stride , unsigned char * op , <nl> typedef struct { <nl> TIFFPredictorState predict ; <nl> z_stream stream ; <nl> + tmsize_t tbuf_size ; /* only set / used on reading for now */ <nl> uint16 * tbuf ; <nl> uint16 stride ; <nl> int state ; <nl> PixarLogSetupDecode ( TIFF * tif ) <nl> sp -> tbuf = ( uint16 *) _TIFFmalloc ( tbuf_size ); <nl> if ( sp -> tbuf == NULL ) <nl> return ( 0 ); <nl> + sp -> tbuf_size = tbuf_size ; <nl> if ( sp -> user_datafmt == PIXARLOGDATAFMT_UNKNOWN ) <nl> sp -> user_datafmt = PixarLogGuessDataFmt ( td ); <nl> if ( sp -> user_datafmt == PIXARLOGDATAFMT_UNKNOWN ) { <nl> PixarLogDecode ( TIFF * tif , uint8 * op , tmsize_t occ , uint16 s ) <nl> TIFFErrorExt ( tif -> tif_clientdata , module , " ZLib cannot deal with buffers this size "); <nl> return ( 0 ); <nl> } <nl> + /* Check that we will not fill more than what was allocated */ <nl> + if ( sp -> stream . avail_out > sp -> tbuf_size ) <nl> + { <nl> + TIFFErrorExt ( tif -> tif_clientdata , module , " sp -> stream . avail_out > sp -> tbuf_size "); <nl> + return ( 0 ); <nl> + } <nl> do { <nl> int state = inflate (& sp -> stream , Z_PARTIAL_FLUSH ); <nl> if ( state == Z_STREAM_END ) {
mmm libtiff / tif_vms . c <nl> ppp libtiff / tif_vms . c <nl> TIFFOpen ( const char * name , const char * mode ) <nl> tdata_t <nl> _TIFFmalloc ( tsize_t s ) <nl> { <nl> + if ( s == 0 ) <nl> + return (( void *) NULL ); <nl> + <nl> return ( malloc (( size_t ) s )); <nl> } <nl> mmm libtiff / tif_unix . c <nl> ppp libtiff / tif_unix . c <nl> TIFFOpen ( const char * name , const char * mode ) <nl> tdata_t <nl> _TIFFmalloc ( tsize_t s ) <nl> { <nl> + if ( s == 0 ) <nl> + return (( void *) NULL ); <nl> + <nl> return ( malloc (( size_t ) s )); <nl> } <nl>  <nl> TIFFOpenW ( const wchar_t * name , const char * mode ) <nl> void * <nl> _TIFFmalloc ( tmsize_t s ) <nl> { <nl> + if ( s == 0 ) <nl> + return (( void *) NULL ); <nl> + <nl> return ( malloc (( size_t ) s )); <nl> } <nl> mmm libtiff / tif_win32 . c <nl> ppp libtiff / tif_win32 . c <nl> TIFFOpen ( const char * name , const char * mode ) <nl> tdata_t <nl> _TIFFmalloc ( tsize_t s ) <nl> { <nl> + if ( s == 0 ) <nl> + return (( void *) NULL ); <nl> + <nl> return ( malloc (( size_t ) s )); <nl> } <nl>  <nl> TIFFOpenW ( const wchar_t * name , const char * mode ) <nl> void * <nl> _TIFFmalloc ( tmsize_t s ) <nl> { <nl> + if ( s == 0 ) <nl> + return (( void *) NULL ); <nl> + <nl> return ( malloc (( size_t ) s )); <nl> } <nl>  <nl> TIFFOpenW ( const wchar_t * name , const char * mode ) <nl> void * <nl> _TIFFmalloc ( tmsize_t s ) <nl> { <nl> + if ( s == 0 ) <nl> + return (( void *) NULL ); <nl> + <nl> return ( malloc (( size_t ) s )); <nl> } <nl> 
mmm libtiff / tif_read . c <nl> ppp libtiff / tif_read . c <nl> TIFFReadEncodedStrip ( TIFF * tif , uint32 strip , void * buf , tmsize_t size ) <nl> rowsperstrip = td -> td_rowsperstrip ; <nl> if ( rowsperstrip > td -> td_imagelength ) <nl> rowsperstrip = td -> td_imagelength ; <nl> - stripsperplane =(( td -> td_imagelength + rowsperstrip - 1 )/ rowsperstrip ); <nl> + stripsperplane = TIFFhowmany_32_maxuint_compat ( td -> td_imagelength , rowsperstrip ); <nl> stripinplane =( strip % stripsperplane ); <nl> plane =( uint16 )( strip / stripsperplane ); <nl> rows = td -> td_imagelength - stripinplane * rowsperstrip ;mmm libtiff / tiffiop . h <nl> ppp libtiff / tiffiop . h <nl> TIFFReadEncodedStrip ( TIFF * tif , uint32 strip , void * buf , tmsize_t size ) <nl> rowsperstrip = td -> td_rowsperstrip ; <nl> if ( rowsperstrip > td -> td_imagelength ) <nl> rowsperstrip = td -> td_imagelength ; <nl> - stripsperplane =(( td -> td_imagelength + rowsperstrip - 1 )/ rowsperstrip ); <nl> + stripsperplane = TIFFhowmany_32_maxuint_compat ( td -> td_imagelength , rowsperstrip ); <nl> stripinplane =( strip % stripsperplane ); <nl> plane =( uint16 )( strip / stripsperplane ); <nl> rows = td -> td_imagelength - stripinplane * rowsperstrip ; <nl> struct tiff { <nl> # define TIFFhowmany_32 ( x , y ) ((( uint32 ) x < ( 0xffffffff - ( uint32 )( y - 1 ))) ? \ <nl> (((( uint32 )( x ))+((( uint32 )( y ))- 1 ))/(( uint32 )( y ))) : \ <nl> 0U ) <nl> +/* Variant of TIFFhowmany_32 () that doesn ' t return 0 if x close to MAXUINT . */ <nl> +/* Caution : TIFFhowmany_32_maxuint_compat ( x , y )* y might overflow */ <nl> +# define TIFFhowmany_32_maxuint_compat ( x , y ) \ <nl> + ((( uint32 )( x ) / ( uint32 )( y )) + (((( uint32 )( x ) % ( uint32 )( y )) != 0 ) ? 1 : 0 )) <nl> # define TIFFhowmany8_32 ( x ) ((( x )& 0x07 )?(( uint32 )( x )>> 3 )+ 1 :( uint32 )( x )>> 3 ) <nl> # define TIFFroundup_32 ( x , y ) ( TIFFhowmany_32 ( x , y )*( y )) <nl> # define TIFFhowmany_64 ( x , y ) (((( uint64 )( x ))+((( uint64 )( y ))- 1 ))/(( uint64 )( y )))
mmm libtiff / tif_ojpeg . c <nl> ppp libtiff / tif_ojpeg . c <nl> typedef enum { <nl>  <nl> typedef struct { <nl> TIFF * tif ; <nl> + int decoder_ok ; <nl> # ifndef LIBJPEG_ENCAP_EXTERNAL <nl> JMP_BUF exit_jmpbuf ; <nl> # endif <nl> OJPEGPreDecode ( TIFF * tif , uint16 s ) <nl> } <nl> sp -> write_curstrile ++; <nl> } <nl> + sp -> decoder_ok = 1 ; <nl> return ( 1 ); <nl> } <nl>  <nl> OJPEGPreDecodeSkipScanlines ( TIFF * tif ) <nl> static int <nl> OJPEGDecode ( TIFF * tif , uint8 * buf , tmsize_t cc , uint16 s ) <nl> { <nl> + static const char module []=" OJPEGDecode "; <nl> OJPEGState * sp =( OJPEGState *) tif -> tif_data ; <nl> ( void ) s ; <nl> + if ( ! sp -> decoder_ok ) <nl> + { <nl> + TIFFErrorExt ( tif -> tif_clientdata , module ," Cannot decode : decoder not correctly initialized "); <nl> + return 0 ; <nl> + } <nl> if ( sp -> libjpeg_jpeg_query_style == 0 ) <nl> { <nl> if ( OJPEGDecodeRaw ( tif , buf , cc )== 0 )
mmm tools / tiffcp . c <nl> ppp tools / tiffcp . c <nl> static copyFunc pickCopyFunc ( TIFF *, TIFF *, uint16 , uint16 ); <nl> static int <nl> tiffcp ( TIFF * in , TIFF * out ) <nl> { <nl> - uint16 bitspersample , samplesperpixel ; <nl> - uint16 input_compression , input_photometric ; <nl> + uint16 bitspersample , samplesperpixel = 1 ; <nl> + uint16 input_compression , input_photometric = PHOTOMETRIC_MINISBLACK ; <nl> copyFunc cf ; <nl> uint32 width , length ; <nl> struct cpTag * p ;mmm tools / tiffcrop . c <nl> ppp tools / tiffcrop . c <nl> static copyFunc pickCopyFunc ( TIFF *, TIFF *, uint16 , uint16 ); <nl> static int <nl> tiffcp ( TIFF * in , TIFF * out ) <nl> { <nl> - uint16 bitspersample , samplesperpixel ; <nl> - uint16 input_compression , input_photometric ; <nl> + uint16 bitspersample , samplesperpixel = 1 ; <nl> + uint16 input_compression , input_photometric = PHOTOMETRIC_MINISBLACK ; <nl> copyFunc cf ; <nl> uint32 width , length ; <nl> struct cpTag * p ; <nl> static int readContigStripsIntoBuffer ( TIFF * in , uint8 * buf ) <nl> { <nl> uint8 * bufp = buf ; <nl> int32 bytes_read = 0 ; <nl> - uint16 strip , nstrips = TIFFNumberOfStrips ( in ); <nl> + uint32 strip , nstrips = TIFFNumberOfStrips ( in ); <nl> uint32 stripsize = TIFFStripSize ( in ); <nl> uint32 rows = 0 ; <nl> uint32 rps = TIFFGetFieldDefaulted ( in , TIFFTAG_ROWSPERSTRIP , & rps ); <nl> static int readSeparateStripsIntoBuffer ( TIFF * in , uint8 * obuf , uint32 length , <nl> uint32 width , uint16 spp , <nl> struct dump_opts * dump ) <nl> { <nl> - int i , j , bytes_per_sample , bytes_per_pixel , shift_width , result = 1 ; <nl> + int i , bytes_per_sample , bytes_per_pixel , shift_width , result = 1 ; <nl> + uint32 j ; <nl> int32 bytes_read = 0 ; <nl> - uint16 bps , nstrips , planar , strips_per_sample ; <nl> + uint16 bps , planar ; <nl> + uint32 nstrips ; <nl> + uint32 strips_per_sample ; <nl> uint32 src_rowsize , dst_rowsize , rows_processed , rps ; <nl> uint32 rows_this_strip = 0 ; <nl> tsample_t s ;
mmm libtiff / tif_dirread . c <nl> ppp libtiff / tif_dirread . c <nl> EstimateStripByteCounts ( TIFF * tif , TIFFDirEntry * dir , uint16 dircount ) <nl> td -> td_stripbytecount = ( uint64 *) <nl> _TIFFCheckMalloc ( tif , td -> td_nstrips , sizeof ( uint64 ), <nl> " for \" StripByteCounts \" array "); <nl> + if ( td -> td_stripbytecount == NULL ) <nl> + return - 1 ; <nl> + <nl> if ( td -> td_compression != COMPRESSION_NONE ) { <nl> uint64 space ; <nl> uint64 filesize ;
mmm tools / tiffcp . c <nl> ppp tools / tiffcp . c <nl> DECLAREcpFunc ( cpDecodedStrips ) <nl> tstrip_t s , ns = TIFFNumberOfStrips ( in ); <nl> uint32 row = 0 ; <nl> _TIFFmemset ( buf , 0 , stripsize ); <nl> - for ( s = 0 ; s < ns ; s ++) { <nl> + for ( s = 0 ; s < ns && row < imagelength ; s ++) { <nl> tsize_t cc = ( row + rowsperstrip > imagelength ) ? <nl> TIFFVStripSize ( in , imagelength - row ) : stripsize ; <nl> if ( TIFFReadEncodedStrip ( in , s , buf , cc ) < 0
mmm tools / tiffcp . c <nl> ppp tools / tiffcp . c <nl> DECLAREreadFunc ( readContigTilesIntoBuffer ) <nl> uint32 colb = 0 ; <nl> uint32 col ; <nl>  <nl> - for ( col = 0 ; col < imagewidth ; col += tw ) { <nl> + for ( col = 0 ; col < imagewidth && colb < imagew ; col += tw ) { <nl> if ( TIFFReadTile ( in , tilebuf , col , row , 0 , 0 ) < 0 <nl> && ! ignore ) { <nl> TIFFError ( TIFFFileName ( in ), <nl> DECLAREwriteFunc ( writeBufferToContigTiles ) <nl> uint32 colb = 0 ; <nl> uint32 col ; <nl>  <nl> - for ( col = 0 ; col < imagewidth ; col += tw ) { <nl> + for ( col = 0 ; col < imagewidth && colb < imagew ; col += tw ) { <nl> /* <nl> * Tile is clipped horizontally . Calculate <nl> * visible portion and skewing factors .
mmm libtiff / tif_aux . c <nl> ppp libtiff / tif_aux . c <nl> tdata_t <nl> _TIFFCheckMalloc ( TIFF * tif , size_t nmemb , size_t elem_size , const char * what ) <nl> { <nl> - tdata_t * cp = NULL ; <nl> + tdata_t cp = NULL ; <nl> tsize_t bytes = nmemb * elem_size ; <nl>  <nl> /*
mmm libtiff / tif_predict . c <nl> ppp libtiff / tif_predict . c <nl> fpAcc ( TIFF * tif , uint8 * cp0 , tmsize_t cc ) <nl> tmsize_t wc = cc / bps ; <nl> tmsize_t count = cc ; <nl> uint8 * cp = ( uint8 *) cp0 ; <nl> - uint8 * tmp = ( uint8 *) _TIFFmalloc ( cc ); <nl> + uint8 * tmp ; <nl>  <nl> if ( cc %( bps * stride )!= 0 ) <nl> { <nl> fpAcc ( TIFF * tif , uint8 * cp0 , tmsize_t cc ) <nl> return 0 ; <nl> } <nl>  <nl> + tmp = ( uint8 *) _TIFFmalloc ( cc ); <nl> if (! tmp ) <nl> return 0 ; <nl>  <nl> fpDiff ( TIFF * tif , uint8 * cp0 , tmsize_t cc ) <nl> tmsize_t wc = cc / bps ; <nl> tmsize_t count ; <nl> uint8 * cp = ( uint8 *) cp0 ; <nl> - uint8 * tmp = ( uint8 *) _TIFFmalloc ( cc ); <nl> + uint8 * tmp ; <nl>  <nl> if (( cc %( bps * stride ))!= 0 ) <nl> { <nl> fpDiff ( TIFF * tif , uint8 * cp0 , tmsize_t cc ) <nl> "% s ", "( cc %( bps * stride ))!= 0 "); <nl> return 0 ; <nl> } <nl> + <nl> + tmp = ( uint8 *) _TIFFmalloc ( cc ); <nl> if (! tmp ) <nl> return 0 ; <nl>  <nl> PredictorEncodeTile ( TIFF * tif , uint8 * bp0 , tmsize_t cc0 , uint16 s ) <nl> { <nl> TIFFErrorExt ( tif -> tif_clientdata , " PredictorEncodeTile ", <nl> "% s ", "( cc0 % rowsize )!= 0 "); <nl> + _TIFFfree ( working_copy ); <nl> return 0 ; <nl> } <nl> while ( cc > 0 ) {
mmm tools / tiffcp . c <nl> ppp tools / tiffcp . c <nl> bad : <nl>  <nl> static void <nl> cpStripToTile ( uint8 * out , uint8 * in , <nl> - uint32 rows , uint32 cols , int outskew , int inskew ) <nl> + uint32 rows , uint32 cols , int outskew , int64 inskew ) <nl> { <nl> while ( rows -- > 0 ) { <nl> uint32 j = cols ; <nl> DECLAREreadFunc ( readContigTilesIntoBuffer ) <nl> tdata_t tilebuf ; <nl> uint32 imagew = TIFFScanlineSize ( in ); <nl> uint32 tilew = TIFFTileRowSize ( in ); <nl> - int iskew = imagew - tilew ; <nl> + int64 iskew = ( int64 ) imagew - ( int64 ) tilew ; <nl> uint8 * bufp = ( uint8 *) buf ; <nl> uint32 tw , tl ; <nl> uint32 row ; <nl> DECLAREreadFunc ( readContigTilesIntoBuffer ) <nl> status = 0 ; <nl> goto done ; <nl> } <nl> - if ( colb + tilew > imagew ) { <nl> + if ( colb > iskew ) { <nl> uint32 width = imagew - colb ; <nl> uint32 oskew = tilew - width ; <nl> cpStripToTile ( bufp + colb ,
mmm tools / tiffcrop . c <nl> ppp tools / tiffcrop . c <nl> static int readContigStripsIntoBuffer ( TIFF * in , uint8 * buf ) <nl> ( unsigned long ) strip , ( unsigned long ) rows ); <nl> return 0 ; <nl> } <nl> - bufp += bytes_read ; <nl> + bufp += stripsize ; <nl> } <nl>  <nl> return 1 ;
mmm tools / tiffcrop . c <nl> ppp tools / tiffcrop . c <nl> static int readContigTilesIntoBuffer ( TIFF * in , uint8 * buf , <nl> } <nl> } <nl>  <nl> - tilebuf = _TIFFmalloc ( tile_buffsize ); <nl> + /* Add 3 padding bytes for extractContigSamplesShifted32bits */ <nl> + if ( tile_buffsize > 0xFFFFFFFFU - 3 ) <nl> + { <nl> + TIFFError (" readContigTilesIntoBuffer ", " Integer overflow when calculating buffer size ."); <nl> + exit (- 1 ); <nl> + } <nl> + tilebuf = _TIFFmalloc ( tile_buffsize + 3 ); <nl> if ( tilebuf == 0 ) <nl> return 0 ; <nl> + tilebuf [ tile_buffsize ] = 0 ; <nl> + tilebuf [ tile_buffsize + 1 ] = 0 ; <nl> + tilebuf [ tile_buffsize + 2 ] = 0 ; <nl>  <nl> dst_rowsize = (( imagewidth * bps * spp ) + 7 ) / 8 ; <nl> for ( row = 0 ; row < imagelength ; row += tl )
mmm libtiff / tif_next . c <nl> ppp libtiff / tif_next . c <nl> case 0 : op [ 0 ] = ( unsigned char ) (( v ) << 6 ); break ; \ <nl> case 1 : op [ 0 ] |= ( v ) << 4 ; break ; \ <nl> case 2 : op [ 0 ] |= ( v ) << 2 ; break ; \ <nl> - case 3 : * op ++ |= ( v ); break ; \ <nl> + case 3 : * op ++ |= ( v ); op_offset ++; break ; \ <nl> } \ <nl> } <nl>  <nl> NeXTDecode ( TIFF * tif , uint8 * buf , tmsize_t occ , uint16 s ) <nl> uint32 imagewidth = tif -> tif_dir . td_imagewidth ; <nl> if ( isTiled ( tif ) ) <nl> imagewidth = tif -> tif_dir . td_tilewidth ; <nl> + tmsize_t op_offset = 0 ; <nl>  <nl> /* <nl> * The scanline is composed of a sequence of constant <nl> NeXTDecode ( TIFF * tif , uint8 * buf , tmsize_t occ , uint16 s ) <nl> * bounds , potentially resulting in a security <nl> * issue . <nl> */ <nl> - while ( n -- > 0 && npixels < imagewidth ) <nl> + while ( n -- > 0 && npixels < imagewidth && op_offset < scanline ) <nl> SETPIXEL ( op , grey ); <nl> if ( npixels >= imagewidth ) <nl> break ; <nl> + if ( op_offset >= scanline ) { <nl> + TIFFErrorExt ( tif -> tif_clientdata , module , " Invalid data for scanline % ld ", <nl> + ( long ) tif -> tif_row ); <nl> + return ( 0 ); <nl> + } <nl> if ( cc == 0 ) <nl> goto bad ; <nl> n = * bp ++, cc --;
mmm tools / tiffset . c <nl> ppp tools / tiffset . c <nl> ****************************************************************************** <nl> * <nl> * $ Log $ <nl> - * Revision 1 . 11 2005 - 09 - 13 14 : 13 : 42 dron <nl> + * Revision 1 . 12 2007 - 02 - 24 17 : 14 : 14 dron <nl> + * Properly handle tags with TIFF_VARIABLE writecount . As per bug <nl> + * http :// bugzilla . remotesensing . org / show_bug . cgi ? id = 1350 <nl> + * <nl> + * Revision 1 . 11 2005 / 09 / 13 14 : 13 : 42 dron <nl> * Avoid warnings . <nl> * <nl> * Revision 1 . 10 2005 / 02 / 24 14 : 47 : 11 fwarmerdam <nl> main ( int argc , char * argv []) <nl> if ( TIFFSetField ( tiff , fip -> field_tag , argv [ arg_index ]) != 1 ) <nl> fprintf ( stderr , " Failed to set % s =% s \ n ", <nl> fip -> field_name , argv [ arg_index ] ); <nl> - } else if ( fip -> field_writecount > 0 ) { <nl> + } else if ( fip -> field_writecount > 0 <nl> + || fip -> field_writecount == TIFF_VARIABLE ) { <nl> int ret = 1 ; <nl> short wc ; <nl> 
mmm tools / tiff2pdf . c <nl> ppp tools / tiff2pdf . c <nl> tsize_t t2p_readwrite_pdf_image_tile ( T2P * t2p , TIFF * input , TIFF * output , ttile_ <nl> return ( 0 ); <nl> } <nl> if ( TIFFGetField ( input , TIFFTAG_JPEGTABLES , & count , & jpt ) != 0 ) { <nl> - if ( count >= 4 ) { <nl> + if ( count > 4 ) { <nl> int retTIFFReadRawTile ; <nl> /* Ignore EOI marker of JpegTables */ <nl> _TIFFmemcpy ( buffer , jpt , count - 2 );
mmm libtiff / tif_jpeg . c <nl> ppp libtiff / tif_jpeg . c <nl> JPEGVSetField ( TIFF * tif , ttag_t tag , va_list ap ) <nl> case TIFFTAG_JPEGTABLESMODE : <nl> sp -> jpegtablesmode = va_arg ( ap , int ); <nl> return ( 1 ); /* pseudo tag */ <nl> + case TIFFTAG_YCBCRSUBSAMPLING : <nl> + /* mark the fact that we have a real ycbcrsubsampling ! */ <nl> + sp -> ycbcrsampling_fetched = 1 ; <nl> + return (* sp -> vsetparent )( tif , tag , ap ); <nl> default : <nl> return (* sp -> vsetparent )( tif , tag , ap ); <nl> } <nl> JPEGVSetField ( TIFF * tif , ttag_t tag , va_list ap ) <nl> * loaded just to get the tags right , even if the imagery is never read . <nl> * It would be more efficient to just load a bit of the header , and <nl> * initialize things from that . <nl> - * o This code doesn ' t know whether or not the tag actually did occur in <nl> - * the file . If it knew this it could skip the hack but this is hard to <nl> - * know since we have already set the " field set " bit for the subsampling <nl> - * TIFFInitJPEG (). <nl> * <nl> * See the bug in bugzilla for details : <nl> * <nl> JPEGFixupTestSubsampling ( TIFF * tif ) <nl> * jpeg data to get the sampling . <nl> */ <nl> if ( ! sp -> cinfo . comm . is_decompressor <nl> - || sp -> ycbcrsampling_fetched ) <nl> + || sp -> ycbcrsampling_fetched <nl> + || sp -> photometric != PHOTOMETRIC_YCBCR ) <nl> return ; <nl>  <nl> sp -> ycbcrsampling_fetched = 1 ;
mmm libtiff / tiffiop . h <nl> ppp libtiff / tiffiop . h <nl> struct tiff { <nl> */ <nl> # ifndef ReadOK <nl> # define ReadOK ( tif , buf , size ) \ <nl> - ( TIFFReadFile ( tif , ( tdata_t ) buf , ( tsize_t ) size ) == ( tsize_t ) size ) <nl> + ( TIFFReadFile ( tif , ( tdata_t ) buf , ( tsize_t )( size )) == ( tsize_t )( size )) <nl> # endif <nl> # ifndef SeekOK <nl> # define SeekOK ( tif , off ) \
mmm tools / gif2tiff . c <nl> ppp tools / gif2tiff . c <nl> process ( register int code , unsigned char ** fill ) <nl> } <nl>  <nl> if ( oldcode == - 1 ) { <nl> + if ( code >= clear ) { <nl> + fprintf ( stderr , " bad input : code =% d is larger than clear =% d \ n ", code , clear ); <nl> + return 0 ; <nl> + } <nl> *(* fill )++ = suffix [ code ]; <nl> firstchar = oldcode = code ; <nl> return 1 ;
mmm bin / varnishd / cache_waiter . h <nl> ppp bin / varnishd / cache_waiter . h <nl> struct sess ; <nl> typedef void * waiter_init_f ( void ); <nl> typedef void waiter_pass_f ( void * priv , const struct sess *); <nl>  <nl> - extern int vca_pipes [ 2 ]; <nl> - <nl> struct waiter { <nl> const char * name ; <nl> waiter_init_f * init ;mmm bin / varnishd / cache_acceptor . c <nl> ppp bin / varnishd / cache_acceptor . c <nl> struct sess ; <nl> typedef void * waiter_init_f ( void ); <nl> typedef void waiter_pass_f ( void * priv , const struct sess *); <nl>  <nl> - extern int vca_pipes [ 2 ]; <nl> - <nl> struct waiter { <nl> const char * name ; <nl> waiter_init_f * init ; <nl> static const struct linger linger = { <nl>  <nl> static unsigned char need_sndtimeo , need_rcvtimeo , need_linger , need_test ; <nl>  <nl> - int vca_pipes [ 2 ] = { - 1 , - 1 }; <nl> - <nl> static void <nl> sock_test ( int fd ) <nl> { <nl> ccf_start ( struct cli * cli , const char * const * av , void * priv ) <nl> AN ( vca_act -> init ); <nl> AN ( vca_act -> pass ); <nl>  <nl> - AZ ( pipe ( vca_pipes )); /* XXX */ <nl> waiter_priv = vca_act -> init (); <nl> AZ ( pthread_create (& VCA_thread , NULL , vca_acct , NULL )); <nl> VSL ( SLT_Debug , 0 , " Acceptor is % s ", vca_act -> name );
mmm bin / varnishd / cache_acceptor_poll . c <nl> ppp bin / varnishd / cache_acceptor_poll . c <nl>  <nl> static pthread_t vca_poll_thread ; <nl> static struct pollfd * pollfd ; <nl> - static unsigned npoll ; <nl> + static unsigned npoll , hpoll ; <nl>  <nl> static VTAILQ_HEAD (, sess ) sesshead = VTAILQ_HEAD_INITIALIZER ( sesshead ); <nl>  <nl> vca_poll ( int fd ) <nl>  <nl> assert ( fd >= 0 ); <nl> vca_pollspace (( unsigned ) fd ); <nl> + if ( hpoll < fd ) <nl> + hpoll = fd ; <nl> pollfd [ fd ]. fd = fd ; <nl> pollfd [ fd ]. events = POLLIN ; <nl> } <nl> vca_unpoll ( int fd ) <nl> vca_pollspace (( unsigned ) fd ); <nl> pollfd [ fd ]. fd = - 1 ; <nl> pollfd [ fd ]. events = 0 ; <nl> + if ( hpoll == fd ) { <nl> + while ( pollfd [-- hpoll ]. fd == - 1 ) <nl> + continue ; <nl> + } <nl> } <nl>  <nl> /*--------------------------------------------------------------------*/ <nl> vca_main ( void * arg ) <nl> vca_poll ( vca_pipes [ 0 ]); <nl>  <nl> while ( 1 ) { <nl> - v = poll ( pollfd , npoll , 100 ); <nl> + v = poll ( pollfd , hpoll + 1 , 100 ); <nl> if ( v && pollfd [ vca_pipes [ 0 ]]. revents ) { <nl> v --; <nl> i = read ( vca_pipes [ 0 ], & sp , sizeof sp );
mmm bin / varnishd / cache_center . c <nl> ppp bin / varnishd / cache_center . c <nl> cnt_recv ( struct sess * sp ) <nl> return ( 0 ); <nl> } <nl>  <nl> + if ( params -> http_gzip_support && <nl> + ( recv_handling != VCL_RET_PIPE ) && <nl> + ( recv_handling != VCL_RET_PASS )) { <nl> + if ( RFC2616_Req_Gzip ( sp )) { <nl> + http_Unset ( sp -> http , H_Accept_Encoding ); <nl> + http_PrintfHeader ( sp -> wrk , sp -> fd , sp -> http , <nl> + " Accept - Encoding : gzip "); <nl> + } else { <nl> + http_Unset ( sp -> http , H_Accept_Encoding ); <nl> + } <nl> + } <nl> + <nl> SHA256_Init ( sp -> wrk -> sha256ctx ); <nl> VCL_hash_method ( sp ); <nl> assert ( sp -> handling == VCL_RET_HASH );
mmm bin / varnishd / cache_center . c <nl> ppp bin / varnishd / cache_center . c <nl> cnt_miss ( struct sess * sp ) <nl> HSH_Unbusy ( sp -> obj ); <nl> HSH_Deref ( sp -> obj ); <nl> sp -> obj = NULL ; <nl> + vbe_free_bereq ( sp -> bereq ); <nl> + sp -> bereq = NULL ; <nl> sp -> step = STP_ERROR ; <nl> return ( 0 ); <nl> }
mmm lib / libvarnish / vcli_proto . c <nl> ppp lib / libvarnish / vcli_proto . c <nl> read_tmo ( int fd , char * ptr , unsigned len , double tmo ) <nl> pfd . events = POLLIN ; <nl> for ( j = 0 ; len > 0 ; ) { <nl> i = poll (& pfd , 1 , to ); <nl> + if ( i < 0 ) { <nl> + errno = EINTR ; <nl> + return (- 1 ); <nl> + } <nl> if ( i == 0 ) { <nl> errno = ETIMEDOUT ; <nl> return (- 1 );
mmm bin / varnishtop / varnishtop . c <nl> ppp bin / varnishtop / varnishtop . c <nl>  <nl> static const char progname [] = " varnishtop "; <nl> static float period = 60 ; /* seconds */ <nl> + static int end_of_file = 0 ; <nl>  <nl> struct top { <nl> uint8_t tag ; <nl> update ( int p ) <nl> if ( n < p ) <nl> n ++; <nl> AC ( erase ()); <nl> - AC ( mvprintw ( 0 , 0 , "%* s ", COLS - 1 , VUT . name )); <nl> + if ( end_of_file ) <nl> + AC ( mvprintw ( 0 , COLS - 1 - strlen ( VUT . name ) - 5 , "% s ( EOF )", <nl> + VUT . name )); <nl> + else <nl> + AC ( mvprintw ( 0 , COLS - 1 - strlen ( VUT . name ), "% s ", VUT . name )); <nl> AC ( mvprintw ( 0 , 0 , " list length % u ", ntop )); <nl> for ( tp = VRB_MIN ( top_tree , & top_tree_head ); tp != NULL ; tp = tp2 ) { <nl> tp2 = VRB_NEXT ( top_tree , & top_tree_head , tp ); <nl> main ( int argc , char ** argv ) <nl> VUT . dispatch_f = & accumulate ; <nl> VUT . dispatch_priv = NULL ; <nl> VUT_Main (); <nl> + end_of_file = 1 ; <nl> if ( once ) <nl> dump (); <nl> else
mmm bin / varnishd / cache_expire . c <nl> ppp bin / varnishd / cache_expire . c <nl> EXP_Touch ( const struct object * o , double now ) <nl>  <nl> CHECK_OBJ_NOTNULL ( o , OBJECT_MAGIC ); <nl> oe = o -> objexp ; <nl> + if ( oe == NULL ) <nl> + return ; <nl> CHECK_OBJ_NOTNULL ( oe , OBJEXP_MAGIC ); <nl> if ( oe -> lru_stamp + params -> lru_timeout > now ) <nl> return ;
mmm bin / varnishd / cache / cache_fetch . c <nl> ppp bin / varnishd / cache / cache_fetch . c <nl> vbf_stp_error ( struct worker * wrk , struct busyobj * bo ) <nl> l = ll ; <nl> if ( VFP_GetStorage ( bo -> vfc , & l , & ptr ) != VFP_OK ) <nl> break ; <nl> + if ( l > ll ) <nl> + l = ll ; <nl> memcpy ( ptr , VSB_data ( synth_body ) + o , l ); <nl> VFP_Extend ( bo -> vfc , l ); <nl> ll -= l ;
mmm bin / varnishd / cache_waiter_poll . c <nl> ppp bin / varnishd / cache_waiter_poll . c <nl> vca_main ( void * arg ) <nl> if ( pollfd [ fd ]. revents ) { <nl> v --; <nl> i = HTC_Rx ( sp -> htc ); <nl> + if ( pollfd [ fd ]. revents != POLLIN ) <nl> + VSL ( SLT_Debug , fd , " Poll : % x / % d ", <nl> + pollfd [ fd ]. revents , i ); <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> if ( i == 0 ) { <nl> /* Mov to front of list for speed */ <nl> vca_main ( void * arg ) <nl> SES_Delete ( sp ); <nl> } <nl> } <nl> + assert ( v == 0 ); <nl> } <nl> NEEDLESS_RETURN ( NULL ); <nl> }
mmm bin / varnishd / mgt_child . c <nl> ppp bin / varnishd / mgt_child . c <nl> mgt_run ( int dflag , const char * T_arg ) <nl>  <nl> setproctitle (" Varnish - Mgr % s ", heritage . name ); <nl>  <nl> + memset (& sac , 0 , sizeof sac ); <nl> sac . sa_handler = SIG_IGN ; <nl> sac . sa_flags = SA_RESTART ; <nl> 
mmm bin / varnishd / storage / storage_persistent . h <nl> ppp bin / varnishd / storage / storage_persistent . h <nl> struct smp_segptr { <nl> struct smp_object { <nl> uint8_t hash [ 32 ]; /* really : DIGEST_LEN */ <nl> struct exp exp ; <nl> + uint32_t __filler__ ; /* -> align / 8 on 32bit */ <nl> double ban ; <nl> uint64_t ptr ; /* rel to silo */ <nl> };mmm bin / varnishd / storage / storage_persistent_mgt . c <nl> ppp bin / varnishd / storage / storage_persistent_mgt . c <nl> struct smp_segptr { <nl> struct smp_object { <nl> uint8_t hash [ 32 ]; /* really : DIGEST_LEN */ <nl> struct exp exp ; <nl> + uint32_t __filler__ ; /* -> align / 8 on 32bit */ <nl> double ban ; <nl> uint64_t ptr ; /* rel to silo */ <nl> }; <nl> smp_mgt_init ( struct stevedore * parent , int ac , char * const * av ) <nl> ASSERT_MGT (); <nl>  <nl> AZ ( av [ ac ]); <nl> + <nl> + /* Necessary alignment . See also smp_object :: __filler__ */ <nl> + assert ( sizeof ( struct smp_object ) % 8 == 0 ); <nl> + <nl> # define SIZOF ( foo ) fprintf ( stderr , \ <nl> " sizeof (% s ) = % zu = 0x % zx \ n ", # foo , sizeof ( foo ), sizeof ( foo )); <nl> SIZOF ( struct smp_ident );
mmm lib / libvarnish / vrnd . c <nl> ppp lib / libvarnish / vrnd . c <nl> VRND_CryptoQuality ( void * ptr , size_t len ) <nl> ssize_t l ; <nl>  <nl> AN ( ptr ); <nl> - fd = open ("/ dev / random ", O_RDONLY ); <nl> + fd = open ("/ dev / urandom ", O_RDONLY ); <nl> if ( fd < 0 ) <nl> return (- 1 ); <nl> for ( p = ptr ; len > 0 ; len --, p ++) {
mmm bin / varnishd / cache_hash . c <nl> ppp bin / varnishd / cache_hash . c <nl> HSH_FindBan ( struct sess * sp , struct objcore ** oc ) <nl> CHECK_OBJ_NOTNULL ( oc1 , OBJCORE_MAGIC ); <nl> oh = oc1 -> objhead ; <nl> CHECK_OBJ_NOTNULL ( oh , OBJHEAD_MAGIC ); <nl> - Lck_Lock (& oh -> mtx ); <nl> + if ( Lck_Trylock (& oh -> mtx )) { <nl> + * oc = NULL ; <nl> + return ; <nl> + } <nl> VTAILQ_FOREACH ( oc2 , & oh -> objcs , list ) <nl> if ( oc1 == oc2 ) <nl> break ;
mmm lib / libvarnishapi / vsl_dispatch . c <nl> ppp lib / libvarnishapi / vsl_dispatch . c <nl> vtx_set_parent ( struct vtx * parent , struct vtx * child ) <nl>  <nl> CHECK_OBJ_NOTNULL ( parent , VTX_MAGIC ); <nl> CHECK_OBJ_NOTNULL ( child , VTX_MAGIC ); <nl> + assert ( parent != child ); <nl> AZ ( parent -> flags & VTX_F_COMPLETE ); <nl> AZ ( child -> flags & VTX_F_COMPLETE ); <nl> AZ ( child -> parent ); <nl> vtx_scan_begin ( struct VSLQ * vslq , struct vtx * vtx , const uint32_t * ptr ) <nl> vtx -> reason = reason ; <nl>  <nl> if ( p_vxid == 0 ) <nl> - /* No parent */ <nl> + /* Zero means no parent */ <nl> return ( 0 ); <nl> + if ( p_vxid == vtx -> key . vxid ) <nl> + return ( vtx_diag_tag ( vtx , ptr , " link to self ")); <nl>  <nl> if ( vslq -> grouping == VSL_g_vxid ) <nl> return ( 0 ); /* No links */ <nl> vtx_scan_link ( struct VSLQ * vslq , struct vtx * vtx , const uint32_t * ptr ) <nl> if ( vslq -> grouping == VSL_g_request && vtx -> type == VSL_t_sess ) <nl> return ( 0 ); /* No links */ <nl>  <nl> + if ( c_vxid == 0 ) <nl> + return ( vtx_diag_tag ( vtx , ptr , " illegal link vxid ")); <nl> + if ( c_vxid == vtx -> key . vxid ) <nl> + return ( vtx_diag_tag ( vtx , ptr , " link to self ")); <nl> + <nl> /* Lookup and check child vtx */ <nl> c_vtx = vtx_lookup ( vslq , c_vxid ); <nl> if ( c_vtx == NULL ) {
mmm bin / varnishd / storage_persistent_subr . c <nl> ppp bin / varnishd / storage_persistent_subr . c <nl> smp_def_sign ( const struct smp_sc * sc , struct smp_signctx * ctx , <nl> AZ ( off & 7 ); /* Alignment */ <nl> assert ( strlen ( id ) < sizeof ctx -> ss -> ident ); <nl>  <nl> - memset ( ctx , 0 , sizeof ctx ); <nl> + memset ( ctx , 0 , sizeof * ctx ); <nl> ctx -> ss = ( void *)( sc -> base + off ); <nl> ctx -> unique = sc -> unique ; <nl> ctx -> id = id ;
mmm bin / varnishd / mgt_child . c <nl> ppp bin / varnishd / mgt_child . c <nl> start_child ( struct cli * cli ) <nl> unsigned u ; <nl> char * p ; <nl> struct vev * e ; <nl> - int i , cp [ 2 ]; <nl> + int i , j , cp [ 2 ]; <nl>  <nl> if ( child_state != CH_STOPPED && child_state != CH_DIED ) <nl> return ; <nl> start_child ( struct cli * cli ) <nl> /* Close anything we shouldn ' t know about */ <nl> closelog (); <nl> printf (" Closed fds :"); <nl> - for ( i = STDERR_FILENO + 1 ; i < getdtablesize (); i ++) { <nl> + j = getdtablesize (); <nl> + for ( i = STDERR_FILENO + 1 ; i < j ; i ++) { <nl> if ( vbit_test ( fd_map , i )) <nl> continue ; <nl> if ( close ( i ) == 0 )mmm bin / varnishd / varnishd . c <nl> ppp bin / varnishd / varnishd . c <nl> start_child ( struct cli * cli ) <nl> unsigned u ; <nl> char * p ; <nl> struct vev * e ; <nl> - int i , cp [ 2 ]; <nl> + int i , j , cp [ 2 ]; <nl>  <nl> if ( child_state != CH_STOPPED && child_state != CH_DIED ) <nl> return ; <nl> start_child ( struct cli * cli ) <nl> /* Close anything we shouldn ' t know about */ <nl> closelog (); <nl> printf (" Closed fds :"); <nl> - for ( i = STDERR_FILENO + 1 ; i < getdtablesize (); i ++) { <nl> + j = getdtablesize (); <nl> + for ( i = STDERR_FILENO + 1 ; i < j ; i ++) { <nl> if ( vbit_test ( fd_map , i )) <nl> continue ; <nl> if ( close ( i ) == 0 ) <nl> DebugStunt ( void ) <nl> pipes [ 1 ][ 1 ] = 1 ; <nl>  <nl> /* close the rest */ <nl> - for ( i = 5 ; i < getdtablesize (); i ++) <nl> + j = getdtablesize (); <nl> + for ( i = 5 ; i < j ; i ++) <nl> ( void ) close ( i ); <nl>  <nl> pfd [ 0 ]. fd = pipes [ 0 ][ 0 ];
mmm bin / varnishtop / varnishtop . c <nl> ppp bin / varnishtop / varnishtop . c <nl> static int end_of_file = 0 ; <nl>  <nl> struct top { <nl> uint8_t tag ; <nl> - char * rec_data ; <nl> + const char * rec_data ; <nl> + char * rec_buf ; <nl> int clen ; <nl> unsigned hash ; <nl> VRB_ENTRY ( top ) e_order ; <nl> accumulate ( struct VSL_data * vsl , struct VSL_transaction * const pt [], <nl> t . hash = u ; <nl> t . tag = tag ; <nl> t . clen = len ; <nl> - t . rec_data = ( char *) VSL_CDATA ( tr -> c -> rec . ptr ); <nl> + t . rec_data = VSL_CDATA ( tr -> c -> rec . ptr ); <nl>  <nl> AZ ( pthread_mutex_lock (& mtx )); <nl> tp = VRB_FIND ( t_key , & h_key , & t ); <nl> accumulate ( struct VSL_data * vsl , struct VSL_transaction * const pt [], <nl> tp -> count = 1 . 0 ; <nl> tp -> clen = len ; <nl> tp -> tag = tag ; <nl> - tp -> rec_data = strdup ( t . rec_data ); <nl> + tp -> rec_buf = strdup ( t . rec_data ); <nl> + tp -> rec_data = tp -> rec_buf ; <nl> AN ( tp -> rec_data ); <nl> VRB_INSERT ( t_key , & h_key , tp ); <nl> VRB_INSERT ( t_order , & h_order , tp ); <nl> update ( int p ) <nl> if ( tp -> count * 10 < t || l > LINES * 10 ) { <nl> VRB_REMOVE ( t_key , & h_key , tp ); <nl> VRB_REMOVE ( t_order , & h_order , tp ); <nl> - free ( tp -> rec_data ); <nl> + free ( tp -> rec_buf ); <nl> free ( tp ); <nl> ntop --; <nl> }
mmm bin / varnishd / cache_cli . c <nl> ppp bin / varnishd / cache_cli . c <nl> CLI_Init ( void ) <nl> vsb_clear ( cli -> sb ); <nl> cli_dispatch ( cli , CLI_cmds , buf ); <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> i = cli_writeres ( heritage . fds [ 1 ], cli ); <nl> if ( i ) { <nl> VSL ( SLT_Error , 0 , " CLI write failed ( errno =% d )", errno );mmm bin / varnishd / mgt_cli . c <nl> ppp bin / varnishd / mgt_cli . c <nl> CLI_Init ( void ) <nl> vsb_clear ( cli -> sb ); <nl> cli_dispatch ( cli , CLI_cmds , buf ); <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> i = cli_writeres ( heritage . fds [ 1 ], cli ); <nl> if ( i ) { <nl> VSL ( SLT_Error , 0 , " CLI write failed ( errno =% d )", errno ); <nl> mcf_passthru ( struct cli * cli , const char * const * av , void * priv ) <nl> vsb_putc ( sb , '\ n '); <nl> xxxassert (! vsb_overflowed ( sb )); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> i = write ( cli_o , vsb_data ( sb ), vsb_len ( sb )); <nl> xxxassert ( i == vsb_len ( sb )); <nl> vsb_delete ( sb ); <nl> mgt_cli_callback ( const struct ev * e , int what ) <nl> vsb_clear ( cp -> cli -> sb ); <nl> cli_dispatch ( cp -> cli , cli_proto , p ); <nl> vsb_finish ( cp -> cli -> sb ); <nl> + AZ ( vsb_overflowed ( cp -> cli -> sb )); <nl>  <nl> /* send the result back */ <nl> if ( cli_writeres ( cp -> fdo , cp -> cli ))mmm bin / varnishd / cache_synthetic . c <nl> ppp bin / varnishd / cache_synthetic . c <nl> CLI_Init ( void ) <nl> vsb_clear ( cli -> sb ); <nl> cli_dispatch ( cli , CLI_cmds , buf ); <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> i = cli_writeres ( heritage . fds [ 1 ], cli ); <nl> if ( i ) { <nl> VSL ( SLT_Error , 0 , " CLI write failed ( errno =% d )", errno ); <nl> mcf_passthru ( struct cli * cli , const char * const * av , void * priv ) <nl> vsb_putc ( sb , '\ n '); <nl> xxxassert (! vsb_overflowed ( sb )); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> i = write ( cli_o , vsb_data ( sb ), vsb_len ( sb )); <nl> xxxassert ( i == vsb_len ( sb )); <nl> vsb_delete ( sb ); <nl> mgt_cli_callback ( const struct ev * e , int what ) <nl> vsb_clear ( cp -> cli -> sb ); <nl> cli_dispatch ( cp -> cli , cli_proto , p ); <nl> vsb_finish ( cp -> cli -> sb ); <nl> + AZ ( vsb_overflowed ( cp -> cli -> sb )); <nl>  <nl> /* send the result back */ <nl> if ( cli_writeres ( cp -> fdo , cp -> cli )) <nl> SYN_ErrorPage ( struct sess * sp , int status , const char * reason ) <nl> " </ body >\ n " <nl> "</ html >\ n "); <nl> vsb_finish (& vsb ); <nl> + AZ ( vsb_overflowed (& vsb )); <nl> w -> acct . hdrbytes = WRK_Write ( w , vsb_data (& vsb ), vsb_len (& vsb )); <nl> ( void ) WRK_Flush ( w ); <nl> vsb_delete (& vsb );mmm bin / varnishd / mgt_vcc . c <nl> ppp bin / varnishd / mgt_vcc . c <nl> CLI_Init ( void ) <nl> vsb_clear ( cli -> sb ); <nl> cli_dispatch ( cli , CLI_cmds , buf ); <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> i = cli_writeres ( heritage . fds [ 1 ], cli ); <nl> if ( i ) { <nl> VSL ( SLT_Error , 0 , " CLI write failed ( errno =% d )", errno ); <nl> mcf_passthru ( struct cli * cli , const char * const * av , void * priv ) <nl> vsb_putc ( sb , '\ n '); <nl> xxxassert (! vsb_overflowed ( sb )); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> i = write ( cli_o , vsb_data ( sb ), vsb_len ( sb )); <nl> xxxassert ( i == vsb_len ( sb )); <nl> vsb_delete ( sb ); <nl> mgt_cli_callback ( const struct ev * e , int what ) <nl> vsb_clear ( cp -> cli -> sb ); <nl> cli_dispatch ( cp -> cli , cli_proto , p ); <nl> vsb_finish ( cp -> cli -> sb ); <nl> + AZ ( vsb_overflowed ( cp -> cli -> sb )); <nl>  <nl> /* send the result back */ <nl> if ( cli_writeres ( cp -> fdo , cp -> cli )) <nl> SYN_ErrorPage ( struct sess * sp , int status , const char * reason ) <nl> " </ body >\ n " <nl> "</ html >\ n "); <nl> vsb_finish (& vsb ); <nl> + AZ ( vsb_overflowed (& vsb )); <nl> w -> acct . hdrbytes = WRK_Write ( w , vsb_data (& vsb ), vsb_len (& vsb )); <nl> ( void ) WRK_Flush ( w ); <nl> vsb_delete (& vsb ); <nl> mgt_run_cc ( const char * source , struct vsb * sb ) <nl> vsb_new (& cmdsb , cmdline , sizeof cmdline , 0 ); <nl> mgt_make_cc_cmd (& cmdsb , sf , of ); <nl> vsb_finish (& cmdsb ); <nl> + AZ ( vsb_overflowed (& cmdsb )); <nl> /* XXX check vsb state */ <nl>  <nl> if ( pipe ( p ) < 0 ) { <nl> mgt_vcc_default ( const char * b_arg , const char * f_arg , int f_fd , int C_flag ) <nl> vf = mgt_VccCompileFile ( sb , f_arg , C_flag , f_fd ); <nl> } <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> fprintf ( stderr , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> mcf_config_inline ( struct cli * cli , const char * const * av , void * priv ) <nl> XXXAN ( sb ); <nl> vf = mgt_VccCompile ( sb , av [ 3 ], NULL , 0 ); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> cli_out ( cli , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> mcf_config_load ( struct cli * cli , const char * const * av , void * priv ) <nl> XXXAN ( sb ); <nl> vf = mgt_VccCompileFile ( sb , av [ 3 ], 0 , - 1 ); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> cli_out ( cli , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb );mmm bin / varnishd / cache_vary . c <nl> ppp bin / varnishd / cache_vary . c <nl> CLI_Init ( void ) <nl> vsb_clear ( cli -> sb ); <nl> cli_dispatch ( cli , CLI_cmds , buf ); <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> i = cli_writeres ( heritage . fds [ 1 ], cli ); <nl> if ( i ) { <nl> VSL ( SLT_Error , 0 , " CLI write failed ( errno =% d )", errno ); <nl> mcf_passthru ( struct cli * cli , const char * const * av , void * priv ) <nl> vsb_putc ( sb , '\ n '); <nl> xxxassert (! vsb_overflowed ( sb )); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> i = write ( cli_o , vsb_data ( sb ), vsb_len ( sb )); <nl> xxxassert ( i == vsb_len ( sb )); <nl> vsb_delete ( sb ); <nl> mgt_cli_callback ( const struct ev * e , int what ) <nl> vsb_clear ( cp -> cli -> sb ); <nl> cli_dispatch ( cp -> cli , cli_proto , p ); <nl> vsb_finish ( cp -> cli -> sb ); <nl> + AZ ( vsb_overflowed ( cp -> cli -> sb )); <nl>  <nl> /* send the result back */ <nl> if ( cli_writeres ( cp -> fdo , cp -> cli )) <nl> SYN_ErrorPage ( struct sess * sp , int status , const char * reason ) <nl> " </ body >\ n " <nl> "</ html >\ n "); <nl> vsb_finish (& vsb ); <nl> + AZ ( vsb_overflowed (& vsb )); <nl> w -> acct . hdrbytes = WRK_Write ( w , vsb_data (& vsb ), vsb_len (& vsb )); <nl> ( void ) WRK_Flush ( w ); <nl> vsb_delete (& vsb ); <nl> mgt_run_cc ( const char * source , struct vsb * sb ) <nl> vsb_new (& cmdsb , cmdline , sizeof cmdline , 0 ); <nl> mgt_make_cc_cmd (& cmdsb , sf , of ); <nl> vsb_finish (& cmdsb ); <nl> + AZ ( vsb_overflowed (& cmdsb )); <nl> /* XXX check vsb state */ <nl>  <nl> if ( pipe ( p ) < 0 ) { <nl> mgt_vcc_default ( const char * b_arg , const char * f_arg , int f_fd , int C_flag ) <nl> vf = mgt_VccCompileFile ( sb , f_arg , C_flag , f_fd ); <nl> } <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> fprintf ( stderr , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> mcf_config_inline ( struct cli * cli , const char * const * av , void * priv ) <nl> XXXAN ( sb ); <nl> vf = mgt_VccCompile ( sb , av [ 3 ], NULL , 0 ); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> cli_out ( cli , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> mcf_config_load ( struct cli * cli , const char * const * av , void * priv ) <nl> XXXAN ( sb ); <nl> vf = mgt_VccCompileFile ( sb , av [ 3 ], 0 , - 1 ); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> cli_out ( cli , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> VRY_Create ( const struct sess * sp ) <nl> vsb_clear ( sbh ); <nl> vsb_printf ( sbh , "% c %.* s :% c ", 1 + ( q - p ), q - p , p , 0 ); <nl> vsb_finish ( sbh ); <nl> + AZ ( vsb_overflowed ( sbh )); <nl>  <nl> /* Append to vary matching string */ <nl> vsb_bcat ( sb , vsb_data ( sbh ), vsb_len ( sbh )); <nl> VRY_Create ( const struct sess * sp ) <nl> vsb_printf ( sb , "% c ", 0 ); <nl>  <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> l = vsb_len ( sb ); <nl> sp -> obj -> vary = malloc ( l ); <nl> AN ( sp -> obj -> vary );mmm bin / varnishd / varnishd . c <nl> ppp bin / varnishd / varnishd . c <nl> CLI_Init ( void ) <nl> vsb_clear ( cli -> sb ); <nl> cli_dispatch ( cli , CLI_cmds , buf ); <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> i = cli_writeres ( heritage . fds [ 1 ], cli ); <nl> if ( i ) { <nl> VSL ( SLT_Error , 0 , " CLI write failed ( errno =% d )", errno ); <nl> mcf_passthru ( struct cli * cli , const char * const * av , void * priv ) <nl> vsb_putc ( sb , '\ n '); <nl> xxxassert (! vsb_overflowed ( sb )); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> i = write ( cli_o , vsb_data ( sb ), vsb_len ( sb )); <nl> xxxassert ( i == vsb_len ( sb )); <nl> vsb_delete ( sb ); <nl> mgt_cli_callback ( const struct ev * e , int what ) <nl> vsb_clear ( cp -> cli -> sb ); <nl> cli_dispatch ( cp -> cli , cli_proto , p ); <nl> vsb_finish ( cp -> cli -> sb ); <nl> + AZ ( vsb_overflowed ( cp -> cli -> sb )); <nl>  <nl> /* send the result back */ <nl> if ( cli_writeres ( cp -> fdo , cp -> cli )) <nl> SYN_ErrorPage ( struct sess * sp , int status , const char * reason ) <nl> " </ body >\ n " <nl> "</ html >\ n "); <nl> vsb_finish (& vsb ); <nl> + AZ ( vsb_overflowed (& vsb )); <nl> w -> acct . hdrbytes = WRK_Write ( w , vsb_data (& vsb ), vsb_len (& vsb )); <nl> ( void ) WRK_Flush ( w ); <nl> vsb_delete (& vsb ); <nl> mgt_run_cc ( const char * source , struct vsb * sb ) <nl> vsb_new (& cmdsb , cmdline , sizeof cmdline , 0 ); <nl> mgt_make_cc_cmd (& cmdsb , sf , of ); <nl> vsb_finish (& cmdsb ); <nl> + AZ ( vsb_overflowed (& cmdsb )); <nl> /* XXX check vsb state */ <nl>  <nl> if ( pipe ( p ) < 0 ) { <nl> mgt_vcc_default ( const char * b_arg , const char * f_arg , int f_fd , int C_flag ) <nl> vf = mgt_VccCompileFile ( sb , f_arg , C_flag , f_fd ); <nl> } <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> fprintf ( stderr , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> mcf_config_inline ( struct cli * cli , const char * const * av , void * priv ) <nl> XXXAN ( sb ); <nl> vf = mgt_VccCompile ( sb , av [ 3 ], NULL , 0 ); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> cli_out ( cli , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> mcf_config_load ( struct cli * cli , const char * const * av , void * priv ) <nl> XXXAN ( sb ); <nl> vf = mgt_VccCompileFile ( sb , av [ 3 ], 0 , - 1 ); <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> if ( vsb_len ( sb ) > 0 ) <nl> cli_out ( cli , "% s ", vsb_data ( sb )); <nl> vsb_delete ( sb ); <nl> VRY_Create ( const struct sess * sp ) <nl> vsb_clear ( sbh ); <nl> vsb_printf ( sbh , "% c %.* s :% c ", 1 + ( q - p ), q - p , p , 0 ); <nl> vsb_finish ( sbh ); <nl> + AZ ( vsb_overflowed ( sbh )); <nl>  <nl> /* Append to vary matching string */ <nl> vsb_bcat ( sb , vsb_data ( sbh ), vsb_len ( sbh )); <nl> VRY_Create ( const struct sess * sp ) <nl> vsb_printf ( sb , "% c ", 0 ); <nl>  <nl> vsb_finish ( sb ); <nl> + AZ ( vsb_overflowed ( sb )); <nl> l = vsb_len ( sb ); <nl> sp -> obj -> vary = malloc ( l ); <nl> AN ( sp -> obj -> vary ); <nl> cli_check ( const struct cli * cli ) <nl> return ; <nl> } <nl> vsb_finish ( cli -> sb ); <nl> + AZ ( vsb_overflowed ( cli -> sb )); <nl> fprintf ( stderr , " Error :\ n % s \ n ", vsb_data ( cli -> sb )); <nl> exit ( 2 ); <nl> } <nl> main ( int argc , char * argv []) <nl> if ( cli [ 0 ]. result != CLIS_OK ) { <nl> fprintf ( stderr , " Parameter errors :\ n "); <nl> vsb_finish ( cli [ 0 ]. sb ); <nl> + AZ ( vsb_overflowed ( cli [ 0 ]. sb )); <nl> fprintf ( stderr , "% s \ n ", vsb_data ( cli [ 0 ]. sb )); <nl> exit ( 1 ); <nl> }
mmm bin / varnishd / cache_center . c <nl> ppp bin / varnishd / cache_center . c <nl> cnt_fetch ( struct sess * sp ) <nl> * Space for producing a Content - Length : header including padding <nl> * A billion gigabytes is enough for anybody . <nl> */ <nl> - l += strlen (" Content - Length : XxxXxxXxxXxxXxxXxx " + sizeof ( void *)); <nl> + l += strlen (" Content - Length : XxxXxxXxxXxxXxxXxx ") + sizeof ( void *); <nl>  <nl> if ( sp -> wrk -> ttl < sp -> t_req + params -> shortlived || <nl> sp -> objcore == NULL )
mmm lib / libvcc / vcc_symb . c <nl> ppp lib / libvcc / vcc_symb . c <nl> VCC_Symbol ( struct vcc * tl , struct symbol * parent , <nl> assert ( l > 0 ); <nl>  <nl> VTAILQ_FOREACH ( sym , & parent -> children , list ) { <nl> - if ( sym -> lorev > vhi || sym -> hirev < vlo ) <nl> - continue ; <nl> i = strncasecmp ( sym -> name , b , l ); <nl> if ( i < 0 ) <nl> continue ; <nl> VCC_Symbol ( struct vcc * tl , struct symbol * parent , <nl> } <nl> if ( l > sym -> nlen ) <nl> continue ; <nl> + if ( sym -> lorev > vhi || sym -> hirev < vlo ) <nl> + continue ; <nl> if ( q < e ) <nl> break ; <nl> if (( kind == SYM_NONE && kind == sym -> kind )) <nl> static void <nl> vcc_walksymbols ( struct vcc * tl , const struct symbol * root , <nl> symwalk_f * func , vcc_kind_t kind ) <nl> { <nl> - struct symbol * sym ; <nl> + struct symbol * sym , * sym2 = NULL ; <nl>  <nl> VTAILQ_FOREACH ( sym , & root -> children , list ) { <nl> + if ( sym2 != NULL ) <nl> + assert ( strcasecmp ( sym -> name , sym2 -> name ) >= 0 ); <nl> + sym2 = sym ; <nl> if ( kind == SYM_NONE || kind == sym -> kind ) <nl> func ( tl , sym ); <nl> ERRCHK ( tl );
mmm bin / varnishreplay / varnishreplay . c <nl> ppp bin / varnishreplay / varnishreplay . c <nl> replay_thread ( void * arg ) <nl> freez ( df_c ); <nl> bogus = 0 ; <nl> } <nl> + <nl> + /* leftovers */ <nl> + freez ( msg -> ptr ); <nl> + freez ( msg ); <nl> + freez ( df_H ); <nl> + freez ( df_Host ); <nl> + freez ( df_Uq ); <nl> + freez ( df_m ); <nl> + freez ( df_c ); <nl> + <nl> return ( 0 ); <nl> } <nl> 
mmm bin / varnishd / cache / cache_backend_cfg . c <nl> ppp bin / varnishd / cache / cache_backend_cfg . c <nl> cli_backend_set_health ( struct cli * cli , const char * const * av , void * priv ) <nl>  <nl> static struct cli_proto backend_cmds [] = { <nl> { " backend . list ", " backend . list ", <nl> - "\ tList all backends \ n ", 0 , 1 , " d ", cli_backend_list }, <nl> + "\ tList all backends \ n ", 0 , 1 , "", cli_backend_list }, <nl> { " backend . set_health ", " backend . set_health matcher state ", <nl> - "\ tShow a backend \ n ", 2 , 2 , " d ", cli_backend_set_health }, <nl> + "\ tShow a backend \ n ", 2 , 2 , "", cli_backend_set_health }, <nl> { NULL } <nl> }; <nl> 
mmm bin / varnishd / mgt_vcc . c <nl> ppp bin / varnishd / mgt_vcc . c <nl> mgt_CallCc ( const char * source , struct vsb * sb ) <nl> vsb_printf ( sb , <nl> " Cannot open temporary source file \"% s \": % s \ n ", <nl> sf , strerror ( errno )); <nl> - free ( sf ); <nl> return ( NULL ); <nl> } <nl> fs = fdopen ( sfd , " r +");
mmm bin / varnishncsa / varnishncsa . c <nl> ppp bin / varnishncsa / varnishncsa . c <nl> trimline ( const char * str , const char * end ) <nl> /* nothing */ ; <nl>  <nl> /* trim trailing space */ <nl> - while ( str [ len - 1 ] == ' ') <nl> + while ( len && str [ len - 1 ] == ' ') <nl> -- len ; <nl>  <nl> /* copy and return */
mmm bin / varnishd / varnishd . c <nl> ppp bin / varnishd / varnishd . c <nl> main ( int argc , char * const * argv ) <nl> if ( b_arg != NULL && f_arg != NULL ) { <nl> fprintf ( stderr , " Only one of - b or - f can be specified \ n "); <nl> usage (); <nl> - } else if ( S_arg == NULL && T_arg == NULL ) { <nl> + } <nl> + if ( S_arg == NULL && T_arg == NULL && d_flag == 0 && b_arg == NULL && <nl> + f_arg == NULL ) { <nl> fprintf ( stderr , <nl> " At least one of - d , - b , - f , - S or - T must be specified \ n "); <nl> usage ();
mmm bin / varnishd / cache / cache_vcl . c <nl> ppp bin / varnishd / cache / cache_vcl . c <nl> vcl_call_method ( struct worker * wrk , struct req * req , struct busyobj * bo , <nl> CHECK_OBJ_NOTNULL ( bo , BUSYOBJ_MAGIC ); <nl> vsl = bo -> vsl ; <nl> } <nl> + if ( method == VCL_MET_BACKEND_FETCH || <nl> + method == VCL_MET_PASS || <nl> + method == VCL_MET_MISS || <nl> + method == VCL_MET_PIPE || <nl> + method == VCL_MET_BACKEND_RESPONSE ) { <nl> + /* XXX : temporary workaround */ <nl> + AN ( req ); <nl> + bo = req -> busyobj ; <nl> + CHECK_OBJ_NOTNULL ( bo , BUSYOBJ_MAGIC ); <nl> + } <nl> aws = WS_Snapshot ( wrk -> aws ); <nl> wrk -> handling = 0 ; <nl> wrk -> cur_method = method ; <nl> VSLb ( vsl , SLT_VCL_call , "% s ", VCL_Method_Name ( method )); <nl> - ( void ) func ( wrk , req , NULL , ws ); <nl> + ( void ) func ( wrk , req , bo , ws ); <nl> VSLb ( vsl , SLT_VCL_return , "% s ", VCL_Return_Name ( wrk -> handling )); <nl> wrk -> cur_method = 0 ; <nl> WS_Reset ( wrk -> aws , aws );
mmm bin / varnishd / cache_session . c <nl> ppp bin / varnishd / cache_session . c <nl> SES_RefSrcAddr ( struct sess * sp ) <nl> c3 = c ; <nl> continue ; <nl> } <nl> - TAILQ_REMOVE ( ch , c2 , list ); <nl> - free ( c2 ); <nl> + TAILQ_REMOVE ( ch , c , list ); <nl> + free ( c ); <nl> VSL_stats -> n_srcaddr --; <nl> } <nl> if ( c3 == NULL ) {
mmm bin / varnishd / cache_httpd . c <nl> ppp bin / varnishd / cache_httpd . c <nl> HttpdAnalyze ( struct sess * sp ) <nl>  <nl> sp -> handling = HND_Unclass ; <nl>  <nl> + memset (& sp -> http , 0 , sizeof sp -> http ); <nl> + <nl> /* First , isolate and possibly identify request type */ <nl> sp -> http . req = sp -> rcv ; <nl> for ( p = sp -> rcv ; isalpha (* p ); p ++) <nl> HttpdAnalyze ( struct sess * sp ) <nl> if (* p == '\ r ') <nl> p ++; <nl>  <nl> - memset (& sp -> http , 0 , sizeof sp -> http ); <nl> - <nl> for (; p < sp -> rcv + sp -> rcv_len ; p = r ) { <nl> q = strchr ( p , '\ n '); <nl> r = q + 1 ;
mmm bin / varnishd / cache / cache_req_fsm . c <nl> ppp bin / varnishd / cache / cache_req_fsm . c <nl> CNT_AcctLogCharge ( struct dstat * ds , struct req * req ) <nl>  <nl> a = & req -> acct ; <nl>  <nl> - if (!( req -> res_mode & RES_PIPE )) { <nl> + if ( req -> vsl -> wid && !( req -> res_mode & RES_PIPE )) { <nl> VSLb ( req -> vsl , SLT_ReqAcct , "% ju % ju % ju % ju % ju % ju ", <nl> ( uintmax_t ) a -> req_hdrbytes , <nl> ( uintmax_t ) a -> req_bodybytes ,
mmm bin / varnishd / mgt / mgt_main . c <nl> ppp bin / varnishd / mgt / mgt_main . c <nl> main ( int argc , char * const * argv ) <nl> assert ( VTIM_parse (" Sunday , 06 - Nov - 94 08 : 49 : 37 GMT ") == 784111777 ); <nl> assert ( VTIM_parse (" Sun Nov 6 08 : 49 : 37 1994 ") == 784111777 ); <nl>  <nl> - /* <nl> - * Check that our SHA256 works <nl> - */ <nl> + /* Check that our SHA256 works */ <nl> SHA256_Test (); <nl>  <nl> - /* <nl> - * Create a cli for convenience in otherwise CLI functions <nl> - */ <nl> - <nl> + /* Create a cli for convenience in otherwise CLI functions */ <nl> INIT_OBJ ( cli , CLI_MAGIC ); <nl> cli [ 0 ]. sb = VSB_new_auto (); <nl> XXXAN ( cli [ 0 ]. sb ); <nl> main ( int argc , char * const * argv ) <nl> clilim = 32768 ; <nl> cli [ 0 ]. limit = & clilim ; <nl>  <nl> + /* Various initializations */ <nl> VTAILQ_INIT (& heritage . socks ); <nl> + mgt_evb = vev_new_base (); <nl> + AN ( mgt_evb ); <nl>  <nl> init_params ( cli ); <nl> cli_check ( cli ); <nl> main ( int argc , char * const * argv ) <nl>  <nl> mgt_pid = getpid (); /* daemon () changed this */ <nl>  <nl> - mgt_evb = vev_new_base (); <nl> - XXXAN ( mgt_evb ); <nl> - <nl> if ( d_flag ) <nl> mgt_cli_setup ( 0 , 1 , 1 , " debug ", cli_stdin_close , NULL ); <nl> 
mmm bin / varnishd / cache_pool . c <nl> ppp bin / varnishd / cache_pool . c <nl> WRK_QueueSession ( struct sess * sp ) <nl> unsigned onq ; <nl>  <nl> onq = nq + 1 ; <nl> - if ( onq > nwq ) <nl> + if ( onq >= nwq ) <nl> onq = 0 ; <nl> sp -> workreq . sess = sp ; <nl> qp = wq [ onq ];
mmm bin / varnishd / mgt_child . c <nl> ppp bin / varnishd / mgt_child . c <nl> mgt_sigchld ( struct ev * e , int what ) <nl> ev_poker = NULL ; <nl>  <nl> r = wait4 (- 1 , & status , WNOHANG , NULL ); <nl> - if ( r != child_pid ) { <nl> + if ( r != child_pid || r == - 1 ) { <nl> fprintf ( stderr , " Unknown child died pid =% d status = 0x % x \ n ", <nl> r , status ); <nl> return ( 0 );
mmm bin / varnishd / cache_hash . c <nl> ppp bin / varnishd / cache_hash . c <nl> HSH_Deref ( struct object * o ) <nl> } <nl> assert ( o -> refcnt > 0 ); <nl> r = -- o -> refcnt ; <nl> - hsh_rush ( oh ); <nl> + if ( oh != NULL ) <nl> + hsh_rush ( oh ); <nl> if ( oh != NULL ) { <nl> if (! r ) <nl> VTAILQ_REMOVE (& oh -> objects , o , list );
mmm lib / libvmod_directors / shard_cfg . c <nl> ppp lib / libvmod_directors / shard_cfg . c <nl> shardcfg_backend_cmp ( const struct shard_backend * a , <nl> ai = a -> ident ; <nl> bi = b -> ident ; <nl>  <nl> + assert ( ai || a -> backend ); <nl> + assert ( bi || b -> backend ); <nl> + <nl> /* vcl_names are unique , so we can compare the backend pointers */ <nl> if ( ai == NULL && bi == NULL ) <nl> return a -> backend != b -> backend ; <nl> static int <nl> shardcfg_backend_del_cmp ( const struct shard_backend * task , <nl> const struct shard_backend * b ) <nl> { <nl> - if ( task -> backend && task -> ident == NULL ) <nl> + assert ( task -> backend || task -> ident ); <nl> + <nl> + if ( task -> ident == NULL ) <nl> return task -> backend != b -> backend ; <nl>  <nl> return shardcfg_backend_cmp ( task , b );
mmm bin / varnishd / mgt_event . c <nl> ppp bin / varnishd / mgt_event . c <nl> ev_compact_pfd ( struct evbase * evb ) <nl> DBG ( evb , "...[% d ] fd = % d \ n ", u , p -> fd ); <nl> if ( p -> fd >= 0 ) <nl> continue ; <nl> + if ( u == evb -> lpfd - 1 ) <nl> + break ; <nl> lfd = evb -> pfd [ evb -> lpfd - 1 ]. fd ; <nl> VTAILQ_FOREACH ( ep , & evb -> events , __list ) <nl> if ( ep -> fd == lfd )
mmm bin / varnishd / cache / cache_vrt . c <nl> ppp bin / varnishd / cache / cache_vrt . c <nl> VRT_acl_log ( VRT_CTX , const char * msg ) <nl> { <nl>  <nl> CHECK_OBJ_NOTNULL ( ctx , VRT_CTX_MAGIC ); <nl> - VSLb ( ctx -> vsl , SLT_VCL_acl , "% s ", msg ); <nl> + AN ( msg ); <nl> + if ( ctx -> vsl != NULL ) <nl> + VSLb ( ctx -> vsl , SLT_VCL_acl , "% s ", msg ); <nl> + else <nl> + VSL ( SLT_VCL_acl , 0 , "% s ", msg ); <nl> } <nl>  <nl> /*--------------------------------------------------------------------*/
mmm bin / varnishd / cache_fetch . c <nl> ppp bin / varnishd / cache_fetch . c <nl> FetchBody ( struct sess * sp ) <nl> } else <nl> cls = 0 ; <nl>  <nl> + { <nl> + /* Sanity check fetch methods accounting */ <nl> + struct storage * st ; <nl> + unsigned uu ; <nl> + <nl> + uu = 0 ; <nl> + TAILQ_FOREACH ( st , & sp -> obj -> store , list ) <nl> + uu += st -> len ; <nl> + assert ( uu == sp -> obj -> len ); <nl> + } <nl> + <nl> http_CopyHttp (& sp -> obj -> http , hp ); <nl>  <nl> if ( http_GetHdr ( vc -> http , H_Connection , & b ) && ! strcasecmp ( b , " close "))
mmm bin / varnishhist / varnishhist . c <nl> ppp bin / varnishhist / varnishhist . c <nl> r_hist ( void ) <nl> r = y * m ; <nl> for ( x = 0 ; x < HIST_W ; x ++) { <nl> if ( bucket_miss [ x ] > r ) <nl> - addch ('|'); <nl> - else if ( bucket_hit [ x ] + bucket_miss [ x ] > r ) <nl> addch ('#'); <nl> + else if ( bucket_hit [ x ] + bucket_miss [ x ] > r ) <nl> + addch ('|'); <nl> else <nl> addch (' '); <nl> }
mmm bin / varnishd / waiter / cache_waiter_kqueue . c <nl> ppp bin / varnishd / waiter / cache_waiter_kqueue . c <nl> vwk_fini ( struct waiter * w ) <nl> vwk -> kq = - 1 ; <nl> Lck_Unlock (& vwk -> mtx ); <nl> AZ ( pthread_join ( vwk -> thread , & vp )); <nl> + Lck_Delete (& vwk -> mtx ); <nl> } <nl>  <nl> /*--------------------------------------------------------------------*/
mmm bin / varnishd / varnishd . c <nl> ppp bin / varnishd / varnishd . c <nl> DebugStunt ( void ) <nl> d_child = strtoul ( buf , & p , 0 ); <nl> assert ( p != NULL ); <nl> printf (" New Pid % d \ n ", d_child ); <nl> + assert ( d_child != 0 ); <nl> i = strlen ( p ); <nl> j = write ( pipes [ 1 ][ 1 ], p , i ); <nl> assert ( j == i );
mmm bin / varnishd / varnishd . c <nl> ppp bin / varnishd / varnishd . c <nl> main ( int argc , char * argv []) <nl> const char * h_flag = " classic "; <nl> const char * s_arg = " file "; <nl> const char * T_arg = NULL ; <nl> - unsigned C_flag ; <nl> + unsigned C_flag = 0 ; <nl> char * p ; <nl> struct params param ; <nl> struct cli cli [ 1 ]; <nl> main ( int argc , char * argv []) <nl>  <nl> if ( mgt_vcc_default ( b_arg , f_arg , C_flag )) <nl> exit ( 2 ); <nl> + if ( C_flag ) <nl> + exit ( 0 ); <nl>  <nl> setup_storage ( s_arg ); <nl> setup_hash ( h_flag );mmm bin / varnishd / mgt_vcc . c <nl> ppp bin / varnishd / mgt_vcc . c <nl> main ( int argc , char * argv []) <nl> const char * h_flag = " classic "; <nl> const char * s_arg = " file "; <nl> const char * T_arg = NULL ; <nl> - unsigned C_flag ; <nl> + unsigned C_flag = 0 ; <nl> char * p ; <nl> struct params param ; <nl> struct cli cli [ 1 ]; <nl> main ( int argc , char * argv []) <nl>  <nl> if ( mgt_vcc_default ( b_arg , f_arg , C_flag )) <nl> exit ( 2 ); <nl> + if ( C_flag ) <nl> + exit ( 0 ); <nl>  <nl> setup_storage ( s_arg ); <nl> setup_hash ( h_flag ); <nl> mgt_vcc_default ( const char * b_arg , const char * f_arg , int C_flag ) <nl> if ( C_flag ) { <nl> csrc = VCC_Compile ( sb , buf , NULL ); <nl> fputs ( csrc , stdout ); <nl> - exit ( 0 ); <nl> + return ( 0 ); <nl> } <nl> vf = mgt_VccCompile ( sb , buf , NULL ); <nl> free ( buf ); <nl> } else if ( C_flag ) { <nl> csrc = VCC_CompileFile ( sb , f_arg ); <nl> fputs ( csrc , stdout ); <nl> - exit ( 0 ); <nl> + return ( 0 ); <nl> } else { <nl> vf = mgt_VccCompileFile ( sb , f_arg ); <nl> }
mmm bin / varnishd / cache / cache_req . c <nl> ppp bin / varnishd / cache / cache_req . c <nl> Req_Cleanup ( struct sess * sp , struct worker * wrk , struct req * req ) <nl> req -> is_hit = 0 ; <nl>  <nl> WS_Reset ( req -> ws , 0 ); <nl> - WS_Reset ( wrk -> aws , 0 ); <nl> } <nl>  <nl> /*----------------------------------------------------------------------mmm bin / varnishd / cache / cache_req_fsm . c <nl> ppp bin / varnishd / cache / cache_req_fsm . c <nl> Req_Cleanup ( struct sess * sp , struct worker * wrk , struct req * req ) <nl> req -> is_hit = 0 ; <nl>  <nl> WS_Reset ( req -> ws , 0 ); <nl> - WS_Reset ( wrk -> aws , 0 ); <nl> } <nl>  <nl> /*---------------------------------------------------------------------- <nl> CNT_Request ( struct worker * wrk , struct req * req ) <nl> CHECK_OBJ_ORNULL ( wrk -> nobjhead , OBJHEAD_MAGIC ); <nl> CHECK_OBJ_NOTNULL ( req , REQ_MAGIC ); <nl>  <nl> - /* <nl> - * We don ' t want the thread workspace to be used for <nl> - * anything of long duration , so mandate that it be <nl> - * empty on state - transitions . <nl> - */ <nl> - WS_Assert ( wrk -> aws ); <nl> - AZ ( WS_Snapshot ( wrk -> aws )); <nl> - <nl> switch ( req -> req_step ) { <nl> # define REQ_STEP ( l , u , arg ) \ <nl> case R_STP_ ## u : \ <nl> CNT_Request ( struct worker * wrk , struct req * req ) <nl> default : <nl> WRONG (" State engine misfire "); <nl> } <nl> - WS_Assert ( wrk -> aws ); <nl> CHECK_OBJ_ORNULL ( wrk -> nobjhead , OBJHEAD_MAGIC ); <nl> } <nl> wrk -> vsl = NULL ;
mmm bin / varnishd / cache / cache_http1_fetch . c <nl> ppp bin / varnishd / cache / cache_http1_fetch . c <nl> V1F_fetch_hdr ( struct worker * wrk , struct busyobj * bo , struct req * req ) <nl> } else { <nl> i = HTTP1_IterateReqBody ( req , vbf_iter_req_body , wrk ); <nl> } <nl> - if ( req -> req_body_status == REQ_BODY_DONE ) { <nl> + if ( req -> req_body_status == REQ_BODY_TAKEN ) { <nl> retry = - 1 ; <nl> } else if ( req -> req_body_status == REQ_BODY_FAIL ) { <nl> VSLb ( bo -> vsl , SLT_FetchError ,mmm include / tbl / req_body . h <nl> ppp include / tbl / req_body . h <nl> V1F_fetch_hdr ( struct worker * wrk , struct busyobj * bo , struct req * req ) <nl> } else { <nl> i = HTTP1_IterateReqBody ( req , vbf_iter_req_body , wrk ); <nl> } <nl> - if ( req -> req_body_status == REQ_BODY_DONE ) { <nl> + if ( req -> req_body_status == REQ_BODY_TAKEN ) { <nl> retry = - 1 ; <nl> } else if ( req -> req_body_status == REQ_BODY_FAIL ) { <nl> VSLb ( bo -> vsl , SLT_FetchError , <nl> REQ_BODY ( PRESENT ) <nl> REQ_BODY ( CHUNKED ) <nl> REQ_BODY ( TAKEN ) <nl> REQ_BODY ( CACHED ) <nl> - REQ_BODY ( DONE ) <nl> REQ_BODY ( FAIL ) <nl> REQ_BODY ( NONE ) <nl> mmm bin / varnishd / cache / cache_http1_fsm . c <nl> ppp bin / varnishd / cache / cache_http1_fsm . c <nl> V1F_fetch_hdr ( struct worker * wrk , struct busyobj * bo , struct req * req ) <nl> } else { <nl> i = HTTP1_IterateReqBody ( req , vbf_iter_req_body , wrk ); <nl> } <nl> - if ( req -> req_body_status == REQ_BODY_DONE ) { <nl> + if ( req -> req_body_status == REQ_BODY_TAKEN ) { <nl> retry = - 1 ; <nl> } else if ( req -> req_body_status == REQ_BODY_FAIL ) { <nl> VSLb ( bo -> vsl , SLT_FetchError , <nl> REQ_BODY ( PRESENT ) <nl> REQ_BODY ( CHUNKED ) <nl> REQ_BODY ( TAKEN ) <nl> REQ_BODY ( CACHED ) <nl> - REQ_BODY ( DONE ) <nl> REQ_BODY ( FAIL ) <nl> REQ_BODY ( NONE ) <nl>  <nl> HTTP1_IterateReqBody ( struct req * req , req_body_iter_f * func , void * priv ) <nl> case REQ_BODY_PRESENT : <nl> case REQ_BODY_CHUNKED : <nl> break ; <nl> - case REQ_BODY_DONE : <nl> case REQ_BODY_TAKEN : <nl> VSLb ( req -> vsl , SLT_VCL_Error , <nl> " Uncached req . body can only be consumed once ."); <nl> int <nl> HTTP1_DiscardReqBody ( struct req * req ) <nl> { <nl>  <nl> - if ( req -> req_body_status == REQ_BODY_DONE ) <nl> - return ( 0 ); <nl> if ( req -> req_body_status == REQ_BODY_FAIL ) <nl> return ( 0 ); <nl> if ( req -> req_body_status == REQ_BODY_TAKEN )
mmm bin / varnishd / mgt / mgt_shmem . c <nl> ppp bin / varnishd / mgt / mgt_shmem . c <nl> void <nl> mgt_shm_atexit ( void ) <nl> { <nl>  <nl> + /* Do not let VCC kill our VSM */ <nl> + if ( getpid () != mgt_pid ) <nl> + return ; <nl> if ( heritage . vsm != NULL ) <nl> VSM_common_delete (& heritage . vsm ); <nl> }
mmm bin / varnishd / cache / cache_vary . c <nl> ppp bin / varnishd / cache / cache_vary . c <nl> VRY_Match ( struct req * req , const uint8_t * vary ) <nl> vsp [ ln + 1 ] = 0xff ; <nl> vsp [ ln + 2 ] = 0 ; <nl> VRY_Validate ( vsp ); <nl> - req -> vary_l = vsp + 3 ; <nl> + req -> vary_l = vsp + ln + 3 ; <nl>  <nl> i = vry_cmp ( vary , vsp ); <nl> assert ( i == 0 || i == 2 );
mmm bin / varnishd / cache / cache_center . c <nl> ppp bin / varnishd / cache / cache_center . c <nl> cnt_prepresp ( struct sess * sp , struct worker * wrk , struct req * req ) <nl> break ; <nl> if ( bo != NULL ) { <nl> AN ( bo -> do_stream ); <nl> - VDI_CloseFd (& bo -> vbc ); <nl> HSH_Drop ( wrk , & sp -> req -> obj ); <nl> VBO_DerefBusyObj ( wrk , & bo ); <nl> } else {
mmm lib / libvcc / vcc_action . c <nl> ppp lib / libvcc / vcc_action . c <nl> parse_new ( struct vcc * tl ) <nl> vcc_ErrWhere ( tl , tl -> t ); <nl> return ; <nl> } <nl> - XXXAZ ( sy1 ); <nl>  <nl> sy1 = VCC_AddSymbolTok ( tl , tl -> t , SYM_NONE ); // XXX : NONE ? <nl> XXXAN ( sy1 );
mmm bin / varnishd / cache_acceptor . c <nl> ppp bin / varnishd / cache_acceptor . c <nl> vca_write_obj ( struct worker * w , struct sess * sp ) <nl> sp -> obj -> age + sp -> t_req - sp -> obj -> entered ); <nl> sbuf_printf ( w -> sb , " Via : 1 . 1 varnish \ r \ n "); <nl> sbuf_printf ( w -> sb , " X - Varnish : xid % u \ r \ n ", sp -> obj -> xid ); <nl> + if ( http_GetProto ( sp -> http , & r ) && strcmp ( r , " HTTP / 1 . 1 ")) <nl> + sbuf_printf ( w -> sb , " Connection : close \ r \ n "); <nl> sbuf_printf ( w -> sb , "\ r \ n "); <nl> sbuf_finish ( w -> sb ); <nl> vca_write ( sp , sbuf_data ( w -> sb ), sbuf_len ( w -> sb ));
mmm bin / varnishd / tcp . c <nl> ppp bin / varnishd / tcp . c <nl> # include < errno . h > <nl> # include < netdb . h > <nl> # include < stdio . h > <nl> +# include < stdlib . h > <nl> # include < string . h > <nl> # include < unistd . h > <nl>  <nl> accept_filter ( int fd ) <nl> } <nl> # endif <nl>  <nl> + static char * <nl> + strndup ( const char * p , unsigned n ) <nl> +{ <nl> + char * q ; <nl> + <nl> + q = malloc ( n + 1 ); <nl> + if ( q != NULL ) { <nl> + memcpy ( q , p , n ); <nl> + q [ n ] = '\ 0 '; <nl> + } <nl> + return ( q ); <nl> +} <nl> + <nl> int <nl> TCP_parse ( const char * str , char ** addr , char ** port ) <nl> {
mmm bin / varnishncsa / varnishncsa . c <nl> ppp bin / varnishncsa / varnishncsa . c <nl> h_ncsa ( void * priv , enum VSL_tag_e tag , unsigned fd , <nl> const char * p ; <nl> struct vsb * os ; <nl>  <nl> + /* XXX : Ignore fd ' s outside 65536 */ <nl> + if ( fd >= 65536 ) <nl> + return ( reopen ); <nl> + <nl> if ( fd >= nll ) { <nl> struct logline ** newll = ll ; <nl> size_t newnll = nll ;
mmm bin / varnishtest / vtc_varnish . c <nl> ppp bin / varnishtest / vtc_varnish . c <nl> varnish_ask_cli ( const struct varnish * v , const char * cmd , char ** repl ) <nl> assert ( i == strlen ( cmd )); <nl> i = write ( v -> cli_fd , "\ n ", 1 ); <nl> assert ( i == 1 ); <nl> - i = cli_readres ( v -> cli_fd , & retval , & r , 10 . 0 ); <nl> + i = cli_readres ( v -> cli_fd , & retval , & r , 20 . 0 ); <nl> if ( i != 0 ) { <nl> vtc_log ( v -> vl , 0 , " CLI failed (% s ) = % d % u % s ", <nl> cmd , i , retval , r ); <nl> varnish_start ( struct varnish * v ) <nl> return ; <nl> vtc_log ( v -> vl , 2 , " Start "); <nl> u = varnish_ask_cli ( v , " start ", NULL ); <nl> + if ( vtc_error ) <nl> + return ; <nl> assert ( u == CLIS_OK ); <nl> u = varnish_ask_cli ( v , " debug . xid 1000 ", NULL ); <nl> + if ( vtc_error ) <nl> + return ; <nl> assert ( u == CLIS_OK ); <nl> } <nl> mmm lib / libvarnish / cli_common . c <nl> ppp lib / libvarnish / cli_common . c <nl> varnish_ask_cli ( const struct varnish * v , const char * cmd , char ** repl ) <nl> assert ( i == strlen ( cmd )); <nl> i = write ( v -> cli_fd , "\ n ", 1 ); <nl> assert ( i == 1 ); <nl> - i = cli_readres ( v -> cli_fd , & retval , & r , 10 . 0 ); <nl> + i = cli_readres ( v -> cli_fd , & retval , & r , 20 . 0 ); <nl> if ( i != 0 ) { <nl> vtc_log ( v -> vl , 0 , " CLI failed (% s ) = % d % u % s ", <nl> cmd , i , retval , r ); <nl> varnish_start ( struct varnish * v ) <nl> return ; <nl> vtc_log ( v -> vl , 2 , " Start "); <nl> u = varnish_ask_cli ( v , " start ", NULL ); <nl> + if ( vtc_error ) <nl> + return ; <nl> assert ( u == CLIS_OK ); <nl> u = varnish_ask_cli ( v , " debug . xid 1000 ", NULL ); <nl> + if ( vtc_error ) <nl> + return ; <nl> assert ( u == CLIS_OK ); <nl> } <nl>  <nl> cli_readres ( int fd , unsigned * status , char ** ptr , double tmo ) <nl> * status = CLIS_COMMS ; <nl> if ( ptr != NULL ) <nl> * ptr = strdup (" CLI communication error ( hdr )"); <nl> - return ( 1 ); <nl> + if ( i != 0 ) <nl> + return ( i ); <nl> + return ( 400 ); <nl> } <nl> assert ( i == CLI_LINE0_LEN ); <nl> assert ( res [ 3 ] == ' ');
mmm bin / varnishd / http2 / cache_http2_proto . c <nl> ppp bin / varnishd / http2 / cache_http2_proto . c <nl> h2_end_headers ( struct worker * wrk , struct h2_sess * h2 , <nl> assert ( r2 -> state == H2_S_OPEN ); <nl> h2e = h2h_decode_fini ( h2 , r2 -> decode ); <nl> FREE_OBJ ( r2 -> decode ); <nl> - if ( h2 -> rxf_flags & H2FF_HEADERS_END_STREAM ) <nl> - r2 -> state = H2_S_CLOS_REM ; <nl> h2 -> new_req = NULL ; <nl> + if ( r2 -> req -> req_body_status == REQ_BODY_NONE ) { <nl> + /* REQ_BODY_NONE implies one of the frames in the <nl> + * header block contained END_STREAM */ <nl> + r2 -> state = H2_S_CLOS_REM ; <nl> + } <nl> if ( h2e != NULL ) { <nl> Lck_Lock (& h2 -> sess -> mtx ); <nl> VSLb ( h2 -> vsl , SLT_Debug , " HPACK / FINI % s ", h2e -> name );
mmm bin / varnishd / storage / storage_umem . c <nl> ppp bin / varnishd / storage / storage_umem . c <nl> static void v_matchproto_ ( storage_open_f ) <nl> smu_open ( struct stevedore * st ) <nl> { <nl> struct smu_sc * smu_sc ; <nl> + char ident [ strlen ( st -> ident ) + 1 ]; <nl>  <nl> ASSERT_CLI (); <nl> st -> lru = LRU_Alloc (); <nl> smu_open ( struct stevedore * st ) <nl>  <nl> smu_open_init (); <nl>  <nl> - smu_sc -> smu_cache = umem_cache_createf ( st -> ident , <nl> + AN ( strcpy ( ident , st -> ident )); <nl> + smu_sc -> smu_cache = umem_cache_createf ( ident , <nl> sizeof ( struct smu ), <nl> 0 , // align <nl> smu_smu_constructor ,
mmm bin / varnishd / cache_waiter_poll . c <nl> ppp bin / varnishd / cache_waiter_poll . c <nl> vca_main ( void * arg ) <nl> continue ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> vca_unpoll ( fd ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> }mmm bin / varnishd / cache_waiter_kqueue . c <nl> ppp bin / varnishd / cache_waiter_kqueue . c <nl> vca_main ( void * arg ) <nl> continue ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> vca_unpoll ( fd ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> } <nl> vca_kqueue_main ( void * arg ) <nl> if ( sp -> t_open > deadline ) <nl> break ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> }mmm bin / varnishd / cache_waiter_epoll . c <nl> ppp bin / varnishd / cache_waiter_epoll . c <nl> vca_main ( void * arg ) <nl> continue ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> vca_unpoll ( fd ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> } <nl> vca_kqueue_main ( void * arg ) <nl> if ( sp -> t_open > deadline ) <nl> break ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> } <nl> vca_main ( void * arg ) <nl> if ( sp -> t_open > deadline ) <nl> break ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> }mmm bin / varnishd / cache_waiter_ports . c <nl> ppp bin / varnishd / cache_waiter_ports . c <nl> vca_main ( void * arg ) <nl> continue ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> vca_unpoll ( fd ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> } <nl> vca_kqueue_main ( void * arg ) <nl> if ( sp -> t_open > deadline ) <nl> break ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> } <nl> vca_main ( void * arg ) <nl> if ( sp -> t_open > deadline ) <nl> break ; <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> } <nl> vca_main ( void * arg ) <nl> VTAILQ_REMOVE (& sesshead , sp , list ); <nl> if ( sp -> fd != - 1 ) <nl> vca_del ( sp -> fd ); <nl> + TCP_linger ( sp -> fd , 0 ); <nl> vca_close_session ( sp , " timeout "); <nl> SES_Delete ( sp ); <nl> }
mmm bin / varnishd / cache / cache_director . c <nl> ppp bin / varnishd / cache / cache_director . c <nl> do_list ( struct cli * cli , struct director * d , void * priv ) <nl> if ( d -> vdir -> admin_health == VDI_AH_DELETED ) <nl> return ( 0 ); <nl>  <nl> + // XXX admin health " probe " for the no - probe case is confusing <nl> VCLI_Out ( cli , "\ n %- 30s %- 7s ", d -> vdir -> cli_name , VDI_Ahealth ( d )); <nl>  <nl> if ( d -> vdir -> methods -> list != NULL )
mmm bin / varnishd / cache_http . c <nl> ppp bin / varnishd / cache_http . c <nl> http_Read ( struct http * hp , int fd , void * p , unsigned len ) <nl> b += u ; <nl> len -= u ; <nl> } <nl> - if ( len > 0 ) { <nl> + while ( len > 0 ) { <nl> i = read ( fd , b , len ); <nl> - if ( i < 0 ) <nl> + if ( i <= 0 ) <nl> return ( i ); <nl> u += i ; <nl> + len -= u ; <nl> } <nl> return ( u ); <nl> }
mmm bin / varnishncsa / varnishncsa . c <nl> ppp bin / varnishncsa / varnishncsa . c <nl> dispatch_f ( struct VSL_data * vsl , struct VSL_transaction * const pt [], <nl> for ( t = pt [ 0 ]; t != NULL ; t = *++ pt ) { <nl> CTX . gen ++; <nl> if ( t -> type != VSL_t_req ) <nl> + /* Only look at client requests */ <nl> + continue ; <nl> + if ( t -> reason == VSL_r_esi ) <nl> + /* Skip ESI requests */ <nl> continue ; <nl> CTX . hitmiss = "-"; <nl> CTX . handling = "-";
mmm src / txn . cpp <nl> ppp src / txn . cpp <nl> Nan :: NAN_METHOD_RETURN_TYPE TxnWrap :: putCommon ( Nan :: NAN_METHOD_ARGS_TYPE info , v <nl> } <nl>  <nl> NAN_METHOD ( TxnWrap :: putString ) { <nl> + if (! info [ 2 ]-> IsString ()) <nl> + return Nan :: ThrowError (" Value must be a string ."); <nl> return putCommon ( info , []( Nan :: NAN_METHOD_ARGS_TYPE info , MDB_val & data ) -> void { <nl> CustomExternalStringResource :: writeTo ( Local < String >:: Cast ( info [ 2 ]), & data ); <nl> }, []( MDB_val & data ) -> void {
mmm src / mapi_attr . c <nl> ppp src / mapi_attr . c <nl> mapi_attr_read ( size_t len , unsigned char * buf ) <nl> uint32 i , j ; <nl> assert ( len > 4 ); <nl> uint32 num_properties = GETINT32 ( buf + idx ); <nl> + assert (( num_properties + 1 ) != 0 ); <nl> MAPI_Attr ** attrs = CHECKED_XMALLOC ( MAPI_Attr *, ( num_properties + 1 )); <nl>  <nl> idx += 4 ; <nl> mapi_attr_read ( size_t len , unsigned char * buf ) <nl> /* read the data into a buffer */ <nl> a -> names [ i ]. data <nl> = CHECKED_XMALLOC ( unsigned char , a -> names [ i ]. len ); <nl> + assert (( idx +( a -> names [ i ]. len * 2 )) <= len ); <nl> for ( j = 0 ; j < ( a -> names [ i ]. len >> 1 ); j ++) <nl> a -> names [ i ]. data [ j ] = ( buf + idx )[ j * 2 ]; <nl>  <nl> mapi_attr_read ( size_t len , unsigned char * buf ) <nl> case szMAPI_BINARY : <nl> CHECKINT32 ( idx , len ); v -> len = GETINT32 ( buf + idx ); idx += 4 ; <nl>  <nl> + assert ( v -> len + idx <= len ); <nl> + <nl> if ( a -> type == szMAPI_UNICODE_STRING ) <nl> { <nl> + assert ( v -> len != 0 ); <nl> v -> data . buf = ( unsigned char *) unicode_to_utf8 ( v -> len , buf + idx ); <nl> } <nl> else
mmm modules / stream_out / rtpfmt . c <nl> ppp modules / stream_out / rtpfmt . c <nl> int rtp_packetize_xiph_config ( sout_stream_id_sys_t * id , const char * fmtp , <nl> char * end = strchr ( start , ';'); <nl> assert ( end != NULL ); <nl> size_t len = end - start ; <nl> - char b64 [ len + 1 ]; <nl> + <nl> + char * b64 = malloc ( len + 1 ); <nl> + if (! b64 ) <nl> + return VLC_EGENERIC ; <nl> + <nl> memcpy ( b64 , start , len ); <nl> b64 [ len ] = '\ 0 '; <nl>  <nl> int rtp_packetize_xiph_config ( sout_stream_id_sys_t * id , const char * fmtp , <nl> int i_data ; <nl>  <nl> i_data = vlc_b64_decode_binary (& p_orig , b64 ); <nl> + free ( b64 ); <nl> if ( i_data <= 9 ) <nl> { <nl> free ( p_orig );
mmm modules / demux / mp4 / libmp4 . c <nl> ppp modules / demux / mp4 / libmp4 . c <nl> static int MP4_ReadBox_String ( stream_t * p_stream , MP4_Box_t * p_box ) <nl> { <nl> MP4_READBOX_ENTER ( MP4_Box_data_string_t ); <nl>  <nl> + if ( p_box -> i_size < 8 || p_box -> i_size > SIZE_MAX ) <nl> + MP4_READBOX_EXIT ( 0 ); <nl> + <nl> p_box -> data . p_string -> psz_text = malloc ( p_box -> i_size + 1 - 8 ); /* +\ 0 , - name , - size */ <nl> if ( p_box -> data . p_string -> psz_text == NULL ) <nl> MP4_READBOX_EXIT ( 0 );
mmm modules / codec / schroedinger . c <nl> ppp modules / codec / schroedinger . c <nl> static block_t * Encode ( encoder_t * p_enc , picture_t * p_pic ) <nl> * is appended to the sequence header to allow guard <nl> * against poor streaming servers */ <nl> /* XXX , should this be done using the packetizer ? */ <nl> + <nl> + if ( len > UINT32_MAX - sizeof ( eos ) ) <nl> + return NULL ; <nl> + <nl> p_enc -> fmt_out . p_extra = malloc ( len + sizeof ( eos ) ); <nl> if ( ! p_enc -> fmt_out . p_extra ) <nl> return NULL ;
mmm src / misc / update . c <nl> ppp src / misc / update . c <nl> static bool GetUpdateFile ( update_t * p_update ) <nl> } <nl>  <nl> const int64_t i_read = stream_Size ( p_stream ); <nl> + <nl> + if ( i_read < 0 || i_read >= UINT16_MAX ) <nl> + { <nl> + msg_Err ( p_update -> p_libvlc , " Status file too large "); <nl> + goto error ; <nl> + } <nl> + <nl> psz_update_data = malloc ( i_read + 1 ); /* terminating '\ 0 ' */ <nl> if ( ! psz_update_data ) <nl> goto error ;
mmm src / window . c <nl> ppp src / window . c <nl> win_exchange ( long Prenum ) <nl>  <nl> ( void ) win_comp_pos (); // recompute window positions <nl>  <nl> + if ( wp -> w_buffer != curbuf ) <nl> + reset_VIsual_and_resel (); <nl> + else if ( VIsual_active ) <nl> + wp -> w_cursor = curwin -> w_cursor ; <nl> + <nl> win_enter ( wp , TRUE ); <nl> redraw_all_later ( NOT_VALID ); <nl> } <nl> frame_remove ( frame_T * frp ) <nl> win_alloc_lines ( win_T * wp ) <nl> { <nl> wp -> w_lines_valid = 0 ; <nl> - wp -> w_lines = ALLOC_CLEAR_MULT ( wline_T , Rows ); <nl> + wp -> w_lines = ALLOC_CLEAR_MULT ( wline_T , Rows ); <nl> if ( wp -> w_lines == NULL ) <nl> return FAIL ; <nl> return OK ;mmm src / version . c <nl> ppp src / version . c <nl> win_exchange ( long Prenum ) <nl>  <nl> ( void ) win_comp_pos (); // recompute window positions <nl>  <nl> + if ( wp -> w_buffer != curbuf ) <nl> + reset_VIsual_and_resel (); <nl> + else if ( VIsual_active ) <nl> + wp -> w_cursor = curwin -> w_cursor ; <nl> + <nl> win_enter ( wp , TRUE ); <nl> redraw_all_later ( NOT_VALID ); <nl> } <nl> frame_remove ( frame_T * frp ) <nl> win_alloc_lines ( win_T * wp ) <nl> { <nl> wp -> w_lines_valid = 0 ; <nl> - wp -> w_lines = ALLOC_CLEAR_MULT ( wline_T , Rows ); <nl> + wp -> w_lines = ALLOC_CLEAR_MULT ( wline_T , Rows ); <nl> if ( wp -> w_lines == NULL ) <nl> return FAIL ; <nl> return OK ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4154 , <nl> /**/ <nl> 4153 , <nl> /**/
mmm src / message . c <nl> ppp src / message . c <nl> str2special ( <nl> * sp = str + 1 ; <nl> } <nl> else <nl> - // single - byte character or illegal byte <nl> - * sp = str + 1 ; <nl> + // single - byte character , NUL or illegal byte <nl> + * sp = str + (* str == NUL ? 0 : 1 ); <nl>  <nl> // Make special keys and C0 control characters in <> form , also < M - Space >. <nl> // Use < Space > only for lhs of a mapping .mmm src / version . c <nl> ppp src / version . c <nl> str2special ( <nl> * sp = str + 1 ; <nl> } <nl> else <nl> - // single - byte character or illegal byte <nl> - * sp = str + 1 ; <nl> + // single - byte character , NUL or illegal byte <nl> + * sp = str + (* str == NUL ? 0 : 1 ); <nl>  <nl> // Make special keys and C0 control characters in <> form , also < M - Space >. <nl> // Use < Space > only for lhs of a mapping . <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 9 , <nl> /**/ <nl> 8 , <nl> /**/
mmm src / edit . c <nl> ppp src / edit . c <nl> ins_bs ( <nl> # endif <nl>  <nl> // delete characters until we are at or before want_vcol <nl> - while ( vcol > want_vcol <nl> + while ( vcol > want_vcol && curwin -> w_cursor . col > 0 <nl> && ( cc = *( ml_get_cursor () - 1 ), VIM_ISWHITE ( cc ))) <nl> ins_bs_one (& vcol ); <nl> mmm src / version . c <nl> ppp src / version . c <nl> ins_bs ( <nl> # endif <nl>  <nl> // delete characters until we are at or before want_vcol <nl> - while ( vcol > want_vcol <nl> + while ( vcol > want_vcol && curwin -> w_cursor . col > 0 <nl> && ( cc = *( ml_get_cursor () - 1 ), VIM_ISWHITE ( cc ))) <nl> ins_bs_one (& vcol ); <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5162 , <nl> /**/ <nl> 5161 , <nl> /**/
mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> ex_put ( exarg_T * eap ) <nl> eap -> forceit = TRUE ; <nl> } <nl> curwin -> w_cursor . lnum = eap -> line2 ; <nl> + check_cursor_col (); <nl> do_put ( eap -> regname , NULL , eap -> forceit ? BACKWARD : FORWARD , 1L , <nl> PUT_LINE | PUT_CURSLINE ); <nl> }mmm src / version . c <nl> ppp src / version . c <nl> ex_put ( exarg_T * eap ) <nl> eap -> forceit = TRUE ; <nl> } <nl> curwin -> w_cursor . lnum = eap -> line2 ; <nl> + check_cursor_col (); <nl> do_put ( eap -> regname , NULL , eap -> forceit ? BACKWARD : FORWARD , 1L , <nl> PUT_LINE | PUT_CURSLINE ); <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3581 , <nl> /**/ <nl> 3580 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 378 , <nl> /**/ <nl> 377 , <nl> /**/mmm src / undo . c <nl> ppp src / undo . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 378 , <nl> /**/ <nl> 377 , <nl> /**/ <nl> unserialize_uep ( bufinfo_T * bi , int * error , char_u * file_name ) <nl> { <nl> int i ; <nl> u_entry_T * uep ; <nl> - char_u ** array ; <nl> + char_u ** array = NULL ; <nl> char_u * line ; <nl> int line_len ; <nl>  <nl> unserialize_uep ( bufinfo_T * bi , int * error , char_u * file_name ) <nl> uep -> ue_size = undo_read_4c ( bi ); <nl> if ( uep -> ue_size > 0 ) <nl> { <nl> - array = ( char_u **) U_ALLOC_LINE ( sizeof ( char_u *) * uep -> ue_size ); <nl> + if ( uep -> ue_size < LONG_MAX / ( int ) sizeof ( char_u *)) <nl> + array = ( char_u **) U_ALLOC_LINE ( sizeof ( char_u *) * uep -> ue_size ); <nl> if ( array == NULL ) <nl> { <nl> * error = TRUE ; <nl> unserialize_uep ( bufinfo_T * bi , int * error , char_u * file_name ) <nl> } <nl> vim_memset ( array , 0 , sizeof ( char_u *) * uep -> ue_size ); <nl> } <nl> - else <nl> - array = NULL ; <nl> uep -> ue_array = array ; <nl>  <nl> for ( i = 0 ; i < uep -> ue_size ; ++ i )
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5122 , <nl> /**/ <nl> 5121 , <nl> /**/mmm src / indent . c <nl> ppp src / indent . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5122 , <nl> /**/ <nl> 5121 , <nl> /**/ <nl> get_lisp_indent ( void ) <nl> } <nl> } <nl> } <nl> + if (* that == NUL ) <nl> + break ; <nl> } <nl> if (* that == '(' || * that == '[') <nl> ++ parencount ;
mmm src / textformat . c <nl> ppp src / textformat . c <nl> same_leader ( <nl> if ( leader1_len == 0 ) <nl> return ( leader2_len == 0 ); <nl>  <nl> + char_u * lnum_line = NULL ; <nl> + int line_len = 0 ; <nl> + <nl> // If first leader has ' f ' flag , the lines can be joined only if the <nl> // second line does not have a leader . <nl> // If first leader has ' e ' flag , the lines can never be joined . <nl> same_leader ( <nl> return FALSE ; <nl> if (* p == COM_START ) <nl> { <nl> - if (*( ml_get ( lnum ) + leader1_len ) == NUL ) <nl> + if ( lnum_line == NULL ) <nl> + { <nl> + lnum_line = ml_get ( lnum ); <nl> + line_len = ( int ) STRLEN ( lnum_line ); <nl> + } <nl> + if ( line_len <= leader1_len ) <nl> return FALSE ; <nl> if ( leader2_flags == NULL || leader2_len == 0 ) <nl> return FALSE ;mmm src / version . c <nl> ppp src / version . c <nl> same_leader ( <nl> if ( leader1_len == 0 ) <nl> return ( leader2_len == 0 ); <nl>  <nl> + char_u * lnum_line = NULL ; <nl> + int line_len = 0 ; <nl> + <nl> // If first leader has ' f ' flag , the lines can be joined only if the <nl> // second line does not have a leader . <nl> // If first leader has ' e ' flag , the lines can never be joined . <nl> same_leader ( <nl> return FALSE ; <nl> if (* p == COM_START ) <nl> { <nl> - if (*( ml_get ( lnum ) + leader1_len ) == NUL ) <nl> + if ( lnum_line == NULL ) <nl> + { <nl> + lnum_line = ml_get ( lnum ); <nl> + line_len = ( int ) STRLEN ( lnum_line ); <nl> + } <nl> + if ( line_len <= leader1_len ) <nl> return FALSE ; <nl> if ( leader2_flags == NULL || leader2_len == 0 ) <nl> return FALSE ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1225 , <nl> /**/ <nl> 1224 , <nl> /**/
mmm src / testing . c <nl> ppp src / testing . c <nl> f_assert_fails ( typval_T * argvars , typval_T * rettv ) <nl> in_assert_fails = TRUE ; <nl>  <nl> do_cmdline_cmd ( cmd ); <nl> + <nl> + // reset here for any errors reported below <nl> + trylevel = save_trylevel ; <nl> + suppress_errthrow = FALSE ; <nl> + <nl> if ( called_emsg == called_emsg_before ) <nl> { <nl> prepare_assert_error (& ga ); <nl> f_assert_fails ( typval_T * argvars , typval_T * rettv ) <nl> CHECK_LIST_MATERIALIZE ( list ); <nl> tv = & list -> lv_first -> li_tv ; <nl> expected = tv_get_string_buf_chk ( tv , buf ); <nl> + if ( expected == NULL ) <nl> + goto theend ; <nl> if (! pattern_match ( expected , actual , FALSE )) <nl> { <nl> error_found = TRUE ; <nl> f_assert_fails ( typval_T * argvars , typval_T * rettv ) <nl> { <nl> tv = & list -> lv_u . mat . lv_last -> li_tv ; <nl> expected = tv_get_string_buf_chk ( tv , buf ); <nl> + if ( expected == NULL ) <nl> + goto theend ; <nl> if (! pattern_match ( expected , actual , FALSE )) <nl> { <nl> error_found = TRUE ;mmm src / version . c <nl> ppp src / version . c <nl> f_assert_fails ( typval_T * argvars , typval_T * rettv ) <nl> in_assert_fails = TRUE ; <nl>  <nl> do_cmdline_cmd ( cmd ); <nl> + <nl> + // reset here for any errors reported below <nl> + trylevel = save_trylevel ; <nl> + suppress_errthrow = FALSE ; <nl> + <nl> if ( called_emsg == called_emsg_before ) <nl> { <nl> prepare_assert_error (& ga ); <nl> f_assert_fails ( typval_T * argvars , typval_T * rettv ) <nl> CHECK_LIST_MATERIALIZE ( list ); <nl> tv = & list -> lv_first -> li_tv ; <nl> expected = tv_get_string_buf_chk ( tv , buf ); <nl> + if ( expected == NULL ) <nl> + goto theend ; <nl> if (! pattern_match ( expected , actual , FALSE )) <nl> { <nl> error_found = TRUE ; <nl> f_assert_fails ( typval_T * argvars , typval_T * rettv ) <nl> { <nl> tv = & list -> lv_u . mat . lv_last -> li_tv ; <nl> expected = tv_get_string_buf_chk ( tv , buf ); <nl> + if ( expected == NULL ) <nl> + goto theend ; <nl> if (! pattern_match ( expected , actual , FALSE )) <nl> { <nl> error_found = TRUE ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 404 , <nl> /**/ <nl> 403 , <nl> /**/
mmm src / spellsuggest . c <nl> ppp src / spellsuggest . c <nl> suggest_trie_walk ( <nl> sp -> ts_isdiff = ( newscore != 0 ) <nl> ? DIFF_YES : DIFF_NONE ; <nl> } <nl> - else if ( sp -> ts_isdiff == DIFF_INSERT ) <nl> + else if ( sp -> ts_isdiff == DIFF_INSERT <nl> + && sp -> ts_fidx > 0 ) <nl> // When inserting trail bytes don ' t advance in the <nl> // bad word . <nl> -- sp -> ts_fidx ;mmm src / version . c <nl> ppp src / version . c <nl> suggest_trie_walk ( <nl> sp -> ts_isdiff = ( newscore != 0 ) <nl> ? DIFF_YES : DIFF_NONE ; <nl> } <nl> - else if ( sp -> ts_isdiff == DIFF_INSERT ) <nl> + else if ( sp -> ts_isdiff == DIFF_INSERT <nl> + && sp -> ts_fidx > 0 ) <nl> // When inserting trail bytes don ' t advance in the <nl> // bad word . <nl> -- sp -> ts_fidx ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5123 , <nl> /**/ <nl> 5122 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3582 , <nl> /**/ <nl> 3581 , <nl> /**/mmm src / spellsuggest . c <nl> ppp src / spellsuggest . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3582 , <nl> /**/ <nl> 3581 , <nl> /**/ <nl> suggest_trie_walk ( <nl> // char , e . g ., " thes ," -> " these ". <nl> p = fword + sp -> ts_fidx ; <nl> MB_PTR_BACK ( fword , p ); <nl> - if (! spell_iswordp ( p , curwin )) <nl> + if (! spell_iswordp ( p , curwin ) && * preword != NUL ) <nl> { <nl> p = preword + STRLEN ( preword ); <nl> MB_PTR_BACK ( preword , p );
mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> do_one_cmd ( cmdlinep , sourcing , <nl>  <nl> # ifdef FEAT_WINDOWS <nl> /* : wincmd range depends on the argument . */ <nl> - if ( ea . cmdidx == CMD_wincmd ) <nl> - get_wincmd_addr_type ( p , & ea ); <nl> + if ( ea . cmdidx == CMD_wincmd && p != NULL ) <nl> + get_wincmd_addr_type ( skipwhite ( p ), & ea ); <nl> # endif <nl> } <nl> mmm src / version . c <nl> ppp src / version . c <nl> do_one_cmd ( cmdlinep , sourcing , <nl>  <nl> # ifdef FEAT_WINDOWS <nl> /* : wincmd range depends on the argument . */ <nl> - if ( ea . cmdidx == CMD_wincmd ) <nl> - get_wincmd_addr_type ( p , & ea ); <nl> + if ( ea . cmdidx == CMD_wincmd && p != NULL ) <nl> + get_wincmd_addr_type ( skipwhite ( p ), & ea ); <nl> # endif <nl> } <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 580 , <nl> /**/ <nl> 579 , <nl> /**/
mmm src / vim9compile . c <nl> ppp src / vim9compile . c <nl> compile_nested_function ( exarg_T * eap , cctx_T * cctx , garray_T * lines_to_free ) <nl> int r = FAIL ; <nl> compiletype_T compile_type ; <nl> isn_T * funcref_isn = NULL ; <nl> + lvar_T * lvar = NULL ; <nl>  <nl> if ( eap -> forceit ) <nl> { <nl> compile_nested_function ( exarg_T * eap , cctx_T * cctx , garray_T * lines_to_free ) <nl> else <nl> { <nl> // Define a local variable for the function reference . <nl> - lvar_T * lvar = reserve_local ( cctx , func_name , name_end - name_start , <nl> + lvar = reserve_local ( cctx , func_name , name_end - name_start , <nl> TRUE , ufunc -> uf_func_type ); <nl> - <nl> if ( lvar == NULL ) <nl> goto theend ; <nl> if ( generate_FUNCREF ( cctx , ufunc , & funcref_isn ) == FAIL ) <nl> compile_nested_function ( exarg_T * eap , cctx_T * cctx , garray_T * lines_to_free ) <nl> && compile_def_function ( ufunc , TRUE , compile_type , cctx ) == FAIL ) <nl> { <nl> func_ptr_unref ( ufunc ); <nl> + if ( lvar != NULL ) <nl> + // Now the local variable can ' t be used . <nl> + * lvar -> lv_name = '/'; // impossible value <nl> goto theend ; <nl> } <nl> mmm src / version . c <nl> ppp src / version . c <nl> compile_nested_function ( exarg_T * eap , cctx_T * cctx , garray_T * lines_to_free ) <nl> int r = FAIL ; <nl> compiletype_T compile_type ; <nl> isn_T * funcref_isn = NULL ; <nl> + lvar_T * lvar = NULL ; <nl>  <nl> if ( eap -> forceit ) <nl> { <nl> compile_nested_function ( exarg_T * eap , cctx_T * cctx , garray_T * lines_to_free ) <nl> else <nl> { <nl> // Define a local variable for the function reference . <nl> - lvar_T * lvar = reserve_local ( cctx , func_name , name_end - name_start , <nl> + lvar = reserve_local ( cctx , func_name , name_end - name_start , <nl> TRUE , ufunc -> uf_func_type ); <nl> - <nl> if ( lvar == NULL ) <nl> goto theend ; <nl> if ( generate_FUNCREF ( cctx , ufunc , & funcref_isn ) == FAIL ) <nl> compile_nested_function ( exarg_T * eap , cctx_T * cctx , garray_T * lines_to_free ) <nl> && compile_def_function ( ufunc , TRUE , compile_type , cctx ) == FAIL ) <nl> { <nl> func_ptr_unref ( ufunc ); <nl> + if ( lvar != NULL ) <nl> + // Now the local variable can ' t be used . <nl> + * lvar -> lv_name = '/'; // impossible value <nl> goto theend ; <nl> } <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 221 , <nl> /**/ <nl> 220 , <nl> /**/
mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> getcmdline_int ( <nl> # endif <nl> expand_T xpc ; <nl> long * b_im_ptr = NULL ; <nl> + buf_T * b_im_ptr_buf = NULL ; // buffer where b_im_ptr is valid <nl> cmdline_info_T save_ccline ; <nl> int did_save_ccline = FALSE ; <nl> int cmdline_type ; <nl> getcmdline_int ( <nl> b_im_ptr = & curbuf -> b_p_iminsert ; <nl> else <nl> b_im_ptr = & curbuf -> b_p_imsearch ; <nl> + b_im_ptr_buf = curbuf ; <nl> if (* b_im_ptr == B_IMODE_LMAP ) <nl> State |= MODE_LANGMAP ; <nl> # ifdef HAVE_INPUT_METHOD <nl> getcmdline_int ( <nl> goto cmdline_not_changed ; <nl>  <nl> case Ctrl_HAT : <nl> - cmdline_toggle_langmap ( b_im_ptr ); <nl> + cmdline_toggle_langmap ( <nl> + buf_valid ( b_im_ptr_buf ) ? b_im_ptr : NULL ); <nl> goto cmdline_not_changed ; <nl>  <nl> // case '@': only in very old vi <nl> returncmd : <nl> # endif <nl>  <nl> # ifdef HAVE_INPUT_METHOD <nl> - if ( b_im_ptr != NULL && * b_im_ptr != B_IMODE_LMAP ) <nl> + if ( b_im_ptr != NULL && buf_valid ( b_im_ptr_buf ) <nl> + && * b_im_ptr != B_IMODE_LMAP ) <nl> im_save_status ( b_im_ptr ); <nl> im_set_active ( FALSE ); <nl> # endifmmm src / version . c <nl> ppp src / version . c <nl> getcmdline_int ( <nl> # endif <nl> expand_T xpc ; <nl> long * b_im_ptr = NULL ; <nl> + buf_T * b_im_ptr_buf = NULL ; // buffer where b_im_ptr is valid <nl> cmdline_info_T save_ccline ; <nl> int did_save_ccline = FALSE ; <nl> int cmdline_type ; <nl> getcmdline_int ( <nl> b_im_ptr = & curbuf -> b_p_iminsert ; <nl> else <nl> b_im_ptr = & curbuf -> b_p_imsearch ; <nl> + b_im_ptr_buf = curbuf ; <nl> if (* b_im_ptr == B_IMODE_LMAP ) <nl> State |= MODE_LANGMAP ; <nl> # ifdef HAVE_INPUT_METHOD <nl> getcmdline_int ( <nl> goto cmdline_not_changed ; <nl>  <nl> case Ctrl_HAT : <nl> - cmdline_toggle_langmap ( b_im_ptr ); <nl> + cmdline_toggle_langmap ( <nl> + buf_valid ( b_im_ptr_buf ) ? b_im_ptr : NULL ); <nl> goto cmdline_not_changed ; <nl>  <nl> // case '@': only in very old vi <nl> returncmd : <nl> # endif <nl>  <nl> # ifdef HAVE_INPUT_METHOD <nl> - if ( b_im_ptr != NULL && * b_im_ptr != B_IMODE_LMAP ) <nl> + if ( b_im_ptr != NULL && buf_valid ( b_im_ptr_buf ) <nl> + && * b_im_ptr != B_IMODE_LMAP ) <nl> im_save_status ( b_im_ptr ); <nl> im_set_active ( FALSE ); <nl> # endif <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 490 , <nl> /**/ <nl> 489 , <nl> /**/
mmm src / register . c <nl> ppp src / register . c <nl> do_put ( <nl> ptr += yanklen ; <nl>  <nl> // insert block ' s trailing spaces only if there ' s text behind <nl> - if (( j < count - 1 || ! shortline ) && spaces ) <nl> + if (( j < count - 1 || ! shortline ) && spaces > 0 ) <nl> { <nl> vim_memset ( ptr , ' ', ( size_t ) spaces ); <nl> ptr += spaces ; <nl> error : <nl> msgmore ( nr_lines ); <nl> curwin -> w_set_curswant = TRUE ; <nl>  <nl> + // Make sure the cursor is not after the NUL . <nl> + int len = ( int ) STRLEN ( ml_get_curline ()); <nl> + if ( curwin -> w_cursor . col > len ) <nl> + { <nl> + if ( cur_ve_flags == VE_ALL ) <nl> + curwin -> w_cursor . coladd = curwin -> w_cursor . col - len ; <nl> + curwin -> w_cursor . col = len ; <nl> + } <nl> + <nl> end : <nl> if ( cmdmod . cmod_flags & CMOD_LOCKMARKS ) <nl> {mmm src / version . c <nl> ppp src / version . c <nl> do_put ( <nl> ptr += yanklen ; <nl>  <nl> // insert block ' s trailing spaces only if there ' s text behind <nl> - if (( j < count - 1 || ! shortline ) && spaces ) <nl> + if (( j < count - 1 || ! shortline ) && spaces > 0 ) <nl> { <nl> vim_memset ( ptr , ' ', ( size_t ) spaces ); <nl> ptr += spaces ; <nl> error : <nl> msgmore ( nr_lines ); <nl> curwin -> w_set_curswant = TRUE ; <nl>  <nl> + // Make sure the cursor is not after the NUL . <nl> + int len = ( int ) STRLEN ( ml_get_curline ()); <nl> + if ( curwin -> w_cursor . col > len ) <nl> + { <nl> + if ( cur_ve_flags == VE_ALL ) <nl> + curwin -> w_cursor . coladd = curwin -> w_cursor . col - len ; <nl> + curwin -> w_cursor . col = len ; <nl> + } <nl> + <nl> end : <nl> if ( cmdmod . cmod_flags & CMOD_LOCKMARKS ) <nl> { <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1376 , <nl> /**/ <nl> 1375 , <nl> /**/
mmm src / typval . c <nl> ppp src / typval . c <nl> eval_string ( char_u ** arg , typval_T * rettv , int evaluate , int interpolate ) <nl> // to 9 characters ( 6 for the char and 3 for a modifier ): <nl> // reserve space for 5 extra . <nl> if (* p == '<') <nl> + { <nl> + int modifiers = 0 ; <nl> + int flags = FSK_KEYCODE | FSK_IN_STRING ; <nl> + <nl> extra += 5 ; <nl> + <nl> + // Skip to the '>' to avoid using '{' inside for string <nl> + // interpolation . <nl> + if ( p [ 1 ] != '*') <nl> + flags |= FSK_SIMPLIFY ; <nl> + if ( find_special_key (& p , & modifiers , flags , NULL ) != 0 ) <nl> + -- p ; // leave " p " on the ">" <nl> + } <nl> } <nl> else if ( interpolate && (* p == '{' || * p == '}')) <nl> {mmm src / version . c <nl> ppp src / version . c <nl> eval_string ( char_u ** arg , typval_T * rettv , int evaluate , int interpolate ) <nl> // to 9 characters ( 6 for the char and 3 for a modifier ): <nl> // reserve space for 5 extra . <nl> if (* p == '<') <nl> + { <nl> + int modifiers = 0 ; <nl> + int flags = FSK_KEYCODE | FSK_IN_STRING ; <nl> + <nl> extra += 5 ; <nl> + <nl> + // Skip to the '>' to avoid using '{' inside for string <nl> + // interpolation . <nl> + if ( p [ 1 ] != '*') <nl> + flags |= FSK_SIMPLIFY ; <nl> + if ( find_special_key (& p , & modifiers , flags , NULL ) != 0 ) <nl> + -- p ; // leave " p " on the ">" <nl> + } <nl> } <nl> else if ( interpolate && (* p == '{' || * p == '}')) <nl> { <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 104 , <nl> /**/ <nl> 103 , <nl> /**/
mmm src / normal . c <nl> ppp src / normal . c <nl> nv_scroll ( cmdarg_T * cap ) <nl> { <nl> ( void ) hasFolding ( curwin -> w_cursor . lnum , <nl> & curwin -> w_cursor . lnum , NULL ); <nl> - -- curwin -> w_cursor . lnum ; <nl> + if ( curwin -> w_cursor . lnum > curwin -> w_topline ) <nl> + -- curwin -> w_cursor . lnum ; <nl> } <nl> } <nl> elsemmm src / version . c <nl> ppp src / version . c <nl> nv_scroll ( cmdarg_T * cap ) <nl> { <nl> ( void ) hasFolding ( curwin -> w_cursor . lnum , <nl> & curwin -> w_cursor . lnum , NULL ); <nl> - -- curwin -> w_cursor . lnum ; <nl> + if ( curwin -> w_cursor . lnum > curwin -> w_topline ) <nl> + -- curwin -> w_cursor . lnum ; <nl> } <nl> } <nl> else <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1189 , <nl> /**/ <nl> 1188 , <nl> /**/
mmm src / term . c <nl> ppp src / term . c <nl> check_termcode ( <nl> if (* tp == ESC && ! p_ek && ( State & MODE_INSERT )) <nl> continue ; <nl>  <nl> + tp [ len ] = NUL ; <nl> key_name [ 0 ] = NUL ; // no key name found yet <nl> key_name [ 1 ] = NUL ; // no key name found yet <nl> modifiers = 0 ; // no modifiers yetmmm src / version . c <nl> ppp src / version . c <nl> check_termcode ( <nl> if (* tp == ESC && ! p_ek && ( State & MODE_INSERT )) <nl> continue ; <nl>  <nl> + tp [ len ] = NUL ; <nl> key_name [ 0 ] = NUL ; // no key name found yet <nl> key_name [ 1 ] = NUL ; // no key name found yet <nl> modifiers = 0 ; // no modifiers yet <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 18 , <nl> /**/ <nl> 17 , <nl> /**/
mmm src / spell . c <nl> ppp src / spell . c <nl> spell_move_to ( <nl> char_u * line ; <nl> char_u * p ; <nl> char_u * endp ; <nl> - hlf_T attr ; <nl> + hlf_T attr = 0 ; <nl> int len ; <nl> # ifdef FEAT_SYN_HL <nl> int has_syntax = syntax_present ( wp ); <nl> spell_move_to ( <nl>  <nl> while (! got_int ) <nl> { <nl> + int empty_line ; <nl> + <nl> line = ml_get_buf ( wp -> w_buffer , lnum , FALSE ); <nl>  <nl> len = ( int ) STRLEN ( line ); <nl> spell_move_to ( <nl> } <nl>  <nl> // Copy the line into " buf " and append the start of the next line if <nl> - // possible . <nl> + // possible . Note : this ml_get_buf () may make " line " invalid , check <nl> + // for empty line first . <nl> + empty_line = * skipwhite ( line ) == NUL ; <nl> STRCPY ( buf , line ); <nl> if ( lnum < wp -> w_buffer -> b_ml . ml_line_count ) <nl> spell_cat_line ( buf + STRLEN ( buf ), <nl> spell_move_to ( <nl> -- capcol ; <nl>  <nl> // But after empty line check first word in next line <nl> - if (* skipwhite ( line ) == NUL ) <nl> + if ( empty_line ) <nl> capcol = 0 ; <nl> } <nl> mmm src / version . c <nl> ppp src / version . c <nl> spell_move_to ( <nl> char_u * line ; <nl> char_u * p ; <nl> char_u * endp ; <nl> - hlf_T attr ; <nl> + hlf_T attr = 0 ; <nl> int len ; <nl> # ifdef FEAT_SYN_HL <nl> int has_syntax = syntax_present ( wp ); <nl> spell_move_to ( <nl>  <nl> while (! got_int ) <nl> { <nl> + int empty_line ; <nl> + <nl> line = ml_get_buf ( wp -> w_buffer , lnum , FALSE ); <nl>  <nl> len = ( int ) STRLEN ( line ); <nl> spell_move_to ( <nl> } <nl>  <nl> // Copy the line into " buf " and append the start of the next line if <nl> - // possible . <nl> + // possible . Note : this ml_get_buf () may make " line " invalid , check <nl> + // for empty line first . <nl> + empty_line = * skipwhite ( line ) == NUL ; <nl> STRCPY ( buf , line ); <nl> if ( lnum < wp -> w_buffer -> b_ml . ml_line_count ) <nl> spell_cat_line ( buf + STRLEN ( buf ), <nl> spell_move_to ( <nl> -- capcol ; <nl>  <nl> // But after empty line check first word in next line <nl> - if (* skipwhite ( line ) == NUL ) <nl> + if ( empty_line ) <nl> capcol = 0 ; <nl> } <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5072 , <nl> /**/ <nl> 5071 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4979 , <nl> /**/ <nl> 4978 , <nl> /**/mmm src / window . c <nl> ppp src / window . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4979 , <nl> /**/ <nl> 4978 , <nl> /**/ <nl> wingotofile : <nl> CHECK_CMDWIN ; <nl> if (( len = find_ident_under_cursor (& ptr , FIND_IDENT )) == 0 ) <nl> break ; <nl> + <nl> + // Make a copy , if the line was changed it will be freed . <nl> + ptr = vim_strnsave ( ptr , len ); <nl> + if ( ptr == NULL ) <nl> + break ; <nl> + <nl> find_pattern_in_path ( ptr , 0 , len , TRUE , <nl> Prenum == 0 ? TRUE : FALSE , type , <nl> Prenum1 , ACTION_SPLIT , ( linenr_T ) 1 , ( linenr_T ) MAXLNUM ); <nl> + vim_free ( ptr ); <nl> curwin -> w_set_curswant = TRUE ; <nl> break ; <nl> # endif
mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> getcmdline ( firstc , count , indent ) <nl> */ <nl> for (;;) <nl> { <nl> + redir_off = TRUE ; /* Don ' t redirect the typed command . <nl> + Repeated , because a ": redir " inside <nl> + completion may switch it on . */ <nl> # ifdef USE_ON_FLY_SCROLL <nl> dont_scroll = FALSE ; /* allow scrolling here */ <nl> # endifmmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> getcmdline ( firstc , count , indent ) <nl> */ <nl> for (;;) <nl> { <nl> + redir_off = TRUE ; /* Don ' t redirect the typed command . <nl> + Repeated , because a ": redir " inside <nl> + completion may switch it on . */ <nl> # ifdef USE_ON_FLY_SCROLL <nl> dont_scroll = FALSE ; /* allow scrolling here */ <nl> # endif <nl> ex_redir ( eap ) <nl> else <nl> EMSG2 ( _ ( e_invarg2 ), eap -> arg ); <nl> } <nl> + <nl> + /* Make sure redirection is not off . Can happen for cmdline completion <nl> + * that indirectly invokes a command to catch its output . */ <nl> + if ( redir_fd != NULL <nl> +# ifdef FEAT_EVAL <nl> + || redir_reg || redir_vname <nl> +# endif <nl> + ) <nl> + redir_off = FALSE ; <nl> } <nl>  <nl> /*mmm src / version . c <nl> ppp src / version . c <nl> getcmdline ( firstc , count , indent ) <nl> */ <nl> for (;;) <nl> { <nl> + redir_off = TRUE ; /* Don ' t redirect the typed command . <nl> + Repeated , because a ": redir " inside <nl> + completion may switch it on . */ <nl> # ifdef USE_ON_FLY_SCROLL <nl> dont_scroll = FALSE ; /* allow scrolling here */ <nl> # endif <nl> ex_redir ( eap ) <nl> else <nl> EMSG2 ( _ ( e_invarg2 ), eap -> arg ); <nl> } <nl> + <nl> + /* Make sure redirection is not off . Can happen for cmdline completion <nl> + * that indirectly invokes a command to catch its output . */ <nl> + if ( redir_fd != NULL <nl> +# ifdef FEAT_EVAL <nl> + || redir_reg || redir_vname <nl> +# endif <nl> + ) <nl> + redir_off = FALSE ; <nl> } <nl>  <nl> /* <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 98 , <nl> /**/ <nl> 97 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5016 , <nl> /**/ <nl> 5015 , <nl> /**/mmm src / register . c <nl> ppp src / register . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5016 , <nl> /**/ <nl> 5015 , <nl> /**/ <nl> error : <nl> len = STRLEN ( y_array [ y_size - 1 ]); <nl> col = ( colnr_T ) len - lendiff ; <nl> if ( col > 1 ) <nl> - curbuf -> b_op_end . col = col - 1 <nl> - - mb_head_off ( y_array [ y_size - 1 ], <nl> + { <nl> + curbuf -> b_op_end . col = col - 1 ; <nl> + if ( len > 0 ) <nl> + curbuf -> b_op_end . col -= mb_head_off ( y_array [ y_size - 1 ], <nl> y_array [ y_size - 1 ] + len - 1 ); <nl> + } <nl> else <nl> curbuf -> b_op_end . col = 0 ; <nl> 
mmm src / scriptfile . c <nl> ppp src / scriptfile . c <nl> get_one_sourceline ( source_cookie_T * sp ) <nl> break ; // all the lines are processed <nl> ga_concat (& ga , (( char_u **) sp -> buflines . ga_data )[ sp -> buf_lnum ]); <nl> sp -> buf_lnum ++; <nl> + if ( ga_grow (& ga , 1 ) == FAIL ) <nl> + break ; <nl> buf = ( char_u *) ga . ga_data ; <nl> + buf [ ga . ga_len ++] = NUL ; <nl> } <nl> else <nl> {mmm src / version . c <nl> ppp src / version . c <nl> get_one_sourceline ( source_cookie_T * sp ) <nl> break ; // all the lines are processed <nl> ga_concat (& ga , (( char_u **) sp -> buflines . ga_data )[ sp -> buf_lnum ]); <nl> sp -> buf_lnum ++; <nl> + if ( ga_grow (& ga , 1 ) == FAIL ) <nl> + break ; <nl> buf = ( char_u *) ga . ga_data ; <nl> + buf [ ga . ga_len ++] = NUL ; <nl> } <nl> else <nl> { <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4647 , <nl> /**/ <nl> 4646 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3625 , <nl> /**/ <nl> 3624 , <nl> /**/mmm src / cindent . c <nl> ppp src / cindent . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3625 , <nl> /**/ <nl> 3624 , <nl> /**/ <nl> get_baseclass_amount ( int col ) <nl> static pos_T * <nl> find_start_brace ( void ) // XXX <nl> { <nl> - pos_T cursor_save ; <nl> - pos_T * trypos ; <nl> - pos_T * pos ; <nl> - static pos_T pos_copy ; <nl> + pos_T cursor_save ; <nl> + pos_T * trypos ; <nl> + pos_T * pos ; <nl> + static pos_T pos_copy ; <nl>  <nl> cursor_save = curwin -> w_cursor ; <nl> while (( trypos = findmatchlimit ( NULL , '{', FM_BLOCKSTOP , 0 )) != NULL ) <nl> find_start_brace ( void ) // XXX <nl> && ( pos = ind_find_start_CORS ( NULL )) == NULL ) // XXX <nl> break ; <nl> if ( pos != NULL ) <nl> - curwin -> w_cursor . lnum = pos -> lnum ; <nl> + curwin -> w_cursor = * pos ; <nl> } <nl> curwin -> w_cursor = cursor_save ; <nl> return trypos ;
mmm src / textobject . c <nl> ppp src / textobject . c <nl> current_quote ( <nl>  <nl> // Find out if we have a quote in the selection . <nl> while ( i <= col_end ) <nl> + { <nl> + // check for going over the end of the line , which can happen if <nl> + // the line was changed after the Visual area was selected . <nl> + if ( line [ i ] == NUL ) <nl> + break ; <nl> if ( line [ i ++] == quotechar ) <nl> { <nl> selected_quote = TRUE ; <nl> break ; <nl> } <nl> + } <nl> } <nl>  <nl> if (! vis_empty && line [ col_start ] == quotechar )mmm src / version . c <nl> ppp src / version . c <nl> current_quote ( <nl>  <nl> // Find out if we have a quote in the selection . <nl> while ( i <= col_end ) <nl> + { <nl> + // check for going over the end of the line , which can happen if <nl> + // the line was changed after the Visual area was selected . <nl> + if ( line [ i ] == NUL ) <nl> + break ; <nl> if ( line [ i ++] == quotechar ) <nl> { <nl> selected_quote = TRUE ; <nl> break ; <nl> } <nl> + } <nl> } <nl>  <nl> if (! vis_empty && line [ col_start ] == quotechar ) <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5120 , <nl> /**/ <nl> 5119 , <nl> /**/
mmm src / ops . c <nl> ppp src / ops . c <nl> op_yank ( oap , deleting , mess ) <nl> /* Copy the text from register 0 to the clipboard register . */ <nl> copy_yank_reg (&( y_regs [ PLUS_REGISTER ])); <nl>  <nl> - /* No need to copy to * register upon ' unnamed ' now - see below */ <nl> clip_own_selection (& clip_plus ); <nl> clip_gen_set_selection (& clip_plus ); <nl> - if (! clip_isautosel () && ! did_star ) <nl> + if (! clip_isautosel () && ! did_star && curr == &( y_regs [ PLUS_REGISTER ])) <nl> { <nl> copy_yank_reg (&( y_regs [ STAR_REGISTER ])); <nl> clip_own_selection (& clip_star );mmm src / version . c <nl> ppp src / version . c <nl> op_yank ( oap , deleting , mess ) <nl> /* Copy the text from register 0 to the clipboard register . */ <nl> copy_yank_reg (&( y_regs [ PLUS_REGISTER ])); <nl>  <nl> - /* No need to copy to * register upon ' unnamed ' now - see below */ <nl> clip_own_selection (& clip_plus ); <nl> clip_gen_set_selection (& clip_plus ); <nl> - if (! clip_isautosel () && ! did_star ) <nl> + if (! clip_isautosel () && ! did_star && curr == &( y_regs [ PLUS_REGISTER ])) <nl> { <nl> copy_yank_reg (&( y_regs [ STAR_REGISTER ])); <nl> clip_own_selection (& clip_star ); <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 151 , <nl> /**/ <nl> 150 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4397 , <nl> /**/ <nl> 4396 , <nl> /**/mmm src / testing . c <nl> ppp src / testing . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4397 , <nl> /**/ <nl> 4396 , <nl> /**/ <nl> ga_concat_shorten_esc ( garray_T * gap , char_u * str ) <nl> { <nl> same_len = 1 ; <nl> s = p ; <nl> - c = mb_ptr2char_adv (& s ); <nl> + c = mb_cptr2char_adv (& s ); <nl> clen = s - p ; <nl> while (* s != NUL && c == mb_ptr2char ( s )) <nl> {
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3489 , <nl> /**/ <nl> 3488 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3489 , <nl> /**/ <nl> 3488 , <nl> /**/ <nl> get_address ( <nl>  <nl> // When '/' or '?' follows another address , start from <nl> // there . <nl> - if ( lnum != MAXLNUM ) <nl> - curwin -> w_cursor . lnum = lnum ; <nl> + if ( lnum > 0 && lnum != MAXLNUM ) <nl> + curwin -> w_cursor . lnum = <nl> + lnum > curbuf -> b_ml . ml_line_count <nl> + ? curbuf -> b_ml . ml_line_count : lnum ; <nl>  <nl> // Start a forward search at the end of the line ( unless <nl> // before the first line ).
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3428 , <nl> /**/ <nl> 3427 , <nl> /**/mmm src / normal . c <nl> ppp src / normal . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3428 , <nl> /**/ <nl> 3427 , <nl> /**/ <nl> nv_replace ( cmdarg_T * cap ) <nl> { <nl> /* <nl> * Get ptr again , because u_save and / or showmatch () will have <nl> - * released the line . At the same time we let know that the <nl> - * line will be changed . <nl> + * released the line . This may also happen in ins_copychar (). <nl> + * At the same time we let know that the line will be changed . <nl> */ <nl> - ptr = ml_get_buf ( curbuf , curwin -> w_cursor . lnum , TRUE ); <nl> if ( cap -> nchar == Ctrl_E || cap -> nchar == Ctrl_Y ) <nl> { <nl> int c = ins_copychar ( curwin -> w_cursor . lnum <nl> + ( cap -> nchar == Ctrl_Y ? - 1 : 1 )); <nl> + <nl> + ptr = ml_get_buf ( curbuf , curwin -> w_cursor . lnum , TRUE ); <nl> if ( c != NUL ) <nl> ptr [ curwin -> w_cursor . col ] = c ; <nl> } <nl> else <nl> + { <nl> + ptr = ml_get_buf ( curbuf , curwin -> w_cursor . lnum , TRUE ); <nl> ptr [ curwin -> w_cursor . col ] = cap -> nchar ; <nl> + } <nl> if ( p_sm && msg_silent == 0 ) <nl> showmatch ( cap -> nchar ); <nl> ++ curwin -> w_cursor . col ;
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 360 , <nl> /**/ <nl> 359 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 360 , <nl> /**/ <nl> 359 , <nl> /**/ <nl> do_cmdline ( <nl>  <nl> // Check for the next breakpoint at or after the ": while " <nl> // or ": for ". <nl> - if ( breakpoint != NULL ) <nl> + if ( breakpoint != NULL && lines_ga . ga_len > current_line ) <nl> { <nl> * breakpoint = dbg_find_breakpoint ( <nl> getline_equal ( fgetline , cookie , getsourceline ),
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 765 , <nl> /**/ <nl> 764 , <nl> /**/mmm src / register . c <nl> ppp src / register . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 765 , <nl> /**/ <nl> 764 , <nl> /**/ <nl> do_put ( <nl> // adjust '] mark <nl> curbuf -> b_op_end . lnum = curwin -> w_cursor . lnum - 1 ; <nl> curbuf -> b_op_end . col = bd . textcol + totlen - 1 ; <nl> + if ( curbuf -> b_op_end . col < 0 ) <nl> + curbuf -> b_op_end . col = 0 ; <nl> curbuf -> b_op_end . coladd = 0 ; <nl> if ( flags & PUT_CURSEND ) <nl> {
mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> ex_normal ( eap ) <nl> tasave_T tabuf ; <nl> int save_insertmode = p_im ; <nl> int save_finish_op = finish_op ; <nl> + int save_opcount = opcount ; <nl> # ifdef FEAT_MBYTE <nl> char_u * arg = NULL ; <nl> int l ; <nl> ex_normal ( eap ) <nl> restart_edit = save_restart_edit ; <nl> p_im = save_insertmode ; <nl> finish_op = save_finish_op ; <nl> + opcount = save_opcount ; <nl> msg_didout |= save_msg_didout ; /* don ' t reset msg_didout now */ <nl>  <nl> /* Restore the state ( needed when called from a function executed formmm src / globals . h <nl> ppp src / globals . h <nl> ex_normal ( eap ) <nl> tasave_T tabuf ; <nl> int save_insertmode = p_im ; <nl> int save_finish_op = finish_op ; <nl> + int save_opcount = opcount ; <nl> # ifdef FEAT_MBYTE <nl> char_u * arg = NULL ; <nl> int l ; <nl> ex_normal ( eap ) <nl> restart_edit = save_restart_edit ; <nl> p_im = save_insertmode ; <nl> finish_op = save_finish_op ; <nl> + opcount = save_opcount ; <nl> msg_didout |= save_msg_didout ; /* don ' t reset msg_didout now */ <nl>  <nl> /* Restore the state ( needed when called from a function executed for <nl> EXTERN int State INIT (= NORMAL ); /* This is the current state of the <nl> * command interpreter . */ <nl>  <nl> EXTERN int finish_op INIT (= FALSE );/* TRUE while an operator is pending */ <nl> + EXTERN int opcount INIT (= 0 ); /* count for pending operator */ <nl>  <nl> /* <nl> * ex mode ( Q ) statemmm src / normal . c <nl> ppp src / normal . c <nl> ex_normal ( eap ) <nl> tasave_T tabuf ; <nl> int save_insertmode = p_im ; <nl> int save_finish_op = finish_op ; <nl> + int save_opcount = opcount ; <nl> # ifdef FEAT_MBYTE <nl> char_u * arg = NULL ; <nl> int l ; <nl> ex_normal ( eap ) <nl> restart_edit = save_restart_edit ; <nl> p_im = save_insertmode ; <nl> finish_op = save_finish_op ; <nl> + opcount = save_opcount ; <nl> msg_didout |= save_msg_didout ; /* don ' t reset msg_didout now */ <nl>  <nl> /* Restore the state ( needed when called from a function executed for <nl> EXTERN int State INIT (= NORMAL ); /* This is the current state of the <nl> * command interpreter . */ <nl>  <nl> EXTERN int finish_op INIT (= FALSE );/* TRUE while an operator is pending */ <nl> + EXTERN int opcount INIT (= 0 ); /* count for pending operator */ <nl>  <nl> /* <nl> * ex mode ( Q ) state <nl> normal_cmd ( oap , toplevel ) <nl> oparg_T * oap ; <nl> int toplevel ; /* TRUE when called from main () */ <nl> { <nl> - static long opcount = 0 ; /* ca . opcount saved here */ <nl> cmdarg_T ca ; /* command arguments */ <nl> int c ; <nl> int ctrl_w = FALSE ; /* got CTRL - W command */mmm src / version . c <nl> ppp src / version . c <nl> ex_normal ( eap ) <nl> tasave_T tabuf ; <nl> int save_insertmode = p_im ; <nl> int save_finish_op = finish_op ; <nl> + int save_opcount = opcount ; <nl> # ifdef FEAT_MBYTE <nl> char_u * arg = NULL ; <nl> int l ; <nl> ex_normal ( eap ) <nl> restart_edit = save_restart_edit ; <nl> p_im = save_insertmode ; <nl> finish_op = save_finish_op ; <nl> + opcount = save_opcount ; <nl> msg_didout |= save_msg_didout ; /* don ' t reset msg_didout now */ <nl>  <nl> /* Restore the state ( needed when called from a function executed for <nl> EXTERN int State INIT (= NORMAL ); /* This is the current state of the <nl> * command interpreter . */ <nl>  <nl> EXTERN int finish_op INIT (= FALSE );/* TRUE while an operator is pending */ <nl> + EXTERN int opcount INIT (= 0 ); /* count for pending operator */ <nl>  <nl> /* <nl> * ex mode ( Q ) state <nl> normal_cmd ( oap , toplevel ) <nl> oparg_T * oap ; <nl> int toplevel ; /* TRUE when called from main () */ <nl> { <nl> - static long opcount = 0 ; /* ca . opcount saved here */ <nl> cmdarg_T ca ; /* command arguments */ <nl> int c ; <nl> int ctrl_w = FALSE ; /* got CTRL - W command */ <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 22 , <nl> /**/ <nl> 21 , <nl> /**/
mmm src / normal . c <nl> ppp src / normal . c <nl> get_visual_text ( <nl> } <nl> if (** pp == NUL ) <nl> * lenp = 0 ; <nl> - if ( has_mbyte && * lenp > 0 ) <nl> - // Correct the length to include all bytes of the last character . <nl> - * lenp += (* mb_ptr2len )(* pp + (* lenp - 1 )) - 1 ; <nl> + if (* lenp > 0 ) <nl> + { <nl> + if ( has_mbyte ) <nl> + // Correct the length to include all bytes of the last <nl> + // character . <nl> + * lenp += (* mb_ptr2len )(* pp + (* lenp - 1 )) - 1 ; <nl> + else if ((* pp )[* lenp - 1 ] == NUL ) <nl> + // Do not include a trailing NUL . <nl> + * lenp -= 1 ; <nl> + } <nl> } <nl> reset_VIsual_and_resel (); <nl> return OK ;mmm src / version . c <nl> ppp src / version . c <nl> get_visual_text ( <nl> } <nl> if (** pp == NUL ) <nl> * lenp = 0 ; <nl> - if ( has_mbyte && * lenp > 0 ) <nl> - // Correct the length to include all bytes of the last character . <nl> - * lenp += (* mb_ptr2len )(* pp + (* lenp - 1 )) - 1 ; <nl> + if (* lenp > 0 ) <nl> + { <nl> + if ( has_mbyte ) <nl> + // Correct the length to include all bytes of the last <nl> + // character . <nl> + * lenp += (* mb_ptr2len )(* pp + (* lenp - 1 )) - 1 ; <nl> + else if ((* pp )[* lenp - 1 ] == NUL ) <nl> + // Do not include a trailing NUL . <nl> + * lenp -= 1 ; <nl> + } <nl> } <nl> reset_VIsual_and_resel (); <nl> return OK ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4956 , <nl> /**/ <nl> 4955 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 322 , <nl> /**/ <nl> 321 , <nl> /**/mmm src / spellfile . c <nl> ppp src / spellfile . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 322 , <nl> /**/ <nl> 321 , <nl> /**/ <nl> spell_read_tree ( <nl> len = get4c ( fd ); <nl> if ( len < 0 ) <nl> return SP_TRUNCERROR ; <nl> + if ( len >= 0x3ffffff ) <nl> + /* Invalid length , multiply with sizeof ( int ) would overflow . */ <nl> + return SP_FORMERROR ; <nl> if ( len > 0 ) <nl> { <nl> /* Allocate the byte array . */
mmm src / eval . c <nl> ppp src / eval . c <nl> do_string_sub ( <nl> * - The text after the match . <nl> */ <nl> sublen = vim_regsub (& regmatch , sub , expr , tail , 0 , REGSUB_MAGIC ); <nl> + if ( sublen <= 0 ) <nl> + { <nl> + ga_clear (& ga ); <nl> + break ; <nl> + } <nl> if ( ga_grow (& ga , ( int )(( end - tail ) + sublen - <nl> ( regmatch . endp [ 0 ] - regmatch . startp [ 0 ]))) == FAIL ) <nl> {mmm src / version . c <nl> ppp src / version . c <nl> do_string_sub ( <nl> * - The text after the match . <nl> */ <nl> sublen = vim_regsub (& regmatch , sub , expr , tail , 0 , REGSUB_MAGIC ); <nl> + if ( sublen <= 0 ) <nl> + { <nl> + ga_clear (& ga ); <nl> + break ; <nl> + } <nl> if ( ga_grow (& ga , ( int )(( end - tail ) + sublen - <nl> ( regmatch . endp [ 0 ] - regmatch . startp [ 0 ]))) == FAIL ) <nl> { <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1145 , <nl> /**/ <nl> 1144 , <nl> /**/
mmm src / window . c <nl> ppp src / window . c <nl> win_close ( win_T * win , int free_buf ) <nl> */ <nl> if ( wp -> w_buffer != curbuf ) <nl> { <nl> + reset_VIsual_and_resel (); // stop Visual mode <nl> + <nl> other_buffer = TRUE ; <nl> win -> w_closing = TRUE ; <nl> apply_autocmds ( EVENT_BUFLEAVE , NULL , NULL , FALSE , curbuf );mmm src / version . c <nl> ppp src / version . c <nl> win_close ( win_T * win , int free_buf ) <nl> */ <nl> if ( wp -> w_buffer != curbuf ) <nl> { <nl> + reset_VIsual_and_resel (); // stop Visual mode <nl> + <nl> other_buffer = TRUE ; <nl> win -> w_closing = TRUE ; <nl> apply_autocmds ( EVENT_BUFLEAVE , NULL , NULL , FALSE , curbuf ); <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 17 , <nl> /**/ <nl> 16 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 377 , <nl> /**/ <nl> 376 , <nl> /**/mmm src / undo . c <nl> ppp src / undo . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 377 , <nl> /**/ <nl> 376 , <nl> /**/ <nl> u_read_undo ( char_u * name , char_u * hash , char_u * orig_name ) <nl> linenr_T line_lnum ; <nl> colnr_T line_colnr ; <nl> linenr_T line_count ; <nl> - int num_head = 0 ; <nl> + long num_head = 0 ; <nl> long old_header_seq , new_header_seq , cur_header_seq ; <nl> long seq_last , seq_cur ; <nl> long last_save_nr = 0 ; <nl> u_read_undo ( char_u * name , char_u * hash , char_u * orig_name ) <nl> * When there are no headers uhp_table is NULL . */ <nl> if ( num_head > 0 ) <nl> { <nl> - uhp_table = ( u_header_T **) U_ALLOC_LINE ( <nl> + if ( num_head < LONG_MAX / ( long ) sizeof ( u_header_T *)) <nl> + uhp_table = ( u_header_T **) U_ALLOC_LINE ( <nl> num_head * sizeof ( u_header_T *)); <nl> if ( uhp_table == NULL ) <nl> goto error ;
mmm src / regexp . c <nl> ppp src / regexp . c <nl> regmatch ( scan ) <nl> */ <nl> for (;;) <nl> { <nl> - /* Some patterns may cause a long time to match , even though they are not <nl> - * illegal . E . g ., "\([ a - z ]\+\)\+ Q ". Allow breaking them with CTRL - C . */ <nl> + /* Some patterns may take a long time to match , e . g ., "\([ a - z ]\+\)\+ Q ". <nl> + * Allow interrupting them with CTRL - C . */ <nl> fast_breakcheck (); <nl>  <nl> # ifdef DEBUGmmm src / regexp_nfa . c <nl> ppp src / regexp_nfa . c <nl> regmatch ( scan ) <nl> */ <nl> for (;;) <nl> { <nl> - /* Some patterns may cause a long time to match , even though they are not <nl> - * illegal . E . g ., "\([ a - z ]\+\)\+ Q ". Allow breaking them with CTRL - C . */ <nl> + /* Some patterns may take a long time to match , e . g ., "\([ a - z ]\+\)\+ Q ". <nl> + * Allow interrupting them with CTRL - C . */ <nl> fast_breakcheck (); <nl>  <nl> # ifdef DEBUG <nl> nfa_regmatch ( prog , start , submatch , m ) <nl> return FALSE ; <nl> } <nl> # endif <nl> + /* Some patterns may take a long time to match , especially when using <nl> + * recursive_regmatch (). Allow interrupting them with CTRL - C . */ <nl> + fast_breakcheck (); <nl> + if ( got_int ) <nl> + return FALSE ; <nl> + <nl> nfa_match = FALSE ; <nl>  <nl> /* Allocate memory for the lists of nodes . */mmm src / version . c <nl> ppp src / version . c <nl> regmatch ( scan ) <nl> */ <nl> for (;;) <nl> { <nl> - /* Some patterns may cause a long time to match , even though they are not <nl> - * illegal . E . g ., "\([ a - z ]\+\)\+ Q ". Allow breaking them with CTRL - C . */ <nl> + /* Some patterns may take a long time to match , e . g ., "\([ a - z ]\+\)\+ Q ". <nl> + * Allow interrupting them with CTRL - C . */ <nl> fast_breakcheck (); <nl>  <nl> # ifdef DEBUG <nl> nfa_regmatch ( prog , start , submatch , m ) <nl> return FALSE ; <nl> } <nl> # endif <nl> + /* Some patterns may take a long time to match , especially when using <nl> + * recursive_regmatch (). Allow interrupting them with CTRL - C . */ <nl> + fast_breakcheck (); <nl> + if ( got_int ) <nl> + return FALSE ; <nl> + <nl> nfa_match = FALSE ; <nl>  <nl> /* Allocate memory for the lists of nodes . */ <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 8 , <nl> /**/ <nl> 7 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5063 , <nl> /**/ <nl> 5062 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5063 , <nl> /**/ <nl> 5062 , <nl> /**/ <nl> theend : <nl> static void <nl> append_command ( char_u * cmd ) <nl> { <nl> - char_u * s = cmd ; <nl> - char_u * d ; <nl> + size_t len = STRLEN ( IObuff ); <nl> + char_u * s = cmd ; <nl> + char_u * d ; <nl>  <nl> + if ( len > IOSIZE - 100 ) <nl> + { <nl> + // Not enough space , truncate and put in "...". <nl> + d = IObuff + IOSIZE - 100 ; <nl> + d -= mb_head_off ( IObuff , d ); <nl> + STRCPY ( d , "..."); <nl> + } <nl> STRCAT ( IObuff , ": "); <nl> d = IObuff + STRLEN ( IObuff ); <nl> while (* s != NUL && d - IObuff + 5 < IOSIZE )
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4219 , <nl> /**/ <nl> 4218 , <nl> /**/mmm src / register . c <nl> ppp src / register . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4219 , <nl> /**/ <nl> 4218 , <nl> /**/ <nl> yank_copy_line ( struct block_def * bd , long y_idx , int exclude_trailing_space ) <nl> { <nl> int s = bd -> textlen + bd -> endspaces ; <nl>  <nl> - while ( VIM_ISWHITE (*( bd -> textstart + s - 1 )) && s > 0 ) <nl> + while ( s > 0 && VIM_ISWHITE (*( bd -> textstart + s - 1 ))) <nl> { <nl> s = s - (* mb_head_off )( bd -> textstart , bd -> textstart + s - 1 ) - 1 ; <nl> pnew --;
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 209 , <nl> /**/ <nl> 208 , <nl> /**/mmm src / if_python . c <nl> ppp src / if_python . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 209 , <nl> /**/ <nl> 208 , <nl> /**/ <nl> py_fix_cursor ( int lo , int hi , int extra ) <nl> curwin -> w_cursor . lnum = lo ; <nl> check_cursor (); <nl> } <nl> + else <nl> + check_cursor_col (); <nl> changed_cline_bef_curs (); <nl> } <nl> invalidate_botline (); <nl> SetBufferLine ( buf_T * buf , int n , PyObject * line , int * len_change ) <nl>  <nl> curbuf = savebuf ; <nl>  <nl> + /* Check that the cursor is not beyond the end of the line now . */ <nl> + if ( buf == curwin -> w_buffer ) <nl> + check_cursor_col (); <nl> + <nl> if ( PyErr_Occurred () || VimErrorCheck ()) <nl> return FAIL ; <nl> 
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 946 , <nl> /**/ <nl> 945 , <nl> /**/mmm src / term . c <nl> ppp src / term . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 946 , <nl> /**/ <nl> 945 , <nl> /**/ <nl> check_termcode ( max_offset , buf , bufsize , buflen ) <nl> * The final byte is ' R '. now it is only used for checking for <nl> * ambiguous - width character state . <nl> */ <nl> + p = tp [ 0 ] == CSI ? tp + 1 : tp + 2 ; <nl> if ((* T_CRV != NUL || * T_U7 != NUL ) <nl> && (( tp [ 0 ] == ESC && tp [ 1 ] == '[' && len >= 3 ) <nl> - || ( tp [ 0 ] == CSI && len >= 2 ))) <nl> + || ( tp [ 0 ] == CSI && len >= 2 )) <nl> + && ( VIM_ISDIGIT (* p ) || * p == '>' || * p == '?')) <nl> { <nl> j = 0 ; <nl> extra = 0 ; <nl> check_termcode ( max_offset , buf , bufsize , buflen ) <nl> && !( tp [ i ] >= '{' && tp [ i ] <= '~') <nl> && ! ASCII_ISALPHA ( tp [ i ]); ++ i ) <nl> if ( tp [ i ] == ';' && ++ j == 1 ) <nl> - extra = atoi (( char *) tp + i + 1 ); <nl> + extra = i + 1 ; <nl> if ( i == len ) <nl> return - 1 ; /* not enough characters */ <nl>  <nl> check_termcode ( max_offset , buf , bufsize , buflen ) <nl> # ifdef FEAT_AUTOCMD <nl> did_cursorhold = TRUE ; <nl> # endif <nl> + if ( extra > 0 ) <nl> + extra = atoi (( char *) tp + extra ); <nl> if ( extra == 2 ) <nl> aw = " single "; <nl> else if ( extra == 3 ) <nl> check_termcode ( max_offset , buf , bufsize , buflen ) <nl> /* rxvt sends its version number : " 20703 " is 2 . 7 . 3 . <nl> * Ignore it for when the user has set ' term ' to xterm , <nl> * even though it ' s an rxvt . */ <nl> + if ( extra > 0 ) <nl> + extra = atoi (( char *) tp + extra ); <nl> if ( extra > 20000 ) <nl> extra = 0 ; <nl> 
mmm src / scriptfile . c <nl> ppp src / scriptfile . c <nl> get_one_sourceline ( source_cookie_T * sp ) <nl> break ; <nl> buf = ( char_u *) ga . ga_data ; <nl> buf [ ga . ga_len ++] = NUL ; <nl> + len = ga . ga_len ; <nl> } <nl> else <nl> { <nl> get_one_sourceline ( source_cookie_T * sp ) <nl> if ( fgets (( char *) buf + ga . ga_len , ga . ga_maxlen - ga . ga_len , <nl> sp -> fp ) == NULL ) <nl> break ; <nl> + len = ga . ga_len + ( int ) STRLEN ( buf + ga . ga_len ); <nl> } <nl> - len = ga . ga_len + ( int ) STRLEN ( buf + ga . ga_len ); <nl> # ifdef USE_CRNL <nl> // Ignore a trailing CTRL - Z , when in Dos mode . Only recognize the <nl> // CTRL - Z by its own , or after a NL .mmm src / version . c <nl> ppp src / version . c <nl> get_one_sourceline ( source_cookie_T * sp ) <nl> break ; <nl> buf = ( char_u *) ga . ga_data ; <nl> buf [ ga . ga_len ++] = NUL ; <nl> + len = ga . ga_len ; <nl> } <nl> else <nl> { <nl> get_one_sourceline ( source_cookie_T * sp ) <nl> if ( fgets (( char *) buf + ga . ga_len , ga . ga_maxlen - ga . ga_len , <nl> sp -> fp ) == NULL ) <nl> break ; <nl> + len = ga . ga_len + ( int ) STRLEN ( buf + ga . ga_len ); <nl> } <nl> - len = ga . ga_len + ( int ) STRLEN ( buf + ga . ga_len ); <nl> # ifdef USE_CRNL <nl> // Ignore a trailing CTRL - Z , when in Dos mode . Only recognize the <nl> // CTRL - Z by its own , or after a NL . <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4974 , <nl> /**/ <nl> 4973 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3923 , <nl> /**/ <nl> 3922 , <nl> /**/mmm src / userfunc . c <nl> ppp src / userfunc . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3923 , <nl> /**/ <nl> 3922 , <nl> /**/ <nl> get_function_args ( <nl> if ( theline == NULL ) <nl> break ; <nl> vim_free (* line_to_free ); <nl> + if (* eap -> cmdlinep == * line_to_free ) <nl> + * eap -> cmdlinep = theline ; <nl> * line_to_free = theline ; <nl> whitep = ( char_u *)" "; <nl> p = skipwhite ( theline );
mmm src / regexp . c <nl> ppp src / regexp . c <nl> reg_match_visual ( void ) <nl> if ( lnum < top . lnum || lnum > bot . lnum ) <nl> return FALSE ; <nl>  <nl> + col = ( colnr_T )( rex . input - rex . line ); <nl> if ( mode == ' v ') <nl> { <nl> - col = ( colnr_T )( rex . input - rex . line ); <nl> if (( lnum == top . lnum && col < top . col ) <nl> || ( lnum == bot . lnum && col >= bot . col + (* p_sel != ' e '))) <nl> return FALSE ; <nl> reg_match_visual ( void ) <nl> end = end2 ; <nl> if ( top . col == MAXCOL || bot . col == MAXCOL || curswant == MAXCOL ) <nl> end = MAXCOL ; <nl> - cols = win_linetabsize ( wp , rex . line , ( colnr_T )( rex . input - rex . line )); <nl> + <nl> + // getvvcol () flushes rex . line , need to get it again <nl> + rex . line = reg_getline ( rex . lnum ); <nl> + rex . input = rex . line + col ; <nl> + <nl> + cols = win_linetabsize ( wp , rex . line , col ); <nl> if ( cols < start || cols > end - (* p_sel == ' e ')) <nl> return FALSE ; <nl> }mmm src / version . c <nl> ppp src / version . c <nl> reg_match_visual ( void ) <nl> if ( lnum < top . lnum || lnum > bot . lnum ) <nl> return FALSE ; <nl>  <nl> + col = ( colnr_T )( rex . input - rex . line ); <nl> if ( mode == ' v ') <nl> { <nl> - col = ( colnr_T )( rex . input - rex . line ); <nl> if (( lnum == top . lnum && col < top . col ) <nl> || ( lnum == bot . lnum && col >= bot . col + (* p_sel != ' e '))) <nl> return FALSE ; <nl> reg_match_visual ( void ) <nl> end = end2 ; <nl> if ( top . col == MAXCOL || bot . col == MAXCOL || curswant == MAXCOL ) <nl> end = MAXCOL ; <nl> - cols = win_linetabsize ( wp , rex . line , ( colnr_T )( rex . input - rex . line )); <nl> + <nl> + // getvvcol () flushes rex . line , need to get it again <nl> + rex . line = reg_getline ( rex . lnum ); <nl> + rex . input = rex . line + col ; <nl> + <nl> + cols = win_linetabsize ( wp , rex . line , col ); <nl> if ( cols < start || cols > end - (* p_sel == ' e ')) <nl> return FALSE ; <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3949 , <nl> /**/ <nl> 3948 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 352 , <nl> /**/ <nl> 351 , <nl> /**/mmm src / gui_w48 . c <nl> ppp src / gui_w48 . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 352 , <nl> /**/ <nl> 351 , <nl> /**/ <nl> _TextAreaWndProc ( <nl> case WM_NOTIFY : Handle_WM_Notify ( hwnd , ( LPNMHDR ) lParam ); <nl> return TRUE ; <nl> # endif <nl> + /* Workaround for the problem that MyWindowProc () returns FALSE on 64 <nl> + * bit windows when cross - compiled using Mingw libraries . ( Andy <nl> + * Kittner ) */ <nl> + case WM_NCCREATE : <nl> + MyWindowProc ( hwnd , uMsg , wParam , lParam ); <nl> + return TRUE ; <nl>  <nl> - default : <nl> - return MyWindowProc ( hwnd , uMsg , wParam , lParam ); <nl> + default : <nl> + return MyWindowProc ( hwnd , uMsg , wParam , lParam ); <nl> } <nl> } <nl> 
mmm src / diff . c <nl> ppp src / diff . c <nl> diff_mark_adjust_tp ( <nl> for ( i = 0 ; i < DB_COUNT ; ++ i ) <nl> if ( tp -> tp_diffbuf [ i ] != NULL && i != idx ) <nl> { <nl> - dp -> df_lnum [ i ] -= off ; <nl> + if ( dp -> df_lnum [ i ] > off ) <nl> + dp -> df_lnum [ i ] -= off ; <nl> + else <nl> + dp -> df_lnum [ i ] = 1 ; <nl> dp -> df_count [ i ] += n ; <nl> } <nl> } <nl> ex_diffgetput ( exarg_T * eap ) <nl> { <nl> // remember deleting the last line of the buffer <nl> buf_empty = curbuf -> b_ml . ml_line_count == 1 ; <nl> - ml_delete ( lnum ); <nl> - -- added ; <nl> + if ( ml_delete ( lnum ) == OK ) <nl> + -- added ; <nl> } <nl> for ( i = 0 ; i < dp -> df_count [ idx_from ] - start_skip - end_skip ; ++ i ) <nl> {mmm src / version . c <nl> ppp src / version . c <nl> diff_mark_adjust_tp ( <nl> for ( i = 0 ; i < DB_COUNT ; ++ i ) <nl> if ( tp -> tp_diffbuf [ i ] != NULL && i != idx ) <nl> { <nl> - dp -> df_lnum [ i ] -= off ; <nl> + if ( dp -> df_lnum [ i ] > off ) <nl> + dp -> df_lnum [ i ] -= off ; <nl> + else <nl> + dp -> df_lnum [ i ] = 1 ; <nl> dp -> df_count [ i ] += n ; <nl> } <nl> } <nl> ex_diffgetput ( exarg_T * eap ) <nl> { <nl> // remember deleting the last line of the buffer <nl> buf_empty = curbuf -> b_ml . ml_line_count == 1 ; <nl> - ml_delete ( lnum ); <nl> - -- added ; <nl> + if ( ml_delete ( lnum ) == OK ) <nl> + -- added ; <nl> } <nl> for ( i = 0 ; i < dp -> df_count [ idx_from ] - start_skip - end_skip ; ++ i ) <nl> { <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 101 , <nl> /**/ <nl> 100 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4436 , <nl> /**/ <nl> 4435 , <nl> /**/mmm src / indent . c <nl> ppp src / indent . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4436 , <nl> /**/ <nl> 4435 , <nl> /**/ <nl> change_indent ( <nl> new_cursor_col += (* mb_ptr2len )( ptr + new_cursor_col ); <nl> else <nl> ++ new_cursor_col ; <nl> + if ( ptr [ new_cursor_col ] == NUL ) <nl> + break ; <nl> vcol += lbr_chartabsize ( ptr , ptr + new_cursor_col , ( colnr_T ) vcol ); <nl> } <nl> vcol = last_vcol ;
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 322 , <nl> /**/ <nl> 321 , <nl> /**/mmm src / quickfix . c <nl> ppp src / quickfix . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 322 , <nl> /**/ <nl> 321 , <nl> /**/ <nl> qf_fill_buffer ( qf_list_T * qfl , buf_T * buf , qfline_T * old_last , int qf_winid ) <nl> } <nl>  <nl> // Check if there is anything to display <nl> - if ( qfl != NULL ) <nl> + if ( qfl != NULL && qfl -> qf_start != NULL ) <nl> { <nl> char_u dirname [ MAXPATHL ]; <nl> int invalid_val = FALSE ;
mmm src / option . c <nl> ppp src / option . c <nl> check_colorcolumn ( wp ) <nl> int i ; <nl> int j = 0 ; <nl>  <nl> + if ( wp -> w_buffer == NULL ) <nl> + return NULL ; /* buffer was closed */ <nl> + <nl> for ( s = wp -> w_p_cc ; * s != NUL && count < 255 ;) <nl> { <nl> if (* s == '-' || * s == '+')mmm src / version . c <nl> ppp src / version . c <nl> check_colorcolumn ( wp ) <nl> int i ; <nl> int j = 0 ; <nl>  <nl> + if ( wp -> w_buffer == NULL ) <nl> + return NULL ; /* buffer was closed */ <nl> + <nl> for ( s = wp -> w_p_cc ; * s != NUL && count < 255 ;) <nl> { <nl> if (* s == '-' || * s == '+') <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 316 , <nl> /**/ <nl> 315 , <nl> /**/
mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> getcmdline_int ( <nl> int indent , // indent for inside conditionals <nl> int clear_ccline ) // clear ccline first <nl> { <nl> + static int depth = 0 ; // call depth <nl> int c ; <nl> int i ; <nl> int j ; <nl> getcmdline_int ( <nl> int cmdline_type ; <nl> int wild_type ; <nl>  <nl> + // one recursion level deeper <nl> + ++ depth ; <nl> + <nl> if ( ccline . cmdbuff != NULL ) <nl> { <nl> // Being called recursively . Since ccline is global , we need to save <nl> getcmdline_int ( <nl> if ( init_ccline ( firstc , indent ) != OK ) <nl> goto theend ; // out of memory <nl>  <nl> + if ( depth == 50 ) <nl> + { <nl> + // Somehow got into a loop recursively calling getcmdline (), bail out . <nl> + emsg ( _ ( e_command_too_recursive )); <nl> + goto theend ; <nl> + } <nl> + <nl> ExpandInit (& xpc ); <nl> ccline . xpc = & xpc ; <nl>  <nl> theend : <nl> { <nl> char_u * p = ccline . cmdbuff ; <nl>  <nl> + -- depth ; <nl> if ( did_save_ccline ) <nl> restore_cmdline (& save_ccline ); <nl> elsemmm src / version . c <nl> ppp src / version . c <nl> getcmdline_int ( <nl> int indent , // indent for inside conditionals <nl> int clear_ccline ) // clear ccline first <nl> { <nl> + static int depth = 0 ; // call depth <nl> int c ; <nl> int i ; <nl> int j ; <nl> getcmdline_int ( <nl> int cmdline_type ; <nl> int wild_type ; <nl>  <nl> + // one recursion level deeper <nl> + ++ depth ; <nl> + <nl> if ( ccline . cmdbuff != NULL ) <nl> { <nl> // Being called recursively . Since ccline is global , we need to save <nl> getcmdline_int ( <nl> if ( init_ccline ( firstc , indent ) != OK ) <nl> goto theend ; // out of memory <nl>  <nl> + if ( depth == 50 ) <nl> + { <nl> + // Somehow got into a loop recursively calling getcmdline (), bail out . <nl> + emsg ( _ ( e_command_too_recursive )); <nl> + goto theend ; <nl> + } <nl> + <nl> ExpandInit (& xpc ); <nl> ccline . xpc = & xpc ; <nl>  <nl> theend : <nl> { <nl> char_u * p = ccline . cmdbuff ; <nl>  <nl> + -- depth ; <nl> if ( did_save_ccline ) <nl> restore_cmdline (& save_ccline ); <nl> else <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4975 , <nl> /**/ <nl> 4974 , <nl> /**/
mmm src / window . c <nl> ppp src / window . c <nl> win_goto ( wp ) <nl>  <nl> # ifdef FEAT_CONCEAL <nl> /* Conceal cursor line in previous window , unconceal in current window . */ <nl> - if ( win_valid ( owp )) <nl> + if ( win_valid ( owp ) && owp -> w_p_cole > 0 && ! msg_scrolled ) <nl> update_single_line ( owp , owp -> w_cursor . lnum ); <nl> - update_single_line ( curwin , curwin -> w_cursor . lnum ); <nl> + if ( curwin -> w_p_cole > 0 && ! msg_scrolled ) <nl> + need_cursor_line_redraw = TRUE ; <nl> # endif <nl> } <nl> mmm src / version . c <nl> ppp src / version . c <nl> win_goto ( wp ) <nl>  <nl> # ifdef FEAT_CONCEAL <nl> /* Conceal cursor line in previous window , unconceal in current window . */ <nl> - if ( win_valid ( owp )) <nl> + if ( win_valid ( owp ) && owp -> w_p_cole > 0 && ! msg_scrolled ) <nl> update_single_line ( owp , owp -> w_cursor . lnum ); <nl> - update_single_line ( curwin , curwin -> w_cursor . lnum ); <nl> + if ( curwin -> w_p_cole > 0 && ! msg_scrolled ) <nl> + need_cursor_line_redraw = TRUE ; <nl> # endif <nl> } <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 801 , <nl> /**/ <nl> 800 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1365 , <nl> /**/ <nl> 1364 , <nl> /**/mmm src / getchar . c <nl> ppp src / getchar . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1365 , <nl> /**/ <nl> 1364 , <nl> /**/ <nl> openscript ( <nl> emsg ( _ ( e_nesting )); <nl> return ; <nl> } <nl> + <nl> + // Disallow sourcing a file in the sandbox , the commands would be executed <nl> + // later , possibly outside of the sandbox . <nl> + if ( check_secure ()) <nl> + return ; <nl> + <nl> # ifdef FEAT_EVAL <nl> if ( ignore_script ) <nl> /* Not reading from script , also don ' t open one . Warning message ? */
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4925 , <nl> /**/ <nl> 4924 , <nl> /**/mmm src / textobject . c <nl> ppp src / textobject . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4925 , <nl> /**/ <nl> 4924 , <nl> /**/ <nl> find_next_quote ( <nl> if ( c == NUL ) <nl> return - 1 ; <nl> else if ( escape != NULL && vim_strchr ( escape , c )) <nl> + { <nl> ++ col ; <nl> + if ( line [ col ] == NUL ) <nl> + return - 1 ; <nl> + } <nl> else if ( c == quotechar ) <nl> break ; <nl> if ( has_mbyte )
mmm src / spell . c <nl> ppp src / spell . c <nl> spell_dump_compl ( <nl> n = arridx [ depth ] + curi [ depth ]; <nl> ++ curi [ depth ]; <nl> c = byts [ n ]; <nl> - if ( c == 0 ) <nl> + if ( c == 0 || depth >= MAXWLEN - 1 ) <nl> { <nl> - // End of word , deal with the word . <nl> + // End of word or reached maximum length , deal with the <nl> + // word . <nl> // Don ' t use keep - case words in the fold - case tree , <nl> // they will appear in the keep - case tree . <nl> // Only use the word when the region matches .mmm src / version . c <nl> ppp src / version . c <nl> spell_dump_compl ( <nl> n = arridx [ depth ] + curi [ depth ]; <nl> ++ curi [ depth ]; <nl> c = byts [ n ]; <nl> - if ( c == 0 ) <nl> + if ( c == 0 || depth >= MAXWLEN - 1 ) <nl> { <nl> - // End of word , deal with the word . <nl> + // End of word or reached maximum length , deal with the <nl> + // word . <nl> // Don ' t use keep - case words in the fold - case tree , <nl> // they will appear in the keep - case tree . <nl> // Only use the word when the region matches . <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 35 , <nl> /**/ <nl> 34 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4418 , <nl> /**/ <nl> 4417 , <nl> /**/mmm src / charset . c <nl> ppp src / charset . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4418 , <nl> /**/ <nl> 4417 , <nl> /**/ <nl> vim_isupper ( int c ) <nl> return isupper ( c ); <nl> } <nl>  <nl> + int <nl> + vim_isalpha ( int c ) <nl> +{ <nl> + return vim_islower ( c ) || vim_isupper ( c ); <nl> +} <nl> + <nl> int <nl> vim_toupper ( int c ) <nl> {mmm src / filepath . c <nl> ppp src / filepath . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4418 , <nl> /**/ <nl> 4417 , <nl> /**/ <nl> vim_isupper ( int c ) <nl> return isupper ( c ); <nl> } <nl>  <nl> + int <nl> + vim_isalpha ( int c ) <nl> +{ <nl> + return vim_islower ( c ) || vim_isupper ( c ); <nl> +} <nl> + <nl> int <nl> vim_toupper ( int c ) <nl> { <nl> unix_expandpath ( <nl> else if ( path_end >= path + wildoff <nl> && ( vim_strchr (( char_u *)"*?[{~$", * path_end ) != NULL <nl> || (! p_fic && ( flags & EW_ICASE ) <nl> - && isalpha ( PTR2CHAR ( path_end ))))) <nl> + && vim_isalpha ( PTR2CHAR ( path_end ))))) <nl> e = p ; <nl> if ( has_mbyte ) <nl> {
mmm src / spellsuggest . c <nl> ppp src / spellsuggest . c <nl> spell_suggest ( int count ) <nl> curwin -> w_cursor . col = VIsual . col ; <nl> ++ badlen ; <nl> end_visual_mode (); <nl> + // make sure we don ' t include the NUL at the end of the line <nl> + line = ml_get_curline (); <nl> + if ( badlen > STRLEN ( line ) - curwin -> w_cursor . col ) <nl> + badlen = STRLEN ( line ) - curwin -> w_cursor . col ; <nl> } <nl> // Find the start of the badly spelled word . <nl> else if ( spell_move_to ( curwin , FORWARD , TRUE , TRUE , NULL ) == 0mmm src / version . c <nl> ppp src / version . c <nl> spell_suggest ( int count ) <nl> curwin -> w_cursor . col = VIsual . col ; <nl> ++ badlen ; <nl> end_visual_mode (); <nl> + // make sure we don ' t include the NUL at the end of the line <nl> + line = ml_get_curline (); <nl> + if ( badlen > STRLEN ( line ) - curwin -> w_cursor . col ) <nl> + badlen = STRLEN ( line ) - curwin -> w_cursor . col ; <nl> } <nl> // Find the start of the badly spelled word . <nl> else if ( spell_move_to ( curwin , FORWARD , TRUE , TRUE , NULL ) == 0 <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4563 , <nl> /**/ <nl> 4562 , <nl> /**/
mmm src / vim9expr . c <nl> ppp src / vim9expr . c <nl> compile_get_env ( char_u ** arg , cctx_T * cctx ) <nl> len = get_env_len ( arg ); <nl> if ( len == 0 ) <nl> { <nl> - semsg ( _ ( e_syntax_error_at_str ), start - 1 ); <nl> + semsg ( _ ( e_syntax_error_at_str ), start ); <nl> return FAIL ; <nl> } <nl> mmm src / version . c <nl> ppp src / version . c <nl> compile_get_env ( char_u ** arg , cctx_T * cctx ) <nl> len = get_env_len ( arg ); <nl> if ( len == 0 ) <nl> { <nl> - semsg ( _ ( e_syntax_error_at_str ), start - 1 ); <nl> + semsg ( _ ( e_syntax_error_at_str ), start ); <nl> return FAIL ; <nl> } <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4049 , <nl> /**/ <nl> 4048 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5148 , <nl> /**/ <nl> 5147 , <nl> /**/mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5148 , <nl> /**/ <nl> 5147 , <nl> /**/ <nl> cmdline_insert_reg ( int * gotesc UNUSED ) <nl> { <nl> int i ; <nl> int c ; <nl> + int save_new_cmdpos = new_cmdpos ; <nl>  <nl> # ifdef USE_ON_FLY_SCROLL <nl> dont_scroll = TRUE ; // disallow scrolling here <nl> cmdline_insert_reg ( int * gotesc UNUSED ) <nl> # ifdef FEAT_EVAL <nl> /* <nl> * Insert the result of an expression . <nl> - * Need to save the current command line , to be able to enter <nl> - * a new one ... <nl> */ <nl> new_cmdpos = - 1 ; <nl> if ( c == '=') <nl> cmdline_insert_reg ( int * gotesc UNUSED ) <nl> } <nl> # endif <nl> } <nl> + new_cmdpos = save_new_cmdpos ; <nl> + <nl> // remove the double quote <nl> redrawcmd (); <nl> 
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3847 , <nl> /**/ <nl> 3846 , <nl> /**/mmm src / eval . c <nl> ppp src / eval . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3847 , <nl> /**/ <nl> 3846 , <nl> /**/ <nl> eval_lambda ( <nl> ++* arg ; <nl> ret = eval1 ( arg , rettv , evalarg ); <nl> * arg = skipwhite_and_linebreak (* arg , evalarg ); <nl> - if (** arg != ')') <nl> + if (** arg == ')') <nl> + { <nl> + ++* arg ; <nl> + } <nl> + else <nl> { <nl> emsg ( _ ( e_missing_closing_paren )); <nl> ret = FAIL ; <nl> } <nl> - ++* arg ; <nl> } <nl> if ( ret != OK ) <nl> return FAIL ;
mmm src / cindent . c <nl> ppp src / cindent . c <nl> skip_string ( char_u * p ) <nl> while ( vim_isdigit ( p [ i - 1 ])) // '\ 000 ' <nl> ++ i ; <nl> } <nl> - if ( p [ i ] == '\'') // check for trailing ' <nl> + if ( p [ i - 1 ] != NUL && p [ i ] == '\'') // check for trailing ' <nl> { <nl> p += i ; <nl> continue ;mmm src / version . c <nl> ppp src / version . c <nl> skip_string ( char_u * p ) <nl> while ( vim_isdigit ( p [ i - 1 ])) // '\ 000 ' <nl> ++ i ; <nl> } <nl> - if ( p [ i ] == '\'') // check for trailing ' <nl> + if ( p [ i - 1 ] != NUL && p [ i ] == '\'') // check for trailing ' <nl> { <nl> p += i ; <nl> continue ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4968 , <nl> /**/ <nl> 4967 , <nl> /**/
mmm src / regexp_nfa . c <nl> ppp src / regexp_nfa . c <nl> nfa_regmatch ( <nl> case NFA_MARK_GT : <nl> case NFA_MARK_LT : <nl> { <nl> + size_t col = rex . input - rex . line ; <nl> pos_T * pos = getmark_buf ( rex . reg_buf , t -> state -> val , FALSE ); <nl>  <nl> + // Line may have been freed , get it again . <nl> + if ( REG_MULTI ) <nl> + { <nl> + rex . line = reg_getline ( rex . lnum ); <nl> + rex . input = rex . line + col ; <nl> + } <nl> + <nl> // Compare the mark position to the match position , if the mark <nl> // exists and mark is set in reg_buf . <nl> if ( pos != NULL && pos -> lnum > 0 )mmm src / version . c <nl> ppp src / version . c <nl> nfa_regmatch ( <nl> case NFA_MARK_GT : <nl> case NFA_MARK_LT : <nl> { <nl> + size_t col = rex . input - rex . line ; <nl> pos_T * pos = getmark_buf ( rex . reg_buf , t -> state -> val , FALSE ); <nl>  <nl> + // Line may have been freed , get it again . <nl> + if ( REG_MULTI ) <nl> + { <nl> + rex . line = reg_getline ( rex . lnum ); <nl> + rex . input = rex . line + col ; <nl> + } <nl> + <nl> // Compare the mark position to the match position , if the mark <nl> // exists and mark is set in reg_buf . <nl> if ( pos != NULL && pos -> lnum > 0 ) <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3612 , <nl> /**/ <nl> 3611 , <nl> /**/mmm src / regexp . c <nl> ppp src / regexp . c <nl> nfa_regmatch ( <nl> case NFA_MARK_GT : <nl> case NFA_MARK_LT : <nl> { <nl> + size_t col = rex . input - rex . line ; <nl> pos_T * pos = getmark_buf ( rex . reg_buf , t -> state -> val , FALSE ); <nl>  <nl> + // Line may have been freed , get it again . <nl> + if ( REG_MULTI ) <nl> + { <nl> + rex . line = reg_getline ( rex . lnum ); <nl> + rex . input = rex . line + col ; <nl> + } <nl> + <nl> // Compare the mark position to the match position , if the mark <nl> // exists and mark is set in reg_buf . <nl> if ( pos != NULL && pos -> lnum > 0 ) <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3612 , <nl> /**/ <nl> 3611 , <nl> /**/ <nl> typedef struct { <nl> // The current match - position is stord in these variables : <nl> linenr_T lnum ; // line number , relative to first line <nl> char_u * line ; // start of current line <nl> - char_u * input ; // current input , points into " regline " <nl> + char_u * input ; // current input , points into " line " <nl>  <nl> int need_clear_subexpr ; // subexpressions still need to be cleared <nl> # ifdef FEAT_SYN_HL
mmm src / regexp_bt . c <nl> ppp src / regexp_bt . c <nl> regmatch ( <nl> if ( rex . input == rex . line ) <nl> { <nl> // backup to last char of previous line <nl> + if ( rex . lnum == 0 ) <nl> + { <nl> + status = RA_NOMATCH ; <nl> + break ; <nl> + } <nl> -- rex . lnum ; <nl> rex . line = reg_getline ( rex . lnum ); <nl> // Just in case regrepeat () didn ' t countmmm src / version . c <nl> ppp src / version . c <nl> regmatch ( <nl> if ( rex . input == rex . line ) <nl> { <nl> // backup to last char of previous line <nl> + if ( rex . lnum == 0 ) <nl> + { <nl> + status = RA_NOMATCH ; <nl> + break ; <nl> + } <nl> -- rex . lnum ; <nl> rex . line = reg_getline ( rex . lnum ); <nl> // Just in case regrepeat () didn ' t count <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4440 , <nl> /**/ <nl> 4439 , <nl> /**/
mmm src / regexp_nfa . c <nl> ppp src / regexp_nfa . c <nl> find_match_text ( colnr_T startcol , int regstart , char_u * match_text ) <nl> match = FALSE ; <nl> break ; <nl> } <nl> - len2 += MB_CHAR2LEN ( c2 ); <nl> + len2 += enc_utf8 ? utf_ptr2len ( rex . line + col + len2 ) <nl> + : MB_CHAR2LEN ( c2 ); <nl> } <nl> if ( match <nl> // check that no composing char followsmmm src / version . c <nl> ppp src / version . c <nl> find_match_text ( colnr_T startcol , int regstart , char_u * match_text ) <nl> match = FALSE ; <nl> break ; <nl> } <nl> - len2 += MB_CHAR2LEN ( c2 ); <nl> + len2 += enc_utf8 ? utf_ptr2len ( rex . line + col + len2 ) <nl> + : MB_CHAR2LEN ( c2 ); <nl> } <nl> if ( match <nl> // check that no composing char follows <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3409 , <nl> /**/ <nl> 3408 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 240 , <nl> /**/ <nl> 239 , <nl> /**/mmm src / spellfile . c <nl> ppp src / spellfile . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 240 , <nl> /**/ <nl> 239 , <nl> /**/ <nl> sug_filltree ( spellinfo_T * spin , slang_T * slang ) <nl>  <nl> /* <nl> * Go through the whole case - folded tree , soundfold each word and put it <nl> - * in the trie . <nl> + * in the trie . Bail out if the tree is empty . <nl> */ <nl> byts = slang -> sl_fbyts ; <nl> idxs = slang -> sl_fidxs ; <nl> + if ( byts == NULL || idxs == NULL ) <nl> + return FAIL ; <nl>  <nl> arridx [ 0 ] = 0 ; <nl> curi [ 0 ] = 1 ;
mmm src / eval . c <nl> ppp src / eval . c <nl> eval_expr_typval ( typval_T * expr , typval_T * argv , int argc , typval_T * rettv ) <nl> if ( fc == NULL ) <nl> return FAIL ; <nl>  <nl> - // Shortcut to call a compiled function without overhead . <nl> + // Shortcut to call a compiled function with minimal overhead . <nl> r = call_def_function ( partial -> pt_func , argc , argv , <nl> DEF_USE_PT_ARGV , partial , fc , rettv ); <nl> remove_funccal (); <nl> eval_next_non_blank ( char_u * arg , evalarg_T * evalarg , int * getnext ) <nl>  <nl> if ( next != NULL ) <nl> { <nl> - * getnext = TRUE ; <nl> + * getnext = * p != NL ; <nl> return skipwhite ( next ); <nl> } <nl> }mmm src / version . c <nl> ppp src / version . c <nl> eval_expr_typval ( typval_T * expr , typval_T * argv , int argc , typval_T * rettv ) <nl> if ( fc == NULL ) <nl> return FAIL ; <nl>  <nl> - // Shortcut to call a compiled function without overhead . <nl> + // Shortcut to call a compiled function with minimal overhead . <nl> r = call_def_function ( partial -> pt_func , argc , argv , <nl> DEF_USE_PT_ARGV , partial , fc , rettv ); <nl> remove_funccal (); <nl> eval_next_non_blank ( char_u * arg , evalarg_T * evalarg , int * getnext ) <nl>  <nl> if ( next != NULL ) <nl> { <nl> - * getnext = TRUE ; <nl> + * getnext = * p != NL ; <nl> return skipwhite ( next ); <nl> } <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 552 , <nl> /**/ <nl> 551 , <nl> /**/
mmm src / indent . c <nl> ppp src / indent . c <nl> ex_retab ( exarg_T * eap ) <nl> if ( ptr [ col ] == NUL ) <nl> break ; <nl> vcol += chartabsize ( ptr + col , ( colnr_T ) vcol ); <nl> + if ( vcol >= MAXCOL ) <nl> + { <nl> + emsg ( _ ( e_resulting_text_too_long )); <nl> + break ; <nl> + } <nl> if ( has_mbyte ) <nl> col += (* mb_ptr2len )( ptr + col ); <nl> elsemmm src / version . c <nl> ppp src / version . c <nl> ex_retab ( exarg_T * eap ) <nl> if ( ptr [ col ] == NUL ) <nl> break ; <nl> vcol += chartabsize ( ptr + col , ( colnr_T ) vcol ); <nl> + if ( vcol >= MAXCOL ) <nl> + { <nl> + emsg ( _ ( e_resulting_text_too_long )); <nl> + break ; <nl> + } <nl> if ( has_mbyte ) <nl> col += (* mb_ptr2len )( ptr + col ); <nl> else <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4359 , <nl> /**/ <nl> 4358 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3884 , <nl> /**/ <nl> 3883 , <nl> /**/mmm src / arglist . c <nl> ppp src / arglist . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3884 , <nl> /**/ <nl> 3883 , <nl> /**/ <nl> do_arg_all ( <nl> tabpage_T * old_curtab , * last_curtab ; <nl> win_T * new_curwin = NULL ; <nl> tabpage_T * new_curtab = NULL ; <nl> + int prev_arglist_locked = arglist_locked ; <nl>  <nl> # ifdef FEAT_CMDWIN <nl> if ( cmdwin_type != 0 ) <nl> do_arg_all ( <nl> // watch out for its size to be changed . <nl> alist = curwin -> w_alist ; <nl> ++ alist -> al_refcount ; <nl> + arglist_locked = TRUE ; <nl>  <nl> old_curwin = curwin ; <nl> old_curtab = curtab ; <nl> do_arg_all ( <nl>  <nl> // Remove the " lock " on the argument list . <nl> alist_unlink ( alist ); <nl> + arglist_locked = prev_arglist_locked ; <nl>  <nl> -- autocmd_no_enter ; <nl> 
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3564 , <nl> /**/ <nl> 3563 , <nl> /**/mmm src / move . c <nl> ppp src / move . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3564 , <nl> /**/ <nl> 3563 , <nl> /**/ <nl> update_topline ( void ) <nl> check_cursor_lnum (); <nl> curwin -> w_topline = curwin -> w_cursor . lnum ; <nl> curwin -> w_botline = curwin -> w_topline ; <nl> - curwin -> w_valid |= VALID_BOTLINE | VALID_BOTLINE_AP ; <nl> curwin -> w_scbind_pos = 1 ; <nl> return ; <nl> }
mmm src / gui_x11 . c <nl> ppp src / gui_x11 . c <nl> gui_mch_get_color ( char_u * name ) <nl> guicolor_T <nl> gui_mch_get_rgb_color ( int r , int g , int b ) <nl> { <nl> - char spec [ 8 ]; /* space enough to hold "# RRGGBB " */ <nl> XColor available ; <nl> Colormap colormap ; <nl>  <nl> +/* Using XParseColor () is very slow , put rgb in XColor directly . <nl> + <nl> + char spec [ 8 ]; // space enough to hold "# RRGGBB " <nl> vim_snprintf ( spec , sizeof ( spec ), "#%. 2x %. 2x %. 2x ", r , g , b ); <nl> - colormap = DefaultColormap ( gui . dpy , DefaultScreen ( gui . dpy )); <nl> if ( XParseColor ( gui . dpy , colormap , ( char *) spec , & available ) != 0 <nl> && XAllocColor ( gui . dpy , colormap , & available ) != 0 ) <nl> return ( guicolor_T ) available . pixel ; <nl> +*/ <nl> + colormap = DefaultColormap ( gui . dpy , DefaultScreen ( gui . dpy )); <nl> + vim_memset (& available , 0 , sizeof ( XColor )); <nl> + available . red = r << 8 ; <nl> + available . green = g << 8 ; <nl> + available . blue = b << 8 ; <nl> + if ( XAllocColor ( gui . dpy , colormap , & available ) != 0 ) <nl> + return ( guicolor_T ) available . pixel ; <nl>  <nl> return INVALCOLOR ; <nl> }mmm src / version . c <nl> ppp src / version . c <nl> gui_mch_get_color ( char_u * name ) <nl> guicolor_T <nl> gui_mch_get_rgb_color ( int r , int g , int b ) <nl> { <nl> - char spec [ 8 ]; /* space enough to hold "# RRGGBB " */ <nl> XColor available ; <nl> Colormap colormap ; <nl>  <nl> +/* Using XParseColor () is very slow , put rgb in XColor directly . <nl> + <nl> + char spec [ 8 ]; // space enough to hold "# RRGGBB " <nl> vim_snprintf ( spec , sizeof ( spec ), "#%. 2x %. 2x %. 2x ", r , g , b ); <nl> - colormap = DefaultColormap ( gui . dpy , DefaultScreen ( gui . dpy )); <nl> if ( XParseColor ( gui . dpy , colormap , ( char *) spec , & available ) != 0 <nl> && XAllocColor ( gui . dpy , colormap , & available ) != 0 ) <nl> return ( guicolor_T ) available . pixel ; <nl> +*/ <nl> + colormap = DefaultColormap ( gui . dpy , DefaultScreen ( gui . dpy )); <nl> + vim_memset (& available , 0 , sizeof ( XColor )); <nl> + available . red = r << 8 ; <nl> + available . green = g << 8 ; <nl> + available . blue = b << 8 ; <nl> + if ( XAllocColor ( gui . dpy , colormap , & available ) != 0 ) <nl> + return ( guicolor_T ) available . pixel ; <nl>  <nl> return INVALCOLOR ; <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1800 , <nl> /**/ <nl> 1799 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5013 , <nl> /**/ <nl> 5012 , <nl> /**/mmm src / textformat . c <nl> ppp src / textformat . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5013 , <nl> /**/ <nl> 5012 , <nl> /**/ <nl> op_format ( <nl> { <nl> curwin -> w_cursor = saved_cursor ; <nl> saved_cursor . lnum = 0 ; <nl> + <nl> + // formatting may have made the cursor position invalid <nl> + check_cursor (); <nl> } <nl>  <nl> if ( oap -> is_VIsual )
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1143 , <nl> /**/ <nl> 1142 , <nl> /**/mmm src / buffer . c <nl> ppp src / buffer . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1143 , <nl> /**/ <nl> 1142 , <nl> /**/ <nl> build_stl_str_hl ( <nl> # endif <nl> if ( vim_strchr ( STL_ALL , * s ) == NULL ) <nl> { <nl> + if (* s == NUL ) // can happen with "% 0 " <nl> + break ; <nl> s ++; <nl> continue ; <nl> }
mmm src / edit . c <nl> ppp src / edit . c <nl> bracketed_paste ( paste_mode_T mode , int drop , garray_T * gap ) <nl> break ; <nl>  <nl> case PASTE_EX : <nl> - if ( gap != NULL && ga_grow ( gap , idx ) == OK ) <nl> + // add one for the NUL that is going to be appended <nl> + if ( gap != NULL && ga_grow ( gap , idx + 1 ) == OK ) <nl> { <nl> mch_memmove (( char *) gap -> ga_data + gap -> ga_len , <nl> buf , ( size_t ) idx );mmm src / version . c <nl> ppp src / version . c <nl> bracketed_paste ( paste_mode_T mode , int drop , garray_T * gap ) <nl> break ; <nl>  <nl> case PASTE_EX : <nl> - if ( gap != NULL && ga_grow ( gap , idx ) == OK ) <nl> + // add one for the NUL that is going to be appended <nl> + if ( gap != NULL && ga_grow ( gap , idx + 1 ) == OK ) <nl> { <nl> mch_memmove (( char *) gap -> ga_data + gap -> ga_len , <nl> buf , ( size_t ) idx ); <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4218 , <nl> /**/ <nl> 4217 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3487 , <nl> /**/ <nl> 3486 , <nl> /**/mmm src / drawscreen . c <nl> ppp src / drawscreen . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3487 , <nl> /**/ <nl> 3486 , <nl> /**/ <nl> win_redr_status ( win_T * wp , int ignore_pum UNUSED ) <nl> *( p + len ++) = ' '; <nl> if ( bt_help ( wp -> w_buffer )) <nl> { <nl> - STRCPY ( p + len , _ ("[ Help ]")); <nl> + vim_snprintf (( char *) p + len , MAXPATHL - len , "% s ", _ ("[ Help ]")); <nl> len += ( int ) STRLEN ( p + len ); <nl> } <nl> # ifdef FEAT_QUICKFIX <nl> if ( wp -> w_p_pvw ) <nl> { <nl> - STRCPY ( p + len , _ ("[ Preview ]")); <nl> + vim_snprintf (( char *) p + len , MAXPATHL - len , "% s ", _ ("[ Preview ]")); <nl> len += ( int ) STRLEN ( p + len ); <nl> } <nl> # endif <nl> win_redr_status ( win_T * wp , int ignore_pum UNUSED ) <nl> # endif <nl> ) <nl> { <nl> - STRCPY ( p + len , "[+]"); <nl> - len += 3 ; <nl> + vim_snprintf (( char *) p + len , MAXPATHL - len , "% s ", "[+]"); <nl> + len += ( int ) STRLEN ( p + len ); <nl> } <nl> if ( wp -> w_buffer -> b_p_ro ) <nl> { <nl> - STRCPY ( p + len , _ ("[ RO ]")); <nl> + vim_snprintf (( char *) p + len , MAXPATHL - len , "% s ", _ ("[ RO ]")); <nl> len += ( int ) STRLEN ( p + len ); <nl> } <nl> 
mmm src / window . c <nl> ppp src / window . c <nl> win_equal_rec ( <nl> if ( hnc ) // add next_curwin size <nl> { <nl> next_curwin_size -= p_wiw - ( m - n ); <nl> + if ( next_curwin_size < 0 ) <nl> + next_curwin_size = 0 ; <nl> new_size += next_curwin_size ; <nl> room -= new_size - next_curwin_size ; <nl> } <nl> scroll_to_fraction ( win_T * wp , int prev_height ) <nl> void <nl> win_new_width ( win_T * wp , int width ) <nl> { <nl> - wp -> w_width = width ; <nl> + // Should we give an error if width < 0 ? <nl> + wp -> w_width = width < 0 ? 0 : width ; <nl> wp -> w_lines_valid = 0 ; <nl> changed_line_abv_curs_win ( wp ); <nl> // Handled in win_fix_scroll ()mmm src / version . c <nl> ppp src / version . c <nl> win_equal_rec ( <nl> if ( hnc ) // add next_curwin size <nl> { <nl> next_curwin_size -= p_wiw - ( m - n ); <nl> + if ( next_curwin_size < 0 ) <nl> + next_curwin_size = 0 ; <nl> new_size += next_curwin_size ; <nl> room -= new_size - next_curwin_size ; <nl> } <nl> scroll_to_fraction ( win_T * wp , int prev_height ) <nl> void <nl> win_new_width ( win_T * wp , int width ) <nl> { <nl> - wp -> w_width = width ; <nl> + // Should we give an error if width < 0 ? <nl> + wp -> w_width = width < 0 ? 0 : width ; <nl> wp -> w_lines_valid = 0 ; <nl> changed_line_abv_curs_win ( wp ); <nl> // Handled in win_fix_scroll () <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 598 , <nl> /**/ <nl> 597 , <nl> /**/
mmm src / ops . c <nl> ppp src / ops . c <nl> op_delete ( oap ) <nl> did_yank = TRUE ; <nl> } <nl>  <nl> - /* Yank into small delete register when no register specified and the <nl> - * delete is within one line . */ <nl> - if ( oap -> regname == 0 && oap -> motion_type != MLINE <nl> + /* Yank into small delete register when no named register specified <nl> + * and the delete is within one line . */ <nl> + if (( <nl> +# ifdef FEAT_CLIPBOARD <nl> + (( clip_unnamed & CLIP_UNNAMED ) && oap -> regname == '*') || <nl> + (( clip_unnamed & CLIP_UNNAMED_PLUS ) && oap -> regname == '+') || <nl> +# endif <nl> + oap -> regname == 0 ) && oap -> motion_type != MLINE <nl> && oap -> line_count == 1 ) <nl> { <nl> oap -> regname = '-';mmm src / version . c <nl> ppp src / version . c <nl> op_delete ( oap ) <nl> did_yank = TRUE ; <nl> } <nl>  <nl> - /* Yank into small delete register when no register specified and the <nl> - * delete is within one line . */ <nl> - if ( oap -> regname == 0 && oap -> motion_type != MLINE <nl> + /* Yank into small delete register when no named register specified <nl> + * and the delete is within one line . */ <nl> + if (( <nl> +# ifdef FEAT_CLIPBOARD <nl> + (( clip_unnamed & CLIP_UNNAMED ) && oap -> regname == '*') || <nl> + (( clip_unnamed & CLIP_UNNAMED_PLUS ) && oap -> regname == '+') || <nl> +# endif <nl> + oap -> regname == 0 ) && oap -> motion_type != MLINE <nl> && oap -> line_count == 1 ) <nl> { <nl> oap -> regname = '-'; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 498 , <nl> /**/ <nl> 497 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4214 , <nl> /**/ <nl> 4213 , <nl> /**/mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4214 , <nl> /**/ <nl> 4213 , <nl> /**/ <nl> init_ccline ( int firstc , int indent ) <nl> ccline . cmdindent = ( firstc > 0 ? indent : 0 ); <nl>  <nl> // alloc initial ccline . cmdbuff <nl> - alloc_cmdbuff ( exmode_active ? 250 : indent + 1 ); <nl> + alloc_cmdbuff ( indent + 50 ); <nl> if ( ccline . cmdbuff == NULL ) <nl> return FAIL ; <nl> ccline . cmdlen = ccline . cmdpos = 0 ;
mmm src / move . c <nl> ppp src / move . c <nl> adjust_skipcol ( void ) <nl> return ; <nl>  <nl> int width1 = curwin -> w_width - curwin_col_off (); <nl> + if ( width1 <= 0 ) <nl> + return ; // no text will be displayed <nl> + <nl> int width2 = width1 + curwin_col_off2 (); <nl> long so = get_scrolloff_value (); <nl> int scrolloff_cols = so == 0 ? 0 : width1 + ( so - 1 ) * width2 ;mmm src / version . c <nl> ppp src / version . c <nl> adjust_skipcol ( void ) <nl> return ; <nl>  <nl> int width1 = curwin -> w_width - curwin_col_off (); <nl> + if ( width1 <= 0 ) <nl> + return ; // no text will be displayed <nl> + <nl> int width2 = width1 + curwin_col_off2 (); <nl> long so = get_scrolloff_value (); <nl> int scrolloff_cols = so == 0 ? 0 : width1 + ( so - 1 ) * width2 ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1247 , <nl> /**/ <nl> 1246 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 35 , <nl> /**/ <nl> 34 , <nl> /**/mmm src / os_win32 . c <nl> ppp src / os_win32 . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 35 , <nl> /**/ <nl> 34 , <nl> /**/ <nl> get_exe_name ( void ) <nl> * "! xxd " it ' s found in our starting directory . Needed because <nl> * SearchPath () also looks there . */ <nl> p = mch_getenv (" PATH "); <nl> - if ( STRLEN ( p ) + STRLEN ( exe_path ) + 2 < MAXPATHL ); <nl> + if ( STRLEN ( p ) + STRLEN ( exe_path ) + 2 < MAXPATHL ) <nl> { <nl> STRCPY ( temp , p ); <nl> STRCAT ( temp , ";");
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4217 , <nl> /**/ <nl> 4216 , <nl> /**/mmm src / undo . c <nl> ppp src / undo . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4217 , <nl> /**/ <nl> 4216 , <nl> /**/ <nl> u_undo_end ( <nl> } <nl> } <nl> # endif <nl> + if ( VIsual_active ) <nl> + check_pos ( curbuf , & VIsual ); <nl>  <nl> smsg_attr_keep ( 0 , _ ("% ld % s ; % s #% ld % s "), <nl> u_oldcount < 0 ? - u_oldcount : u_oldcount ,
mmm src / buffer . c <nl> ppp src / buffer . c <nl> fname_match ( <nl> rmp -> rm_ic = p_fic || ignore_case ; <nl> if ( vim_regexec ( rmp , name , ( colnr_T ) 0 )) <nl> match = name ; <nl> - else <nl> + else if ( rmp -> regprog != NULL ) <nl> { <nl> // Replace $( HOME ) with '~' and try matching again . <nl> p = home_replace_save ( NULL , name );mmm src / version . c <nl> ppp src / version . c <nl> fname_match ( <nl> rmp -> rm_ic = p_fic || ignore_case ; <nl> if ( vim_regexec ( rmp , name , ( colnr_T ) 0 )) <nl> match = name ; <nl> - else <nl> + else if ( rmp -> regprog != NULL ) <nl> { <nl> // Replace $( HOME ) with '~' and try matching again . <nl> p = home_replace_save ( NULL , name ); <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4901 , <nl> /**/ <nl> 4900 , <nl> /**/
mmm src / indent . c <nl> ppp src / indent . c <nl> get_lisp_indent ( void ) <nl> amount += 2 ; <nl> else <nl> { <nl> - that ++; <nl> - amount ++; <nl> + if (* that != NUL ) <nl> + { <nl> + that ++; <nl> + amount ++; <nl> + } <nl> firsttry = amount ; <nl>  <nl> while ( VIM_ISWHITE (* that ))mmm src / version . c <nl> ppp src / version . c <nl> get_lisp_indent ( void ) <nl> amount += 2 ; <nl> else <nl> { <nl> - that ++; <nl> - amount ++; <nl> + if (* that != NUL ) <nl> + { <nl> + that ++; <nl> + amount ++; <nl> + } <nl> firsttry = amount ; <nl>  <nl> while ( VIM_ISWHITE (* that )) <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5151 , <nl> /**/ <nl> 5150 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 530 , <nl> /**/ <nl> 529 , <nl> /**/mmm src / mark . c <nl> ppp src / mark . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 530 , <nl> /**/ <nl> 529 , <nl> /**/ <nl> movemark ( int count ) <nl> fname2fnum ( jmp ); <nl> if ( jmp -> fmark . fnum != curbuf -> b_fnum ) <nl> { <nl> - // jump to other file <nl> - if ( buflist_findnr ( jmp -> fmark . fnum ) == NULL ) <nl> + // Make a copy , an autocommand may make " jmp " invalid . <nl> + fmark_T fmark = jmp -> fmark ; <nl> + <nl> + // jump to the file with the mark <nl> + if ( buflist_findnr ( fmark . fnum ) == NULL ) <nl> { // Skip this one .. <nl> count += count < 0 ? - 1 : 1 ; <nl> continue ; <nl> } <nl> - if ( buflist_getfile ( jmp -> fmark . fnum , jmp -> fmark . mark . lnum , <nl> - 0 , FALSE ) == FAIL ) <nl> + if ( buflist_getfile ( fmark . fnum , fmark . mark . lnum , 0 , FALSE ) == FAIL ) <nl> return ( pos_T *) NULL ; <nl> // Set lnum again , autocommands my have changed it <nl> - curwin -> w_cursor = jmp -> fmark . mark ; <nl> + curwin -> w_cursor = fmark . mark ; <nl> pos = ( pos_T *)- 1 ; <nl> } <nl> else
mmm src / buffer . c <nl> ppp src / buffer . c <nl> do_buffer_ext ( <nl> if (( flags & DOBUF_NOPOPUP ) && bt_popup ( buf ) && ! bt_terminal ( buf )) <nl> return OK ; <nl> # endif <nl> + if (( action == DOBUF_GOTO || action == DOBUF_SPLIT ) <nl> + && ( buf -> b_flags & BF_DUMMY )) <nl> + { <nl> + // disallow navigating to the dummy buffer <nl> + semsg ( _ ( e_buffer_nr_does_not_exist ), count ); <nl> + return FAIL ; <nl> + } <nl>  <nl> # ifdef FEAT_GUI <nl> need_mouse_correct = TRUE ;mmm src / version . c <nl> ppp src / version . c <nl> do_buffer_ext ( <nl> if (( flags & DOBUF_NOPOPUP ) && bt_popup ( buf ) && ! bt_terminal ( buf )) <nl> return OK ; <nl> # endif <nl> + if (( action == DOBUF_GOTO || action == DOBUF_SPLIT ) <nl> + && ( buf -> b_flags & BF_DUMMY )) <nl> + { <nl> + // disallow navigating to the dummy buffer <nl> + semsg ( _ ( e_buffer_nr_does_not_exist ), count ); <nl> + return FAIL ; <nl> + } <nl>  <nl> # ifdef FEAT_GUI <nl> need_mouse_correct = TRUE ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 789 , <nl> /**/ <nl> 788 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 148 , <nl> /**/ <nl> 147 , <nl> /**/mmm src / if_tcl . c <nl> ppp src / if_tcl . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 148 , <nl> /**/ <nl> 147 , <nl> /**/ <nl> tclvimexpr ( <nl> if ( str == NULL ) <nl> Tcl_SetResult ( interp , _ (" invalid expression "), TCL_STATIC ); <nl> else <nl> + { <nl> Tcl_SetResult ( interp , str , TCL_VOLATILE ); <nl> + vim_free ( str ); <nl> + } <nl> err = vimerror ( interp ); <nl> # else <nl> Tcl_SetResult ( interp , _ (" expressions disabled at compile time "), TCL_STATIC );
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3950 , <nl> /**/ <nl> 3949 , <nl> /**/mmm src / charset . c <nl> ppp src / charset . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3950 , <nl> /**/ <nl> 3949 , <nl> /**/ <nl> getvcol ( <nl> posptr = NULL ; // continue until the NUL <nl> else <nl> { <nl> - // Special check for an empty line , which can happen on exit , when <nl> - // ml_get_buf () always returns an empty string . <nl> - if (* ptr == NUL ) <nl> - pos -> col = 0 ; <nl> + colnr_T i ; <nl> + <nl> + // In a few cases the position can be beyond the end of the line . <nl> + for ( i = 0 ; i < pos -> col ; ++ i ) <nl> + if ( ptr [ i ] == NUL ) <nl> + { <nl> + pos -> col = i ; <nl> + break ; <nl> + } <nl> posptr = ptr + pos -> col ; <nl> if ( has_mbyte ) <nl> // always start on the first byte
mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> ex_close ( eap ) <nl> { <nl> # ifdef FEAT_CMDWIN <nl> if ( cmdwin_type != 0 ) <nl> - cmdwin_result = K_IGNORE ; <nl> + cmdwin_result = Ctrl_C ; <nl> else <nl> # endif <nl> if (! text_locked ()mmm src / version . c <nl> ppp src / version . c <nl> ex_close ( eap ) <nl> { <nl> # ifdef FEAT_CMDWIN <nl> if ( cmdwin_type != 0 ) <nl> - cmdwin_result = K_IGNORE ; <nl> + cmdwin_result = Ctrl_C ; <nl> else <nl> # endif <nl> if (! text_locked () <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 193 , <nl> /**/ <nl> 192 , <nl> /**/mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> ex_close ( eap ) <nl> { <nl> # ifdef FEAT_CMDWIN <nl> if ( cmdwin_type != 0 ) <nl> - cmdwin_result = K_IGNORE ; <nl> + cmdwin_result = Ctrl_C ; <nl> else <nl> # endif <nl> if (! text_locked () <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 193 , <nl> /**/ <nl> 192 , <nl> /**/ <nl> ex_window () <nl> ccline . cmdbuff = vim_strsave (( char_u *)" qa "); <nl> cmdwin_result = CAR ; <nl> } <nl> + else if ( cmdwin_result == Ctrl_C ) <nl> + { <nl> + /* : q or : close , don ' t execute any command <nl> + * and don ' t modify the cmd window . */ <nl> + ccline . cmdbuff = NULL ; <nl> + } <nl> else <nl> ccline . cmdbuff = vim_strsave ( ml_get_curline ()); <nl> if ( ccline . cmdbuff == NULL )
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 466 , <nl> /**/ <nl> 465 , <nl> /**/mmm src / ops . c <nl> ppp src / ops . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 466 , <nl> /**/ <nl> 465 , <nl> /**/ <nl> op_delete ( oap ) <nl> ++ curwin -> w_cursor . lnum ; <nl> del_lines (( long )( oap -> line_count - 2 ), FALSE ); <nl>  <nl> + if ( delete_last_line ) <nl> + oap -> end . lnum = curbuf -> b_ml . ml_line_count ; <nl> + <nl> n = ( oap -> end . col + 1 - ! oap -> inclusive ); <nl> if ( oap -> inclusive && delete_last_line <nl> && n > ( int ) STRLEN ( ml_get ( oap -> end . lnum )))
mmm src / normal . c <nl> ppp src / normal . c <nl> nv_brace ( cap ) <nl> clearopbeep ( cap -> oap ); <nl> else <nl> { <nl> + /* Don ' t leave the cursor on the NUL past a line */ <nl> + if ( curwin -> w_cursor . col > 0 && gchar_cursor () == NUL ) <nl> + { <nl> + -- curwin -> w_cursor . col ; <nl> + cap -> oap -> inclusive = TRUE ; <nl> + } <nl> # ifdef FEAT_VIRTUALEDIT <nl> curwin -> w_cursor . coladd = 0 ; <nl> # endifmmm src / version . c <nl> ppp src / version . c <nl> nv_brace ( cap ) <nl> clearopbeep ( cap -> oap ); <nl> else <nl> { <nl> + /* Don ' t leave the cursor on the NUL past a line */ <nl> + if ( curwin -> w_cursor . col > 0 && gchar_cursor () == NUL ) <nl> + { <nl> + -- curwin -> w_cursor . col ; <nl> + cap -> oap -> inclusive = TRUE ; <nl> + } <nl> # ifdef FEAT_VIRTUALEDIT <nl> curwin -> w_cursor . coladd = 0 ; <nl> # endif <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 190 , <nl> /**/ <nl> 189 , <nl> /**/
mmm src / normal . c <nl> ppp src / normal . c <nl> n_start_visual_mode ( int c ) <nl> VIsual_mode = c ; <nl> VIsual_active = TRUE ; <nl> VIsual_reselect = TRUE ; <nl> - trigger_modechanged (); <nl>  <nl> // Corner case : the 0 position in a tab may change when going into <nl> // virtualedit . Recalculate curwin -> w_cursor to avoid bad highlighting . <nl> n_start_visual_mode ( int c ) <nl> foldAdjustVisual (); <nl> # endif <nl>  <nl> + trigger_modechanged (); <nl> setmouse (); <nl> # ifdef FEAT_CONCEAL <nl> // Check if redraw is needed after changing the state .mmm src / version . c <nl> ppp src / version . c <nl> n_start_visual_mode ( int c ) <nl> VIsual_mode = c ; <nl> VIsual_active = TRUE ; <nl> VIsual_reselect = TRUE ; <nl> - trigger_modechanged (); <nl>  <nl> // Corner case : the 0 position in a tab may change when going into <nl> // virtualedit . Recalculate curwin -> w_cursor to avoid bad highlighting . <nl> n_start_visual_mode ( int c ) <nl> foldAdjustVisual (); <nl> # endif <nl>  <nl> + trigger_modechanged (); <nl> setmouse (); <nl> # ifdef FEAT_CONCEAL <nl> // Check if redraw is needed after changing the state . <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3610 , <nl> /**/ <nl> 3609 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4233 , <nl> /**/ <nl> 4232 , <nl> /**/mmm src / getchar . c <nl> ppp src / getchar . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4233 , <nl> /**/ <nl> 4232 , <nl> /**/ <nl> add_buff ( <nl> static void <nl> delete_buff_tail ( buffheader_T * buf , int slen ) <nl> { <nl> - int len = ( int ) STRLEN ( buf -> bh_curr -> b_str ); <nl> + int len ; <nl>  <nl> + if ( buf -> bh_curr == NULL || buf -> bh_curr -> b_str == NULL ) <nl> + return ; // nothing to delete <nl> + len = ( int ) STRLEN ( buf -> bh_curr -> b_str ); <nl> if ( len >= slen ) <nl> { <nl> buf -> bh_curr -> b_str [ len - slen ] = NUL ;
mmm src / buffer . c <nl> ppp src / buffer . c <nl> buflist_match ( <nl>  <nl> // First try the short file name , then the long file name . <nl> match = fname_match ( rmp , buf -> b_sfname , ignore_case ); <nl> - if ( match == NULL ) <nl> + if ( match == NULL && rmp -> regprog != NULL ) <nl> match = fname_match ( rmp , buf -> b_ffname , ignore_case ); <nl>  <nl> return match ;mmm src / version . c <nl> ppp src / version . c <nl> buflist_match ( <nl>  <nl> // First try the short file name , then the long file name . <nl> match = fname_match ( rmp , buf -> b_sfname , ignore_case ); <nl> - if ( match == NULL ) <nl> + if ( match == NULL && rmp -> regprog != NULL ) <nl> match = fname_match ( rmp , buf -> b_ffname , ignore_case ); <nl>  <nl> return match ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4938 , <nl> /**/ <nl> 4937 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 339 , <nl> /**/ <nl> 338 , <nl> /**/mmm src / gui_x11 . c <nl> ppp src / gui_x11 . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 339 , <nl> /**/ <nl> 338 , <nl> /**/ <nl> gui_x11_create_blank_mouse ( void ) <nl> { <nl> Pixmap blank_pixmap = XCreatePixmap ( gui . dpy , gui . wid , 1 , 1 , 1 ); <nl> GC gc = XCreateGC ( gui . dpy , blank_pixmap , ( unsigned long ) 0 , ( XGCValues *) 0 ); <nl> - XDrawPoint ( gui . dpy , blank_pixmap , gc , 0 , 0 ); <nl> - XFreeGC ( gui . dpy , gc ); <nl> + <nl> + if ( gc != NULL ) <nl> + { <nl> + XDrawPoint ( gui . dpy , blank_pixmap , gc , 0 , 0 ); <nl> + XFreeGC ( gui . dpy , gc ); <nl> + } <nl> return XCreatePixmapCursor ( gui . dpy , blank_pixmap , blank_pixmap , <nl> - ( XColor *)& gui . norm_pixel , ( XColor *)& gui . norm_pixel , 0 , 0 ); <nl> + ( XColor *)& gui . norm_pixel , ( XColor *)& gui . norm_pixel , 0 , 0 ); <nl> } <nl>  <nl> /*
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 102 , <nl> /**/ <nl> 101 , <nl> /**/mmm src / insexpand . c <nl> ppp src / insexpand . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 102 , <nl> /**/ <nl> 101 , <nl> /**/ <nl> ins_comp_get_next_word_or_line ( <nl> { <nl> char_u * tmp_ptr = ptr ; <nl>  <nl> - if ( compl_status_adding ()) <nl> + if ( compl_status_adding () && compl_length <= ( int ) STRLEN ( tmp_ptr )) <nl> { <nl> tmp_ptr += compl_length ; <nl> // Skip if already inside a word .
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 246 , <nl> /**/ <nl> 245 , <nl> /**/mmm src / tag . c <nl> ppp src / tag . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 246 , <nl> /**/ <nl> 245 , <nl> /**/ <nl> do_tag ( <nl> char_u * buf_ffname = curbuf -> b_ffname ; // name to use for <nl> // priority computation <nl> int use_tfu = 1 ; <nl> + char_u * tofree = NULL ; <nl>  <nl> // remember the matches for the last used tag <nl> static int num_matches = 0 ; <nl> do_tag ( <nl> * When desired match not found yet , try to find it ( and others ). <nl> */ <nl> if ( use_tagstack ) <nl> - name = tagstack [ tagstackidx ]. tagname ; <nl> + { <nl> + // make a copy , the tagstack may change in ' tagfunc ' <nl> + name = vim_strsave ( tagstack [ tagstackidx ]. tagname ); <nl> + vim_free ( tofree ); <nl> + tofree = name ; <nl> + } <nl> # if defined ( FEAT_QUICKFIX ) <nl> else if ( g_do_tagpreview != 0 ) <nl> name = ptag_entry . tagname ; <nl> end_do_tag : <nl> g_do_tagpreview = 0 ; // don ' t do tag preview next time <nl> # endif <nl>  <nl> + vim_free ( tofree ); <nl> # ifdef FEAT_CSCOPE <nl> return jumped_to_tag ; <nl> # else
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4646 , <nl> /**/ <nl> 4645 , <nl> /**/mmm src / regexp_bt . c <nl> ppp src / regexp_bt . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4646 , <nl> /**/ <nl> 4645 , <nl> /**/ <nl> regmatch ( <nl> int mark = OPERAND ( scan )[ 0 ]; <nl> int cmp = OPERAND ( scan )[ 1 ]; <nl> pos_T * pos ; <nl> + size_t col = REG_MULTI ? rex . input - rex . line : 0 ; <nl>  <nl> pos = getmark_buf ( rex . reg_buf , mark , FALSE ); <nl> + <nl> + // Line may have been freed , get it again . <nl> + if ( REG_MULTI ) <nl> + { <nl> + rex . line = reg_getline ( rex . lnum ); <nl> + rex . input = rex . line + col ; <nl> + } <nl> + <nl> if ( pos == NULL // mark doesn ' t exist <nl> || pos -> lnum <= 0 ) // mark isn ' t set in reg_buf <nl> {
mmm src / insexpand . c <nl> ppp src / insexpand . c <nl> ins_compl_infercase_gettext ( <nl> // growarray . Add the character in the next round . <nl> if ( ga_grow (& gap , IOSIZE ) == FAIL ) <nl> return ( char_u *)"[ failed ]"; <nl> + * p = NUL ; <nl> STRCPY ( gap . ga_data , IObuff ); <nl> gap . ga_len = ( int ) STRLEN ( IObuff ); <nl> }mmm src / version . c <nl> ppp src / version . c <nl> ins_compl_infercase_gettext ( <nl> // growarray . Add the character in the next round . <nl> if ( ga_grow (& gap , IOSIZE ) == FAIL ) <nl> return ( char_u *)"[ failed ]"; <nl> + * p = NUL ; <nl> STRCPY ( gap . ga_data , IObuff ); <nl> gap . ga_len = ( int ) STRLEN ( IObuff ); <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 60 , <nl> /**/ <nl> 59 , <nl> /**/
mmm src / vim . h <nl> ppp src / vim . h <nl> || defined ( FEAT_GUI_MAC ) \ <nl> || defined ( FEAT_GUI_W32 ) \ <nl> || defined ( FEAT_GUI_W16 ) \ <nl> - || defined ( FEAT_GUI_BEOS ) \ <nl> - || defined ( FEAT_GUI_AMIGA ) \ <nl> || defined ( FEAT_GUI_PHOTON ) \ <nl> || defined ( FEAT_GUI_KDE ) <nl> # if ! defined ( FEAT_GUI ) && ! defined ( NO_X11_INCLUDES ) <nl> typedef struct VimClipboard <nl> int_u format ; /* Vim ' s own special clipboard format */ <nl> int_u format_raw ; /* Vim ' s raw text clipboard format */ <nl> # endif <nl> -# ifdef FEAT_GUI_BEOS <nl> - /* no clipboard at the moment */ <nl> -# endif <nl> } VimClipboard ; <nl> # else <nl> typedef int VimClipboard ; /* This is required for the prototypes . */
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 46 , <nl> /**/ <nl> 45 , <nl> /**/mmm src / insexpand . c <nl> ppp src / insexpand . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 46 , <nl> /**/ <nl> 45 , <nl> /**/ <nl> ins_compl_add ( <nl> { <nl> if (! match_at_original_text ( match ) <nl> && STRNCMP ( match -> cp_str , str , len ) == 0 <nl> - && match -> cp_str [ len ] == NUL ) <nl> + && (( int ) STRLEN ( match -> cp_str ) <= len <nl> + || match -> cp_str [ len ] == NUL )) <nl> return NOTDONE ; <nl> match = match -> cp_next ; <nl> } while ( match != NULL && ! is_first_match ( match ));
mmm src / help . c <nl> ppp src / help . c <nl> find_help_tags ( <nl> || ( vim_strchr (( char_u *)"% _z @", arg [ 1 ]) != NULL <nl> && arg [ 2 ] != NUL ))) <nl> { <nl> - STRCPY ( d , "/\\\\"); <nl> - STRCPY ( d + 3 , arg + 1 ); <nl> + vim_snprintf (( char *) d , IOSIZE , "/\\\\% s ", arg + 1 ); <nl> // Check for "/\\ _ $", should be "/\\ _ \$" <nl> if ( d [ 3 ] == ' _ ' && d [ 4 ] == '$') <nl> STRCPY ( d + 4 , "\\$");mmm src / version . c <nl> ppp src / version . c <nl> find_help_tags ( <nl> || ( vim_strchr (( char_u *)"% _z @", arg [ 1 ]) != NULL <nl> && arg [ 2 ] != NUL ))) <nl> { <nl> - STRCPY ( d , "/\\\\"); <nl> - STRCPY ( d + 3 , arg + 1 ); <nl> + vim_snprintf (( char *) d , IOSIZE , "/\\\\% s ", arg + 1 ); <nl> // Check for "/\\ _ $", should be "/\\ _ \$" <nl> if ( d [ 3 ] == ' _ ' && d [ 4 ] == '$') <nl> STRCPY ( d + 4 , "\\$"); <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3669 , <nl> /**/ <nl> 3668 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5164 , <nl> /**/ <nl> 5163 , <nl> /**/mmm src / diff . c <nl> ppp src / diff . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5164 , <nl> /**/ <nl> 5163 , <nl> /**/ <nl> diff_mark_adjust_tp ( <nl> // 2 . 3 . 4 . 5 .: inserted / deleted lines touching this diff . <nl> if ( deleted > 0 ) <nl> { <nl> + off = 0 ; <nl> if ( dp -> df_lnum [ idx ] >= line1 ) <nl> { <nl> - off = dp -> df_lnum [ idx ] - lnum_deleted ; <nl> if ( last <= line2 ) <nl> { <nl> // 4 . delete all lines of diff <nl> diff_mark_adjust_tp ( <nl> else <nl> { <nl> // 5 . delete lines at or just before top of diff <nl> + off = dp -> df_lnum [ idx ] - lnum_deleted ; <nl> n = off ; <nl> dp -> df_count [ idx ] -= line2 - dp -> df_lnum [ idx ] + 1 ; <nl> check_unchanged = TRUE ; <nl> diff_mark_adjust_tp ( <nl> } <nl> else <nl> { <nl> - off = 0 ; <nl> if ( last < line2 ) <nl> { <nl> // 2 . delete at end of diff
mmm src / ops . c <nl> ppp src / ops . c <nl> op_replace ( oparg_T * oap , int c ) <nl>  <nl> while ( LTOREQ_POS ( curwin -> w_cursor , oap -> end )) <nl> { <nl> + int done = FALSE ; <nl> + <nl> n = gchar_cursor (); <nl> if ( n != NUL ) <nl> { <nl> op_replace ( oparg_T * oap , int c ) <nl> if ( curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> oap -> end . col += new_byte_len - old_byte_len ; <nl> replace_character ( c ); <nl> + done = TRUE ; <nl> } <nl> else <nl> { <nl> op_replace ( oparg_T * oap , int c ) <nl> if ( curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> getvpos (& oap -> end , end_vcol ); <nl> } <nl> - PBYTE ( curwin -> w_cursor , c ); <nl> + // with " coladd " set may move to just after a TAB <nl> + if ( gchar_cursor () != NUL ) <nl> + { <nl> + PBYTE ( curwin -> w_cursor , c ); <nl> + done = TRUE ; <nl> + } <nl> } <nl> } <nl> - else if ( virtual_op && curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> + if (! done && virtual_op && curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> { <nl> int virtcols = oap -> end . coladd ; <nl> mmm src / version . c <nl> ppp src / version . c <nl> op_replace ( oparg_T * oap , int c ) <nl>  <nl> while ( LTOREQ_POS ( curwin -> w_cursor , oap -> end )) <nl> { <nl> + int done = FALSE ; <nl> + <nl> n = gchar_cursor (); <nl> if ( n != NUL ) <nl> { <nl> op_replace ( oparg_T * oap , int c ) <nl> if ( curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> oap -> end . col += new_byte_len - old_byte_len ; <nl> replace_character ( c ); <nl> + done = TRUE ; <nl> } <nl> else <nl> { <nl> op_replace ( oparg_T * oap , int c ) <nl> if ( curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> getvpos (& oap -> end , end_vcol ); <nl> } <nl> - PBYTE ( curwin -> w_cursor , c ); <nl> + // with " coladd " set may move to just after a TAB <nl> + if ( gchar_cursor () != NUL ) <nl> + { <nl> + PBYTE ( curwin -> w_cursor , c ); <nl> + done = TRUE ; <nl> + } <nl> } <nl> } <nl> - else if ( virtual_op && curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> + if (! done && virtual_op && curwin -> w_cursor . lnum == oap -> end . lnum ) <nl> { <nl> int virtcols = oap -> end . coladd ; <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 483 , <nl> /**/ <nl> 482 , <nl> /**/
mmm src / spell . c <nl> ppp src / spell . c <nl> did_set_spelllang ( win_T * wp ) <nl> { <nl> spell_load_lang ( lang ); <nl> // SpellFileMissing autocommands may do anything , including <nl> - // destroying the buffer we are using ... <nl> - if (! bufref_valid (& bufref )) <nl> + // destroying the buffer we are using or closing the window . <nl> + if (! bufref_valid (& bufref ) || ! win_valid_any_tab ( wp )) <nl> { <nl> ret_msg = N_ ( e_spellfilemising_autocommand_deleted_buffer ); <nl> goto theend ;mmm src / version . c <nl> ppp src / version . c <nl> did_set_spelllang ( win_T * wp ) <nl> { <nl> spell_load_lang ( lang ); <nl> // SpellFileMissing autocommands may do anything , including <nl> - // destroying the buffer we are using ... <nl> - if (! bufref_valid (& bufref )) <nl> + // destroying the buffer we are using or closing the window . <nl> + if (! bufref_valid (& bufref ) || ! win_valid_any_tab ( wp )) <nl> { <nl> ret_msg = N_ ( e_spellfilemising_autocommand_deleted_buffer ); <nl> goto theend ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 882 , <nl> /**/ <nl> 881 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 25 , <nl> /**/ <nl> 24 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 25 , <nl> /**/ <nl> 24 , <nl> /**/ <nl> parse_command_modifiers ( <nl> size_t len = STRLEN ( cmd_start ); <nl>  <nl> // Special case : empty command uses "+": <nl> - // "'<,'> mods " -> " mods '<,'>+ <nl> + // "'<,'> mods " -> " mods *+ <nl> + // Use "*" instead of "'<,'>" to avoid the command getting <nl> + // longer , in case is was allocated . <nl> mch_memmove ( orig_cmd , cmd_start , len ); <nl> - STRCPY ( orig_cmd + len , "'<,'>+"); <nl> + STRCPY ( orig_cmd + len , " *+"); <nl> } <nl> else <nl> {
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1378 , <nl> /**/ <nl> 1377 , <nl> /**/mmm src / register . c <nl> ppp src / register . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1378 , <nl> /**/ <nl> 1377 , <nl> /**/ <nl> op_yank ( oparg_T * oap , int deleting , int mess ) <nl> // double - count it . <nl> bd . startspaces = ( ce - cs + 1 ) <nl> - oap -> start . coladd ; <nl> + if ( bd . startspaces < 0 ) <nl> + bd . startspaces = 0 ; <nl> startcol ++; <nl> } <nl> }
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 389 , <nl> /**/ <nl> 388 , <nl> /**/mmm src / tag . c <nl> ppp src / tag . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 389 , <nl> /**/ <nl> 388 , <nl> /**/ <nl> do_tag ( <nl> max_num_matches = MAXCOL ; // If less than max_num_matches <nl> // found : all matches found . <nl>  <nl> + // A tag function may do anything , which may cause various <nl> + // information to become invalid . At least check for the tagstack <nl> + // to still be the same . <nl> + if ( tagstack != curwin -> w_tagstack ) <nl> + { <nl> + emsg ( _ ( e_window_unexpectedly_close_while_searching_for_tags )); <nl> + FreeWild ( new_num_matches , new_matches ); <nl> + break ; <nl> + } <nl> + <nl> // If there already were some matches for the same name , move them <nl> // to the start . Avoids that the order changes when using <nl> // ": tnext " and jumping to another file .mmm src / errors . h <nl> ppp src / errors . h <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 389 , <nl> /**/ <nl> 388 , <nl> /**/ <nl> do_tag ( <nl> max_num_matches = MAXCOL ; // If less than max_num_matches <nl> // found : all matches found . <nl>  <nl> + // A tag function may do anything , which may cause various <nl> + // information to become invalid . At least check for the tagstack <nl> + // to still be the same . <nl> + if ( tagstack != curwin -> w_tagstack ) <nl> + { <nl> + emsg ( _ ( e_window_unexpectedly_close_while_searching_for_tags )); <nl> + FreeWild ( new_num_matches , new_matches ); <nl> + break ; <nl> + } <nl> + <nl> // If there already were some matches for the same name , move them <nl> // to the start . Avoids that the order changes when using <nl> // ": tnext " and jumping to another file . <nl> EXTERN char e_non_null_dict_required_for_argument_nr [] <nl> EXTERN char e_non_null_list_required_for_argument_nr [] <nl> INIT (= N_ (" E1298 : Non - NULL List required for argument % d ")); <nl> # endif <nl> + EXTERN char e_window_unexpectedly_close_while_searching_for_tags [] <nl> + INIT (= N_ (" E1299 : Window unexpectedly closed while searching for tags "));
mmm src / diff . c <nl> ppp src / diff . c <nl> diff_buf_delete ( buf_T * buf ) <nl> tp -> tp_diffbuf [ i ] = NULL ; <nl> tp -> tp_diff_invalid = TRUE ; <nl> if ( tp == curtab ) <nl> - diff_redraw ( TRUE ); <nl> + { <nl> + // don ' t redraw right away , more might change or buffer state <nl> + // is invalid right now <nl> + need_diff_redraw = TRUE ; <nl> + redraw_later ( VALID ); <nl> + } <nl> } <nl> } <nl> } <nl> diff_redraw ( <nl>  <nl> need_diff_redraw = FALSE ; <nl> FOR_ALL_WINDOWS ( wp ) <nl> - if ( wp -> w_p_diff ) <nl> + // when closing windows or wiping buffers skip invalid window <nl> + if ( wp -> w_p_diff && buf_valid ( wp -> w_buffer )) <nl> { <nl> redraw_win_later ( wp , SOME_VALID ); <nl> if ( wp != curwin )mmm src / version . c <nl> ppp src / version . c <nl> diff_buf_delete ( buf_T * buf ) <nl> tp -> tp_diffbuf [ i ] = NULL ; <nl> tp -> tp_diff_invalid = TRUE ; <nl> if ( tp == curtab ) <nl> - diff_redraw ( TRUE ); <nl> + { <nl> + // don ' t redraw right away , more might change or buffer state <nl> + // is invalid right now <nl> + need_diff_redraw = TRUE ; <nl> + redraw_later ( VALID ); <nl> + } <nl> } <nl> } <nl> } <nl> diff_redraw ( <nl>  <nl> need_diff_redraw = FALSE ; <nl> FOR_ALL_WINDOWS ( wp ) <nl> - if ( wp -> w_p_diff ) <nl> + // when closing windows or wiping buffers skip invalid window <nl> + if ( wp -> w_p_diff && buf_valid ( wp -> w_buffer )) <nl> { <nl> redraw_win_later ( wp , SOME_VALID ); <nl> if ( wp != curwin ) <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5163 , <nl> /**/ <nl> 5162 , <nl> /**/
mmm src / eval . c <nl> ppp src / eval . c <nl> num_divide ( varnumber_T n1 , varnumber_T n2 , int * failed ) <nl> else <nl> result = VARNUM_MAX ; <nl> } <nl> + else if ( n1 == VARNUM_MIN && n2 == - 1 ) <nl> + { <nl> + // specific case : trying to do VARNUM_MIN / - 1 results in a positive <nl> + // number that doesn ' t fit in varnumber_T and causes an FPE <nl> + result = VARNUM_MAX ; <nl> + } <nl> else <nl> result = n1 / n2 ; <nl>  <nl> var2fpos ( <nl> } <nl>  <nl> /* <nl> - * Convert list in " arg " into position " psop " and optional file number " fnump ". <nl> + * Convert list in " arg " into position " posp " and optional file number " fnump ". <nl> * When " fnump " is NULL there is no file number , only 3 items : [ lnum , col , off ] <nl> * Note that the column is passed on as - is , the caller may want to decrement <nl> * it to use 1 for the first column .mmm src / version . c <nl> ppp src / version . c <nl> num_divide ( varnumber_T n1 , varnumber_T n2 , int * failed ) <nl> else <nl> result = VARNUM_MAX ; <nl> } <nl> + else if ( n1 == VARNUM_MIN && n2 == - 1 ) <nl> + { <nl> + // specific case : trying to do VARNUM_MIN / - 1 results in a positive <nl> + // number that doesn ' t fit in varnumber_T and causes an FPE <nl> + result = VARNUM_MAX ; <nl> + } <nl> else <nl> result = n1 / n2 ; <nl>  <nl> var2fpos ( <nl> } <nl>  <nl> /* <nl> - * Convert list in " arg " into position " psop " and optional file number " fnump ". <nl> + * Convert list in " arg " into position " posp " and optional file number " fnump ". <nl> * When " fnump " is NULL there is no file number , only 3 items : [ lnum , col , off ] <nl> * Note that the column is passed on as - is , the caller may want to decrement <nl> * it to use 1 for the first column . <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 804 , <nl> /**/ <nl> 803 , <nl> /**/
mmm src / quickfix . c <nl> ppp src / quickfix . c <nl> qf_update_buffer ( qf_info_T * qi , qfline_T * old_last ) <nl> qf_winid = win -> w_id ; <nl> } <nl>  <nl> + // autocommands may cause trouble <nl> + incr_quickfix_busy (); <nl> + <nl> if ( old_last == NULL ) <nl> // set curwin / curbuf to buf and save a few things <nl> aucmd_prepbuf (& aco , buf ); <nl> qf_update_buffer ( qf_info_T * qi , qfline_T * old_last ) <nl> // when the added lines are not visible . <nl> if (( win = qf_find_win ( qi )) != NULL && old_line_count < win -> w_botline ) <nl> redraw_buf_later ( buf , UPD_NOT_VALID ); <nl> + <nl> + // always called after incr_quickfix_busy () <nl> + decr_quickfix_busy (); <nl> } <nl> } <nl> mmm src / version . c <nl> ppp src / version . c <nl> qf_update_buffer ( qf_info_T * qi , qfline_T * old_last ) <nl> qf_winid = win -> w_id ; <nl> } <nl>  <nl> + // autocommands may cause trouble <nl> + incr_quickfix_busy (); <nl> + <nl> if ( old_last == NULL ) <nl> // set curwin / curbuf to buf and save a few things <nl> aucmd_prepbuf (& aco , buf ); <nl> qf_update_buffer ( qf_info_T * qi , qfline_T * old_last ) <nl> // when the added lines are not visible . <nl> if (( win = qf_find_win ( qi )) != NULL && old_line_count < win -> w_botline ) <nl> redraw_buf_later ( buf , UPD_NOT_VALID ); <nl> + <nl> + // always called after incr_quickfix_busy () <nl> + decr_quickfix_busy (); <nl> } <nl> } <nl>  <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 805 , <nl> /**/ <nl> 804 , <nl> /**/
mmm src / vim9class . c <nl> ppp src / vim9class . c <nl> class_object_index ( <nl> cl = rettv -> vval . v_object -> obj_class ; <nl> } <nl>  <nl> + if ( cl == NULL ) <nl> + { <nl> + emsg ( _ ( e_incomplete_type )); <nl> + return FAIL ; <nl> + } <nl> + <nl> if (* name_end == '(') <nl> { <nl> int on_class = rettv -> v_type == VAR_CLASS ;mmm src / version . c <nl> ppp src / version . c <nl> class_object_index ( <nl> cl = rettv -> vval . v_object -> obj_class ; <nl> } <nl>  <nl> + if ( cl == NULL ) <nl> + { <nl> + emsg ( _ ( e_incomplete_type )); <nl> + return FAIL ; <nl> + } <nl> + <nl> if (* name_end == '(') <nl> { <nl> int on_class = rettv -> v_type == VAR_CLASS ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1402 , <nl> /**/ <nl> 1401 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1531 , <nl> /**/ <nl> 1530 , <nl> /**/mmm src / register . c <nl> ppp src / register . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1531 , <nl> /**/ <nl> 1530 , <nl> /**/ <nl> get_register ( <nl> if ( copy ) <nl> { <nl> // If we run out of memory some or all of the lines are empty . <nl> - if ( reg -> y_size == 0 ) <nl> + if ( reg -> y_size == 0 || y_current -> y_array == NULL ) <nl> reg -> y_array = NULL ; <nl> else <nl> reg -> y_array = ALLOC_MULT ( char_u *, reg -> y_size );
mmm src / vim9cmds . c <nl> ppp src / vim9cmds . c <nl> compile_lock_unlock ( <nl> size_t len ; <nl> char_u * buf ; <nl> isntype_T isn = ISN_EXEC ; <nl> + char * cmd = eap -> cmdidx == CMD_lockvar ? " lockvar " : " unlockvar "; <nl>  <nl> if ( cctx -> ctx_skip == SKIP_YES ) <nl> return OK ; <nl>  <nl> + if (* p == NUL ) <nl> + { <nl> + semsg ( _ ( e_argument_required_for_str ), cmd ); <nl> + return FAIL ; <nl> + } <nl> + <nl> // Cannot use : lockvar and : unlockvar on local variables . <nl> if ( p [ 1 ] != ':') <nl> { <nl> compile_lock_unlock ( <nl> ret = FAIL ; <nl> else <nl> { <nl> - char * cmd = eap -> cmdidx == CMD_lockvar ? " lockvar " : " unlockvar "; <nl> - <nl> if ( deep < 0 ) <nl> vim_snprintf (( char *) buf , len , "% s ! % s ", cmd , p ); <nl> elsemmm src / version . c <nl> ppp src / version . c <nl> compile_lock_unlock ( <nl> size_t len ; <nl> char_u * buf ; <nl> isntype_T isn = ISN_EXEC ; <nl> + char * cmd = eap -> cmdidx == CMD_lockvar ? " lockvar " : " unlockvar "; <nl>  <nl> if ( cctx -> ctx_skip == SKIP_YES ) <nl> return OK ; <nl>  <nl> + if (* p == NUL ) <nl> + { <nl> + semsg ( _ ( e_argument_required_for_str ), cmd ); <nl> + return FAIL ; <nl> + } <nl> + <nl> // Cannot use : lockvar and : unlockvar on local variables . <nl> if ( p [ 1 ] != ':') <nl> { <nl> compile_lock_unlock ( <nl> ret = FAIL ; <nl> else <nl> { <nl> - char * cmd = eap -> cmdidx == CMD_lockvar ? " lockvar " : " unlockvar "; <nl> - <nl> if ( deep < 0 ) <nl> vim_snprintf (( char *) buf , len , "% s ! % s ", cmd , p ); <nl> else <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 211 , <nl> /**/ <nl> 210 , <nl> /**/
mmm src / register . c <nl> ppp src / register . c <nl> do_put ( <nl> vim_memset ( ptr , ' ', ( size_t ) spaces ); <nl> ptr += spaces ; <nl> } <nl> + else <nl> + totlen -= spaces ; // didn ' t use these spaces <nl> } <nl>  <nl> // may insert some spaces after the new textmmm src / version . c <nl> ppp src / version . c <nl> do_put ( <nl> vim_memset ( ptr , ' ', ( size_t ) spaces ); <nl> ptr += spaces ; <nl> } <nl> + else <nl> + totlen -= spaces ; // didn ' t use these spaces <nl> } <nl>  <nl> // may insert some spaces after the new text <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 11 , <nl> /**/ <nl> 10 , <nl> /**/
mmm src / vim9compile . c <nl> ppp src / vim9compile . c <nl> compile_def_function ( <nl> cmd = ea . cmd ; <nl> if ((* cmd != '$' || starts_with_colon ) <nl> && ( starts_with_colon || !(* cmd == '\'' <nl> - || ( cmd [ 0 ] == cmd [ 1 ] && (* cmd == '+' || * cmd == '-'))))) <nl> + || ( cmd [ 0 ] != NUL && cmd [ 0 ] == cmd [ 1 ] <nl> + && (* cmd == '+' || * cmd == '-'))))) <nl> { <nl> ea . cmd = skip_range ( ea . cmd , TRUE , NULL ); <nl> if ( ea . cmd > cmd )mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> compile_def_function ( <nl> cmd = ea . cmd ; <nl> if ((* cmd != '$' || starts_with_colon ) <nl> && ( starts_with_colon || !(* cmd == '\'' <nl> - || ( cmd [ 0 ] == cmd [ 1 ] && (* cmd == '+' || * cmd == '-'))))) <nl> + || ( cmd [ 0 ] != NUL && cmd [ 0 ] == cmd [ 1 ] <nl> + && (* cmd == '+' || * cmd == '-'))))) <nl> { <nl> ea . cmd = skip_range ( ea . cmd , TRUE , NULL ); <nl> if ( ea . cmd > cmd ) <nl> find_ex_command ( <nl> } <nl>  <nl> // Check for "++ nr " and "-- nr ". <nl> - if ( p == eap -> cmd && p [ 0 ] == p [ 1 ] && (* p == '+' || * p == '-')) <nl> + if ( p == eap -> cmd && p [ 0 ] != NUL && p [ 0 ] == p [ 1 ] <nl> + && (* p == '+' || * p == '-')) <nl> { <nl> eap -> cmdidx = * p == '+' ? CMD_increment : CMD_decrement ; <nl> return eap -> cmd + 2 ;mmm src / version . c <nl> ppp src / version . c <nl> compile_def_function ( <nl> cmd = ea . cmd ; <nl> if ((* cmd != '$' || starts_with_colon ) <nl> && ( starts_with_colon || !(* cmd == '\'' <nl> - || ( cmd [ 0 ] == cmd [ 1 ] && (* cmd == '+' || * cmd == '-'))))) <nl> + || ( cmd [ 0 ] != NUL && cmd [ 0 ] == cmd [ 1 ] <nl> + && (* cmd == '+' || * cmd == '-'))))) <nl> { <nl> ea . cmd = skip_range ( ea . cmd , TRUE , NULL ); <nl> if ( ea . cmd > cmd ) <nl> find_ex_command ( <nl> } <nl>  <nl> // Check for "++ nr " and "-- nr ". <nl> - if ( p == eap -> cmd && p [ 0 ] == p [ 1 ] && (* p == '+' || * p == '-')) <nl> + if ( p == eap -> cmd && p [ 0 ] != NUL && p [ 0 ] == p [ 1 ] <nl> + && (* p == '+' || * p == '-')) <nl> { <nl> eap -> cmdidx = * p == '+' ? CMD_increment : CMD_decrement ; <nl> return eap -> cmd + 2 ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4009 , <nl> /**/ <nl> 4008 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5126 , <nl> /**/ <nl> 5125 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5126 , <nl> /**/ <nl> 5125 , <nl> /**/ <nl> do_exedit ( <nl> # endif <nl> ) <nl> { <nl> - // Can ' t edit another file when " curbuf_lock " is set . Only ": edit " <nl> - // can bring us here , others are stopped earlier . <nl> - if (* eap -> arg != NUL && curbuf_locked ()) <nl> + // Can ' t edit another file when " textlock " or " curbuf_lock " is set . <nl> + // Only ": edit " or ": script " can bring us here , others are stopped <nl> + // earlier . <nl> + if (* eap -> arg != NUL && text_or_buf_locked ()) <nl> return ; <nl>  <nl> n = readonlymode ;
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 260 , <nl> /**/ <nl> 259 , <nl> /**/mmm src / quickfix . c <nl> ppp src / quickfix . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 260 , <nl> /**/ <nl> 259 , <nl> /**/ <nl> call_qftf_func ( qf_list_T * qfl , int qf_winid , long start_idx , long end_idx ) <nl> { <nl> callback_T * cb = & qftf_cb ; <nl> list_T * qftf_list = NULL ; <nl> + static int recursive = FALSE ; <nl> + <nl> + if ( recursive ) <nl> + return NULL ; // this doesn ' t work properly recursively <nl> + recursive = TRUE ; <nl>  <nl> // If ' quickfixtextfunc ' is set , then use the user - supplied function to get <nl> // the text to display . Use the local value of ' quickfixtextfunc ' if it is <nl> call_qftf_func ( qf_list_T * qfl , int qf_winid , long start_idx , long end_idx ) <nl>  <nl> // create the dict argument <nl> if (( d = dict_alloc_lock ( VAR_FIXED )) == NULL ) <nl> + { <nl> + recursive = FALSE ; <nl> return NULL ; <nl> + } <nl> dict_add_number ( d , " quickfix ", ( long ) IS_QF_LIST ( qfl )); <nl> dict_add_number ( d , " winid ", ( long ) qf_winid ); <nl> dict_add_number ( d , " id ", ( long ) qfl -> qf_id ); <nl> call_qftf_func ( qf_list_T * qfl , int qf_winid , long start_idx , long end_idx ) <nl> dict_unref ( d ); <nl> } <nl>  <nl> + recursive = FALSE ; <nl> return qftf_list ; <nl> } <nl> 
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4895 , <nl> /**/ <nl> 4894 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4895 , <nl> /**/ <nl> 4894 , <nl> /**/ <nl> append_command ( char_u * cmd ) <nl>  <nl> STRCAT ( IObuff , ": "); <nl> d = IObuff + STRLEN ( IObuff ); <nl> - while (* s != NUL && d - IObuff < IOSIZE - 7 ) <nl> + while (* s != NUL && d - IObuff + 5 < IOSIZE ) <nl> { <nl> if ( enc_utf8 ? ( s [ 0 ] == 0xc2 && s [ 1 ] == 0xa0 ) : * s == 0xa0 ) <nl> { <nl> append_command ( char_u * cmd ) <nl> STRCPY ( d , "< a0 >"); <nl> d += 4 ; <nl> } <nl> + else if ( d - IObuff + (* mb_ptr2len )( s ) + 1 >= IOSIZE ) <nl> + break ; <nl> else <nl> MB_COPY_CHAR ( s , d ); <nl> }
mmm src / vim9cmds . c <nl> ppp src / vim9cmds . c <nl> free_locals ( cctx_T * cctx ) <nl> int <nl> check_vim9_unlet ( char_u * name ) <nl> { <nl> + if (* name == NUL ) <nl> + { <nl> + semsg ( _ ( e_argument_required_for_str ), " unlet "); <nl> + return FAIL ; <nl> + } <nl> + <nl> if ( name [ 1 ] != ':' || vim_strchr (( char_u *)" gwtb ", * name ) == NULL ) <nl> { <nl> // " unlet s : var " is allowed in legacy script .mmm src / version . c <nl> ppp src / version . c <nl> free_locals ( cctx_T * cctx ) <nl> int <nl> check_vim9_unlet ( char_u * name ) <nl> { <nl> + if (* name == NUL ) <nl> + { <nl> + semsg ( _ ( e_argument_required_for_str ), " unlet "); <nl> + return FAIL ; <nl> + } <nl> + <nl> if ( name [ 1 ] != ':' || vim_strchr (( char_u *)" gwtb ", * name ) == NULL ) <nl> { <nl> // " unlet s : var " is allowed in legacy script . <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 212 , <nl> /**/ <nl> 211 , <nl> /**/
mmm src / ex_cmds . c <nl> ppp src / ex_cmds . c <nl> ex_copy ( linenr_T line1 , linenr_T line2 , linenr_T n ) <nl> } <nl>  <nl> appended_lines_mark ( n , count ); <nl> + if ( VIsual_active ) <nl> + check_pos ( curbuf , & VIsual ); <nl>  <nl> msgmore (( long ) count ); <nl> }mmm src / version . c <nl> ppp src / version . c <nl> ex_copy ( linenr_T line1 , linenr_T line2 , linenr_T n ) <nl> } <nl>  <nl> appended_lines_mark ( n , count ); <nl> + if ( VIsual_active ) <nl> + check_pos ( curbuf , & VIsual ); <nl>  <nl> msgmore (( long ) count ); <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4215 , <nl> /**/ <nl> 4214 , <nl> /**/
mmm src / drawscreen . c <nl> ppp src / drawscreen . c <nl> win_redr_status ( win_T * wp , int ignore_pum UNUSED ) <nl> p = NameBuff ; <nl> len = ( int ) STRLEN ( p ); <nl>  <nl> - if ( bt_help ( wp -> w_buffer ) <nl> + if (( bt_help ( wp -> w_buffer ) <nl> # ifdef FEAT_QUICKFIX <nl> - || wp -> w_p_pvw <nl> + || wp -> w_p_pvw <nl> # endif <nl> - || bufIsChanged ( wp -> w_buffer ) <nl> - || wp -> w_buffer -> b_p_ro ) <nl> + || bufIsChanged ( wp -> w_buffer ) <nl> + || wp -> w_buffer -> b_p_ro ) <nl> + && len < MAXPATHL - 1 ) <nl> *( p + len ++) = ' '; <nl> if ( bt_help ( wp -> w_buffer )) <nl> {mmm src / version . c <nl> ppp src / version . c <nl> win_redr_status ( win_T * wp , int ignore_pum UNUSED ) <nl> p = NameBuff ; <nl> len = ( int ) STRLEN ( p ); <nl>  <nl> - if ( bt_help ( wp -> w_buffer ) <nl> + if (( bt_help ( wp -> w_buffer ) <nl> # ifdef FEAT_QUICKFIX <nl> - || wp -> w_p_pvw <nl> + || wp -> w_p_pvw <nl> # endif <nl> - || bufIsChanged ( wp -> w_buffer ) <nl> - || wp -> w_buffer -> b_p_ro ) <nl> + || bufIsChanged ( wp -> w_buffer ) <nl> + || wp -> w_buffer -> b_p_ro ) <nl> + && len < MAXPATHL - 1 ) <nl> *( p + len ++) = ' '; <nl> if ( bt_help ( wp -> w_buffer )) <nl> { <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4074 , <nl> /**/ <nl> 4073 , <nl> /**/
mmm src / tag . c <nl> ppp src / tag . c <nl> get_tags ( list , pat ) <nl> /* Skip field without colon . */ <nl> while (* p != NUL && * p >= ' ') <nl> ++ p ; <nl> + if (* p == NUL ) <nl> + break ; <nl> } <nl> } <nl> }mmm src / version . c <nl> ppp src / version . c <nl> get_tags ( list , pat ) <nl> /* Skip field without colon . */ <nl> while (* p != NUL && * p >= ' ') <nl> ++ p ; <nl> + if (* p == NUL ) <nl> + break ; <nl> } <nl> } <nl> } <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 6 , <nl> /**/ <nl> 5 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3741 , <nl> /**/ <nl> 3740 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 3741 , <nl> /**/ <nl> 3740 , <nl> /**/ <nl> ex_open ( exarg_T * eap ) <nl> regmatch . regprog = vim_regcomp ( eap -> arg , magic_isset () ? RE_MAGIC : 0 ); <nl> if ( regmatch . regprog != NULL ) <nl> { <nl> + // make a copy of the line , when searching for a mark it might be <nl> + // flushed <nl> + char_u * line = vim_strsave ( ml_get_curline ()); <nl> + <nl> regmatch . rm_ic = p_ic ; <nl> - p = ml_get_curline (); <nl> - if ( vim_regexec (& regmatch , p , ( colnr_T ) 0 )) <nl> - curwin -> w_cursor . col = ( colnr_T )( regmatch . startp [ 0 ] - p ); <nl> + if ( vim_regexec (& regmatch , line , ( colnr_T ) 0 )) <nl> + curwin -> w_cursor . col = ( colnr_T )( regmatch . startp [ 0 ] - line ); <nl> else <nl> emsg ( _ ( e_nomatch )); <nl> vim_regfree ( regmatch . regprog ); <nl> + vim_free ( line ); <nl> } <nl> // Move to the NUL , ignore any other arguments . <nl> eap -> arg += STRLEN ( eap -> arg );
mmm src / move . c <nl> ppp src / move . c <nl> scrolldown ( <nl> col -= width1 ; <nl> ++ row ; <nl> } <nl> - if ( col > width2 ) <nl> + if ( col > width2 && width2 > 0 ) <nl> { <nl> row += col / width2 ; <nl> col = col % width2 ;mmm src / version . c <nl> ppp src / version . c <nl> scrolldown ( <nl> col -= width1 ; <nl> ++ row ; <nl> } <nl> - if ( col > width2 ) <nl> + if ( col > width2 && width2 > 0 ) <nl> { <nl> row += col / width2 ; <nl> col = col % width2 ; <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 1367 , <nl> /**/ <nl> 1366 , <nl> /**/
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5160 , <nl> /**/ <nl> 5159 , <nl> /**/mmm src / term . c <nl> ppp src / term . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5160 , <nl> /**/ <nl> 5159 , <nl> /**/ <nl> check_shellsize ( void ) <nl> if ( Rows < min_rows ()) // need room for one window and command line <nl> Rows = min_rows (); <nl> limit_screen_size (); <nl> + <nl> + // make sure these values are not invalid <nl> + if ( cmdline_row >= Rows ) <nl> + cmdline_row = Rows - 1 ; <nl> + if ( msg_row >= Rows ) <nl> + msg_row = Rows - 1 ; <nl> } <nl>  <nl> /*
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4977 , <nl> /**/ <nl> 4976 , <nl> /**/mmm src / ex_cmds . c <nl> ppp src / ex_cmds . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4977 , <nl> /**/ <nl> 4976 , <nl> /**/ <nl> ex_substitute ( exarg_T * eap ) <nl> // Save flags for recursion . They can change for e . g . <nl> // : s /^/\= execute (" s #^## gn ") <nl> subflags_save = subflags ; <nl> + <nl> + // Disallow changing text or switching window in an expression . <nl> + ++ textwinlock ; <nl> # endif <nl> // get length of substitution part <nl> sublen = vim_regsub_multi (& regmatch , <nl> sub_firstlnum - regmatch . startpos [ 0 ]. lnum , <nl> sub , sub_firstline , FALSE , magic_isset (), TRUE ); <nl> # ifdef FEAT_EVAL <nl> + -- textwinlock ; <nl> + <nl> // If getting the substitute string caused an error , don ' t do <nl> // the replacement . <nl> // Don ' t keep flags set by a recursive call . <nl> ex_substitute ( exarg_T * eap ) <nl> mch_memmove ( new_end , sub_firstline + copycol , ( size_t ) copy_len ); <nl> new_end += copy_len ; <nl>  <nl> +# ifdef FEAT_EVAL <nl> + ++ textwinlock ; <nl> +# endif <nl> ( void ) vim_regsub_multi (& regmatch , <nl> sub_firstlnum - regmatch . startpos [ 0 ]. lnum , <nl> sub , new_end , TRUE , magic_isset (), TRUE ); <nl> +# ifdef FEAT_EVAL <nl> + -- textwinlock ; <nl> +# endif <nl> sub_nsubs ++; <nl> did_sub = TRUE ; <nl> 
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5024 , <nl> /**/ <nl> 5023 , <nl> /**/mmm src / normal . c <nl> ppp src / normal . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5024 , <nl> /**/ <nl> 5023 , <nl> /**/ <nl> nv_brackets ( cmdarg_T * cap ) <nl> clearop ( cap -> oap ); <nl> else <nl> { <nl> + // Make a copy , if the line was changed it will be freed . <nl> + ptr = vim_strnsave ( ptr , len ); <nl> + if ( ptr == NULL ) <nl> + return ; <nl> + <nl> find_pattern_in_path ( ptr , 0 , len , TRUE , <nl> cap -> count0 == 0 ? ! isupper ( cap -> nchar ) : FALSE , <nl> (( cap -> nchar & 0xf ) == (' d ' & 0xf )) ? FIND_DEFINE : FIND_ANY , <nl> nv_brackets ( cmdarg_T * cap ) <nl> islower ( cap -> nchar ) ? ACTION_SHOW : ACTION_GOTO , <nl> cap -> cmdchar == ']' ? curwin -> w_cursor . lnum + 1 : ( linenr_T ) 1 , <nl> ( linenr_T ) MAXLNUM ); <nl> + vim_free ( ptr ); <nl> curwin -> w_set_curswant = TRUE ; <nl> } <nl> }
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 218 , <nl> /**/ <nl> 217 , <nl> /**/mmm src / edit . c <nl> ppp src / edit . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 218 , <nl> /**/ <nl> 217 , <nl> /**/ <nl> edit_unputchar ( void ) <nl> * Only works when cursor is in the line that changes . <nl> */ <nl> void <nl> - display_dollar ( colnr_T col ) <nl> + display_dollar ( colnr_T col_arg ) <nl> { <nl> + colnr_T col = col_arg < 0 ? 0 : col_arg ; <nl> colnr_T save_col ; <nl>  <nl> if (! redrawing ())
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 2136 , <nl> /**/ <nl> 2135 , <nl> /**/mmm src / window . c <nl> ppp src / window . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 2136 , <nl> /**/ <nl> 2135 , <nl> /**/ <nl> win_enter_ext ( <nl> # ifdef FEAT_JOB_CHANNEL <nl> entering_window ( curwin ); <nl> # endif <nl> + // Careful : autocommands may close the window and make " wp " invalid <nl> if ( trigger_new_autocmds ) <nl> apply_autocmds ( EVENT_WINNEW , NULL , NULL , FALSE , curbuf ); <nl> if ( trigger_enter_autocmds ) <nl> win_enter_ext ( <nl> # endif <nl> curwin -> w_redr_status = TRUE ; <nl> # ifdef FEAT_TERMINAL <nl> - if ( bt_terminal ( wp -> w_buffer )) <nl> + if ( bt_terminal ( curwin -> w_buffer )) <nl> // terminal is likely in another mode <nl> redraw_mode = TRUE ; <nl> # endif
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4899 , <nl> /**/ <nl> 4898 , <nl> /**/mmm src / ex_getln . c <nl> ppp src / ex_getln . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 4899 , <nl> /**/ <nl> 4898 , <nl> /**/ <nl> cmdline_erase_chars ( <nl> { <nl> while ( p > ccline . cmdbuff && vim_isspace ( p [- 1 ])) <nl> -- p ; <nl> - i = vim_iswordc ( p [- 1 ]); <nl> - while ( p > ccline . cmdbuff && ! vim_isspace ( p [- 1 ]) <nl> - && vim_iswordc ( p [- 1 ]) == i ) <nl> - -- p ; <nl> + if ( p > ccline . cmdbuff ) <nl> + { <nl> + i = vim_iswordc ( p [- 1 ]); <nl> + while ( p > ccline . cmdbuff && ! vim_isspace ( p [- 1 ]) <nl> + && vim_iswordc ( p [- 1 ]) == i ) <nl> + -- p ; <nl> + } <nl> } <nl> else <nl> -- p ;
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 614 , <nl> /**/ <nl> 613 , <nl> /**/mmm src / spell . c <nl> ppp src / spell . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 614 , <nl> /**/ <nl> 613 , <nl> /**/ <nl> spell_load_lang ( char_u * lang ) <nl> sl . sl_slang = NULL ; <nl> sl . sl_nobreak = FALSE ; <nl>  <nl> + // Disallow deleting the current buffer . Autocommands can do weird things <nl> + // and cause " lang " to be freed . <nl> + ++ curbuf -> b_locked ; <nl> + <nl> // We may retry when no spell file is found for the language , an <nl> // autocommand may load it then . <nl> for ( round = 1 ; round <= 2 ; ++ round ) <nl> spell_load_lang ( char_u * lang ) <nl> STRCPY ( fname_enc + STRLEN ( fname_enc ) - 3 , " add . spl "); <nl> do_in_runtimepath ( fname_enc , DIP_ALL , spell_load_cb , & sl ); <nl> } <nl> + <nl> + -- curbuf -> b_locked ; <nl> } <nl>  <nl> /*mmm src / buffer . c <nl> ppp src / buffer . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 614 , <nl> /**/ <nl> 613 , <nl> /**/ <nl> spell_load_lang ( char_u * lang ) <nl> sl . sl_slang = NULL ; <nl> sl . sl_nobreak = FALSE ; <nl>  <nl> + // Disallow deleting the current buffer . Autocommands can do weird things <nl> + // and cause " lang " to be freed . <nl> + ++ curbuf -> b_locked ; <nl> + <nl> // We may retry when no spell file is found for the language , an <nl> // autocommand may load it then . <nl> for ( round = 1 ; round <= 2 ; ++ round ) <nl> spell_load_lang ( char_u * lang ) <nl> STRCPY ( fname_enc + STRLEN ( fname_enc ) - 3 , " add . spl "); <nl> do_in_runtimepath ( fname_enc , DIP_ALL , spell_load_cb , & sl ); <nl> } <nl> + <nl> + -- curbuf -> b_locked ; <nl> } <nl>  <nl> /* <nl> can_unload_buffer ( buf_T * buf ) <nl> } <nl> } <nl> if (! can_unload ) <nl> - semsg ( _ ( e_attempt_to_delete_buffer_that_is_in_use_str ), buf -> b_fname ); <nl> + { <nl> + char_u * fname = buf -> b_fname != NULL ? buf -> b_fname : buf -> b_ffname ; <nl> + <nl> + semsg ( _ ( e_attempt_to_delete_buffer_that_is_in_use_str ), <nl> + fname != NULL ? fname : ( char_u *)"[ No Name ]"); <nl> + } <nl> return can_unload ; <nl> } <nl> 
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 105 , <nl> /**/ <nl> 104 , <nl> /**/mmm src / regexp . c <nl> ppp src / regexp . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 105 , <nl> /**/ <nl> 104 , <nl> /**/ <nl> cstrchr ( char_u * s , int c ) <nl> { <nl> if ( enc_utf8 && c > 0x80 ) <nl> { <nl> - if ( utf_fold ( utf_ptr2char ( p )) == cc ) <nl> + int uc = utf_ptr2char ( p ); <nl> + <nl> + // Do not match an illegal byte . E . g . 0xff matches 0xc3 0xbf , <nl> + // not 0xff . <nl> + if (( uc < 0x80 || uc != * p ) && utf_fold ( uc ) == cc ) <nl> return p ; <nl> } <nl> else if (* p == c || * p == cc )
mmm src / version . c <nl> ppp src / version . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5150 , <nl> /**/ <nl> 5149 , <nl> /**/mmm src / ex_docmd . c <nl> ppp src / ex_docmd . c <nl> static char *( features []) = <nl>  <nl> static int included_patches [] = <nl> { /* Add new patch number below this line */ <nl> +/**/ <nl> + 5150 , <nl> /**/ <nl> 5149 , <nl> /**/ <nl> parse_cmd_address ( exarg_T * eap , char ** errormsg , int silent ) <nl> curwin -> w_cursor . lnum = eap -> line2 ; <nl>  <nl> // Don ' t leave the cursor on an illegal line or column , but do <nl> - // accept zero as address , so 0 ;/ PATTERN / works correctly . <nl> + // accept zero as address , so 0 ;/ PATTERN / works correctly <nl> + // ( where zero usually means to use the first line ). <nl> // Check the cursor position before returning . <nl> if ( eap -> line2 > 0 ) <nl> check_cursor (); <nl> + else <nl> + check_cursor_col (); <nl> need_check_cursor = TRUE ; <nl> } <nl> }
mmm src / daemon / protocols / lldp . c <nl> ppp src / daemon / protocols / lldp . c <nl> lldp_decode ( struct lldpd * cfg , char * frame , int s , <nl> case LLDP_TLV_MGMT_ADDR : <nl> CHECK_TLV_SIZE ( 1 , " Management address "); <nl> addr_str_length = PEEK_UINT8 ; <nl> + if ( addr_str_length > sizeof ( addr_str_buffer )) { <nl> + log_warnx (" lldp ", " too large management address on % s ", <nl> + hardware -> h_ifname ); <nl> + goto malformed ; <nl> + } <nl> CHECK_TLV_SIZE ( 1 + addr_str_length , " Management address "); <nl> PEEK_BYTES ( addr_str_buffer , addr_str_length ); <nl> addr_length = addr_str_length - 1 ; <nl> lldp_decode ( struct lldpd * cfg , char * frame , int s , <nl> CHECK_TLV_SIZE ( 1 + addr_str_length + 5 , " Management address "); <nl> iface_subtype = PEEK_UINT8 ; <nl> iface_number = PEEK_UINT32 ; <nl> - <nl> + <nl> af = lldpd_af_from_lldp_proto ( addr_family ); <nl> if ( af == LLDPD_AF_UNSPEC ) <nl> break ; <nl> lldp_decode ( struct lldpd * cfg , char * frame , int s , <nl> TAILQ_INSERT_TAIL (& chassis -> c_mgmt , mgmt , m_entries ); <nl> break ; <nl> case LLDP_TLV_ORG : <nl> - CHECK_TLV_SIZE ( 4 , " Organisational "); <nl> + CHECK_TLV_SIZE ( 1 + ( int ) sizeof ( orgid ), " Organisational "); <nl> PEEK_BYTES ( orgid , sizeof ( orgid )); <nl> tlv_subtype = PEEK_UINT8 ; <nl> if ( memcmp ( dot1 , orgid , sizeof ( orgid )) == 0 ) {
mmm modules / pico_ipv4 . c <nl> ppp modules / pico_ipv4 . c <nl> static int pico_ipv4_process_in ( struct pico_stack * S , struct pico_protocol * self <nl> f -> transport_hdr = (( uint8_t *) f -> net_hdr ) + PICO_SIZE_IP4HDR + option_len ; <nl> f -> transport_len = ( uint16_t )( short_be ( hdr -> len ) - PICO_SIZE_IP4HDR - option_len ); <nl> f -> net_len = ( uint16_t )( PICO_SIZE_IP4HDR + option_len ); <nl> + <nl> + if (( f -> net_hdr + f -> net_len ) > ( f -> buffer + f -> buffer_len )) { <nl> + pico_frame_discard ( f ); <nl> + return 0 ; <nl> + } <nl> # if defined ( PICO_SUPPORT_IPV4FRAG ) || defined ( PICO_SUPPORT_IPV6FRAG ) <nl> f -> frag = short_be ( hdr -> frag ); <nl> # endifmmm modules / pico_tcp . c <nl> ppp modules / pico_tcp . c <nl> static int pico_ipv4_process_in ( struct pico_stack * S , struct pico_protocol * self <nl> f -> transport_hdr = (( uint8_t *) f -> net_hdr ) + PICO_SIZE_IP4HDR + option_len ; <nl> f -> transport_len = ( uint16_t )( short_be ( hdr -> len ) - PICO_SIZE_IP4HDR - option_len ); <nl> f -> net_len = ( uint16_t )( PICO_SIZE_IP4HDR + option_len ); <nl> + <nl> + if (( f -> net_hdr + f -> net_len ) > ( f -> buffer + f -> buffer_len )) { <nl> + pico_frame_discard ( f ); <nl> + return 0 ; <nl> + } <nl> # if defined ( PICO_SUPPORT_IPV4FRAG ) || defined ( PICO_SUPPORT_IPV6FRAG ) <nl> f -> frag = short_be ( hdr -> frag ); <nl> # endif <nl> static inline void tcp_parse_option_mss ( struct pico_socket_tcp * t , uint8_t len , <nl> if ( tcpopt_len_check ( idx , len , PICO_TCPOPTLEN_MSS ) < 0 ) <nl> return ; <nl>  <nl> + if ((* idx + PICO_TCPOPTLEN_MSS ) > len ) <nl> + return ; <nl> + <nl> t -> mss_ok = 1 ; <nl> mss = short_from ( opt + * idx ); <nl> * idx += ( uint32_t ) sizeof ( uint16_t ); <nl> static int tcp_parse_options ( struct pico_frame * f ) <nl> uint8_t * opt = f -> transport_hdr + PICO_SIZE_TCPHDR ; <nl> uint32_t i = 0 ; <nl> f -> timestamp = 0 ; <nl> + <nl> + if ( f -> buffer + f -> buffer_len > f -> transport_hdr + f -> transport_len ) <nl> + return - 1 ; <nl> + <nl> while ( i < ( f -> transport_len - PICO_SIZE_TCPHDR )) { <nl> uint8_t type = opt [ i ++]; <nl> uint8_t len ;
mmm libyara / modules / pe . c <nl> ppp libyara / modules / pe . c <nl> IMPORTED_FUNCTION * pe_parse_import_descriptor ( <nl> IMPORTED_FUNCTION * imported_func = ( IMPORTED_FUNCTION *) <nl> yr_calloc ( 1 , sizeof ( IMPORTED_FUNCTION )); <nl>  <nl> + if (! imported_func ) <nl> + continue ; <nl> + <nl> imported_func -> name = name ; <nl> imported_func -> next = NULL ; <nl>  <nl> IMPORTED_FUNCTION * pe_parse_import_descriptor ( <nl> IMPORTED_FUNCTION * imported_func = ( IMPORTED_FUNCTION *) <nl> yr_calloc ( 1 , sizeof ( IMPORTED_FUNCTION )); <nl>  <nl> + if (! imported_func ) <nl> + continue ; <nl> + <nl> imported_func -> name = name ; <nl> imported_func -> next = NULL ; <nl> 
mmm libyara / modules / pe . c <nl> ppp libyara / modules / pe . c <nl> limitations under the License . <nl>  <nl>  <nl> # define fits_in_pe ( pe , pointer , size ) \ <nl> - (( uint8_t *)( pointer ) + size <= pe -> data + pe -> data_size ) <nl> + ( size <= pe -> data_size && \ <nl> + ( uint8_t *)( pointer ) >= pe -> data && \ <nl> + ( uint8_t *)( pointer ) + size <= pe -> data + pe -> data_size ) <nl>  <nl>  <nl> # define struct_fits_in_pe ( pe , pointer , struct_type ) \
mmm libyara / modules / pe . c <nl> ppp libyara / modules / pe . c <nl> void pe_parse_version_info ( <nl>  <nl> version_info = ( PVERSION_INFO ) ( pe -> data + version_info_offset ); <nl>  <nl> - if (! fits_in_pe ( pe , version_info -> Key , sizeof (" VS_VERSION_INFO "))) <nl> + if (! fits_in_pe ( pe , version_info -> Key , sizeof (" VS_VERSION_INFO ") * 2 )) <nl> return ; <nl>  <nl> if ( strcmp_w ( version_info -> Key , " VS_VERSION_INFO ") != 0 ) <nl> void pe_parse_version_info ( <nl>  <nl> string_file_info = ADD_OFFSET ( version_info , sizeof ( VERSION_INFO ) + 86 ); <nl>  <nl> - while ( fits_in_pe ( pe , string_file_info -> Key , sizeof (" StringFileInfo ")) && <nl> + while ( fits_in_pe ( pe , string_file_info -> Key , sizeof (" StringFileInfo ") * 2 ) && <nl> strcmp_w ( string_file_info -> Key , " StringFileInfo ") == 0 ) <nl> { <nl> PVERSION_INFO string_table = ADD_OFFSET (
mmm libyara / atoms . c <nl> ppp libyara / atoms . c <nl> int yr_atoms_table_quality ( <nl> } <nl> else <nl> { <nl> - if ( atom_length == YR_MAX_ATOM_LENGTH ) <nl> - return table [ middle ]. quality ; <nl> - <nl> int i = middle + 1 ; <nl> int quality = table [ middle ]. quality ; <nl> int min_quality = quality ; <nl>  <nl> + if ( atom_length == YR_MAX_ATOM_LENGTH ) <nl> + return table [ middle ]. quality ; <nl> + <nl> while ( i < end && memcmp ( table [ i ]. atom , atom , atom_length ) == 0 ) <nl> { <nl> if ( min_quality > table [ i ]. quality )
mmm libyara / exefiles . c <nl> ppp libyara / exefiles . c <nl> PIMAGE_NT_HEADERS yr_get_pe_header ( <nl>  <nl> if ( pe_header -> Signature == IMAGE_NT_SIGNATURE && <nl> ( pe_header -> FileHeader . Machine == IMAGE_FILE_MACHINE_I386 || <nl> - pe_header -> FileHeader . Machine == IMAGE_FILE_MACHINE_X64 ) && <nl> + pe_header -> FileHeader . Machine == IMAGE_FILE_MACHINE_AMD64 ) && <nl> buffer_length > headers_size ) <nl> { <nl> return pe_header ;mmm libyara / pe . h <nl> ppp libyara / pe . h <nl> PIMAGE_NT_HEADERS yr_get_pe_header ( <nl>  <nl> if ( pe_header -> Signature == IMAGE_NT_SIGNATURE && <nl> ( pe_header -> FileHeader . Machine == IMAGE_FILE_MACHINE_I386 || <nl> - pe_header -> FileHeader . Machine == IMAGE_FILE_MACHINE_X64 ) && <nl> + pe_header -> FileHeader . Machine == IMAGE_FILE_MACHINE_AMD64 ) && <nl> buffer_length > headers_size ) <nl> { <nl> return pe_header ; <nl> typedef struct _IMAGE_FILE_HEADER { <nl>  <nl>  <nl> # define IMAGE_FILE_MACHINE_I386 0x014c // Intel 386 . <nl> -# define IMAGE_FILE_MACHINE_X64 0x8664 // Intel x64 . <nl> +# define IMAGE_FILE_MACHINE_AMD64 0x8664 // Intel x64 . <nl>  <nl> // <nl> // Directory format .
mmm libyara / modules / pe . c <nl> ppp libyara / modules / pe . c <nl> void pe_parse_certificates ( <nl> } <nl> BIO_read ( date_bio , p , date_bio -> num_write ); <nl> p [ date_bio -> num_write ] = '\ x0 '; <nl> - set_string ( p , pe -> object , " signatures [% i ]. notBefore ", counter ); <nl> + set_string ( p , pe -> object , " signatures [% i ]. not_before ", counter ); <nl> yr_free ( p ); <nl> date_time = X509_get_notAfter ( cert ); <nl> ASN1_TIME_print ( date_bio , date_time ); <nl> void pe_parse_certificates ( <nl> } <nl> BIO_read ( date_bio , p , date_length ); <nl> p [ date_length ] = '\ x0 '; <nl> - set_string ( p , pe -> object , " signatures [% i ]. notAfter ", counter ); <nl> + set_string ( p , pe -> object , " signatures [% i ]. not_after ", counter ); <nl> yr_free ( p ); <nl> } <nl> BIO_set_close ( date_bio , BIO_CLOSE ); <nl> begin_declarations ; <nl> declare_integer (" version "); <nl> declare_string (" algorithm "); <nl> declare_string (" serial "); <nl> - declare_string (" notBefore "); <nl> - declare_string (" notAfter "); <nl> + declare_string (" not_before "); <nl> + declare_string (" not_after "); <nl> end_struct_array (" signatures "); <nl> declare_integer (" number_of_signatures "); <nl> 
mmm libyara / ast . c <nl> ppp libyara / ast . c <nl> void free_term ( TERM * term ) <nl>  <nl> free_term ((( TERM_STRING *) term )-> offset ); <nl> break ; <nl> + <nl> + case TERM_TYPE_STRING_OFFSET : <nl> + <nl> + free_term ((( TERM_STRING *) term )-> index ); <nl> + break ; <nl>  <nl> case TERM_TYPE_STRING_IN_RANGE : <nl> 
mmm libyara / re . c <nl> ppp libyara / re . c <nl> int yr_re_fast_exec ( <nl>  <nl> for ( i = repeat_any_args -> min + 1 ; i <= repeat_any_args -> max ; i ++) <nl> { <nl> - next_input = input + i * input_incr ; <nl> - <nl> if ( bytes_matched + i >= max_bytes_matched ) <nl> break ; <nl>  <nl> + next_input = input + i * input_incr ; <nl> + <nl> if ( *( next_opcode ) != RE_OPCODE_LITERAL || <nl> (*( next_opcode ) == RE_OPCODE_LITERAL && <nl> *( next_opcode + 1 ) == * next_input )) <nl> int yr_re_fast_exec ( <nl>  <nl> input += input_incr * repeat_any_args -> min ; <nl> bytes_matched += repeat_any_args -> min ; <nl> + bytes_matched = yr_min ( bytes_matched , max_bytes_matched ); <nl> ip = next_opcode ; <nl>  <nl> break ;mmm libyara / scan . c <nl> ppp libyara / scan . c <nl> int yr_re_fast_exec ( <nl>  <nl> for ( i = repeat_any_args -> min + 1 ; i <= repeat_any_args -> max ; i ++) <nl> { <nl> - next_input = input + i * input_incr ; <nl> - <nl> if ( bytes_matched + i >= max_bytes_matched ) <nl> break ; <nl>  <nl> + next_input = input + i * input_incr ; <nl> + <nl> if ( *( next_opcode ) != RE_OPCODE_LITERAL || <nl> (*( next_opcode ) == RE_OPCODE_LITERAL && <nl> *( next_opcode + 1 ) == * next_input )) <nl> int yr_re_fast_exec ( <nl>  <nl> input += input_incr * repeat_any_args -> min ; <nl> bytes_matched += repeat_any_args -> min ; <nl> + bytes_matched = yr_min ( bytes_matched , max_bytes_matched ); <nl> ip = next_opcode ; <nl>  <nl> break ; <nl> int _yr_scan_match_callback ( <nl> // total match length is the sum of backward and forward matches . <nl> match_length += callback_args -> forward_matches ; <nl>  <nl> + // make sure that match fits into the data . <nl> + assert ( match_offset + match_length <= callback_args -> data_size ); <nl> + <nl> if ( callback_args -> full_word ) <nl> { <nl> if ( flags & RE_FLAGS_WIDE )
mmm common . h <nl> ppp common . h <nl> bool compile_files ( <nl> { <nl> for ( int i = 0 ; i < argc - 1 ; i ++) <nl> { <nl> + FILE * rule_file ; <nl> const char * ns ; <nl> const char * file_name ; <nl> char * colon = ( char *) strchr ( argv [ i ], ':'); <nl> bool compile_files ( <nl> ns = NULL ; <nl> } <nl>  <nl> - FILE * rule_file = fopen ( file_name , " r "); <nl> + if ( strcmp ( file_name , "-") == 0 ) <nl> + rule_file = stdin ; <nl> + else <nl> + rule_file = fopen ( file_name , " r "); <nl>  <nl> if ( rule_file == NULL ) <nl> {
mmm libyara / include / yara / mem . h <nl> ppp libyara / include / yara / mem . h <nl> limitations under the License . <nl> # ifdef DMALLOC <nl>  <nl> # define yr_malloc malloc <nl> +# define yr_calloc calloc <nl> # define yr_realloc realloc <nl> # define yr_free free <nl> # define yr_strdup strdupmmm libyara / libyara . c <nl> ppp libyara / libyara . c <nl> limitations under the License . <nl> # ifdef DMALLOC <nl>  <nl> # define yr_malloc malloc <nl> +# define yr_calloc calloc <nl> # define yr_realloc realloc <nl> # define yr_free free <nl> # define yr_strdup strdup <nl> limitations under the License . <nl> # include < ctype . h > <nl>  <nl> # include < yara / error . h > <nl> -# include < yara / mem . h > <nl> # include < yara / re . h > <nl> # include < yara / modules . h > <nl> - <nl> +# include < yara / mem . h > <nl>  <nl> # ifdef _WIN32 <nl> # define snprintf _snprintf
mmm libyara / modules / pe . c <nl> ppp libyara / modules / pe . c <nl> PIMAGE_DATA_DIRECTORY pe_get_directory_entry ( <nl> { <nl> PIMAGE_DATA_DIRECTORY result ; <nl>  <nl> - if ( pe -> header -> FileHeader . Machine == 0x8664 ) // is a 64 - bit PE ? <nl> + if ( pe -> header -> FileHeader . Machine == IMAGE_FILE_MACHINE_AMD64 ) <nl> result = &(( PIMAGE_NT_HEADERS64 ) pe -> header )-> <nl> OptionalHeader . DataDirectory [ entry ]; <nl> else <nl> void pe_parse ( <nl> char section_name [ IMAGE_SIZEOF_SHORT_NAME + 1 ]; <nl>  <nl> # define OptionalHeader ( field ) \ <nl> - ( pe -> header -> FileHeader . Machine == 0x8664 ? \ <nl> + ( pe -> header -> FileHeader . Machine == IMAGE_FILE_MACHINE_AMD64 ? \ <nl> (( PIMAGE_NT_HEADERS64 ) pe -> header )-> OptionalHeader . field : \ <nl> pe -> header -> OptionalHeader . field ) <nl> 
mmm libyara / modules / pe . c <nl> ppp libyara / modules / pe . c <nl> IMPORTED_FUNCTION * pe_parse_import_descriptor ( <nl> // I ' ve seen binaries where OriginalFirstThunk is zero . In this case <nl> // use FirstThunk . <nl>  <nl> - if ( offset < 0 ) <nl> + if ( offset <= 0 ) <nl> offset = pe_rva_to_offset ( pe , import_descriptor -> FirstThunk ); <nl>  <nl> if ( offset < 0 )
mmm ext / redcarpet / html . c <nl> ppp ext / redcarpet / html . c <nl> rndr_quote ( struct buf * ob , const struct buf * text , void * opaque ) <nl> if (! text || ! text -> size ) <nl> return 0 ; <nl>  <nl> + struct html_renderopt * options = opaque ; <nl> + <nl> BUFPUTSL ( ob , "< q >"); <nl> - bufput ( ob , text -> data , text -> size ); <nl> + <nl> + if ( options -> flags & HTML_ESCAPE ) <nl> + escape_html ( ob , text -> data , text -> size ); <nl> + else <nl> + bufput ( ob , text -> data , text -> size ); <nl> + <nl> BUFPUTSL ( ob , "</ q >"); <nl>  <nl> return 1 ;
mmm clamav - devel / clamd / session . c <nl> ppp clamav - devel / clamd / session . c <nl> static int multiscan ( const char * dirname , const struct cl_node * root , const stru <nl> closedir ( dd ); <nl> return - 1 ; <nl> } <nl> + free ( fname ); <nl> } else { <nl> if ( S_ISREG ( statbuf . st_mode ) || ( S_ISLNK ( statbuf . st_mode ) && ( checksymlink ( fname ) == 2 ) && cfgopt ( copt , " FollowFileSymlinks ")-> enabled )) { <nl>  <nl> static int multiscan ( const char * dirname , const struct cl_node * root , const stru <nl> } <nl> } <nl> } <nl> + } else { <nl> + free ( fname ); <nl> } <nl> } <nl> }
mmm freshclam / manager . c <nl> ppp freshclam / manager . c <nl> static int updatedb ( const char * dbname , const char * hostname , char * ip , int * sig <nl> } <nl>  <nl> if ( rename ( newfile , newdb ) == - 1 ) { <nl> - logg ("! Can ' t rename % s to % s \ n ", newfile , newdb ); <nl> + logg ("! Can ' t rename % s to % s : % s \ n ", newfile , newdb , strerror ( errno )); <nl> unlink ( newfile ); <nl> free ( newfile ); <nl> return 57 ;
mmm libclamav / matcher - bm . c <nl> ppp libclamav / matcher - bm . c <nl> int cli_bm_scanbuff ( const unsigned char * buffer , uint32_t length , const char ** v <nl> memset (& info , 0 , sizeof ( info )); <nl> i = BM_MIN_LENGTH - BM_BLOCK_SIZE ; <nl> if ( offdata ) { <nl> + if (! offdata -> cnt ) <nl> + return CL_CLEAN ; <nl> for (; offdata -> pos && offdata -> offtab [ offdata -> pos ] > offset ; offdata -> pos --); <nl> if ( offdata -> offtab [ offdata -> pos ] < offset ) <nl> offdata -> pos ++;
mmm libclamav / untar . c <nl> ppp libclamav / untar . c <nl> cli_untar ( const char * dir , unsigned int posix , cli_ctx * ctx ) <nl> if (( ret = cli_checklimits (" cli_untar ", ctx , 0 , 0 , 0 ))!= CL_CLEAN ) <nl> return ret ; <nl>  <nl> + if ( nread < TARCHECKSUMOFFSET + TARCHECKSUMLEN ) <nl> + return ret ; <nl> + <nl> checksum = getchecksum ( block ); <nl> cli_dbgmsg (" cli_untar : Candidate checksum = % d , [% o in octal ]\ n ", checksum , checksum ); <nl> if ( testchecksum ( block , checksum ) != 0 ) {
mmm clambc / bcrun . c <nl> ppp clambc / bcrun . c <nl> int main ( int argc , char * argv []) <nl> f = fopen ( argv [ 1 ], " r "); <nl> if (! f ) { <nl> fprintf ( stderr , " Unable to load % s \ n ", argv [ 1 ]); <nl> + optfree ( opts ); <nl> exit ( 2 ); <nl> } <nl>  <nl> bc = malloc ( sizeof (* bc )); <nl> if (! bc ) { <nl> fprintf ( stderr , " Out of memory \ n "); <nl> + optfree ( opts ); <nl> exit ( 3 ); <nl> } <nl>  <nl> int main ( int argc , char * argv []) <nl> rc = cli_bytecode_load ( bc , f , NULL ); <nl> if ( rc != CL_SUCCESS ) { <nl> fprintf ( stderr ," Unable to load bytecode : % s \ n ", cl_strerror ( rc )); <nl> + optfree ( opts ); <nl> exit ( 4 ); <nl> } <nl> fclose ( f ); <nl> int main ( int argc , char * argv []) <nl> cli_bytecode_destroy_context ( ctx ); <nl> cli_bytecode_destroy ( bc ); <nl> free ( bc ); <nl> + optfree ( opts ); <nl> return 0 ; <nl> }
mmm libclamav / phishcheck . c <nl> ppp libclamav / phishcheck . c <nl> static int url_hash_match ( const struct regex_matcher * rlist , const char * inurl , <nl> size_t j , k , ji , ki ; <nl> int rc ; <nl>  <nl> - if (! rlist -> md5_hashes . bm_patterns ) { <nl> + if (! rlist || ! rlist -> md5_hashes . bm_patterns ) { <nl> return CL_SUCCESS ; <nl> } <nl> if (! inurl )
mmm libclamav / htmlnorm . c <nl> ppp libclamav / htmlnorm . c <nl> abort : <nl> } <nl> if ( file_tmp_o1 ) { <nl> html_output_flush ( file_tmp_o1 ); <nl> - close ( file_tmp_o1 -> fd ); <nl> + if ( file_buff_text -> fd != - 1 ) <nl> + close ( file_tmp_o1 -> fd ); <nl> free ( file_tmp_o1 ); <nl> } <nl> return retval ;
mmm libclamav / bytecode_vm . c <nl> ppp libclamav / bytecode_vm . c <nl> static inline int bcfail ( const char * msg , long a , long b , <nl> # define CHECK_EQ ( a , b ) <nl> # define CHECK_GT ( a , b ) <nl> # endif <nl> -# ifdef CL_DEBUG <nl> +# if 0 /* too verbose , use # ifdef CL_DEBUG if needed */ <nl> # define CHECK_UNREACHABLE do { cli_dbgmsg (" bytecode : unreachable executed !\ n "); return CL_EBYTECODE ; } while ( 0 ) <nl> # define TRACE_PTR ( ptr , s ) cli_dbgmsg (" bytecode trace : ptr % llx , +% x \ n ", ptr , s ); <nl> # define TRACE_R ( x ) cli_dbgmsg (" bytecode trace : % u , read % llx \ n ", pc , ( long long ) x ); <nl> static always_inline void * cli_stack_alloc ( struct stack * stack , unsigned bytes ) <nl> /* not enough room here , allocate new chunk */ <nl> chunk = cli_malloc ( sizeof (* stack -> chunk )); <nl> if (! chunk ) { <nl> - cli_warnmsg (" cli_stack_alloc : Unable to allocate memory for stack - chunk : bytes : % u !\ n ", sizeof (* stack -> chunk )); <nl> + cli_warnmsg (" cli_stack_alloc : Unable to allocate memory for stack - chunk : bytes : % zu !\ n ", sizeof (* stack -> chunk )); <nl> return NULL ; <nl> } <nl> 
mmm clamav - devel / libclamav / others . c <nl> ppp clamav - devel / libclamav / others . c <nl> const char * cl_strerror ( int clerror ) <nl> return " Null argument passed while initialized is required "; <nl> case CL_EIO : <nl> return " Input / Output error "; <nl> + case CL_EFORMAT : <nl> + return " Bad format or broken data "; <nl> default : <nl> return " Unknown error code "; <nl> }
mmm libclamav / dmg . c <nl> ppp libclamav / dmg . c <nl> int cli_scandmg ( cli_ctx * ctx ) <nl> return CL_EFORMAT ; <nl> } <nl> cli_dbgmsg (" cli_scandmg : XML offset % lu len % d \ n ", ( unsigned long ) hdr . xmlOffset , ( int ) hdr . xmlLength ); <nl> + if ( hdr . xmlLength == 0 ) { <nl> + cli_dbgmsg (" cli_scandmg : Embedded XML length is zero .\ n "); <nl> + return CL_EFORMAT ; <nl> + } <nl>  <nl> /* Create temp folder for contents */ <nl> if (!( dirname = cli_gentemp ( ctx -> engine -> tmpdir ))) { <nl> static int dmg_extract_xml ( cli_ctx * ctx , char * dir , struct dmg_koly_block * hdr ) <nl>  <nl> /* Write out TOC XML */ <nl> if (( ofd = open ( xmlfile , O_CREAT | O_RDWR | O_EXCL | O_TRUNC | O_BINARY , S_IRWXU )) < 0 ) { <nl> + cli_errmsg (" cli_scandmg : Can ' t create temporary file % s : % s \ n ", <nl> + xmlfile , cli_strerror ( errno , err , sizeof ( err ))); <nl> + free ( xmlfile ); <nl> return CL_ETMPFILE ; <nl> } <nl> 
mmm libclamunrar / unrar . c <nl> ppp libclamunrar / unrar . c <nl> static int read_tables ( int fd , unpack_data_t * unpack_data ) <nl> rar_addbits ( unpack_data , 7 ); <nl> } <nl> if ( i == 0 ) { <nl> - rar_dbgmsg (" We cannot have repeat previous code at the first position "); <nl> + rar_dbgmsg (" We cannot have repeat previous code at the first position \ n "); <nl> return FALSE ; <nl> } <nl> while ( n -- > 0 && i < table_size ) {
mmm clamav - devel / libclamav / mbox . c <nl> ppp clamav - devel / libclamav / mbox . c <nl> * along with this program ; if not , write to the Free Software <nl> * Foundation , Inc ., 675 Mass Ave , Cambridge , MA 02139 , USA . <nl> */ <nl> - static char const rcsid [] = "$ Id : mbox . c , v 1 . 256 2005 / 07 / 30 15 : 41 : 16 nigelhorne Exp $"; <nl> + static char const rcsid [] = "$ Id : mbox . c , v 1 . 257 2005 / 08 / 03 21 : 15 : 19 nigelhorne Exp $"; <nl>  <nl> # if HAVE_CONFIG_H <nl> # include " clamav - config . h " <nl> getURL ( struct arg * arg ) <nl> * memory leak * here in getaddrinfo (), see <nl> * https :// bugzilla . redhat . com / bugzilla / show_bug . cgi ? id = 139559 <nl> */ <nl> - <nl> if ( curl_easy_perform ( curl ) != CURLE_OK ) { <nl> # ifdef CURLOPT_ERRORBUFFER <nl> cli_warnmsg (" URL % s failed to download : % s \ n ", url , errorbuffer ); <nl> getURL ( struct arg * arg ) <nl> } <nl>  <nl> fclose ( fp ); <nl> - curl_slist_free_all ( headers ); <nl> curl_easy_cleanup ( curl ); <nl> + curl_slist_free_all ( headers ); <nl>  <nl> return NULL ; <nl> }
mmm libclamav / message . c <nl> ppp libclamav / message . c <nl> messageAddArgument ( message * m , const char * arg ) <nl> * FIXME : Bounce message handling is corrupting the in <nl> * core copies of headers <nl> */ <nl> - cli_dbgmsg (" Possible data corruption fixed \ n "); <nl> - p [ 8 ] = '='; <nl> + if ( strlen ( p ) > 8 ) { <nl> + cli_dbgmsg (" Possible data corruption fixed \ n "); <nl> + p [ 8 ] = '='; <nl> + } else { <nl> + cli_dbgmsg (" Possible data corruption not fixed \ n "); <nl> + } <nl> } else { <nl> if (* p ) <nl> cli_dbgmsg (" messageAddArgument , '% s ' contains no '='\ n ", p ); <nl> messageFindArgument ( const message * m , const char * variable ) <nl> cli_dbgmsg (" messageFindArgument : no '=' sign found in MIME header '% s ' (% s )\ n ", variable , messageGetArgument ( m , i )); <nl> return NULL ; <nl> } <nl> - if ((*++ ptr == '"') && ( strchr (& ptr [ 1 ], '"') != NULL )) { <nl> + if (( strlen ( ptr ) > 2 ) && (*++ ptr == '"') && ( strchr (& ptr [ 1 ], '"') != NULL )) { <nl> /* Remove any quote characters */ <nl> char * ret = cli_strdup (++ ptr ); <nl> char * p ;
mmm libclamav / nsis / nulsft . c <nl> ppp libclamav / nsis / nulsft . c <nl> static int nsis_unpack_next ( struct nsis_st * n , cli_ctx * ctx ) { <nl> return CL_BREAK ; <nl> } <nl>  <nl> - if (( ret = cli_checklimits (" NSIS ", ctx 0 , 0 , 0 ))!= CL_CLEAN ) <nl> + if (( ret = cli_checklimits (" NSIS ", ctx , 0 , 0 , 0 ))!= CL_CLEAN ) <nl> return ret ; <nl>  <nl> if ( n -> fno ) <nl> static int nsis_unpack_next ( struct nsis_st * n , cli_ctx * ctx ) { <nl>  <nl> n -> asz -= size + 4 ; <nl>  <nl> - if (( ret = cli_checklimits (" NSIS ", ctx , size , 0 , 0 )!= CL_CLEAN ) { <nl> + if (( ret = cli_checklimits (" NSIS ", ctx , size , 0 , 0 ))!= CL_CLEAN ) { <nl> close ( n -> ofd ); <nl> if ( lseek ( n -> ifd , size , SEEK_CUR )==- 1 ) return CL_EIO ; <nl> return ret ;
mmm libclamav / uuencode . c <nl> ppp libclamav / uuencode . c <nl> static char const rcsid [] = "$ Id : uuencode . c , v 1 . 8 2006 / 12 / 11 11 : 55 : 11 njh Exp $ <nl> int <nl> cli_uuencode ( const char * dir , fmap_t * map ) <nl> { <nl> - int i ; <nl> message * m ; <nl> char buffer [ RFC2821LENGTH + 1 ]; <nl> size_t at = 0 ; <nl>  <nl> - if ( fmap_gets ( map , buffer , & at , sizeof ( buffer ) - 1 )) { <nl> + if (! fmap_gets ( map , buffer , & at , sizeof ( buffer ) - 1 )) { <nl> /* empty message */ <nl> return CL_CLEAN ; <nl> }
mmm clamdtop / clamdtop . c <nl> ppp clamdtop / clamdtop . c <nl> static void show_bar ( WINDOW * win , size_t i , unsigned live , unsigned idle , <nl> waddch ( win , ']' | A_BOLD ); <nl> if ( blink ) { <nl> getyx ( win , y , x ); <nl> + if (( x < 0 ) || ( y < 0 )) { <nl> + return ; /* if getyx () failed , nevermind the blinking */ <nl> + } <nl> if ( x >= 2 ) { <nl> - z = x - 2 ; <nl> - } <nl> + z = x - 2 ; <nl> + } <nl> mvwaddch ( win , y , z , '>' | A_BLINK | COLOR_PAIR ( red_color )); <nl> move ( y , z ); <nl> }
mmm libclamav / mpool . c <nl> ppp libclamav / mpool . c <nl> void mpool_flush ( struct MP * mp ) { <nl> mp -> u . mpm . size = mused - sizeof (* mp ); <nl> } <nl> used += mp -> u . mpm . size ; <nl> + cli_dbgmsg (" pool memory used : %. 3f MB \ n ", used /( 1024 * 1024 . 0 )); <nl> spam (" Map flushed @% p , in use : % lu \ n ", mp , used ); <nl> } <nl> mmm libclamav / bytecode . c <nl> ppp libclamav / bytecode . c <nl> void mpool_flush ( struct MP * mp ) { <nl> mp -> u . mpm . size = mused - sizeof (* mp ); <nl> } <nl> used += mp -> u . mpm . size ; <nl> + cli_dbgmsg (" pool memory used : %. 3f MB \ n ", used /( 1024 * 1024 . 0 )); <nl> spam (" Map flushed @% p , in use : % lu \ n ", mp , used ); <nl> } <nl>  <nl> int cli_bytecode_prepare2 ( struct cl_engine * engine , struct cli_all_bc * bcs , unsi <nl> int rc ; <nl> struct cli_bc_ctx * ctx ; <nl>  <nl> + if (! bcs -> count ) { <nl> + cli_dbgmsg (" No bytecodes loaded , not running builtin test \ n "); <nl> + return CL_SUCCESS ; <nl> + } <nl> + <nl> cli_detect_environment (& bcs -> env ); <nl> switch ( bcs -> env . arch ) { <nl> case arch_i386 :
mmm libclamav / autoit . c <nl> ppp libclamav / autoit . c <nl> static int ea05 ( cli_ctx * ctx , const uint8_t * base , char * tmpd ) { <nl> continue ; <nl> } <nl>  <nl> - if ( UNP . csize < sizeof ( union unaligned_32 )) { <nl> + if ( comp == 1 && UNP . csize < sizeof ( union unaligned_32 )) { <nl> cli_dbgmsg (" autoit : compressed size too small , skipping \ n "); <nl> continue ; <nl> } <nl> static int ea06 ( cli_ctx * ctx , const uint8_t * base , char * tmpd ) { <nl> continue ; <nl> } <nl>  <nl> - if ( UNP . csize < sizeof ( union unaligned_32 )) { <nl> + if ( comp == 1 && UNP . csize < sizeof ( union unaligned_32 )) { <nl> cli_dbgmsg (" autoit : compressed size too small , skipping \ n "); <nl> continue ; <nl> }
mmm sigtool / sigtool . c <nl> ppp sigtool / sigtool . c <nl> static char * sha256file ( const char * file , unsigned int * size ) <nl> sha256_final (& ctx , digest ); <nl> sha = ( char *) malloc ( 65 ); <nl> if (! sha ) <nl> + { <nl> + fclose ( fh ); <nl> return NULL ; <nl> + } <nl> for ( i = 0 ; i < 32 ; i ++) <nl> sprintf ( sha + i * 2 , "% 02x ", digest [ i ]); <nl> + <nl> + fclose ( fh ); <nl> return sha ; <nl> } <nl> 
mmm libclamav / matcher - ac . c <nl> ppp libclamav / matcher - ac . c <nl> inline static int ac_special_altstr ( const char * hexpr , uint8_t sigopts , struct c <nl> /* allocate reusable subexpr */ <nl> if (!( subexpr = cli_calloc ( slen + 1 , sizeof ( char )))) { <nl> cli_errmsg (" ac_special_altstr : Can ' t allocate subexpr container \ n "); <nl> + free ( hexprcpy ); <nl> return CL_EMEM ; <nl> } <nl> 
mmm libclamav / vba_extract . c <nl> ppp libclamav / vba_extract . c <nl> vba_read_project_strings ( int fd , int big_endian ) <nl> unsigned char * buf = NULL ; <nl> uint16_t buflen = 0 ; <nl> uint16_t length = 0 ; <nl> - int ret = 0 ; <nl> - <nl> - /* if no initial name length , exit */ <nl> - if (! read_uint16 ( fd , & length , big_endian )) <nl> - return 0 ; <nl> + int ret = 0 , getnewlength = 1 ; <nl>  <nl> for (;;) { <nl> off_t offset ; <nl> char * name ; <nl>  <nl> + /* if no initial name length , exit */ <nl> + if ( getnewlength && ! read_uint16 ( fd , & length , big_endian )) <nl> + return 0 ; <nl> + getnewlength = 0 ; <nl> + <nl> /* if too short , break */ <nl> if ( length < 6 ) { <nl> if ( lseek ( fd , - 2 , SEEK_CUR ) == - 1 ) { <nl> vba_read_project_strings ( int fd , int big_endian ) <nl> } <nl> cli_dbgmsg (" offset : % lu \ n ", ( unsigned long ) offset ); <nl> vba56_test_middle ( fd ); <nl> + getnewlength = 1 ; <nl> } <nl>  <nl> free ( buf );
mmm libclamav / textdet . c <nl> ppp libclamav / textdet . c <nl> static int td_isutf8 ( const unsigned char * buf , unsigned int len ) <nl>  <nl> static int td_isutf16 ( const unsigned char * buf , unsigned int len ) <nl> { <nl> - unsigned int be = 1 , nobom = 0 , i , c , bad = 0 ; <nl> + unsigned int be = 1 , nobom = 0 , i , c , bad = 0 , high = 0 ; <nl>  <nl>  <nl> if ( len < 2 ) <nl> static int td_isutf16 ( const unsigned char * buf , unsigned int len ) <nl> return 0 ; <nl> else <nl> bad ++; <nl> - } <nl> + } else if ( c >= 128 ) { <nl> + high ++; <nl> + } <nl> } <nl>  <nl> + if ( nobom && high >= len / 4 ) <nl> + return 0 ; <nl> + <nl> if (! nobom && bad >= len / 2 ) <nl> return 0 ; <nl> 
mmm libclamunrar_iface / unrar_iface . c <nl> ppp libclamunrar_iface / unrar_iface . c <nl> /* <nl> * Interface to libclamunrar <nl> - * Copyright ( C ) 2007 Sourcefire , Inc . <nl> + * Copyright ( C ) 2007 - 2013 Sourcefire , Inc . <nl> * Authors : Trog , Torok Edvin , Tomasz Kojm <nl> * <nl> * This library is free software ; you can redistribute it and / or <nl> int unrar_extract_next_prepare ( unrar_state_t * state , const char * dirname ) <nl> snprintf ( filename , 1024 , "% s " PATHSEP "% lu . cmt ", state -> comment_dir , state -> file_count ); <nl> ofd = open ( filename , O_WRONLY | O_CREAT | O_TRUNC | O_BINARY , 0600 ); <nl> if ( ofd < 0 ) { <nl> - free ( comment_header ); <nl> unrar_dbgmsg (" UNRAR : ERROR : Failed to open output file \ n "); <nl> } else { <nl> unrar_dbgmsg (" UNRAR : Copying file comment ( not packed )\ n ");
mmm libclamav / libmspack - 0 . 5alpha / mspack / cabd . c <nl> ppp libclamav / libmspack - 0 . 5alpha / mspack / cabd . c <nl> static int cabd_read_headers ( struct mspack_system * sys , <nl> } <nl> else { <nl> /* ignore invalid file and continue parsing */ <nl> + if ( file -> filename ) { <nl> + sys -> free ( file -> filename ); <nl> + file -> filename = NULL ; <nl> + } <nl> sys -> free ( file ); <nl> sys -> message ( fh , " WARNING ; omitting file % d of % d from file list ", i , num_files ); <nl> }
mmm libclamav / wwunpack . c <nl> ppp libclamav / wwunpack . c <nl> int wwunpack ( uint8_t * exe , uint32_t exesz , uint8_t * wwsect , struct cli_exe_secti <nl> } <nl>  <nl> if (! error ) { <nl> + if ( pe + 6 > exesz || pe + 7 > exesz || pe + 0x28 > exesz || <nl> + pe + 0x50 > exesz || pe + 0x14 > exesz ) <nl> + return CL_EFORMAT ; <nl> exe [ pe + 6 ]=( uint8_t ) scount ; <nl> exe [ pe + 7 ]=( uint8_t )( scount >> 8 ); <nl> cli_writeint32 (& exe [ pe + 0x28 ], cli_readint32 ( wwsect + 0x295 )+ sects [ scount ]. rva + 0x299 );
mmm clamd / server - th . c <nl> ppp clamd / server - th . c <nl> static int handle_stream ( client_conn_t * conn , struct fd_buf * buf , const struct o <nl> pthread_mutex_unlock (& exit_mutex ); <nl> } <nl> * error = 1 ; <nl> + return - 1 ; <nl> } else { <nl> pos = 4 ; <nl> memmove ( buf -> buffer , & buf -> buffer [ pos ], buf -> off - pos );
mmm libclamav / fmap . c <nl> ppp libclamav / fmap . c <nl> static void fmap_aging ( fmap_t * m ) { <nl> } <nl> if ( avail ) { /* at least one page is paged and not locked */ <nl> for ( i = 0 ; i < avail ; i ++) { <nl> - char * pptr = ( char *) m + i * m -> pgsz + m -> hdrsz ; <nl> + char * pptr = ( char *) m + freeme [ i ] * m -> pgsz + m -> hdrsz ; <nl> /* we mark the page as seen */ <nl> fmap_bitmap [ freeme [ i ]] = FM_MASK_SEEN ; <nl> /* and we mmap the page over so the kernel knows there ' s nothing good in there */
mmm libclamav / matcher - ac . c <nl> ppp libclamav / matcher - ac . c <nl> static int ac_findmatch_branch ( const unsigned char * buffer , uint32_t offset , uin <nl> if ( bp == length ) <nl> match = ! match ; <nl> /* ' wide ' characters need a ' wider ' check */ <nl> - else if ( pattern -> sigopts & ACPATT_OPTION_WIDE ) { <nl> + else if (( pattern -> sigopts & ACPATT_OPTION_WIDE ) && ( bp + 1 < length )) { <nl> if (!( isalnum ( buffer [ bp ]) && buffer [ bp + 1 ] == '\ 0 ')) <nl> match = ! match ; <nl> } <nl> /* ' normal ' characters */ <nl> - else if (! isalnum ( buffer [ offset - 1 ])) <nl> + else if (! isalnum ( buffer [ bp ])) <nl> match = ! match ; <nl> } <nl> 
mmm libclamav / bytecode . c <nl> ppp libclamav / bytecode . c <nl> int cli_bytecode_prepare ( struct cl_engine * engine , struct cli_all_bc * bcs , unsig <nl> } <nl> cli_bytecode_context_destroy ( ctx ); <nl>  <nl> + <nl> if ( engine -> bytecode_mode != CL_BYTECODE_MODE_INTERPRETER && <nl> engine -> bytecode_mode != CL_BYTECODE_MODE_OFF ) { <nl> + selfcheck ( 1 , bcs -> engine ); <nl> rc = cli_bytecode_prepare_jit ( bcs ); <nl> if ( rc == CL_SUCCESS ) { <nl> jitok = 1 ;
mmm libclamav / 7z / 7zDec . c <nl> ppp libclamav / 7z / 7zDec . c <nl> static SRes SzFolder_Decode2 ( const CSzFolder * folder , const UInt64 * packSizes , <nl> else <nl> return SZ_ERROR_UNSUPPORTED ; <nl> } <nl> + if (! packSizes ) <nl> + return SZ_ERROR_FAIL ; <nl> offset = GetSum ( packSizes , si ); <nl> inSize = packSizes [ si ]; <nl> RINOK ( LookInStream_SeekTo ( inStream , startPos + offset ));
mmm libclamav / scanners . c <nl> ppp libclamav / scanners . c <nl> static void emax_reached ( cli_ctx * ctx ) { <nl> # define CALL_PRESCAN_CB ( scanfn ) \ <nl> if ( ctx -> engine -> scanfn ) { \ <nl> perf_start ( ctx , PERFT_PRECB ); \ <nl> - switch ( ctx -> engine -> scanfn ( fmap_fd (* ctx -> fmap ), filetype , ctx -> cb_ctx )) { \ <nl> + switch ( ctx -> engine -> scanfn ( fmap_fd (* ctx -> fmap ), filetype , ctx -> cb_ctx )) { \ <nl> case CL_BREAK : \ <nl> cli_dbgmsg (" cli_magic_scandesc : file whitelisted by "# scanfn " callback \ n "); \ <nl> perf_stop ( ctx , PERFT_PRECB ); \ <nl> + ctx -> hook_lsig_matches = old_hook_lsig_matches ; \ <nl> ret_from_magicscan ( CL_CLEAN ); \ <nl> case CL_VIRUS : \ <nl> cli_dbgmsg (" cli_magic_scandesc : file blacklisted by "# scanfn " callback \ n "); \ <nl> cli_append_virus ( ctx , " Detected . By . Callback "); \ <nl> perf_stop ( ctx , PERFT_PRECB ); \ <nl> - ret_from_magicscan ( cli_checkfp ( hash , hashed_size , ctx )); \ <nl> + ctx -> hook_lsig_matches = old_hook_lsig_matches ; \ <nl> + ret_from_magicscan ( cli_checkfp ( hash , hashed_size , ctx )); \ <nl> case CL_CLEAN : \ <nl> break ; \ <nl> default : \ <nl> static int magic_scandesc ( cli_ctx * ctx , cli_file_t type ) <nl> emax_reached ( ctx ); <nl> early_ret_from_magicscan ( CL_CLEAN ); <nl> } <nl> + old_hook_lsig_matches = ctx -> hook_lsig_matches ; <nl>  <nl> perf_start ( ctx , PERFT_FT ); <nl> if ( type == CL_TYPE_ANY ) <nl> static int magic_scandesc ( cli_ctx * ctx , cli_file_t type ) <nl>  <nl> perf_stop ( ctx , PERFT_CACHE ); <nl> hashed_size = (* ctx -> fmap )-> len ; <nl> - old_hook_lsig_matches = ctx -> hook_lsig_matches ; <nl> ctx -> hook_lsig_matches = NULL ; <nl>  <nl> if (!( ctx -> options &~ CL_SCAN_ALLMATCHES ) || ( ctx -> recursion == ctx -> engine -> maxreclevel )) { /* raw mode ( stdin , etc .) or last level of recursion */
mmm libclamav / wwunpack . c <nl> ppp libclamav / wwunpack . c <nl> int wwunpack ( uint8_t * exe , uint32_t exesz , uint8_t * wwsect , struct cli_exe_secti <nl> return CL_EFORMAT ; <nl> exe [ pe + 6 ]=( uint8_t ) scount ; <nl> exe [ pe + 7 ]=( uint8_t )( scount >> 8 ); <nl> + if (! CLI_ISCONTAINED ( wwsect , sects [ scount ]. rsz , wwsect + 0x295 , 4 ) || <nl> + ! CLI_ISCONTAINED ( wwsect , sects [ scount ]. rsz , wwsect + 0x295 + sects [ scount ]. rva , 4 ) || <nl> + ! CLI_ISCONTAINED ( wwsect , sects [ scount ]. rsz , wwsect + 0x295 + sects [ scount ]. rva + 0x299 , 4 )) { <nl> + cli_dbgmsg (" WWPack : unpack memory address out of bounds .\ n "); <nl> + return CL_EFORMAT ; <nl> + } <nl> cli_writeint32 (& exe [ pe + 0x28 ], cli_readint32 ( wwsect + 0x295 )+ sects [ scount ]. rva + 0x299 ); <nl> cli_writeint32 (& exe [ pe + 0x50 ], cli_readint32 (& exe [ pe + 0x50 ])- sects [ scount ]. vsz ); <nl> 
mmm libclamunrar_iface / unrar_iface . c <nl> ppp libclamunrar_iface / unrar_iface . c <nl> int unrar_open ( int fd , const char * dirname , unrar_state_t * state ) <nl> unrar_dbgmsg (" UNRAR : Offset : % x \ n ", offset ); <nl> if ( offset < 0 ){ <nl> unrar_dbgmsg (" UNRAR : Error Offset : % d \ n ", offset ); <nl> - offset = 0 ; <nl> + free ( main_hdr ); <nl> + free ( state -> comment_dir ); <nl> + free ( unpack_data ); <nl> + return UNRAR_ERR ; <nl> } <nl> comment_header = read_header ( fd , COMM_HEAD ); <nl> if ( comment_header ) {
mmm libclamav / stats . c <nl> ppp libclamav / stats . c <nl> end : <nl> cli_warnmsg (" clamav_stats_add_sample : unlcoking mutex failed ( err : % d ): % s \ n ", err , strerror ( err )); <nl> } <nl> # endif <nl> + return ; <nl> } <nl>  <nl> void clamav_stats_flush ( struct cl_engine * engine , void * cbdata ) <nl> void clamav_stats_decrement_count ( const char * virname , const unsigned char * md5 , <nl> cli_warnmsg (" clamav_stats_decrement_count : unlocking mutex failed ( err : % d ): % s \ n ", err , strerror ( err )); <nl> } <nl> # endif <nl> + return ; <nl> } <nl>  <nl> size_t clamav_stats_get_num ( void * cbdata )
mmm libclamav / autoit . c <nl> ppp libclamav / autoit . c <nl> static unsigned int u2a ( uint8_t * dest , unsigned int len ) { <nl> for ( i = 0 ; i < j ; i += 2 ) <nl> cnt +=( src [ i ]!= 0 && src [ i + 1 ]== 0 ); <nl>  <nl> - if ( cnt * 2 < j ) <nl> + if ( cnt * 4 < j ) <nl> return len ; <nl> } <nl>  <nl> static unsigned int u2a ( uint8_t * dest , unsigned int len ) { <nl> return len ; <nl> } <nl>  <nl> + <nl> /********************* <nl> MT realted stuff <nl> *********************/
mmm sigtool / sigtool . c <nl> ppp sigtool / sigtool . c <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> unsigned int i , len = 0 , hlen , negative , altnum , alttype ; <nl> char * buff ; <nl>  <nl> + <nl> + hexcpy = NULL ; <nl> + buff = NULL ; <nl>  <nl> hexcpy = strdup ( hex ); <nl> if (! hexcpy ) { <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> buff = calloc ( strlen ( hex ) + 512 , sizeof ( char )); <nl> if (! buff ) { <nl> mprintf ("! decodehexspecial : Can ' t allocate memory for buff \ n "); <nl> + free ( hexcpy ); <nl> return NULL ; <nl> } <nl> start = hexcpy ; <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> * pt ++ = 0 ; <nl> if (! start ) { <nl> mprintf ("! decodehexspecial : Unexpected EOL \ n "); <nl> + free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl> if ( pt >= hexcpy + 2 ) { <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> if (!( decoded = decodehexstr ( start , & hlen ))) { <nl> mprintf ("! Decoding failed ( 1 ): % s \ n ", pt ); <nl> free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl> memcpy (& buff [ len ], decoded , hlen ); <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> if (!( start = strchr ( pt , ')'))) { <nl> mprintf ("! decodehexspecial : Missing closing parethesis \ n "); <nl> free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl>  <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> if (! strlen ( pt )) { <nl> mprintf ("! decodehexspecial : Empty block \ n "); <nl> free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl>  <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> if (! altnum ) { <nl> mprintf ("! decodehexspecial : Empty block \ n "); <nl> free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl> altnum ++; <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> for ( i = 0 ; i < altnum ; i ++) { <nl> if (!( h = cli_strtok ( pt , i , "|"))) { <nl> free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl>  <nl> if (!( c = cli_hex2str ( h ))) { <nl> free ( h ); <nl> free ( hexcpy ); <nl> + free ( buff ); <nl> return NULL ; <nl> } <nl>  <nl> static char * decodehexspecial ( const char * hex , unsigned int * dlen ) <nl> if ( start ) { <nl> if (!( decoded = decodehexstr ( start , & hlen ))) { <nl> mprintf ("! Decoding failed ( 2 )\ n "); <nl> + free ( buff ); <nl> free ( hexcpy ); <nl> return NULL ; <nl> }
mmm libclamav / pdf . c <nl> ppp libclamav / pdf . c <nl> static int pdf_extract_obj ( struct pdf_struct * pdf , struct pdf_obj * obj ) <nl> n -= q2 - q ; <nl> q = q2 ; <nl> } <nl> - } while ( n > 0 && q2 && q2 [- 1 ] == '\\'); <nl> + } while ( n > 0 && q2 && q2 [- 2 ] == '\\'); <nl> if ( q2 ) <nl> end = q2 - 1 ; <nl> n = end - out ;
mmm libclamav / pdfng . c <nl> ppp libclamav / pdfng . c <nl> char * pdf_finalize_string ( struct pdf_struct * pdf , struct pdf_obj * obj , const cha <nl> /* TODO : replace the escape sequences directly in the wrkstr */ <nl> if ( strchr ( wrkstr , '\\')) { <nl> output = cli_calloc ( wrklen + 1 , sizeof ( char )); <nl> - if (! output ) <nl> + if (! output ) { <nl> + free ( wrkstr ); <nl> return NULL ; <nl> + } <nl>  <nl> outlen = 0 ; <nl> for ( i = 0 ; i < wrklen ; ++ i ) {
mmm 3rdparty / expat / lib / xmlparse . c <nl> ppp 3rdparty / expat / lib / xmlparse . c <nl> doProlog ( XML_Parser parser , <nl> return XML_ERROR_UNCLOSED_TOKEN ; <nl> case XML_TOK_PARTIAL_CHAR : <nl> return XML_ERROR_PARTIAL_CHAR ; <nl> + case - XML_TOK_PROLOG_S : <nl> + tok = - tok ; <nl> + break ; <nl> case XML_TOK_NONE : <nl> # ifdef XML_DTD <nl> /* for internal PE NOT referenced between declarations */mmm 3rdparty / expat / lib / xmltok_impl . c <nl> ppp 3rdparty / expat / lib / xmltok_impl . c <nl> doProlog ( XML_Parser parser , <nl> return XML_ERROR_UNCLOSED_TOKEN ; <nl> case XML_TOK_PARTIAL_CHAR : <nl> return XML_ERROR_PARTIAL_CHAR ; <nl> + case - XML_TOK_PROLOG_S : <nl> + tok = - tok ; <nl> + break ; <nl> case XML_TOK_NONE : <nl> # ifdef XML_DTD <nl> /* for internal PE NOT referenced between declarations */ <nl> PREFIX ( updatePosition )( const ENCODING * enc , <nl> const char * end , <nl> POSITION * pos ) <nl> { <nl> - while ( ptr != end ) { <nl> + while ( ptr < end ) { <nl> switch ( BYTE_TYPE ( enc , ptr )) { <nl> # define LEAD_CASE ( n ) \ <nl> case BT_LEAD ## n : \
mmm src / ui . cpp <nl> ppp src / ui . cpp <nl> public : <nl> if ( ms_uiThread ) <nl> { <nl> ms_uiThread -> Join (); <nl> + delete ms_uiThread ; <nl> ms_uiThread = NULL ; <nl> } <nl> }
mmm src / ui . cpp <nl> ppp src / ui . cpp <nl> void CenterWindowOnHostApplication ( wxTopLevelWindow * win ) <nl> EnumWindows ( EnumProcessWindowsCallback , ( LPARAM ) & data ); <nl>  <nl> if ( data . biggest . IsEmpty ()) <nl> - return ; // no window to center on <nl> + { <nl> + // no parent window to center on , so center on the screen <nl> + win -> Center (); <nl> + return ; <nl> + } <nl>  <nl> const wxRect & host ( data . biggest ); <nl> 
mmm src / ui . cpp <nl> ppp src / ui . cpp <nl> BOOL CALLBACK EnumProcessWindowsCallback ( HWND handle , LPARAM lParam ) <nl>  <nl> RECT rwin ; <nl> GetWindowRect ( handle , & rwin ); <nl> + if ( MonitorFromRect (& rwin , MONITOR_DEFAULTTONULL ) == NULL ) <nl> + return TRUE ; // window is offscreen <nl> + <nl> wxRect r ( rwin . left , rwin . top , rwin . right - rwin . left , rwin . bottom - rwin . top ); <nl> if ( r . width * r . height > data . biggest . width * data . biggest . height ) <nl> data . biggest = r ;
mmm src / gui / curses / gui - curses - chat . c <nl> ppp src / gui / curses / gui - curses - chat . c <nl> gui_chat_draw ( struct t_gui_buffer * buffer , int clear_chat ) <nl>  <nl> if ( clear_chat ) <nl> { <nl> - snprintf ( format_empty , 32 , "%%-% ds ", ptr_win -> win_chat_width ); <nl> + snprintf ( format_empty , sizeof ( format_empty ), <nl> + "%%-% ds ", ptr_win -> win_chat_width ); <nl> for ( i = 0 ; i < ptr_win -> win_chat_height ; i ++) <nl> { <nl> mvwprintw ( GUI_WINDOW_OBJECTS ( ptr_win )-> win_chat , i , 0 ,
mmm src / plugins / irc / irc - ctcp . c <nl> ppp src / plugins / irc / irc - ctcp . c <nl> irc_ctcp_dcc_filename_without_quotes ( const char * filename ) <nl> int length ; <nl>  <nl> length = strlen ( filename ); <nl> - if ( length > 0 ) <nl> + if ( length > 1 ) <nl> { <nl> if (( filename [ 0 ] == '\"') && ( filename [ length - 1 ] == '\"')) <nl> return weechat_strndup ( filename + 1 , length - 2 );
mmm src / plugins / irc / irc - mode . c <nl> ppp src / plugins / irc / irc - mode . c <nl> irc_mode_channel_set ( struct t_irc_server * server , <nl> int smart_filter ; <nl> struct t_irc_nick * ptr_nick ; <nl> struct t_irc_modelist * ptr_modelist ; <nl> + struct t_irc_modelist_item * ptr_item ; <nl>  <nl> if (! server || ! channel || ! modes ) <nl> return 0 ; <nl> irc_mode_channel_set ( struct t_irc_server * server , <nl> } <nl> else if ( set_flag == '-') <nl> { <nl> - irc_modelist_item_free ( ptr_modelist , <nl> - irc_modelist_item_search ( ptr_modelist , ptr_arg )); <nl> + ptr_item = irc_modelist_item_search ( ptr_modelist , <nl> + ptr_arg ); <nl> + if ( ptr_item ) <nl> + irc_modelist_item_free ( ptr_modelist , ptr_item ); <nl> } <nl> } <nl> }
mmm src / core / wee - string . c <nl> ppp src / core / wee - string . c <nl> string_replace_regex ( const char * string , void * regex , const char * replace , <nl> int length , length_replace , start_offset , i , rc , end , last_match ; <nl> regmatch_t regex_match [ 100 ]; <nl>  <nl> - if (! string ) <nl> + if (! string || ! regex ) <nl> return NULL ; <nl>  <nl> length = strlen ( string ) + 1 ;
mmm src / gui / curses / gui - curses - bar - window . c <nl> ppp src / gui / curses / gui - curses - bar - window . c <nl> gui_bar_window_draw ( struct t_gui_bar_window * bar_window , <nl>  <nl> /* move cursor if it was asked in an item content ( input_text does that <nl> to move cursor in user input text ) */ <nl> - if ( window && ( gui_current_window == window ) <nl> + if ((! window || ( gui_current_window == window )) <nl> && ( bar_window -> cursor_x >= 0 ) && ( bar_window -> cursor_y >= 0 )) <nl> { <nl> move ( bar_window -> cursor_y , bar_window -> cursor_x );
mmm src / plugins / irc / irc - command . c <nl> ppp src / plugins / irc / irc - command . c <nl> irc_command_server ( void * data , struct t_gui_buffer * buffer , int argc , <nl> if ( irc_current_server ) <nl> { <nl> ptr_server = irc_current_server -> next_server ; <nl> + if (! ptr_server ) <nl> + ptr_server = irc_servers ; <nl> while ( ptr_server != irc_current_server ) <nl> { <nl> if ( ptr_server -> buffer )
mmm src / plugins / scripts / perl / weechat - perl . c <nl> ppp src / plugins / scripts / perl / weechat - perl . c <nl> weechat_perl_cmd ( t_weechat_plugin * plugin , <nl> ptr_handler -> handler_args ); <nl> } <nl> } <nl> + if (! handler_found ) <nl> + plugin -> print_server ( plugin , " ( none )"); <nl> break ; <nl> case 1 : <nl> if ( plugin -> ascii_strcasecmp ( plugin , argv [ 0 ], " autoload ") == 0 )mmm weechat / src / plugins / scripts / perl / weechat - perl . c <nl> ppp weechat / src / plugins / scripts / perl / weechat - perl . c <nl> weechat_perl_cmd ( t_weechat_plugin * plugin , <nl> ptr_handler -> handler_args ); <nl> } <nl> } <nl> + if (! handler_found ) <nl> + plugin -> print_server ( plugin , " ( none )"); <nl> break ; <nl> case 1 : <nl> if ( plugin -> ascii_strcasecmp ( plugin , argv [ 0 ], " autoload ") == 0 ) <nl> weechat_perl_cmd ( t_weechat_plugin * plugin , <nl> ptr_handler -> handler_args ); <nl> } <nl> } <nl> + if (! handler_found ) <nl> + plugin -> print_server ( plugin , " ( none )"); <nl> break ; <nl> case 1 : <nl> if ( plugin -> ascii_strcasecmp ( plugin , argv [ 0 ], " autoload ") == 0 )
mmm src / plugins / irc / irc - server . c <nl> ppp src / plugins / irc / irc - server . c <nl> irc_server_msgq_flush () <nl> /* new_msg = plugin_modifier_exec ( PLUGIN_MODIFIER_IRC_IN , <nl> irc_recv_msgq -> server -> name , <nl> ptr_data );*/ <nl> + new_msg = NULL ; <nl> + <nl> /* no changes in new message */ <nl> if ( new_msg && ( strcmp ( ptr_data , new_msg ) == 0 )) <nl> {
mmm src / plugins / trigger / trigger - callback . c <nl> ppp src / plugins / trigger / trigger - callback . c <nl> trigger_callback_replace_regex ( struct t_trigger * trigger , <nl>  <nl> for ( i = 0 ; i < trigger -> regex_count ; i ++) <nl> { <nl> + /* if regex is not set ( invalid ), skip it */ <nl> + if (! trigger -> regex [ i ]. regex ) <nl> + continue ; <nl> + <nl> ptr_key = ( trigger -> regex [ i ]. variable ) ? <nl> trigger -> regex [ i ]. variable : <nl> trigger_hook_regex_default_var [ weechat_config_integer ( trigger -> options [ TRIGGER_OPTION_HOOK ])];
mmm src / plugins / scripts / lua / weechat - lua - api . c <nl> ppp src / plugins / scripts / lua / weechat - lua - api . c <nl> weechat_lua_api_config_reload_cb ( void * data , <nl> { <nl> lua_argv [ 0 ] = ( script_callback -> data ) ? script_callback -> data : empty_arg ; <nl> lua_argv [ 1 ] = script_ptr2str ( config_file ); <nl> - lua_argv [ 2 ] = NULL ; <nl>  <nl> rc = ( int *) weechat_lua_exec ( script_callback -> script , <nl> WEECHAT_SCRIPT_EXEC_INT ,
mmm src / gui / gui - buffer . c <nl> ppp src / gui / gui - buffer . c <nl> gui_buffer_local_var_remove ( struct t_gui_buffer * buffer , <nl> buffer -> local_variables = local_var -> next_var ; <nl> if ( buffer -> last_local_var == local_var ) <nl> buffer -> last_local_var = local_var -> prev_var ; <nl> + <nl> + free ( local_var ); <nl> } <nl>  <nl> /*
mmm src / core / hook / wee - hook - line . c <nl> ppp src / core / hook / wee - hook - line . c <nl> hook_line_free_data ( struct t_hook * hook ) <nl> if (! hook || ! hook -> hook_data ) <nl> return ; <nl>  <nl> + if ( HOOK_LINE ( hook , buffers )) <nl> + { <nl> + string_free_split ( HOOK_LINE ( hook , buffers )); <nl> + HOOK_LINE ( hook , buffers ) = NULL ; <nl> + } <nl> if ( HOOK_LINE ( hook , tags_array )) <nl> { <nl> string_free_split_tags ( HOOK_LINE ( hook , tags_array ));
mmm src / gui / gui - buffer . c <nl> ppp src / gui / gui - buffer . c <nl> gui_buffer_set_highlight_words_list ( struct t_gui_buffer * buffer , <nl> } <nl>  <nl> gui_buffer_set_highlight_words ( buffer , words ); <nl> + <nl> + free ( words ); <nl> } <nl>  <nl> /*
mmm src / core / wee - hook . c <nl> ppp src / core / wee - hook . c <nl> hook_process_hashtable ( struct t_weechat_plugin * plugin , <nl>  <nl> hook_add_to_list ( new_hook ); <nl>  <nl> + if ( weechat_debug_core >= 1 ) <nl> + { <nl> + gui_chat_printf ( NULL , <nl> + " debug : hook_process : command =\"% s \", " <nl> + " options =\"% s \", timeout =% d ", <nl> + new_hook_process -> command , <nl> + hashtable_get_string ( new_hook_process -> options , <nl> + " keys_values "), <nl> + new_hook_process -> timeout ); <nl> + } <nl> + <nl> hook_process_run ( new_hook ); <nl>  <nl> return new_hook ;
mmm src / core / wee - command . c <nl> ppp src / core / wee - command . c <nl> COMMAND_CALLBACK ( cursor ) <nl> gui_cursor_move_xy ( x , y ); <nl> } <nl> } <nl> + free ( str_x ); <nl> } <nl> } <nl> else
mmm src / gui / gui - buffer . c <nl> ppp src / gui / gui - buffer . c <nl> gui_buffer_move_to_number ( struct t_gui_buffer * buffer , int number ) <nl> if ( ptr_buffer == ptr_last_buffer ) <nl> break ; <nl> } <nl> - gui_buffers -> prev_buffer = buffer ; <nl> - buffer -> prev_buffer = NULL ; <nl> - buffer -> next_buffer = gui_buffers ; <nl> - gui_buffers = buffer ; <nl> + gui_buffers -> prev_buffer = ptr_last_buffer ; <nl> + ptr_first_buffer -> prev_buffer = NULL ; <nl> + ptr_last_buffer -> next_buffer = gui_buffers ; <nl> + gui_buffers = ptr_first_buffer ; <nl> } <nl> else <nl> { <nl> gui_buffer_move_to_number ( struct t_gui_buffer * buffer , int number ) <nl> for ( ptr_buffer_pos = gui_buffers ; ptr_buffer_pos ; <nl> ptr_buffer_pos = ptr_buffer_pos -> next_buffer ) <nl> { <nl> - if ( ptr_buffer_pos -> number == number ) <nl> + if ( ptr_buffer_pos -> number >= number ) <nl> break ; <nl> } <nl> if ( ptr_buffer_pos )
mmm src / plugins / relay / irc / relay - irc . c <nl> ppp src / plugins / relay / irc / relay - irc . c <nl> relay_irc_recv ( struct t_relay_client * client , const char * data ) <nl> /* server capabilities */ <nl> if ( irc_command && ( weechat_strcasecmp ( irc_command , " cap ") == 0 )) <nl> { <nl> - if (( irc_argc > 0 ) && irc_argv ) <nl> + if ( irc_argc > 0 ) <nl> { <nl> relay_irc_recv_command_capab ( client , <nl> irc_argc , irc_argv , irc_argv_eol );
mmm src / gui / curses / gui - curses - window . c <nl> ppp src / gui / curses / gui - curses - window . c <nl> gui_window_set_custom_color_fg ( WINDOW * window , int fg ) <nl> { <nl> current_bg = window_current_style_bg ; <nl>  <nl> + gui_window_remove_color_style ( window , A_BOLD ); <nl> + <nl> if (( fg > 0 ) && ( fg & GUI_COLOR_EXTENDED_FLAG )) <nl> { <nl> gui_window_set_color ( window , <nl> gui_window_set_custom_color_fg ( WINDOW * window , int fg ) <nl> } <nl> else if ( fg < GUI_CURSES_NUM_WEECHAT_COLORS ) <nl> { <nl> - gui_window_remove_color_style ( window , A_BOLD ); <nl> attributes = gui_weechat_colors [ fg ]. attributes ; <nl> gui_window_set_color_style ( window , attributes ); <nl> fg = gui_weechat_colors [ fg ]. foreground ;
mmm src / plugins / irc / irc - server . c <nl> ppp src / plugins / irc / irc - server . c <nl> irc_server_msgq_flush () <nl> free ( command ); <nl> if ( channel ) <nl> free ( channel ); <nl> + if ( arguments ) <nl> + free ( arguments ); <nl> if ( msg_decoded ) <nl> free ( msg_decoded ); <nl> if ( msg_decoded_without_color )
mmm config . h <nl> ppp config . h <nl> namespace CryptoPP { } <nl> # define __USE_W32_SOCKETS <nl> # endif <nl>  <nl> - typedef unsigned char byte ; // put in global namespace to avoid ambiguity with other byte typedefs <nl> +// Originally in global namespace to avoid ambiguity with other byte typedefs . <nl> +// Moved to Crypto ++ namespace due to C ++ 17 , std :: byte and potential compile problems . Also see <nl> +// http :// www . cryptopp . com / wiki / std :: byte and http :// github . com / weidai11 / cryptopp / issues / 442 <nl> +// typedef unsigned char byte ; <nl> +# define CRYPTOPP_NO_GLOBAL_BYTE 1 <nl>  <nl> NAMESPACE_BEGIN ( CryptoPP ) <nl>  <nl> + typedef unsigned char byte ; <nl> typedef unsigned short word16 ; <nl> typedef unsigned int word32 ; <nl> 
mmm randpool . cpp <nl> ppp randpool . cpp <nl> NAMESPACE_BEGIN ( CryptoPP ) <nl> RandomPool :: RandomPool () <nl> : m_pCipher ( new AES :: Encryption ), m_keySet ( false ) <nl> { <nl> + memset ( m_key , 0 , m_key . SizeInBytes ()); <nl> + memset ( m_seed , 0 , m_seed . SizeInBytes ()); <nl> } <nl>  <nl> void RandomPool :: IncorporateEntropy ( const byte * input , size_t length )
mmm stdcpp . h <nl> ppp stdcpp . h <nl> # include < algorithm > <nl> # include < functional > <nl>  <nl> +// R - value references and std :: move <nl> +# if defined ( __cplusplus >= 201103L ) <nl> +# include < utility > <nl> +# endif <nl> + <nl> # ifdef CRYPTOPP_INCLUDE_VECTOR_CC <nl> // workaround needed on Sun Studio 12u1 Sun C ++ 5 . 10 SunOS_i386 128229 - 02 2009 / 09 / 21 <nl> # include < vector . cc >
mmm misc . h <nl> ppp misc . h <nl> inline T1 RoundUpToMultipleOf ( const T1 & n , const T2 & m ) <nl> //! \ details Internally the function calls C ++ 11 ' s < tt > alignof </ tt > if available . If not available , <nl> //! then the function uses compiler specific extensions such as < tt > __alignof </ tt > and <nl> //! < tt > _alignof_ </ tt >. If an extension is not available , then the function uses <nl> -//! < tt > __BIGGEST_ALIGNMENT__ </ tt >. < tt > sizeof ( T )</ tt > is used if the others are not available . <nl> +//! < tt > __BIGGEST_ALIGNMENT__ </ tt > if < tt > __BIGGEST_ALIGNMENT__ </ tt > is smaller than < tt > sizeof ( T )</ tt >. <nl> +//! < tt > sizeof ( T )</ tt > is used if all others are not available . <nl> //! In < em > all </ em > cases , if < tt > CRYPTOPP_ALLOW_UNALIGNED_DATA_ACCESS </ tt > is defined , then the <nl> //! function returns 1 . <nl> template < class T > <nl> inline unsigned int GetAlignmentOf ( T * dummy = NULL ) // VC60 workaround <nl> return __alignof ( T ); <nl> # elif defined ( __GNUC__ ) <nl> return __alignof__ ( T ); <nl> -# elif __BIGGEST_ALIGNMENT__ <nl> - return __BIGGEST_ALIGNMENT__ ; <nl> # elif CRYPTOPP_BOOL_SLOW_WORD64 <nl> return UnsignedMin ( 4U , sizeof ( T )); <nl> # else <nl> +# if __BIGGEST_ALIGNMENT__ <nl> + if ( __BIGGEST_ALIGNMENT__ < sizeof ( T )) <nl> + return __BIGGEST_ALIGNMENT__ ; <nl> + else <nl> +# endif <nl> return sizeof ( T ); <nl> # endif <nl> }
mmm config . h <nl> ppp config . h <nl> typedef unsigned int word32 ; <nl> # if defined ( _MSC_VER ) || defined ( __BORLANDC__ ) <nl> typedef unsigned __int64 word64 ; <nl> # define W64LIT ( x ) x ## ui64 <nl> -# elif ( _LP64 || __LP64__ ) && ! defined ( __SUNPRO_CC ) <nl> +# elif ( _LP64 || __LP64__ ) <nl> typedef unsigned long word64 ; <nl> # define W64LIT ( x ) x ## UL <nl> # else
mmm kalyna . cpp <nl> ppp kalyna . cpp <nl> void Kalyna :: Base :: UncheckedSetKey ( const byte * key , unsigned int keylen , const N <nl>  <nl> void Kalyna :: Base :: ProcessAndXorBlock ( const byte * inBlock , const byte * xorBlock , byte * outBlock ) const <nl> { <nl> + // Timing attack countermeasure . see comments in Rijndael for more details <nl> + const int cacheLineSize = GetCacheLineSize (); <nl> + volatile word32 _u = 0 ; <nl> + word32 u = _u ; <nl> + <nl> + for ( unsigned int i = 0 ; i < COUNTOF ( KalynaTab :: S ); i += cacheLineSize ) <nl> + u &= * reinterpret_cast < const word32 *>( KalynaTab :: S + i ); <nl> + m_wspace [ 0 ] = u ; <nl> + <nl> switch (( m_nb << 8 ) | m_nk ) <nl> { <nl> case ( 2 << 8 ) | 2 :
mmm ppc - simd . cpp <nl> ppp ppc - simd . cpp <nl> // is needed because additional CXXFLAGS are required to enable the <nl> // appropriate instructions sets in some build configurations . <nl>  <nl> +// TODO : we still need to implement Power8 SHA . Once we have Power8 SHA , <nl> +// we should be able to use CRYPTOPP_POWER8_AES_AVAILABLE and <nl> +// CRYPTOPP_POWER8_SHA_AVAILABLE instead of the broader <nl> +// CRYPTOPP_POWER8_AVAILABLE . The change will need to be coordinated <nl> +// with the defines in config . h . <nl> + <nl> +// TODO : Bob Wilkinson reported we are misdetecting CRYPTOPP_POWER8_AVAILABLE . <nl> +// The problem is , the updated compiler supports them but the down - level <nl> +// assembler and linker do not . We will probably need to fix that through <nl> +// the makefile , similar to the way x86 AES and SHA is handled . Another <nl> +// twist is , we don ' t have access to a test machine and it must be fixed <nl> +// for two compilers ( IBM XL C / C ++ and GCC ). Ugh ... <nl> + <nl> # include " pch . h " <nl> # include " config . h " <nl> # include " stdcpp . h " <nl> bool CPU_ProbePower8 () <nl> { <nl> # if defined ( CRYPTOPP_NO_CPU_FEATURE_PROBES ) <nl> return false ; <nl> -# elif ( CRYPTOPP_POWER7_AVAILABLE ) <nl> +# elif ( CRYPTOPP_POWER8_AVAILABLE ) <nl> # if defined ( CRYPTOPP_GNU_STYLE_INLINE_ASSEMBLY ) <nl>  <nl> // longjmp and clobber warnings . Volatile is required .
mmm secblock . h <nl> ppp secblock . h <nl> public : <nl>  <nl> if ( t . m_size ) <nl> { <nl> + const size_type oldSize = m_size ; <nl> if ( this != & t ) // s += t <nl> { <nl> - const size_type oldSize = m_size ; <nl> Grow ( m_size + t . m_size ); <nl> memcpy_s ( m_ptr + oldSize , ( m_size - oldSize )* sizeof ( T ), t . m_ptr , t . m_size * sizeof ( T )); <nl> } <nl> else // t += t <nl> { <nl> - SecBlock result ( m_size + t . m_size ); <nl> - if ( m_size ) { memcpy_s ( result . m_ptr , result . m_size * sizeof ( T ), m_ptr , m_size * sizeof ( T ));} <nl> - memcpy_s ( result . m_ptr + m_size , ( result . m_size - m_size )* sizeof ( T ), t . m_ptr , t . m_size * sizeof ( T )); <nl> - swap ( result ); <nl> + Grow ( m_size * 2 ); <nl> + memcpy_s ( m_ptr + oldSize , ( m_size - oldSize )* sizeof ( T ), m_ptr , oldSize * sizeof ( T )); <nl> } <nl> } <nl> return * this ;
mmm ecp . cpp <nl> ppp ecp . cpp <nl> ECP :: ECP ( BufferedTransformation & bt ) <nl> GetField (). BERDecodeElement ( seq , m_b ); <nl> // skip optional seed <nl> if (! seq . EndReached ()) <nl> - BERDecodeOctetString ( seq , TheBitBucket ()); <nl> + { <nl> + SecByteBlock seed ; <nl> + unsigned int unused ; <nl> + BERDecodeBitString ( seq , seed , unused ); <nl> + } <nl> seq . MessageEnd (); <nl> } <nl> 
mmm queue . cpp <nl> ppp queue . cpp <nl> public : <nl>  <nl> inline size_t Put ( const byte * begin , size_t length ) <nl> { <nl> + if (! begin || ! length ) return length ; <nl> size_t l = STDMIN ( length , MaxSize ()- m_tail ); <nl> if ( buf + m_tail != begin ) <nl> memcpy ( buf + m_tail , begin , l ); <nl> public : <nl>  <nl> inline size_t Peek ( byte * target , size_t copyMax ) const <nl> { <nl> + if (! target || ! copyMax ) return 0 ; <nl> size_t len = STDMIN ( copyMax , m_tail - m_head ); <nl> memcpy ( target , buf + m_head , len ); <nl> return len ;
mmm secblock . h <nl> ppp secblock . h <nl> public : <nl> /// \ since Crypto ++ 6 . 0 <nl> # if defined ( CRYPTOPP_DOXYGEN_PROCESSING ) <nl> static const size_type ELEMS_MAX = ...; <nl> +# elif defined ( _MSC_VER ) && ( _MSC_VER <= 1400 ) <nl> + static const size_type ELEMS_MAX = (~( size_type ) 0 )/ sizeof ( T ); <nl> # elif defined ( CRYPTOPP_CXX11_ENUM ) <nl> enum : size_type { ELEMS_MAX = SIZE_MAX / sizeof ( T )}; <nl> # else <nl> public : <nl> /// \ since Crypto ++ 6 . 0 <nl> # if defined ( CRYPTOPP_DOXYGEN_PROCESSING ) <nl> static const size_type ELEMS_MAX = ...; <nl> +# elif defined ( _MSC_VER ) && ( _MSC_VER <= 1400 ) <nl> + static const size_type ELEMS_MAX = (~( size_type ) 0 )/ sizeof ( T ); <nl> # elif defined ( CRYPTOPP_CXX11_ENUM ) <nl> enum : size_type { ELEMS_MAX = A :: ELEMS_MAX }; <nl> # else
mmm config . h <nl> ppp config . h <nl> const lword LWORD_MAX = W64LIT ( 0xffffffffffffffff ); <nl> # else <nl> # define CRYPTOPP_NATIVE_DWORD_AVAILABLE 1 <nl> # if defined ( __alpha__ ) || defined ( __ia64__ ) || defined ( _ARCH_PPC64 ) || defined ( __x86_64__ ) || defined ( __mips64 ) || defined ( __sparc64__ ) <nl> -# if defined ( __GNUC__ ) && ! defined ( __INTEL_COMPILER ) && !( CRYPTOPP_GCC_VERSION == 40001 && defined ( __APPLE__ )) && !( defined ( __GNUC__ ) && CRYPTOPP_GCC_VERSION < 50000 && defined ( _ARCH_PPC64 )) && CRYPTOPP_GCC_VERSION >= 30400 <nl> + # if (( CRYPTOPP_GCC_VERSION >= 30400 ) || ( CRYPTOPP_LLVM_CLANG_VERSION >= 30000 ) || ( CRYPTOPP_APPLE_CLANG_VERSION >= 40300 )) && ( __SIZEOF_INT128__ >= 16 ) <nl> // GCC 4 . 0 . 1 on MacOS X is missing __umodti3 and __udivti3 <nl> // GCC 4 . 8 . 3 and bad uint128_t ops on PPC64 / POWER7 ( Issue 421 ) <nl> // mode ( TI ) division broken on amd64 with GCC earlier than GCC 3 . 4
mmm crc - simd . cpp <nl> ppp crc - simd . cpp <nl> # undef CRYPTOPP_ARM_CRC32_AVAILABLE <nl> # endif <nl>  <nl> -# if ( CRYPTOPP_CLMUL_AVAILABLE ) <nl> +# if ( CRYPTOPP_SSE42_AVAILABLE ) <nl> # include < nmmintrin . h > <nl> # endif <nl> mmm sha - simd . cpp <nl> ppp sha - simd . cpp <nl> # undef CRYPTOPP_ARM_CRC32_AVAILABLE <nl> # endif <nl>  <nl> -# if ( CRYPTOPP_CLMUL_AVAILABLE ) <nl> +# if ( CRYPTOPP_SSE42_AVAILABLE ) <nl> # include < nmmintrin . h > <nl> # endif <nl>  <nl> # undef CRYPTOPP_ARM_SHA_AVAILABLE <nl> # endif <nl>  <nl> -# if ( CRYPTOPP_CLMUL_AVAILABLE ) <nl> +# if ( CRYPTOPP_SHANI_AVAILABLE ) <nl> # include < nmmintrin . h > <nl> # include < immintrin . h > <nl> # endif
mmm zrtp / ZrtpSdesStream . cpp <nl> ppp zrtp / ZrtpSdesStream . cpp <nl> bool ZrtpSdesStream :: createSdesProfile ( char * cryptoString , size_t * maxLen ) { <nl> /* Get B64 code for master key and master salt */ <nl> b64Len = b64Encode ( keySalt , keyLenBytes + saltLenBytes , b64keySalt , sizeof ( b64keySalt )); <nl> b64keySalt [ b64Len ] = '\ 0 '; <nl> - * maxLen = snprintf ( cryptoString , * maxLen , "% d % s inline :% s ", tag , pSuite -> name , b64keySalt ); <nl> + memset ( cryptoString , 0 , * maxLen ); <nl> + * maxLen = snprintf ( cryptoString , * maxLen - 1 , "% d % s inline :% s ", tag , pSuite -> name , b64keySalt ); <nl>  <nl> memset ( keySalt , 0 , sizeof ( keySalt )); <nl> return true ;
mmm cryptcommon / ZrtpRandom . cpp <nl> ppp cryptcommon / ZrtpRandom . cpp <nl> int ZrtpRandom :: getRandomData ( uint8_t * buffer , uint32_t length ) { <nl> uint8_t rdata [ AES_BLOCK_SIZE ]; <nl> uint32_t generated = length ; <nl>  <nl> + initialize (); <nl> + <nl> lockRandom . Lock (); <nl>  <nl> /* <nl> int ZrtpRandom :: getRandomData ( uint8_t * buffer , uint32_t length ) { <nl>  <nl> int ZrtpRandom :: addEntropy ( const uint8_t * buffer , uint32_t length ) <nl> { <nl> + initialize (); <nl> + <nl> if ( buffer && length ) { <nl> sha512_hash ( buffer , length , & mainCtx ); <nl> } <nl> void ZrtpRandom :: initialize () { <nl> return ; <nl> } <nl> sha512_begin (& mainCtx ); <nl> + initialized = true ; <nl> lockRandom . Unlock (); <nl> } <nl> 
mmm src / game_config . cpp <nl> ppp src / game_config . cpp <nl> namespace game_config <nl> namespace sounds { <nl> const std :: string turn_bell = " bell . wav ", <nl> timer_bell = " timer . wav ", <nl> - receive_message = " chat - 3 . ogg ", <nl> + receive_message = " chat - 1 . ogg , chat - 2 . ogg , chat - 3 . ogg , chat - 4 . ogg ", <nl> receive_message_highlight = " chat - highlight . ogg ", <nl> receive_message_friend = " chat - 4 . ogg ", <nl> receive_message_server = " receive . wav ",
mmm src / playturn . cpp <nl> ppp src / playturn . cpp <nl> void turn_info :: left_click ( const SDL_MouseButtonEvent & event ) <nl> enemy == units_ . end () && ! current_route_ . steps . empty () && <nl> current_route_ . steps . front () == selected_hex_ ) { <nl>  <nl> + const std :: vector < gamemap :: location > steps = current_route_ . steps ; <nl> const size_t moves = move_unit (& gui_ , gameinfo_ , status_ , map_ , units_ , teams_ , <nl> - current_route_ . steps ,& recorder ,& undo_stack_ ,& next_unit_ ); <nl> + steps ,& recorder ,& undo_stack_ ,& next_unit_ ); <nl>  <nl> cursor :: set ( cursor :: NORMAL ); <nl>  <nl> void turn_info :: left_click ( const SDL_MouseButtonEvent & event ) <nl>  <nl> redo_stack_ . clear (); <nl>  <nl> - assert ( moves <= current_route_ . steps . size ()); <nl> - const gamemap :: location & dst = current_route_ . steps [ moves - 1 ]; <nl> + assert ( moves <= steps . size ()); <nl> + const gamemap :: location & dst = steps [ moves - 1 ]; <nl> const unit_map :: const_iterator u = units_ . find ( dst ); <nl>  <nl> // u may be equal to units_ . end () in the case of e . g . a [ teleport ] <nl> if ( u != units_ . end ()) { <nl> // Reselect the unit if the move was interrupted <nl> - if ( dst != current_route_ . steps . back ()) { <nl> + if ( dst != steps . back ()) { <nl> selected_hex_ = dst ; <nl> gui_ . select_hex ( dst ); <nl> }
mmm src / menu_events . cpp <nl> ppp src / menu_events . cpp <nl> namespace events { <nl> } <nl> } else if ( cmd == " clear ") { <nl> gui_ -> clear_chat_messages (); <nl> - } else if ( cmd == " sunset ") { <nl> + } else if ( game_config :: debug && cmd == " sunset ") { <nl> int delay = lexical_cast_default < int >( data ); <nl> gui_ -> sunset ( delay ); <nl> } else if ( cmd == " w ") {
mmm src / game_events . cpp <nl> ppp src / game_events . cpp <nl> namespace { <nl> state_of_game -> get_variable ( var_name +". recruit ") = side_data [" recruit "]; <nl> state_of_game -> get_variable ( var_name +". fog ") = side_data [" fog "]; <nl> state_of_game -> get_variable ( var_name +". shroud ") = side_data [" shroud "]; <nl> + state_of_game -> get_variable ( var_name +". hidden ") = side_data [" hidden "]; <nl>  <nl> state_of_game -> get_variable ( var_name +". income ") = lexical_cast_default < std :: string >((* teams )[ team_index ]. income (),""); <nl> state_of_game -> get_variable ( var_name +". village_gold ") = lexical_cast_default < std :: string >((* teams )[ team_index ]. village_gold (),"");
mmm src / about . cpp <nl> ppp src / about . cpp <nl> std :: vector < std :: string > get_text () { <nl> "- Michel Loos ", <nl> "- Renato Cunha ", <nl> "- Sérgio de Miranda Costa ", <nl> + "- Tiago Souza ( Salvador )", <nl>  <nl> " _ " N_ ("+ Russian Translation "), <nl> "- Alexandr Menovchicov ",
mmm src / whiteboard / manager . cpp <nl> ppp src / whiteboard / manager . cpp <nl> void manager :: print_help_once () <nl>  <nl> void manager :: set_active ( bool active ) <nl> { <nl> - if ( is_observer ()) <nl> + if ( wait_for_side_init_ <nl> + || executing_actions_ <nl> + || is_observer () <nl> + || resources :: controller -> is_linger_mode ()) <nl> { <nl> active_ = false ; <nl> - LOG_WB << " Whiteboard can ' t be activated by observers .\ n "; <nl> + LOG_WB << " Whiteboard can ' t be activated now .\ n "; <nl> } <nl> else if ( active != active_ ) <nl> { <nl> void manager :: set_invert_behavior ( bool invert ) <nl> bool block_whiteboard_activation = false ; <nl> if ( wait_for_side_init_ <nl> || executing_actions_ <nl> - || is_observer ()) <nl> + || is_observer () <nl> + || resources :: controller -> is_linger_mode ()) <nl> { <nl> block_whiteboard_activation = true ; <nl> }
mmm src / gui / auxiliary / event / dispatcher_private . hpp <nl> ppp src / gui / auxiliary / event / dispatcher_private . hpp <nl> struct find < false > <nl> // MSVC 2008 doesn ' t like operator () here so changed the name . <nl> return functor . template oper < item >( event ); <nl> } else { <nl> - typedef typename boost :: mpl :: next < itor >:: type itor ; <nl> - return find < boost :: is_same < itor , end >:: value > <nl> - :: execute (( itor *) 0 , ( end *) 0 , event , functor ); <nl> + typedef typename boost :: mpl :: next < itor >:: type titor ; <nl> + return find < boost :: is_same < titor , end >:: value > <nl> + :: execute (( titor *) 0 , ( end *) 0 , event , functor ); <nl> } <nl> } <nl> };
mmm src / server / game . cpp <nl> ppp src / server / game . cpp <nl> void game :: transfer_side_control ( const network :: connection sock , const simple_wm <nl> return ; <nl> } <nl> sides_ [ side_num - 1 ] = 0 ; <nl> - bool host_leave = false ; <nl> // If the old player lost his last side , make him an observer . <nl> if ( std :: find ( sides_ . begin (), sides_ . end (), old_player ) == sides_ . end ()) { <nl> observers_ . push_back ( old_player ); <nl> void game :: transfer_side_control ( const network :: connection sock , const simple_wm <nl> simple_wml :: document observer_join ; <nl> observer_join . root (). add_child (" observer "). set_attr_dup (" name ", old_player_name . c_str ()); <nl> send_data ( observer_join , old_player ); <nl> - // If the old player was the host of the game , choose another player . <nl> - /* if ( old_player == owner_ ) { <nl> - host_leave = true ; <nl> - if ( players_ . empty ()) { <nl> - owner_ = newplayer -> first ; <nl> - } else { <nl> - owner_ = players_ . front (); <nl> - } <nl> - notify_new_host (); <nl> - }*/ <nl> } <nl> change_controller ( side_num - 1 , newplayer , false ); <nl>  <nl> - if ( host_leave ) transfer_ai_sides (); <nl> - <nl> // If we gave the new side to an observer add him to players_ . <nl> if ( is_observer ( newplayer -> first )) { <nl> players_ . push_back ( newplayer -> first );
mmm src / server / server . cpp <nl> ppp src / server / server . cpp <nl> void server :: run () <nl> continue ; <nl> } <nl>  <nl> + if ( username == " server ") { <nl> + network :: send_data ( construct_error ( <nl> + " The nick ' server ' is reserved and can not be used by players "), sock ); <nl> + continue ; <nl> + } <nl> + <nl> // check the username isn ' t already taken <nl> player_map :: const_iterator p ; <nl> for ( p = players_ . begin (); p != players_ . end (); ++ p ) {
mmm src / random . cpp <nl> ppp src / random . cpp <nl> # include " random . hpp " <nl> # include " log . hpp " <nl>  <nl> +# include < boost / random / random_device . hpp > <nl>  <nl> # include < cassert > <nl> # include < cstdlib > <nl> +# include < limits > <nl> # include < random > <nl> -# include < boost / random / random_device . hpp > <nl>  <nl> static lg :: log_domain log_random (" random "); <nl> # define DBG_RND LOG_STREAM ( debug , log_random ) <nl> static lg :: log_domain log_random (" random "); <nl> # define WRN_RND LOG_STREAM ( warn , log_random ) <nl> # define ERR_RND LOG_STREAM ( err , log_random ) <nl>  <nl> + static_assert ( std :: numeric_limits < double >:: is_iec559 , " Floating point representation is not IEEE 754 - compliant "); <nl> + <nl> namespace { <nl>  <nl> class rng_default : public randomness :: rng
mmm src / campaign_server / campaign_server . cpp <nl> ppp src / campaign_server / campaign_server . cpp <nl> namespace { <nl> net_manager_ ( min_thread , max_thread ), <nl> server_manager_ ( load_config ()), <nl> hooks_ (), <nl> - input_ ( 0 ) <nl> + input_ ( 0 ), <nl> + compress_level_ ( 0 ) <nl> { <nl> if ( cfg_ . child (" campaigns ") == NULL ) { <nl> cfg_ . add_child (" campaigns ");
mmm src / server / room_manager . cpp <nl> ppp src / server / room_manager . cpp <nl> void room_manager :: load_config ( const config & cfg ) <nl> { <nl> filename_ = cfg [" room_save_file "]; <nl> compress_stored_rooms_ = utils :: string_bool ( cfg [" compress_stored_rooms "], true ); <nl> - new_room_policy_ = pp_from_string ( cfg [" new_room_policy "]); <nl> + PRIVILEGE_POLICY pp = pp_from_string ( cfg [" new_room_policy "]); <nl> + if ( pp != PP_COUNT ) new_room_policy_ = pp ; <nl> } <nl>  <nl> const std :: string & room_manager :: storage_filename () const
mmm src / about . cpp <nl> ppp src / about . cpp <nl> std :: vector < std :: string > get_text () { <nl>  <nl> " _ " N_ ("+ Developers "), <nl> "- Alfredo Beaumont ( ziberpunk )", <nl> + "- Bram Ridder ( Morloth )", <nl> "- Cedric Duval ", <nl> "- Cyril Bouthors ( CyrilB )", <nl> "- Guillaume Melquiond ( silene )", <nl> std :: vector < std :: string > get_text () { <nl> "- Justin Zaun ( jzaun )", <nl>  <nl> " _ " N_ ("+ Multiplayer Maps "), <nl> + "- Mike Quinones ( Doc Paterson )", <nl> "- Peter Groen ( pg )", <nl> "- Tom Chance ( telex4 )", <nl> - "- Mike Quinones ( Doc Paterson )", <nl>  <nl> " _ " N_ ("+ Packagers "), <nl> "- Cyril Bouthors ( CyrilB )",
mmm src / units / map . hpp <nl> ppp src / units / map . hpp <nl> public : <nl> size_t size () const { return lmap_ . size (); } <nl> size_t num_iters () const ; <nl>  <nl> + bool empty () const { return lmap_ . empty (); } <nl> + <nl> void clear ( bool force = false ); <nl>  <nl> /**
mmm src / hotkeys . cpp <nl> ppp src / hotkeys . cpp <nl> void delete_all_wml_hotkeys () <nl> } <nl> } <nl>  <nl> -// retunrs weather a hotkey was deleted . <nl> +// Returns whether a hotkey was deleted . <nl> bool remove_wml_hotkey ( const std :: string & id ) <nl> { <nl> hotkey :: hotkey_command & command = get_hotkey_command ( id );
mmm src / sdl_utils . cpp <nl> ppp src / sdl_utils . cpp <nl> void draw_unit_ellipse ( SDL_Surface * target , short colour , const SDL_Rect & clip , <nl> xpos = behind -> w - xpos - 1 ; <nl>  <nl> int ypos = yit - unity ; <nl> - if ( xit >= clip . x && yit >= clip . y && xit < clip . x + clip . w && yit < clip . y + clip . h && <nl> - xpos >= 0 && ypos >= 0 && xpos < behind -> w && ypos < behind -> h && <nl> + if ( xit >= clip . x && yit >= clip . y && xit < clip . x + clip . w && yit + 1 < clip . y + clip . h && <nl> + xpos >= 0 && ypos >= 0 && xpos < behind -> w && ypos + 1 < behind -> h && <nl> pixels [ ypos *( behind -> w + pad ) + xpos ] == 0 ) { <nl> - SDL_Rect rect = { xit , yit , 1 , 1 }; <nl> + SDL_Rect rect = { xit , yit , 1 , 2 }; <nl> SDL_FillRect ( target ,& rect , colour ); <nl> } <nl>  <nl> yit = yloc + height / 2 + y ; <nl> ypos = yit - unity ; <nl> - if ( xit >= clip . x && yit >= clip . y && xit < clip . x + clip . w && yit < clip . y + clip . h && <nl> - xpos >= 0 && ypos >= 0 && xpos < behind -> w && ypos < behind -> h ) { <nl> - SDL_Rect rect = { xit , yit , 1 , 1 }; <nl> + if ( xit >= clip . x && yit >= clip . y && xit < clip . x + clip . w && yit + 1 < clip . y + clip . h && <nl> + xpos >= 0 && ypos >= 0 && xpos < behind -> w && ypos + 1 < behind -> h ) { <nl> + SDL_Rect rect = { xit , yit , 1 , 2 }; <nl> SDL_FillRect ( target ,& rect , colour ); <nl> } <nl> }
mmm src / time_of_day . cpp <nl> ppp src / time_of_day . cpp <nl> time_of_day :: time_of_day ( const config & cfg ) <nl> time_of_day :: time_of_day () <nl> : lawful_bonus ( 0 ) <nl> , bonus_modified ( 0 ) <nl> +, image () <nl> , name (" NULL_TOD ") <nl> , id (" nulltod ") <nl> +, image_mask () <nl> , red ( 0 ) <nl> , green ( 0 ) <nl> , blue ( 0 ) <nl> +, sounds () <nl> { <nl> } <nl> 
mmm src / variable . cpp <nl> ppp src / variable . cpp <nl> # include " log . hpp " <nl> # include " unit . hpp " <nl> # include " unit_map . hpp " <nl> +# include " team . hpp " <nl>  <nl> static lg :: log_domain log_engine (" engine "); <nl> # define LOG_NG LOG_STREAM ( info , log_engine ) <nl> void scoped_weapon_info :: activate () <nl>  <nl> void scoped_recall_unit :: activate () <nl> { <nl> + const std :: vector < team >& teams = teams_manager :: get_teams (); <nl> + std :: vector < team >:: const_iterator team_it ; <nl> + for ( team_it = teams . begin (); team_it != teams . end (); team_it ++) { <nl> + if ( team_it -> save_id () == player_ ) <nl> + break ; <nl> + } <nl> + <nl> player_info * const player = repos -> get_player ( player_ ); <nl> - if ( player != NULL ) { <nl> - if ( player -> available_units . size () > recall_index_ ) { <nl> + if ( team_it != teams . end ()) { <nl> + if ( team_it -> recall_list (). size () > recall_index_ ) { <nl> config tmp_cfg ; <nl> - player -> available_units [ recall_index_ ]. write ( tmp_cfg ); <nl> + team_it -> recall_list ()[ recall_index_ ]. write ( tmp_cfg ); <nl> tmp_cfg [" x "] = " recall "; <nl> tmp_cfg [" y "] = " recall "; <nl> LOG_NG << " auto - storing $" << name () << " for player : " << player_
mmm src / unit . cpp <nl> ppp src / unit . cpp <nl> void unit :: write ( config & cfg ) const <nl> break ; <nl> case unit_type :: LIMINAL : <nl> cfg [" alignment "] = " liminal "; <nl> + break ; <nl> default : <nl> cfg [" alignment "] = " neutral "; <nl> }
mmm src / campaign_server / campaign_server . cpp <nl> ppp src / campaign_server / campaign_server . cpp <nl> void server :: handle_read_from_fifo ( const boost :: system :: error_code & error , std :: <nl>  <nl> if ( ctl == " shut_down ") { <nl> LOG_CS << " Shut down requested by admin , shutting down ...\ n "; <nl> + throw server_shutdown (" Shut down via fifo command "); <nl> } else if ( ctl == " readonly ") { <nl> if ( ctl . args_count ()) { <nl> cfg_ [" read_only "] = read_only_ = utils :: string_bool ( ctl [ 1 ], true );
mmm src / scripting / lua_unit_attacks . cpp <nl> ppp src / scripting / lua_unit_attacks . cpp <nl> static int impl_unit_attack_match ( lua_State * L ) <nl> { <nl> const_attack_ptr atk = luaW_toweapon ( L , 1 ); <nl> config cfg = luaW_checkconfig ( L , 2 ); <nl> + if (! atk ) { <nl> + return luaL_argerror ( L , 1 , " invalid attack "); <nl> + } <nl> lua_pushboolean ( L , atk -> matches_filter ( cfg )); <nl> return 1 ; <nl> }
mmm src / server / game . cpp <nl> ppp src / server / game . cpp <nl> bool game :: describe_slots () { <nl> std :: string descr = buf . str (); <nl>  <nl> if ((* description_ )[" slots "] != descr ) { <nl> - description_ -> set_attr_dup (" slots ", descr ); <nl> + description_ -> set_attr_dup (" slots ", descr . c_str ()); <nl> return true ; <nl> } else { <nl> return false ;
mmm src / scripting / lua_gui2 . cpp <nl> ppp src / scripting / lua_gui2 . cpp <nl> int intf_set_dialog_callback ( lua_State * L ) <nl> if ( gui2 :: clickable_item * c = dynamic_cast < gui2 :: clickable_item *>( w )) { <nl> static dialog_callback_wrapper wrapper ; <nl> c -> connect_click_handler ( std :: bind (& dialog_callback_wrapper :: forward , wrapper , w )); <nl> - } else if ( gui2 :: selectable_item * s = dynamic_cast < gui2 :: selectable_item *>( w )) { <nl> - connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* s ), std :: bind ( dialog_callback , _1 )); <nl> - } else if ( gui2 :: integer_selector * s = dynamic_cast < gui2 :: integer_selector *>( w )) { <nl> - connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* s ), std :: bind ( dialog_callback , _1 )); <nl> + } else if ( gui2 :: selectable_item * si = dynamic_cast < gui2 :: selectable_item *>( w )) { <nl> + connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* si ), std :: bind ( dialog_callback , _1 )); <nl> + } else if ( gui2 :: integer_selector * is = dynamic_cast < gui2 :: integer_selector *>( w )) { <nl> + connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* is ), std :: bind ( dialog_callback , _1 )); <nl> } <nl> # ifdef GUI2_EXPERIMENTAL_LISTBOX <nl> else if ( gui2 :: list_view * l = dynamic_cast < gui2 :: list_view *>( w )) {
mmm src / playturn . cpp <nl> ppp src / playturn . cpp <nl> bool turn_slice ( game_data & gameinfo , game_state & state_of_game , <nl> unit_map :: const_iterator it = units . find ( next_unit ); <nl> if ( it != units . end ()) { <nl> for (++ it ; it != units . end (); ++ it ) { <nl> - if ( unit_can_move ( it -> first , units , map , teams )) { <nl> + if ( it -> second . side () == team_num && <nl> + unit_can_move ( it -> first , units , map , teams )) { <nl> break ; <nl> } <nl> } <nl> bool turn_slice ( game_data & gameinfo , game_state & state_of_game , <nl>  <nl> if ( it == units . end ()) { <nl> for ( it = units . begin (); it != units . end (); ++ it ) { <nl> - if ( unit_can_move ( it -> first , units , map , teams )) { <nl> + if ( it -> second . side () == team_num && <nl> + unit_can_move ( it -> first , units , map , teams )) { <nl> break ; <nl> } <nl> }
mmm src / savegame . cpp <nl> ppp src / savegame . cpp <nl> bool loadgame :: load_multiplayer_game () <nl> return false ; <nl> } <nl>  <nl> + if ( is_replay_save ( summary_ )) { <nl> + gui2 :: show_transient_message ( video_ , _ (" Load Game "), _ (" Replays are not supported in multiplayer mode .")); <nl> + return false ; <nl> + } <nl> + <nl> if ( gamestate_ . classification (). campaign_type != game_classification :: CAMPAIGN_TYPE :: MULTIPLAYER ) { <nl> gui2 :: show_transient_error_message ( video_ , _ (" This is not a multiplayer save .")); <nl> return false ;
mmm src / map . cpp <nl> ppp src / map . cpp <nl> bool gamemap :: is_village ( const gamemap :: location & loc ) const <nl>  <nl> bool gamemap :: gives_healing ( const gamemap :: location & loc ) const <nl> { <nl> - return is_village ( loc ); <nl> + return on_board ( loc ) && gives_healing ( get_terrain ( loc )); <nl> } <nl>  <nl> bool gamemap :: is_castle ( const gamemap :: location & loc ) const
mmm src / about . cpp <nl> ppp src / about . cpp <nl> void show_about ( display & disp ) <nl> text . push_back ("+ Developers "); <nl> text . push_back ("- Alfredo Beaumont ( ziberpunk )"); <nl> text . push_back ("- Cyril Bouthors ( CyrilB )"); <nl> - text . push_back ("- Guillaume Duwelz - Rebert "); <nl> text . push_back ("- Isaac Clerencia "); <nl> text . push_back ("- J . R . Blain ( Cowboy )"); <nl> text . push_back ("- Justin Zaun ( jzaun )");
mmm src / serialization / binary_or_text . cpp <nl> ppp src / serialization / binary_or_text . cpp <nl>  <nl> bool detect_format_and_read ( config & cfg , std :: istream & in ) <nl> { <nl> - try { <nl> + unsigned char c = in . peek (); <nl> + if ( c < 5 ) { <nl> read_compressed ( cfg , in ); <nl> return true ; <nl> - } catch ( config :: error &) { <nl> + } else { <nl> + read ( cfg , in ); <nl> + return false ; <nl> } <nl> - <nl> - read ( cfg , in ); <nl> - return false ; <nl> } <nl>  <nl> void write_possibly_compressed ( std :: string const & filename , config & cfg , bool compress )
mmm src / generate_report . cpp <nl> ppp src / generate_report . cpp <nl> Units cannot be killed by poison alone . The poison will not reduce it below 1 HP <nl> break ; <nl>  <nl> const t_translation :: t_letter terrain = map . get_terrain ( mouseover ); <nl> + if ( terrain == t_translation :: OFF_MAP_USER ) <nl> + break ; <nl> + <nl> const t_translation :: t_list & underlying = map . underlying_union_terrain ( terrain ); <nl>  <nl> if ( map . is_village ( mouseover )) { <nl> Units cannot be killed by poison alone . The poison will not reduce it below 1 HP <nl> break ; <nl> } <nl>  <nl> + const t_translation :: t_letter terrain = map [ mouseover . x ][ mouseover . y ]; <nl> + <nl> + if ( terrain == t_translation :: OFF_MAP_USER ) <nl> + break ; <nl> + <nl> str << mouseover ; <nl>  <nl> if ( u == units . end () || current_team . shrouded ( mouseover . x , mouseover . y )) <nl> break ; <nl>  <nl> - const t_translation :: t_letter terrain = map [ mouseover . x ][ mouseover . y ]; <nl> - <nl> const int move_cost = u -> second . movement_cost ( terrain ); <nl> const int defense = 100 - u -> second . defense_modifier ( terrain ); <nl> 
mmm src / sdl_utils . cpp <nl> ppp src / sdl_utils . cpp <nl> void fill_rect_alpha ( SDL_Rect & rect , Uint32 colour , Uint8 alpha , surface const & <nl>  <nl> surface get_surface_portion ( surface const & src , SDL_Rect & area ) <nl> { <nl> - if ( area . x >= src -> w || area . y >= src -> h ) { <nl> - std :: cerr << " illegal surface portion ...\ n "; <nl> + // check if there is something in the portion <nl> + if ( area . x >= src -> w || area . y >= src -> h || area . x + area . w < 0 || area . y + area . h < 0 ) { <nl> + // std :: cerr << " illegal surface portion ...\ n "; <nl> return NULL ; <nl> } <nl>  <nl> if ( area . x + area . w > src -> w ) { <nl> area . w = src -> w - area . x ; <nl> } <nl> - <nl> if ( area . y + area . h > src -> h ) { <nl> area . h = src -> h - area . y ; <nl> } <nl> surface get_surface_portion ( surface const & src , SDL_Rect & area ) <nl> return NULL ; <nl> } <nl>  <nl> - SDL_Rect dstarea = { 0 , 0 , 0 , 0 }; <nl> - <nl> - SDL_BlitSurface ( src ,& area , dst ,& dstarea ); <nl> + SDL_BlitSurface ( src ,& area , dst , NULL ); <nl>  <nl> return dst ; <nl> }mmm src / sdl_utils . hpp <nl> ppp src / sdl_utils . hpp <nl> void fill_rect_alpha ( SDL_Rect & rect , Uint32 colour , Uint8 alpha , surface const & <nl>  <nl> surface get_surface_portion ( surface const & src , SDL_Rect & area ) <nl> { <nl> - if ( area . x >= src -> w || area . y >= src -> h ) { <nl> - std :: cerr << " illegal surface portion ...\ n "; <nl> + // check if there is something in the portion <nl> + if ( area . x >= src -> w || area . y >= src -> h || area . x + area . w < 0 || area . y + area . h < 0 ) { <nl> + // std :: cerr << " illegal surface portion ...\ n "; <nl> return NULL ; <nl> } <nl>  <nl> if ( area . x + area . w > src -> w ) { <nl> area . w = src -> w - area . x ; <nl> } <nl> - <nl> if ( area . y + area . h > src -> h ) { <nl> area . h = src -> h - area . y ; <nl> } <nl> surface get_surface_portion ( surface const & src , SDL_Rect & area ) <nl> return NULL ; <nl> } <nl>  <nl> - SDL_Rect dstarea = { 0 , 0 , 0 , 0 }; <nl> - <nl> - SDL_BlitSurface ( src ,& area , dst ,& dstarea ); <nl> + SDL_BlitSurface ( src ,& area , dst , NULL ); <nl>  <nl> return dst ; <nl> } <nl> surface darken_image ( surface const & surf ); <nl> surface recolor_image ( surface surf , const std :: map < Uint32 , Uint32 >& map_rgb ); <nl>  <nl> surface brighten_image ( surface const & surf , fixed_t amount ); <nl> +// send NULL if the portion is outside of the surface <nl> surface get_surface_portion ( surface const & surf , SDL_Rect & rect ); <nl> surface adjust_surface_alpha ( surface const & surf , fixed_t amount , bool optimize = true ); <nl> surface adjust_surface_alpha_add ( surface const & surf , int amount );
mmm src / playsingle_controller . cpp <nl> ppp src / playsingle_controller . cpp <nl> # include " save_blocker . hpp " <nl> # include " soundsource . hpp " <nl> # include " storyscreen / interface . hpp " <nl> +# include " whiteboard / manager . hpp " <nl>  <nl> static lg :: log_domain log_engine (" engine "); <nl> # define ERR_NG LOG_STREAM ( err , log_engine ) <nl> void playsingle_controller :: init_gui (){ <nl> void playsingle_controller :: recruit (){ <nl> if (! browse_ ) <nl> menu_handler_ . recruit ( player_number_ , mouse_handler_ . get_last_hex ()); <nl> + else if ( resources :: whiteboard -> is_active ()) <nl> + menu_handler_ . recruit ( resources :: screen -> viewing_side (), mouse_handler_ . get_last_hex ()); <nl> } <nl>  <nl> void playsingle_controller :: repeat_recruit (){ <nl> if (! browse_ ) <nl> menu_handler_ . repeat_recruit ( player_number_ , mouse_handler_ . get_last_hex ()); <nl> + else if ( resources :: whiteboard -> is_active ()) <nl> + menu_handler_ . repeat_recruit ( resources :: screen -> viewing_side (), mouse_handler_ . get_last_hex ()); <nl> } <nl>  <nl> void playsingle_controller :: recall (){ <nl> if (! browse_ ) <nl> menu_handler_ . recall ( player_number_ , mouse_handler_ . get_last_hex ()); <nl> + else if ( resources :: whiteboard -> is_active ()) <nl> + menu_handler_ . recall ( resources :: screen -> viewing_side (), mouse_handler_ . get_last_hex ()); <nl> } <nl>  <nl> void playsingle_controller :: toggle_shroud_updates (){ <nl> bool playsingle_controller :: can_execute_command ( hotkey :: HOTKEY_COMMAND command , <nl> case hotkey :: HOTKEY_ADD_WAYPOINT : <nl> case hotkey :: HOTKEY_UNIT_HOLD_POSITION : <nl> case hotkey :: HOTKEY_END_UNIT_TURN : <nl> + return ! browse_ && ! linger_ && ! events :: commands_disabled ; <nl> case hotkey :: HOTKEY_RECRUIT : <nl> case hotkey :: HOTKEY_REPEAT_RECRUIT : <nl> case hotkey :: HOTKEY_RECALL : <nl> - return ! browse_ && ! linger_ && ! events :: commands_disabled ; <nl> + return (! browse_ || resources :: whiteboard -> is_active ()) && ! linger_ && ! events :: commands_disabled ; <nl> case hotkey :: HOTKEY_ENDTURN : <nl> return (! browse_ || linger_ ) && ! events :: commands_disabled ; <nl> mmm src / play_controller . cpp <nl> ppp src / play_controller . cpp <nl> # include " save_blocker . hpp " <nl> # include " soundsource . hpp " <nl> # include " storyscreen / interface . hpp " <nl> +# include " whiteboard / manager . hpp " <nl>  <nl> static lg :: log_domain log_engine (" engine "); <nl> # define ERR_NG LOG_STREAM ( err , log_engine ) <nl> void playsingle_controller :: init_gui (){ <nl> void playsingle_controller :: recruit (){ <nl> if (! browse_ ) <nl> menu_handler_ . recruit ( player_number_ , mouse_handler_ . get_last_hex ()); <nl> + else if ( resources :: whiteboard -> is_active ()) <nl> + menu_handler_ . recruit ( resources :: screen -> viewing_side (), mouse_handler_ . get_last_hex ()); <nl> } <nl>  <nl> void playsingle_controller :: repeat_recruit (){ <nl> if (! browse_ ) <nl> menu_handler_ . repeat_recruit ( player_number_ , mouse_handler_ . get_last_hex ()); <nl> + else if ( resources :: whiteboard -> is_active ()) <nl> + menu_handler_ . repeat_recruit ( resources :: screen -> viewing_side (), mouse_handler_ . get_last_hex ()); <nl> } <nl>  <nl> void playsingle_controller :: recall (){ <nl> if (! browse_ ) <nl> menu_handler_ . recall ( player_number_ , mouse_handler_ . get_last_hex ()); <nl> + else if ( resources :: whiteboard -> is_active ()) <nl> + menu_handler_ . recall ( resources :: screen -> viewing_side (), mouse_handler_ . get_last_hex ()); <nl> } <nl>  <nl> void playsingle_controller :: toggle_shroud_updates (){ <nl> bool playsingle_controller :: can_execute_command ( hotkey :: HOTKEY_COMMAND command , <nl> case hotkey :: HOTKEY_ADD_WAYPOINT : <nl> case hotkey :: HOTKEY_UNIT_HOLD_POSITION : <nl> case hotkey :: HOTKEY_END_UNIT_TURN : <nl> + return ! browse_ && ! linger_ && ! events :: commands_disabled ; <nl> case hotkey :: HOTKEY_RECRUIT : <nl> case hotkey :: HOTKEY_REPEAT_RECRUIT : <nl> case hotkey :: HOTKEY_RECALL : <nl> - return ! browse_ && ! linger_ && ! events :: commands_disabled ; <nl> + return (! browse_ || resources :: whiteboard -> is_active ()) && ! linger_ && ! events :: commands_disabled ; <nl> case hotkey :: HOTKEY_ENDTURN : <nl> return (! browse_ || linger_ ) && ! events :: commands_disabled ; <nl>  <nl> bool play_controller :: in_context_menu ( hotkey :: HOTKEY_COMMAND command ) const <nl> case hotkey :: HOTKEY_RECRUIT : <nl> case hotkey :: HOTKEY_REPEAT_RECRUIT : <nl> case hotkey :: HOTKEY_RECALL : { <nl> + wb :: scoped_planned_pathfind_map future ; //< lasts until method returns . <nl> // last_hex_ is set by mouse_events :: mouse_motion <nl> // Enable recruit / recall on castle / keep tiles <nl> for ( unit_map :: const_iterator leader = units_ . begin (); <nl> leader != units_ . end ();++ leader ) { <nl> if ( leader -> can_recruit () && <nl> - leader -> side () == player_number_ && <nl> + leader -> side () == resources :: screen -> viewing_side () && <nl> can_recruit_on ( map_ , leader -> get_location (), mouse_handler_ . get_last_hex ())) <nl> return true ; <nl> }
mmm src / map . cpp <nl> ppp src / map . cpp <nl> bool gamemap :: location :: matches_range ( const std :: string & xloc , const std :: string <nl> std :: vector < std :: string > xlocs = utils :: split ( xloc ); <nl> std :: vector < std :: string > ylocs = utils :: split ( yloc ); <nl>  <nl> - int size ; <nl> + size_t size ; <nl> for ( size = xlocs . size (); size < ylocs . size (); ++ size ) { <nl> xlocs . push_back (""); <nl> } <nl> while ( size > ylocs . size ()) { <nl> ylocs . push_back (""); <nl> } <nl> - for ( int i = 0 ; i != size ; ++ i ) { <nl> + for ( size_t i = 0 ; i != size ; ++ i ) { <nl> if ( matches_range ( xlocs [ i ], ylocs [ i ])) <nl> return true ; <nl> }
mmm src / playcampaign . cpp <nl> ppp src / playcampaign . cpp <nl> LEVEL_RESULT play_game ( display & disp , game_state & gamestate , const config & game_ <nl> gamestate . set_variables (* gamestate . snapshot . child (" variables ")); <nl> } <nl> // Replace game label with that from snapshot <nl> - if (! state . snapshot [" label "]. empty ()){ <nl> - state . label = state . snapshot [" label "]; <nl> + if (! gamestate . snapshot [" label "]. empty ()){ <nl> + gamestate . label = gamestate . snapshot [" label "]; <nl> } <nl> // get the current gold values of players so they don ' t start with the amount <nl> // they had at the start of the scenario
mmm src / upload_log . cpp <nl> ppp src / upload_log . cpp <nl> upload_log :: upload_log ( bool enable ) : <nl>  <nl> void upload_log :: read_replay () <nl> { <nl> - if ( ! uploader_settings :: new_uploader || ! enabled_ || ! game_config :: debug ) { <nl> + if ( ! uploader_settings :: new_uploader || ! enabled_ || game_config :: debug ) { <nl> return ; <nl> } <nl>  <nl> void upload_log :: start ( game_state & state , const std :: string map_data ) <nl> delete game_ ; <nl> game_ = new config (); <nl> (* game_ )[" time "] = lexical_cast < std :: string >( SDL_GetTicks () / 1000 ); <nl> - (* game_ )[" campaign "] = state . classification (). campaign_define ; <nl> + (* game_ )[" campaign "] = state . classification (). campaign_type ; <nl> (* game_ )[" difficulty "] = state . classification (). difficulty ; <nl> - (* game_ )[" scenario "] = state . classification (). scenario ; <nl> + (* game_ )[" scenario "] = state . classification (). label ; <nl> if ( uploader_settings :: new_uploader ) { <nl> // replace newlines in map definition with semicolons so that braindead server - side wml parser doesn ' t get confused <nl> std :: string encoded_map ( map_data );
mmm src / team . cpp <nl> ppp src / team . cpp <nl> void team :: team_info :: read ( const config & cfg ) <nl> if (! user_team_name . translatable ()) <nl> user_team_name = t_string :: from_serialized ( user_team_name ); <nl>  <nl> - if ( cfg . has_attribute (" ai_config ")) { <nl> - ai :: manager :: get_singleton (). add_ai_for_side_from_file ( side , cfg [" ai_config "], true ); <nl> - } else { <nl> - ai :: manager :: get_singleton (). add_ai_for_side_from_config ( side , cfg , true ); <nl> + display * disp = display :: get_singleton (); <nl> + <nl> + if ( disp && ! disp -> in_editor ()) { <nl> + if ( cfg . has_attribute (" ai_config ")) { <nl> + ai :: manager :: get_singleton (). add_ai_for_side_from_file ( side , cfg [" ai_config "], true ); <nl> + } else { <nl> + ai :: manager :: get_singleton (). add_ai_for_side_from_config ( side , cfg , true ); <nl> + } <nl> } <nl>  <nl> std :: vector < std :: string > recruits = utils :: split ( cfg [" recruit "]);
mmm src / variable_info . cpp <nl> ppp src / variable_info . cpp <nl> namespace <nl> char * endptr ; <nl> int res = strtol ( index_str , & endptr , 10 ); <nl>  <nl> - if (* endptr != ']' || res > int ( game_config :: max_loop )) <nl> + if (* endptr != ']' || res > int ( game_config :: max_loop ) || endptr == index_str ) <nl> { <nl> throw invalid_variablename_exception (); <nl> }
mmm src / editor / editor_controller . cpp <nl> ppp src / editor / editor_controller . cpp <nl> bool editor_controller :: execute_command ( hotkey :: HOTKEY_COMMAND command , int inde <nl> gui_ -> init_flags (); <nl> return true ; <nl>  <nl> + // Transitions <nl> + case HOTKEY_EDITOR_PARTIAL_UPDATE_TRANSITIONS : <nl> + context_manager_ -> set_update_trasitions_mode ( 2 ); <nl> + return true ; <nl> case HOTKEY_EDITOR_AUTO_UPDATE_TRANSITIONS : <nl> + context_manager_ -> set_update_trasitions_mode ( 1 ); <nl> + return true ; <nl> + case HOTKEY_EDITOR_NO_UPDATE_TRANSITIONS : <nl> + context_manager_ -> set_update_trasitions_mode ( 0 ); <nl> + return true ; <nl> + case HOTKEY_EDITOR_TOGGLE_TRANSITIONS : <nl> if ( context_manager_ -> toggle_update_transitions ()) <nl> return true ; <nl> // else intentionally fall through <nl> case HOTKEY_EDITOR_UPDATE_TRANSITIONS : <nl> context_manager_ -> refresh_all (); <nl> return true ; <nl> + // Refresh <nl> case HOTKEY_EDITOR_REFRESH : <nl> context_manager_ -> reload_map (); <nl> return true ;
mmm src / actions . cpp <nl> ppp src / actions . cpp <nl> int battle_context :: choose_defender_weapon ( const unit & attacker , const unit & def <nl> choices . push_back ( i ); <nl> } <nl> } <nl> - if ( choices . size () == 0 ) <nl> + if ( choices . empty ()) <nl> return - 1 ; <nl> if ( choices . size () == 1 ) <nl> return choices [ 0 ]; <nl> int battle_context :: choose_attacker_weapon ( const unit & attacker , const unit & def <nl> choices . push_back ( i ); <nl> } <nl> } <nl> - if ( choices . size () == 0 ) <nl> + if ( choices . empty ()) <nl> return - 1 ; <nl> if ( choices . size () == 1 ) { <nl> * defender_weapon = choose_defender_weapon ( attacker , defender , choices [ 0 ], units , <nl> void calculate_healing ( int side , bool update_display ) <nl> healers . push_back ( units . find ( heal_loc -> loc )); <nl> } <nl>  <nl> - if ( healers . size () > 0 ) { <nl> + if (! healers . empty ()) { <nl> DBG_NG << " Unit has " << healers . size () << " potential healers \ n "; <nl> } <nl>  <nl> void calculate_healing ( int side , bool update_display ) <nl> healing = neg_max ; <nl> } <nl>  <nl> - if ( healers . size () > 0 ) { <nl> + if (! healers . empty ()) { <nl> DBG_NG << " Just before healing animations , unit has " << healers . size () << " potential healers \ n "; <nl> } <nl> 
mmm src / menu_events . cpp <nl> ppp src / menu_events . cpp <nl> void console_handler :: do_layers () <nl> const mouse_handler & mousehandler = menu_handler_ . pc_ . get_mouse_handler_base (); <nl> const map_location & loc = mousehandler . get_last_hex (); <nl>  <nl> - gui2 :: dialogs :: terrain_layers :: display ( disp , loc , disp . video ()); <nl> + // <nl> + // It ' s possible to invoke this dialog even if loc isn ' t a valid hex . I ' m not sure <nl> + // exactly how that happens , but it does seem to occur when moving the mouse outside <nl> + // the window to the menu bar . Not sure if there ' s a bug when the set - last - hex code <nl> + // in that case , but this check at least ensures the dialog is only ever shown for a <nl> + // valid , on - map location . Otherwise , an assertion gets thrown . <nl> + // <nl> + // -- vultraz , 2017 - 09 - 21 <nl> + // <nl> + if ( disp . get_map (). on_board_with_border ( loc )) { <nl> + gui2 :: dialogs :: terrain_layers :: display ( disp , loc , disp . video ()); <nl> + } <nl> } <nl>  <nl> void console_handler :: do_fps ()
mmm src / playcampaign . cpp <nl> ppp src / playcampaign . cpp <nl> LEVEL_RESULT play_game ( game_display & disp , saved_game & gamestate , <nl> if ( is_unit_test ) { <nl> return res ; <nl> } <nl> + // in this case we might have skipped state . set_snapshot which means wew cannot do gamestate . convert_to_start_save (); <nl> + if ( res == QUIT ) <nl> + { <nl> + return res ; <nl> + } <nl>  <nl> // Save - management options fire on game end . <nl> // This means : ( a ) we have a victory , or <nl> LEVEL_RESULT play_game ( game_display & disp , saved_game & gamestate , <nl> // On DEFEAT , QUIT , or OBSERVER_END , we ' re done now <nl>  <nl> // If there is no next scenario we ' re done now . <nl> - if ( res == QUIT || ! end_level . proceed_to_next_level || gamestate . carryover_sides_start [" next_scenario "]. empty ()) <nl> + if (! end_level . proceed_to_next_level || gamestate . carryover_sides_start [" next_scenario "]. empty ()) <nl> { <nl> return res ; <nl> }
mmm src / dialogs . cpp <nl> ppp src / dialogs . cpp <nl> bool animate_unit_advancement ( unit_map & units , map_location loc , game_display & g <nl> :: advance_unit ( units , loc , chosen_unit ); <nl> } else { <nl> unit amla_unit ( u -> second ); <nl> + config mod_option (* mod_options [ choice - options . size ()]); <nl>  <nl> LOG_NG << " firing advance event ( AMLA )\ n "; <nl> game_events :: fire (" advance ", loc ); <nl>  <nl> amla_unit . get_experience (- amla_unit . max_experience ()); // subtract xp required <nl> - amla_unit . add_modification (" advance ",* mod_options [ choice - options . size ()]); <nl> + amla_unit . add_modification (" advance ", mod_option ); <nl> units . replace ( new std :: pair < map_location , unit >( loc , amla_unit )); <nl>  <nl> LOG_NG << " firing post_advance event ( AMLA )\ n ";
mmm src / multiplayer_connect . cpp <nl> ppp src / multiplayer_connect . cpp <nl> config connect :: side :: get_config () const <nl> break ; <nl> case CNTR_EMPTY : <nl> description = N_ ("( Empty slot )"); <nl> + res [" no_leader "] = " yes "; <nl> break ; <nl> default : <nl> wassert ( false );
mmm src / mp_options . cpp <nl> ppp src / mp_options . cpp <nl> void manager :: init_info ( const config & cfg , const std :: string & key ) <nl> entry [" id "] = comp [" id "]; <nl> entry [" name "] = comp [" name "]; <nl>  <nl> - if ( comp . has_child (" options ") && ( comp [" allow_new_game "]. to_bool ( true )) { <nl> + if ( comp . has_child (" options ") && comp [" allow_new_game "]. to_bool ( true )) { <nl> const config & options = comp . child (" options "); <nl>  <nl> BOOST_FOREACH ( const config :: any_child & c ,
mmm src / playmp_controller . cpp <nl> ppp src / playmp_controller . cpp <nl> bool playmp_controller :: can_execute_command ( const hotkey :: hotkey_command & cmd , i <nl> switch ( command ){ <nl> case hotkey :: HOTKEY_ENDTURN : <nl> if ( linger_ ) <nl> - { <nl> - return is_host_ ; <nl> + { <nl> + bool has_next_scenario = ! resources :: gamedata -> next_scenario (). empty () && <nl> + resources :: gamedata -> next_scenario () != " null "; <nl> + return is_host_ || ! has_next_scenario ; <nl> } <nl> else <nl> {mmm src / play_controller . cpp <nl> ppp src / play_controller . cpp <nl> bool playmp_controller :: can_execute_command ( const hotkey :: hotkey_command & cmd , i <nl> switch ( command ){ <nl> case hotkey :: HOTKEY_ENDTURN : <nl> if ( linger_ ) <nl> - { <nl> - return is_host_ ; <nl> + { <nl> + bool has_next_scenario = ! resources :: gamedata -> next_scenario (). empty () && <nl> + resources :: gamedata -> next_scenario () != " null "; <nl> + return is_host_ || ! has_next_scenario ; <nl> } <nl> else <nl> { <nl> void play_controller :: set_defeat_music_list ( const std :: string & list ) <nl>  <nl> void play_controller :: check_victory () <nl> { <nl> + if ( linger_ ) <nl> + { <nl> + return ; <nl> + } <nl> std :: set < unsigned > not_defeated ; <nl> for ( unit_map :: const_iterator i = units_ . begin (), <nl> i_end = units_ . end (); i != i_end ; ++ i )
mmm src / formula_string_utils . hpp <nl> ppp src / formula_string_utils . hpp <nl> class variable_set ; <nl>  <nl> namespace utils { <nl>  <nl> +/** <nl> + * Determines if a string might contain variables to interpolate . <nl> + * This can allow one to skip future interpolations ( plural -- if there is only <nl> + * one interpolation , the savings are not worth this check ). In this spirit , <nl> + * precision is sacrificed in the name of efficiency ; the check is quick and <nl> + * allows false positives , but there are no false negatives . ( A false negative <nl> + * would lead to incorrect behavior , whereas a false positive leads to merely <nl> + * inefficient behavior .) In practice , false positives should be uncommon enough <nl> + * to not worry about . <nl> + */ <nl> + inline bool might_contain_variables ( const std :: string & str ) <nl> +{ return str . find ('$') != std :: string :: npos ; } <nl> + <nl> /** <nl> * Function which will interpolate variables , starting with '$' in the string <nl> * ' str ' with the equivalent symbols in the given symbol table . If ' symbols '
mmm src / game_events . cpp <nl> ppp src / game_events . cpp <nl> WML_HANDLER_FUNCTION ( replace_schedule , /* event_info */, cfg ) <nl> ERR_NG << " attempted to to replace ToD schedule with empty schedule \ n "; <nl> } else { <nl> resources :: tod_manager -> replace_schedule ( cfg . get_parsed_config ()); <nl> + resources :: screen -> new_turn (); <nl> LOG_NG << " replaced ToD schedule \ n "; <nl> } <nl> }
mmm src / unit_types . cpp <nl> ppp src / unit_types . cpp <nl> void unit_type_data :: set_config ( config & cfg ) <nl> base_tree . push_back ( id ); <nl> while ( const config & bu = ut . child (" base_unit ")) <nl> { <nl> - if ( std :: find ( base_tree . begin (), base_tree . end (), bu [" id "]) != base_tree . end ()) { <nl> + if ( std :: find ( base_tree . begin (), base_tree . end (), bu [" id "]. str ()) != base_tree . end ()) { <nl> // If you want to allow diamond - style inheritance , replace the config :: error throw with a continue <nl>  <nl> std :: stringstream ss ;
mmm src / persist_context . cpp <nl> ppp src / persist_context . cpp <nl> bool persist_file_context :: clear_var ( const std :: string & global , bool immediate ) <nl> while (( active -> empty ()) && (! namespace_ . lineage_ . empty ())) { <nl> name_space prev = namespace_ . prev (); <nl> active = get_node ( cfg_ , prev ); <nl> + /// @ todo : This assertion replaces a seg fault . Still need to fix the <nl> + /// real bug ( documented as bug # 21093 ). <nl> + assert ( active != NULL ); <nl> active -> clear_children ( namespace_ . node_ ); <nl> if ( active -> has_child (" variables ") && active -> child (" variables "). empty ()) { <nl> active -> clear_children (" variables ");
mmm src / actions / undo . cpp <nl> ppp src / actions / undo . cpp <nl> void undo_list :: add_auto_shroud ( bool turned_on ) <nl> /// @ todo : Consecutive shroud actions can be collapsed into one . <nl>  <nl> // Do not call add (), as this should not clear the redo stack . <nl> - undos_ . push_back ( new undo :: auto_shroud_action ( turned_on )); <nl> + add ( new undo :: auto_shroud_action ( turned_on )); <nl> } <nl>  <nl> /** <nl> void undo_list :: add_update_shroud () <nl> { <nl> /// @ todo : Consecutive shroud actions can be collapsed into one . <nl>  <nl> - // Do not call add (), as this should not clear the redo stack . <nl> - undos_ . push_back ( new undo :: update_shroud_action ()); <nl> + add ( new undo :: update_shroud_action ()); <nl> } <nl>  <nl> 
mmm src / tools / exploder_utils . cpp <nl> ppp src / tools / exploder_utils . cpp <nl> void masked_overwrite_surface ( surface dest , surface src , surface mask , int x , in <nl> small_shift_before = 0 ; <nl> } <nl>  <nl> - if ( x + src_width <= dest -> w ) { <nl> + if ( x + src_width <= unsigned ( dest -> w )) { <nl> small_shift_after = 0 ; <nl> } else { <nl> small_shift_after = src_width - ( dest -> w - x ); <nl> void masked_overwrite_surface ( surface dest , surface src , surface mask , int x , in <nl> y = 0 ; <nl> } <nl>  <nl> - if ( y + src_height > dest -> h ) { <nl> + if ( y + src_height > unsigned ( dest -> h )) { <nl> src_height = dest -> h - y ; <nl> } <nl> 
mmm src / game . cpp <nl> ppp src / game . cpp <nl> void game_controller :: start_wesnothd () <nl>  <nl> std :: string config = " data / lan_server . cfg "; <nl> # ifndef _WIN32 <nl> - config = game_config :: wesnothd_name +" - c " + config + " - d - t 2 - T 5 "; <nl> + config = "\"" + game_config :: wesnothd_name +"\" - c " + config + " - d - t 2 - T 5 "; <nl> LOG_GENERAL << " Starting wesnothd : "<< config << "\ n "; <nl> if ( std :: system ( config . c_str ()) != 0 ) <nl> # else <nl> LOG_GENERAL << " Starting wesnothd \ n "; <nl> // Wesnothd_start . bat has to be included in windows as windows don ' t know how to start <nl> // background job <nl> - if ( std :: system ((" cmd / C start / B " + game_config :: wesnothd_name + " - c " + config + " - t 2 - T 5 "). c_str ()) != 0 ) <nl> + if ( std :: system ((" cmd / C start / B \"" + game_config :: wesnothd_name + "\" - c " + config + " - t 2 - T 5 "). c_str ()) != 0 ) <nl> # endif <nl> { <nl> LOG_GENERAL << " Failed to run server start script \ n ";
mmm src / text . cpp <nl> ppp src / text . cpp <nl> void ttext :: recalculate ( const bool force ) const <nl> << " result " << rect_ <nl> << ".\ n "; <nl>  <nl> - if ( rect_ . width > maximum_width_ ) { <nl> + if ( maximum_width_ != - 1 && rect_ . width > maximum_width_ ) { <nl> ERR_GUI_L << " ttext ::" << __func__ <nl> << " text '" << gui2 :: debug_truncate ( text_ ) <nl> << " ' width " << rect_ . width
mmm src / unit . cpp <nl> ppp src / unit . cpp <nl> void unit :: refresh_unit ( display & disp , gamemap :: location hex , bool with_status ) <nl>  <nl> if (! anim_ ) set_standing ( disp ); <nl> const gamemap :: TERRAIN terrain = map . get_terrain ( hex ); <nl> - const double submerge = is_flying () ? 0 . 0 : map . get_terrain_info ( terrain ). unit_submerge (); <nl> + const double submerge = is_flying () ? 0 . 0 : map . get_terrain_info ( terrain ). unit_submerge () * disp . zoom (); <nl> const int height_adjust = is_flying () ? 0 : int ( map . get_terrain_info ( terrain ). unit_height_adjust () * disp . zoom ()); <nl>  <nl> std :: string image_name ; <nl> void unit :: refresh_unit ( display & disp , gamemap :: location hex , bool with_status ) <nl>  <nl> if ( facing_ == gamemap :: location :: NORTH_WEST || facing_ == gamemap :: location :: SOUTH_WEST ) { <nl> const int d = disp . hex_size () / 2 ; <nl> - unit_anim_halo_ = halo :: add ( x + d - current_frame . halo_x , <nl> - y + d + current_frame . halo_y , <nl> + unit_anim_halo_ = halo :: add ( x + d -( current_frame . halo_x * disp . zoom ()), <nl> + y + d +( current_frame . halo_y * disp . zoom ()), <nl> current_frame . halo [ sub_halo ]. first ); <nl> } else { <nl> const int d = disp . hex_size () / 2 ; <nl> - unit_anim_halo_ = halo :: add ( x + d + current_frame . halo_x , <nl> - y + d + current_frame . halo_y , <nl> + unit_anim_halo_ = halo :: add ( x + d +( current_frame . halo_x * disp . zoom ()), <nl> + y + d +( current_frame . halo_y * disp . zoom ()), <nl> current_frame . halo [ sub_halo ]. first , <nl> halo :: REVERSE ); <nl> } <nl> void unit :: refresh_unit ( display & disp , gamemap :: location hex , bool with_status ) <nl> } else { <nl> loc = image :: locator ( image_name ); <nl> } <nl> - surface image ( image :: get_image ( loc , get_state (" stoned ")==" yes "? image :: GREYED : image :: UNSCALED )); <nl> + surface image ( image :: get_image ( loc , get_state (" stoned ")==" yes "? image :: GREYED : image :: SCALED )); <nl> if ( image == NULL ) { <nl> image = still_image (); <nl> } <nl> void unit :: refresh_unit ( display & disp , gamemap :: location hex , bool with_status ) <nl> if ( max_hitpoints () > 0 ) { <nl> unit_energy = double ( hitpoints ())/ double ( max_hitpoints ()); <nl> } <nl> - disp . draw_bar (* energy_file , x - 5 , y - height_adjust ,( max_hitpoints ()* 2 )/ 3 , unit_energy , hp_color (), bar_alpha ); <nl> + disp . draw_bar (* energy_file , x -( 5 * disp . zoom ()), y - height_adjust ,( max_hitpoints ()* 2 )/ 3 , unit_energy , hp_color (), bar_alpha ); <nl>  <nl> if ( experience () > 0 && can_advance ()) { <nl> const double filled = double ( experience ())/ double ( max_experience ());
mmm src / game_launcher . cpp <nl> ppp src / game_launcher . cpp <nl> game_launcher :: game_launcher ( const commandline_options & cmdline_opts , const char <nl> const std :: string app_basename = filesystem :: base_name ( appname ); <nl> jump_to_editor_ = app_basename . find (" editor ") != std :: string :: npos ; <nl>  <nl> + if ( cmdline_opts_ . core_id ) { <nl> + preferences :: set_core_id (* cmdline_opts_ . core_id ); <nl> + } <nl> if ( cmdline_opts_ . campaign ) { <nl> jump_to_campaign_ . jump_ = true ; <nl> jump_to_campaign_ . campaign_id_ = * cmdline_opts_ . campaign ;
mmm src / hotkey / command_executor . cpp <nl> ppp src / hotkey / command_executor . cpp <nl> void execute_command ( display & disp , const hotkey_command & command , command_execu <nl> } <nl> case LUA_CONSOLE : { <nl> if (! disp . in_game ()) { <nl> - WRN_G << " caution : attempting to interface console with game lua kernel when we are not in game ...\ n "; <nl> + // WRN_G << " caution : attempting to interface console with game lua kernel when we are not in game ...\ n "; <nl> + gui2 :: tlua_interpreter :: display ( disp . video (), gui2 :: tlua_interpreter :: APP ); <nl> + } else { <nl> + gui2 :: tlua_interpreter :: display ( disp . video (), gui2 :: tlua_interpreter :: GAME ); <nl> } <nl> - gui2 :: tlua_interpreter :: display ( disp . video (), gui2 :: tlua_interpreter :: GAME ); <nl> break ; <nl> } <nl> default :
mmm src / multiplayer_ui . cpp <nl> ppp src / multiplayer_ui . cpp <nl> std :: string get_colour_string ( int id ) <nl> } <nl> } <nl>  <nl> - chat :: chat () <nl> + chat :: chat () : <nl> + message_history_ (), <nl> + last_update_ () <nl> { <nl> } <nl>  <nl> ui :: ui ( game_display & disp , const std :: string & title , const config & cfg , chat & c , <nl> chat_textbox_ ( disp . video (), 100 , "", false ), <nl> users_menu_ ( disp . video (), std :: vector < std :: string >(), false , - 1 , - 1 , NULL , & umenu_style ), <nl>  <nl> + user_list_ (), <nl> selected_game_ (""), <nl>  <nl> result_ ( CONTINUE ),
mmm src / unit . cpp <nl> ppp src / unit . cpp <nl> const std :: vector < attack_type >& unit :: attacks () const <nl>  <nl> int unit :: movement_cost ( const gamemap & map , gamemap :: TERRAIN terrain ) const <nl> { <nl> - if ( type_ -> level () == 0 && terrain == gamemap :: TOWER ) <nl> - return 100 ; <nl> +// don ' t allow level 0 units to take villages - removed until AI <nl> +// is smart enough to deal with this . <nl> +// if ( type_ -> level () == 0 && terrain == gamemap :: TOWER ) <nl> +// return 100 ; <nl>  <nl> const int res = type_ -> movement_type (). movement_cost ( map , terrain ); <nl> 
mmm src / mouse_events . cpp <nl> ppp src / mouse_events . cpp <nl> bool mouse_handler :: left_click ( int x , int y , const bool browse ) <nl>  <nl> gui (). unhighlight_reach (); <nl>  <nl> + // If the whiteboard is active , it intercepts any unit movement <nl> if ( resources :: whiteboard -> is_active ()) { <nl> // Unselect the current hex , and create planned move for whiteboard <nl> selected_hex_ = map_location (); <nl> bool mouse_handler :: left_click ( int x , int y , const bool browse ) <nl> { <nl> resources :: whiteboard -> save_temp_move (); <nl> } <nl> - } else { <nl> + // Otherwise proceed to normal unit movement , unless the selected unit already has actions <nl> + // from the whiteboard . <nl> + } else if (! resources :: whiteboard -> unit_has_actions (* u )) { <nl> // register the mouse - UI waypoints into the unit ' s waypoints <nl> u -> waypoints () = waypoints_ ; <nl> 
mmm src / addon / manager . cpp <nl> ppp src / addon / manager . cpp <nl> namespace { <nl> if ( res == gui2 :: twindow :: OK ) { <nl> delete_remote_addon ( disp , addon , connection ); <nl> } <nl> - <nl> - return ; <nl> } <nl> - <nl> // Handle publish option <nl> - if ( index >= int ( addons . size ())) { <nl> + else if ( index >= int ( addons . size ())) { <nl> const std :: string & addon = publish_options [ index - int ( addons . size ())]; <nl> upload_addon_to_server ( disp , addon , connection ); <nl> - return ; <nl> } <nl> - <nl> - if ( check_whether_overwrite ( disp , addons [ index ], publish_options )) <nl> + // Handle download option <nl> + else if ( check_whether_overwrite ( disp , addons [ index ], publish_options )) <nl> { <nl> // Handle download <nl> install_addon ( disp , addons [ index ], titles [ index ], types [ index ], <nl> namespace { <nl> } <nl> } <nl>  <nl> - // Show the dialog again , and position it on the same item installed <nl> + // Show the dialog again , and position it on the last selected item <nl> download_addons ( disp , remote_address , update_mode , do_refresh , index ); <nl>  <nl> } catch ( config :: error & e ) {
mmm doc / doxygen / doxygen . cpp <nl> ppp doc / doxygen / doxygen . cpp <nl> @ li < a href =" hierarchy . html "> Classes </ a > <nl> @ li < a href =" files . html "> Source Files </ a > <nl> @ li < a href =" todo . html "> Todo </ a > <nl> + @ li < a href =" deprecated . html "> Deprecated </ a > <nl> </ td > <nl> </ tr > <nl> </ table >
mmm src / controller_base . cpp <nl> ppp src / controller_base . cpp <nl> # include " controller_base . hpp " <nl> # include " dialogs . hpp " <nl> # include " mouse_handler_base . hpp " <nl> +# include " foreach . hpp " <nl>  <nl> controller_base :: controller_base ( <nl> int ticks , const config & game_config , CVideo & /* video */) : <nl> bool controller_base :: handle_scroll ( CKey & key , int mousex , int mousey , int mouse <nl> bool scrolling = false ; <nl> bool mouse_in_window = ( SDL_GetAppState () & SDL_APPMOUSEFOCUS ) <nl> || utils :: string_bool ( preferences :: get (" scroll_when_mouse_outside "), true ); <nl> - const int scroll_threshold = ( preferences :: mouse_scroll_enabled ()) <nl> + int scroll_threshold = ( preferences :: mouse_scroll_enabled ()) <nl> ? preferences :: mouse_scroll_threshold () <nl> : 0 ; <nl> - <nl> + foreach ( const theme :: menu & m , get_display (). get_theme (). menus ()) { <nl> + if ( point_in_rect ( mousex , mousey , m . get_location ())) { <nl> + scroll_threshold = 0 ; <nl> + } <nl> + } <nl> if (( key [ SDLK_UP ] && have_keyboard_focus ()) <nl> || ( mousey < scroll_threshold && mouse_in_window )) { <nl> get_display (). scroll ( 0 ,- preferences :: scroll_speed ());
mmm src / unit . cpp <nl> ppp src / unit . cpp <nl> bool unit :: internal_matches_filter ( const vconfig & cfg , const gamemap :: location & <nl> std :: vector < std :: pair < int , int > >:: const_iterator range , range_end = ranges . end (); <nl> for ( range = ranges . begin (); range != range_end ; ++ range ) { <nl> for ( int i = range -> first ; i <= range -> second ; ++ i ) { <nl> - if ( i > 0 && i <= teams_ -> size ()) { <nl> + if ( i > 0 && static_cast < size_t >( i ) <= teams_ -> size ()) { <nl> viewers . insert ( i ); <nl> } <nl> } <nl> bool unit :: internal_matches_filter ( const vconfig & cfg , const gamemap :: location & <nl> } else { <nl> // if viewing_side is not defined , default to all enemies <nl> const team & my_team = (* teams_ )[ this -> side ()- 1 ]; <nl> - for ( int i = 1 ; i <= teams_ -> size (); ++ i ) { <nl> + for ( size_t i = 1 ; i <= teams_ -> size (); ++ i ) { <nl> if ( my_team . is_enemy ( i )) { <nl> viewers . insert ( i ); <nl> }
mmm src / game . cpp <nl> ppp src / game . cpp <nl> static int process_command_args ( int argc , char ** argv ) { <nl> python_ai :: invoke (" documentation "); <nl> return 0 ; <nl> } else if ( val == "-- python - shell ") { <nl> - int ret = python_ai :: run_shell (); <nl> + python_ai :: run_shell (); <nl> return 0 ; <nl> # endif <nl> } else if ( val == "-- config - dir ") {
mmm src / units / attack_type . cpp <nl> ppp src / units / attack_type . cpp <nl> static bool matches_simple_filter ( const attack_type & attack , const config & fil <nl> const std :: vector < std :: string > filter_name = utils :: split ( filter [" name "]); <nl> const std :: vector < std :: string > filter_type = utils :: split ( filter [" type "]); <nl> const std :: string filter_special = filter [" special "]; <nl> + const std :: string filter_special_active = filter [" special_active "]; <nl> const std :: string filter_formula = filter [" formula "]; <nl>  <nl> if ( ! filter_range . empty () && std :: find ( filter_range . begin (), filter_range . end (), attack . range ()) == filter_range . end () ) <nl> static bool matches_simple_filter ( const attack_type & attack , const config & fil <nl> if ( ! filter_special . empty () && ! attack . get_special_bool ( filter_special , true ) ) <nl> return false ; <nl>  <nl> + if ( ! filter_special_active . empty () && ! attack . get_special_bool ( filter_special_active , false ) ) <nl> + return false ; <nl> + <nl> if (! filter_formula . empty ()) { <nl> try { <nl> const wfl :: attack_type_callable callable ( attack );
mmm src / addon / info . hpp <nl> ppp src / addon / info . hpp <nl> struct addon_info <nl> std :: vector < std :: string > depends ; <nl> // std :: vector < addon_dependency > conflicts , recommends , replaces ; <nl>  <nl> + std :: string feedback_url ; <nl> + <nl> time_t updated ; <nl>  <nl> // Artificial upload order index used to preserve add - ons upload order <nl> struct addon_info <nl> , version (), author (), size (), downloads () <nl> , uploads (), type (), locales () <nl> , depends () <nl> + , feedback_url () <nl> , updated (), order () <nl> {} <nl>  <nl> struct addon_info <nl> , version (), author (), size (), downloads () <nl> , uploads (), type (), locales () <nl> , depends () <nl> + , feedback_url () <nl> , updated (), order () <nl> { <nl> this -> read ( cfg ); <nl> struct addon_info <nl> this -> type = o . type ; <nl> this -> locales = o . locales ; <nl> this -> depends = o . depends ; <nl> + this -> feedback_url = o . feedback_url ; <nl> this -> updated = o . updated ; <nl> this -> order = o . order ; <nl> }mmm src / addon / info . cpp <nl> ppp src / addon / info . cpp <nl> struct addon_info <nl> std :: vector < std :: string > depends ; <nl> // std :: vector < addon_dependency > conflicts , recommends , replaces ; <nl>  <nl> + std :: string feedback_url ; <nl> + <nl> time_t updated ; <nl>  <nl> // Artificial upload order index used to preserve add - ons upload order <nl> struct addon_info <nl> , version (), author (), size (), downloads () <nl> , uploads (), type (), locales () <nl> , depends () <nl> + , feedback_url () <nl> , updated (), order () <nl> {} <nl>  <nl> struct addon_info <nl> , version (), author (), size (), downloads () <nl> , uploads (), type (), locales () <nl> , depends () <nl> + , feedback_url () <nl> , updated (), order () <nl> { <nl> this -> read ( cfg ); <nl> struct addon_info <nl> this -> type = o . type ; <nl> this -> locales = o . locales ; <nl> this -> depends = o . depends ; <nl> + this -> feedback_url = o . feedback_url ; <nl> this -> updated = o . updated ; <nl> this -> order = o . order ; <nl> } <nl> void addon_info :: read ( const config & cfg ) <nl> } <nl>  <nl> this -> depends = utils :: split ( cfg [" dependencies "]. str ()); <nl> + this -> feedback_url = cfg [" feedback_url "]. str (); <nl>  <nl> this -> updated = cfg [" timestamp "]. to_time_t (); <nl> } <nl> void addon_info :: write ( config & cfg ) const <nl> } <nl>  <nl> cfg [" dependencies "] = utils :: join ( this -> depends ); <nl> + cfg [" feedback_url "] = this -> feedback_url ; <nl>  <nl> cfg [" timestamp "] = this -> updated ; <nl> }
mmm src / whiteboard / highlight_visitor . cpp <nl> ppp src / whiteboard / highlight_visitor . cpp <nl> action_ptr highlight_visitor :: get_execute_target () <nl> } <nl> action_ptr highlight_visitor :: get_delete_target () <nl> { <nl> - action_ptr action ; <nl> + action_ptr action = action_ptr (); <nl> if ( owner_unit_ ) <nl> { <nl> - action = * side_actions_ -> find_last_action_of (* owner_unit_ ); <nl> + side_actions :: iterator it = side_actions_ -> find_last_action_of (* owner_unit_ ); <nl> + if ( it != side_actions_ -> end ()) <nl> + { <nl> + action = * it ; <nl> + } <nl> } <nl> return action ; <nl> }
mmm src / actions / attack . hpp <nl> ppp src / actions / attack . hpp <nl> public : <nl> battle_context ( const battle_context_unit_stats & att , const battle_context_unit_stats & def ); <nl>  <nl> battle_context ( const battle_context & other ); <nl> + battle_context ( battle_context && other ) = default ; <nl>  <nl> battle_context & operator =( const battle_context & other ); <nl> + battle_context & operator =( battle_context && other ) = default ; <nl>  <nl> /** This method returns the statistics of the attacker . */ <nl> const battle_context_unit_stats & get_attacker_stats () constmmm src / mouse_events . cpp <nl> ppp src / mouse_events . cpp <nl> public : <nl> battle_context ( const battle_context_unit_stats & att , const battle_context_unit_stats & def ); <nl>  <nl> battle_context ( const battle_context & other ); <nl> + battle_context ( battle_context && other ) = default ; <nl>  <nl> battle_context & operator =( const battle_context & other ); <nl> + battle_context & operator =( battle_context && other ) = default ; <nl>  <nl> /** This method returns the statistics of the attacker . */ <nl> const battle_context_unit_stats & get_attacker_stats () const <nl> int mouse_handler :: fill_weapon_choices ( <nl> best = bc_vector . size (); <nl> } <nl>  <nl> - bc_vector . push_back ( bc ); <nl> + bc_vector . push_back ( std :: move ( bc )); <nl> } <nl> } <nl> mmm src / reports . cpp <nl> ppp src / reports . cpp <nl> public : <nl> battle_context ( const battle_context_unit_stats & att , const battle_context_unit_stats & def ); <nl>  <nl> battle_context ( const battle_context & other ); <nl> + battle_context ( battle_context && other ) = default ; <nl>  <nl> battle_context & operator =( const battle_context & other ); <nl> + battle_context & operator =( battle_context && other ) = default ; <nl>  <nl> /** This method returns the statistics of the attacker . */ <nl> const battle_context_unit_stats & get_attacker_stats () const <nl> int mouse_handler :: fill_weapon_choices ( <nl> best = bc_vector . size (); <nl> } <nl>  <nl> - bc_vector . push_back ( bc ); <nl> + bc_vector . push_back ( std :: move ( bc )); <nl> } <nl> } <nl>  <nl> static config unit_weapons ( reports :: context & rc , const unit * attacker , const ma <nl> for ( unsigned int i = 0 ; i < attacker -> attacks (). size (); i ++) { <nl> // skip weapons with attack_weight = 0 <nl> if ( attacker -> attacks ()[ i ]. attack_weight () > 0 ) { <nl> - battle_context weapon ( rc . units (), attacker_pos , defender -> get_location (), i , - 1 , 0 . 0 , nullptr , attacker ); <nl> - weapons . push_back ( weapon ); <nl> + weapons . emplace_back ( rc . units (), attacker_pos , defender -> get_location (), i , - 1 , 0 . 0 , nullptr , attacker ); <nl> } <nl> } <nl> 
mmm src / unit . cpp <nl> ppp src / unit . cpp <nl> void unit :: restart_animation ( const game_display & disp , int start_time ) { <nl> } <nl>  <nl> void unit :: set_facing ( gamemap :: location :: DIRECTION dir ) { <nl> - wassert ( dir != gamemap :: location :: NDIRECTIONS ); <nl> - facing_ = dir ; <nl> + if ( dir != gamemap :: location :: NDIRECTIONS ) { <nl> + facing_ = dir ; <nl> + } <nl> + // else look at yourself ( not available so continue to face the same direction ) <nl> } <nl>  <nl> void unit :: redraw_unit ( game_display & disp , const gamemap :: location & loc )
mmm src / gui / widgets / window . hpp <nl> ppp src / gui / widgets / window . hpp <nl> public : <nl> static void set_sunset ( const unsigned interval ) <nl> { sunset_ = interval ? interval : 5 ; } <nl>  <nl> + bool get_need_layout () const { return need_layout_ ; } <nl> + <nl> private : <nl>  <nl> /** Needed so we can change what ' s drawn on the screen . */
mmm src / playlevel . cpp <nl> ppp src / playlevel . cpp <nl> LEVEL_RESULT play_level ( game_data & gameinfo , const config & game_config , <nl> if ( first_human_team != - 1 ) { <nl> clear_shroud ( gui , status , map , gameinfo , units , teams , first_human_team ); <nl> LOG_NG << " b " << ( SDL_GetTicks () - ticks ) << "\ n "; <nl> - gui . scroll_to_tile ( map . starting_position ( first_human_team + 1 ). x , map . starting_position ( first_human_team + 1 ). y , display :: WARP ); <nl> + gui . scroll_to_tile ( map . starting_position ( first_human_team + 1 ). x , <nl> + map . starting_position ( first_human_team + 1 ). y , display :: WARP ); <nl> LOG_NG << " c " << ( SDL_GetTicks () - ticks ) << "\ n "; <nl> } <nl>  <nl> LEVEL_RESULT play_level ( game_data & gameinfo , const config & game_config , <nl> events :: raise_draw_event (); <nl> if (! loading_game ) { <nl> game_events :: fire (" start "); <nl> + game_events :: set_variable (" turn_number ", " 1 "); <nl> } <nl>  <nl> gui . draw ();
mmm src / soundsource . cpp <nl> ppp src / soundsource . cpp <nl> void positional_source :: write_config ( config & cfg ) const <nl> cfg [" delay "] = str_cast < unsigned int >( this -> min_delay_ ); <nl> cfg [" chance "] = str_cast < unsigned int >( this -> chance_ ); <nl> cfg [" check_fogged "] = this -> check_fogged_ ? " yes " : " no "; <nl> - cfg [" check_shrouded "] = this -> check_fogged_ ? " yes " : " no "; <nl> + cfg [" check_shrouded "] = this -> check_shrouded_ ? " yes " : " no "; <nl>  <nl> cfg [" x "] = cfg [" y "] = ""; <nl> bool first_loc = true ;
mmm src / reports . cpp <nl> ppp src / reports . cpp <nl> Units cannot be killed by poison alone . The poison will not reduce it below 1 HP <nl>  <nl> if ( flag_icon . empty ()) { <nl> flag_icon = game_config :: flag_icon_image ; <nl> - old_rgb = game_config :: flag_rgb ; <nl> - new_rgb = team :: get_side_colour_index ( playing_side ); <nl> - mods = "~ RC (" + old_rgb + ">" + new_rgb + ")"; <nl> } <nl> + old_rgb = game_config :: flag_rgb ; <nl> + new_rgb = team :: get_side_colour_index ( playing_side ); <nl> + mods = "~ RC (" + old_rgb + ">" + new_rgb + ")"; <nl>  <nl> // remove animation stuff we don ' t care about <nl> // const std :: vector < std :: string > items = utils :: split ( flag );
mmm src / hotkey / hotkey_item . cpp <nl> ppp src / hotkey / hotkey_item . cpp <nl> void save_hotkeys ( config & cfg ) <nl> cfg . clear_children (" hotkey "); <nl>  <nl> BOOST_FOREACH ( hotkey_ptr item , hotkeys_ ) { <nl> - if (! item -> is_default ()) { <nl> + if (! item -> is_default () && item -> active ()) { <nl> item -> save ( cfg . add_child (" hotkey ")); <nl> } <nl> }
mmm src / menu_events . cpp <nl> ppp src / menu_events . cpp <nl> private : <nl> if ( network :: nconnections () == 0 ) { <nl> std :: cerr << " showing ai formula ...\ n "; <nl> textbox_info_ . show ( gui :: TEXTBOX_AI , sgettext (" prompt ^ Command :"), "", false , * gui_ ); <nl> - } else { <nl> - add_chat_message ( time ( NULL ), _ (" ai "), 0 , " Formula commandline not available in network games "); <nl> } <nl> } <nl> 
mmm src / help . cpp <nl> ppp src / help . cpp <nl> public : <nl> std :: string lang_unit = type -> type_name (); <nl> std :: string ref_id ; <nl> if ( description_type (* type ) == FULL_DESCRIPTION ) { <nl> - ref_id = unit_prefix + type -> id (); <nl> + const std :: string section_prefix = type -> variations (). empty () ? "" : ".."; <nl> + ref_id = section_prefix + unit_prefix + type -> id (); <nl> } else { <nl> ref_id = unknown_unit_topic ; <nl> lang_unit += " (?)";
mmm src / saved_game . cpp <nl> ppp src / saved_game . cpp <nl> void saved_game :: expand_random_scenario () <nl> LOG_NG << " randomly generating scenario ...\ n "; <nl> const cursor :: setter cursor_setter ( cursor :: WAIT ); <nl>  <nl> - starting_pos_ = random_generate_scenario ( starting_pos_ [" scenario_generation "], <nl> + config scenario_new = random_generate_scenario ( starting_pos_ [" scenario_generation "], <nl> starting_pos_ . child (" generator ")); <nl> + // Preserve " story " form the scenario toplevel . <nl> + BOOST_FOREACH ( config & story , starting_pos_ . child_range (" story ")) <nl> + { <nl> + scenario_new . add_child (" story ", story ); <nl> + } <nl> + starting_pos_ = scenario_new ; <nl> } <nl> // it looks like we support a map = where map = filename equals more or less map_data ={ filename } <nl> if ( starting_pos_ [" map_data "]. empty () && starting_pos_ [" map "] != "") {
mmm src / play_controller . cpp <nl> ppp src / play_controller . cpp <nl> void play_controller :: show_help (){ <nl> } <nl>  <nl> void play_controller :: undo (){ <nl> + // deselect unit ( only here , not to be done when undoing attack - move ) <nl> + mouse_handler_ . deselect_hex (); <nl> menu_handler_ . undo ( player_number_ ); <nl> } <nl>  <nl> void play_controller :: redo (){ <nl> + // deselect unit ( only here , not to be done when undoing attack - move ) <nl> + mouse_handler_ . deselect_hex (); <nl> menu_handler_ . redo ( player_number_ ); <nl> } <nl>  <nl> void play_controller :: init_side ( const unsigned int team_index , bool /* is_replay * <nl> gui_ -> invalidate_all (); <nl> } <nl>  <nl> - if (! recorder . is_skipping ()){ <nl> + if (! recorder . is_skipping () && ! skip_replay_ ){ <nl> gui_ -> scroll_to_leader ( units_ , player_number_ ); <nl> } <nl> }
mmm src / display . cpp <nl> ppp src / display . cpp <nl> void display :: clear_redraw_observers () <nl>  <nl> void display :: draw ( bool update , bool force ) { <nl> // log_scope (" display :: draw "); <nl> - if ( screen_ . update_locked ()) { <nl> + if ( screen_ . update_locked () || ( SDL_GetAppState () & SDL_APPACTIVE ) == 0 ) { <nl> return ; <nl> } <nl> bool changed = draw_init ();
mmm src / multiplayer_connect . cpp <nl> ppp src / multiplayer_connect . cpp <nl> config connect :: side :: get_config () const <nl> } <nl> { <nl> res [" id "] = res [" save_id "]; <nl> - const config & ai_cfg = ai :: configuration :: get_ai_config_for ( ai_algorithm_ ); <nl> - res . add_child (" ai ", ai_cfg ); <nl> utils :: string_map symbols ; <nl> - symbols [" playername "] = ai_cfg [" description "]; <nl> + if ( allow_player_ ) { <nl> + const config & ai_cfg = ai :: configuration :: get_ai_config_for ( ai_algorithm_ ); <nl> + res . add_child (" ai ", ai_cfg ); <nl> + symbols [" playername "] = ai_cfg [" description "]; <nl> + } else { // do not import default ai cfg here - all is set by scenario config <nl> + symbols [" playername "] = _ (" Computer Player "); <nl> + } <nl> symbols [" side "] = res [" side "]. str (); <nl> description = vgettext ("$ playername $ side ", symbols ); <nl> }
mmm src / tools / schema / tag . cpp <nl> ppp src / tools / schema / tag . cpp <nl> void class_tag :: add_tag ( const std :: string & path , const class_tag & tag , <nl> it -> second . add_keys ( tag . keys_ ); <nl> it -> second . add_links ( tag . links_ ); <nl> } <nl> + links_ . erase ( tag . get_name ()); <nl> return ; <nl> } <nl> std :: string :: size_type pos = path . find ('/'); <nl> void class_tag :: append_super ( const class_tag & tag , const std :: string & path ){ <nl> add_keys ( tag . keys_ ); <nl> add_links ( tag . links_ ); <nl> for ( tag_map :: const_iterator i = tag . tags_ . begin (); i != tag . tags_ . end ();++ i ){ <nl> + links_ . erase ( i -> first ); <nl> add_link ( path + "/" + i -> first ); <nl> + <nl> } <nl> } <nl> 
mmm src / gui / dialogs / addon / manager . cpp <nl> ppp src / gui / dialogs / addon / manager . cpp <nl> void addon_manager :: apply_filters ( window & window ) <nl> template < void ( addon_manager ::* fptr )( const addon_info & addon , window & window )> <nl> void addon_manager :: execute_action_on_selected_addon ( window & window ) <nl> { <nl> + // Explicitly return to the main page if we ' re in low - res mode so the list is visible . <nl> + if ( stacked_widget * stk = find_widget < stacked_widget >(& window , " main_stack ", false , false )) { <nl> + stk -> select_layer ( 0 ); <nl> + } <nl> + <nl> addon_list & addons = find_widget < addon_list >(& window , " addons ", false ); <nl> const addon_info * addon = addons . get_selected_addon (); <nl> 
mmm src / wesnothd_connection . hpp <nl> ppp src / wesnothd_connection . hpp <nl> public : <nl> // Destroys this object . <nl> void stop (); <nl>  <nl> + bool socket_open () const <nl> + { <nl> + return socket_ . is_open (); <nl> + } <nl> + <nl> /** True if connected and no high - level operation is in progress */ <nl> bool handshake_finished () const <nl> {mmm src / wesnothd_connection . cpp <nl> ppp src / wesnothd_connection . cpp <nl> public : <nl> // Destroys this object . <nl> void stop (); <nl>  <nl> + bool socket_open () const <nl> + { <nl> + return socket_ . is_open (); <nl> + } <nl> + <nl> /** True if connected and no high - level operation is in progress */ <nl> bool handshake_finished () const <nl> { <nl> void wesnothd_connection :: send_data ( const configr_of & request ) <nl> void wesnothd_connection :: cancel () <nl> { <nl> MPTEST_LOG ; <nl> - if ( socket_ . is_open ()) { <nl> + if ( socket_open ()) { <nl> boost :: system :: error_code ec ; <nl>  <nl> # ifdef _MSC_VERmmm src / game_initialization / multiplayer . cpp <nl> ppp src / game_initialization / multiplayer . cpp <nl> public : <nl> // Destroys this object . <nl> void stop (); <nl>  <nl> + bool socket_open () const <nl> + { <nl> + return socket_ . is_open (); <nl> + } <nl> + <nl> /** True if connected and no high - level operation is in progress */ <nl> bool handshake_finished () const <nl> { <nl> void wesnothd_connection :: send_data ( const configr_of & request ) <nl> void wesnothd_connection :: cancel () <nl> { <nl> MPTEST_LOG ; <nl> - if ( socket_ . is_open ()) { <nl> + if ( socket_open ()) { <nl> boost :: system :: error_code ec ; <nl>  <nl> # ifdef _MSC_VER <nl> std :: pair < wesnothd_connection_ptr , config > open_connection ( std :: string host ) <nl> return std :: make_pair ( std :: move ( sock ), config ()); <nl> } <nl>  <nl> + if (! sock -> socket_open ()) { <nl> + throw wesnothd_error (" The server has shut down or restarted ."); <nl> + } <nl> + <nl> data . clear (); <nl> sock -> wait_and_receive_data ( data ); <nl> 
mmm src / multiplayer . cpp <nl> ppp src / multiplayer . cpp <nl> void play_multiplayer ( display & disp , game_data & units_data , config cfg , <nl> } else if ( result < int ( choices . size ()/ 3 )* 2 ) { <nl> controller = " ai "; <nl> result -= choices . size ()/ 3 ; <nl> + sides [ res ]-> values [" description "] = ""; <nl> } else { <nl> controller = " network "; <nl> result -= ( choices . size ()/ 3 )* 2 ;
mmm src / gui / widgets / window . cpp <nl> ppp src / gui / widgets / window . cpp <nl> void window :: layout () <nl>  <nl> log_scope2 ( log_gui_layout , LOG_SCOPE_HEADER ); <nl>  <nl> - point size = get_best_size (); <nl> const point mouse = get_mouse_position (); <nl>  <nl> variables_ . add (" mouse_x ", wfl :: variant ( mouse . x )); <nl> variables_ . add (" mouse_y ", wfl :: variant ( mouse . y )); <nl> variables_ . add (" window_width ", wfl :: variant ( 0 )); <nl> variables_ . add (" window_height ", wfl :: variant ( 0 )); <nl> - variables_ . add (" best_window_width ", wfl :: variant ( size . x )); <nl> - variables_ . add (" best_window_height ", wfl :: variant ( size . y )); <nl> variables_ . add (" size_request_mode ", wfl :: variant (" maximum ")); <nl>  <nl> get_screen_size_variables ( variables_ ); <nl> void window :: layout () <nl> } <nl>  <nl> /***** Get the best location for the window *****/ <nl> - size = get_best_size (); <nl> + point size = get_best_size (); <nl> assert ( size . x <= maximum_width && size . y <= maximum_height ); <nl>  <nl> point origin ( 0 , 0 );
mmm src / cursor . cpp <nl> ppp src / cursor . cpp <nl> void draw ( surface screen ) <nl> if ( use_colour_cursors () == false ) { <nl> return ; <nl> } <nl> - <nl> + <nl> + if ( current_cursor == NUM_CURSORS ) { <nl> + return ; <nl> + } <nl> + <nl> if (! colour_ready ) { <nl> // display start to draw cursor <nl> // so it can now display colour cursor <nl> void draw ( surface screen ) <nl> set ( current_cursor ); <nl> } <nl>  <nl> - if ( current_cursor == NUM_CURSORS ) { <nl> - return ; <nl> - } <nl> - <nl> if ( have_focus == false ) { <nl> cursor_buf = NULL ; <nl> return ;
mmm src / loadscreen . cpp <nl> ppp src / loadscreen . cpp <nl> loadscreen :: loadscreen ( CVideo & screen , const int & percent ): <nl> setconfig_counter ( 0 ), <nl> parser_counter ( 0 ), <nl> screen_ ( screen ), <nl> + textarea_ (), <nl> + logo_surface_ ( NULL ), <nl> logo_drawn_ ( false ), <nl> pby_offset_ ( 0 ), <nl> prcnt_ ( percent )
mmm src / game_preferences . cpp <nl> ppp src / game_preferences . cpp <nl> void encounter_start_units ( unit_map & units ){ <nl> void encounter_recallable_units ( std :: vector < team >& teams ){ <nl> for ( std :: vector < team >:: iterator help_team_it = teams . begin (); <nl> help_team_it != teams . end (); ++ help_team_it ) { <nl> - for ( std :: vector < unit >:: iterator help_recall_it = help_team_it -> recall_list (). begin (); help_recall_it != help_team_it -> recall_list (). end (); help_recall_it ++) { <nl> + for ( std :: vector < unit >:: iterator help_recall_it = help_team_it -> recall_list (). begin (); help_recall_it != help_team_it -> recall_list (). end (); ++ help_recall_it ) { <nl> encountered_units_set . insert ( help_recall_it -> type_id ()); <nl> } <nl> } <nl> } <nl>  <nl> void encounter_map_terrain ( gamemap & map ){ <nl> - for ( int map_x = 0 ; map_x < map . w (); map_x ++) { <nl> - for ( int map_y = 0 ; map_y < map . h (); map_y ++) { <nl> + for ( int map_x = 0 ; map_x < map . w (); ++ map_x ) { <nl> + for ( int map_y = 0 ; map_y < map . h (); ++ map_y ) { <nl> const t_translation :: t_terrain t = map . get_terrain ( map_location ( map_x , map_y )); <nl> preferences :: encountered_terrains (). insert ( t ); <nl> const t_translation :: t_list & underlaying_list = map . underlying_union_terrain ( map_location ( map_x , map_y )); <nl> - for ( std :: vector < t_translation :: t_terrain >:: const_iterator ut = underlaying_list . begin (); ut != underlaying_list . end (); ut ++) { <nl> + for ( std :: vector < t_translation :: t_terrain >:: const_iterator ut = underlaying_list . begin (); ut != underlaying_list . end (); ++ ut ) { <nl> preferences :: encountered_terrains (). insert (* ut ); <nl> }; <nl> }
mmm src / font . cpp <nl> ppp src / font . cpp <nl> struct font_id <nl> }; <nl> bool operator <( const font_id & o ) const <nl> { <nl> - return subset < o . subset || subset == o . subset && size < o . size ; <nl> + return subset < o . subset || ( subset == o . subset && size < o . size ); <nl> }; <nl>  <nl> subset_id subset ;
mmm src / network_worker . cpp <nl> ppp src / network_worker . cpp <nl> static int process_queue ( void * shard_num ) <nl> } else { <nl> std :: string buffer ( buf . begin (), buf . end ()); <nl> std :: istringstream stream ( buffer ); <nl> - // Binary wml starts with a char < 4 , the first char of a gzip header is 31 <nl> - // so test that here and use the proper reader . <nl> try { <nl> - if ( stream . peek () == 31 ) { <nl> - read_gz ( received_data -> config_buf , stream ); <nl> - } else { <nl> - /// @ todo Possibly complain more loudly <nl> - ERR_NW << " Receiving binary WML . Who is sending this ?\ n "; <nl> - } <nl> + read_gz ( received_data -> config_buf , stream ); <nl> } catch ( config :: error & e ) <nl> { <nl> received_data -> config_error = e . message ;
mmm src / version . cpp <nl> ppp src / version . cpp <nl> version_info :: version_info ( unsigned int major , unsigned int minor , unsigned int <nl> } <nl>  <nl> version_info :: version_info ( const std :: string & str ) <nl> - : special_ (""), special_separator_ ('\ 0 '), sane_ ( true ) <nl> + : nums_ () <nl> + , special_ ("") <nl> + , special_separator_ ('\ 0 ') <nl> + , sane_ ( true ) <nl> { <nl> const std :: vector < std :: string > string_parts = utils :: split ( str ,'.'); <nl> // first two components are required to be valid numbers , though
mmm src / server / server . cpp <nl> ppp src / server / server . cpp <nl> std :: string server :: process_command ( const std :: string & query ) { <nl> } else if ( command == " status ") { <nl> out << " STATUS REPORT \ n "; <nl> for ( player_map :: const_iterator pl = players_ . begin (); pl != players_ . end (); ++ pl ) { <nl> - if ( parameters == "" || utils :: wildcard_string_match ( pl -> second . name (), parameters )) { <nl> + if ( parameters == "" <nl> + || utils :: wildcard_string_match ( pl -> second . name (), parameters ) <nl> + || utils :: wildcard_string_match ( network :: ip_address ( pl -> first ), parameters )) { <nl> const network :: connection_stats & stats = network :: get_connection_stats ( pl -> first ); <nl> const int time_connected = stats . time_connected / 1000 ; <nl> const int seconds = time_connected % 60 ; <nl> std :: string server :: process_command ( const std :: string & query ) { <nl> } else { <nl> out << " Command '" << command << "' is not recognized .\ n "; <nl> out << " Available commands are : ( lobby ) msg < message >, motd [< message >]" <nl> - ", status [< nickmask >], metrics , ( k ) ban ( s ) [< mask >], unban < ipmask >" <nl> + ", status [< mask >], metrics , ( k ) ban ( s ) [< mask >], unban < ipmask >" <nl> ", kick < mask >"; <nl> } <nl> 
mmm src / image_modifications . cpp <nl> ppp src / image_modifications . cpp <nl> surface rotate_modification :: operator ()( const surface & src ) const <nl> case 180 : return rotate_180_surface ( src ); <nl> case 270 : return rotate_90_surface ( src , false ); <nl> case 360 : return src ; <nl> - default : return rotate_any_surface ( src , normalized , zoom_ , offset_ ); <nl> } <nl>  <nl> - // Other values are not supported . Ignore them . <nl> - return src ; <nl> + return rotate_any_surface ( src , normalized , zoom_ , offset_ ); <nl> } <nl>  <nl> surface gs_modification :: operator ()( const surface & src ) const <nl> REGISTER_MOD_PARSER ( ROTATE , args ) <nl> lexical_cast_default < int >( slice_params [ 1 ]), <nl> lexical_cast_default < int >( slice_params [ 2 ])); <nl> break ; <nl> - default : <nl> - return NULL ; <nl> - break ; <nl> } <nl> return NULL ; <nl> }
mmm src / chat_events . cpp <nl> ppp src / chat_events . cpp <nl> void chat_handler :: send_command ( const std :: string & cmd , const std :: string & args <nl> else if ( cmd == " ping ") { <nl> data [ cmd ] = std :: to_string ( time ( nullptr )); <nl> } <nl> - else if ( cmd == " green ") { <nl> - data . add_child (" query ")[" type "] = " lobbymsg @" + args ; <nl> - } <nl> - else if ( cmd == " red ") { <nl> - data . add_child (" query ")[" type "] = " lobbymsg #" + args ; <nl> - } <nl> - else if ( cmd == " yellow ") { <nl> - data . add_child (" query ")[" type "] = " lobbymsg < 255 , 255 , 0 >" + args ; <nl> - } <nl> else if ( cmd == " report ") { <nl> data . add_child (" query ")[" type "] = " report " + args ; <nl> }mmm src / chat_command_handler . hpp <nl> ppp src / chat_command_handler . hpp <nl> void chat_handler :: send_command ( const std :: string & cmd , const std :: string & args <nl> else if ( cmd == " ping ") { <nl> data [ cmd ] = std :: to_string ( time ( nullptr )); <nl> } <nl> - else if ( cmd == " green ") { <nl> - data . add_child (" query ")[" type "] = " lobbymsg @" + args ; <nl> - } <nl> - else if ( cmd == " red ") { <nl> - data . add_child (" query ")[" type "] = " lobbymsg #" + args ; <nl> - } <nl> - else if ( cmd == " yellow ") { <nl> - data . add_child (" query ")[" type "] = " lobbymsg < 255 , 255 , 0 >" + args ; <nl> - } <nl> else if ( cmd == " report ") { <nl> data . add_child (" query ")[" type "] = " report " + args ; <nl> } <nl> protected : <nl> _ (" Mute / Unmute all observers . ( toggles )"), ""); <nl> register_command (" ping ", & chat_command_handler :: do_network_send , <nl> ""); <nl> - register_command (" green ", & chat_command_handler :: do_network_send_req_arg , <nl> - "", "", " A "); <nl> - register_command (" red ", & chat_command_handler :: do_network_send_req_arg , <nl> - "", "", " A "); <nl> - register_command (" yellow ", & chat_command_handler :: do_network_send_req_arg , <nl> - "", "", " A "); <nl> register_command (" report ", & chat_command_handler :: do_network_send_req_arg , <nl> _ (" Report abuse , rule violations , etc . to the server moderators . " <nl> " Make sure to mention relevant nicknames , etc ."), "");
mmm src / widgets / textbox . cpp <nl> ppp src / widgets / textbox . cpp <nl> void textbox :: set_text ( std :: string text ) <nl> { <nl> text_ = string_to_wstring ( text ); <nl> cursor_ = text_ . size (); <nl> + selstart_ = - 1 ; <nl> + selend_ = - 1 ; <nl> set_dirty ( true ); <nl> update_text_cache ( true ); <nl> } <nl> void textbox :: clear () <nl> cursor_ = 0 ; <nl> cursor_pos_ = 0 ; <nl> text_pos_ = 0 ; <nl> + selstart_ = - 1 ; <nl> + selend_ = - 1 ; <nl> set_dirty ( true ); <nl> update_text_cache ( true ); <nl> }
mmm src / campaign_server / campaign_server . cpp <nl> ppp src / campaign_server / campaign_server . cpp <nl> namespace { <nl>  <nl> // Copy over COPYING . txt <nl> std :: string contents = read_file (" COPYING . txt "); <nl> - config & copying = dir . add_child (" file "); <nl> - copying [" name "] = " COPYING . txt "; <nl> - copying [" contents "] = contents ; <nl> - <nl> if ( contents . empty ()) { <nl> LOG_CS << " Could not find COPYING . txt , path is \"" <nl> << game_config :: path << "\"\ n "; <nl> + return ; <nl> } <nl> + config & copying = dir . add_child (" file "); <nl> + copying [" name "] = " COPYING . txt "; <nl> + copying [" contents "] = contents ; <nl> + <nl> } <nl> void campaign_server :: convert_binary_to_gzip () <nl> {
mmm src / actions . cpp <nl> ppp src / actions . cpp <nl> bool can_recruit_on ( const gamemap & map , const map_location & leader , const map_lo <nl> if (! map . is_castle ( loc )) <nl> return false ; <nl>  <nl> + if (! map . is_keep ( leader )) <nl> + return false ; <nl> + <nl> castle_cost_calculator calc ( map ); <nl> // The limit computed in the third argument is more than enough for <nl> // any convex castle on the map . Strictly speaking it could be
mmm src / gui / dialogs / lobby / lobby . cpp <nl> ppp src / gui / dialogs / lobby / lobby . cpp <nl> tlobby_main :: tlobby_main ( const config & game_config , <nl> { <nl> // Need to set this in the constructor , pre_show () is too late <nl> set_show_even_without_video ( true ); <nl> + set_allow_plugin_skip ( false ); <nl> } <nl>  <nl> struct lobby_delay_gamelist_update_guard <nl> void tlobby_main :: pre_show ( twindow & window ) <nl> game_config :: lobby_network_timer , std :: bind (& tlobby_main :: network_handler , this ), true ); <nl>  <nl> // Set up Lua plugin context <nl> - set_allow_plugin_skip ( false ); <nl> plugins_context_ . reset ( new plugins_context (" Multiplayer Lobby ")); <nl>  <nl> plugins_context_ -> set_callback (" join ", [&, this ]( const config &) {mmm src / gui / dialogs / multiplayer / mp_create_game . cpp <nl> ppp src / gui / dialogs / multiplayer / mp_create_game . cpp <nl> tlobby_main :: tlobby_main ( const config & game_config , <nl> { <nl> // Need to set this in the constructor , pre_show () is too late <nl> set_show_even_without_video ( true ); <nl> + set_allow_plugin_skip ( false ); <nl> } <nl>  <nl> struct lobby_delay_gamelist_update_guard <nl> void tlobby_main :: pre_show ( twindow & window ) <nl> game_config :: lobby_network_timer , std :: bind (& tlobby_main :: network_handler , this ), true ); <nl>  <nl> // Set up Lua plugin context <nl> - set_allow_plugin_skip ( false ); <nl> plugins_context_ . reset ( new plugins_context (" Multiplayer Lobby ")); <nl>  <nl> plugins_context_ -> set_callback (" join ", [&, this ]( const config &) { <nl> tmp_create_game :: tmp_create_game ( const config & cfg , ng :: create_engine & create_en <nl>  <nl> create_engine_ . get_state () = saved_game (); <nl> create_engine_ . get_state (). classification (). campaign_type = game_classification :: CAMPAIGN_TYPE :: MULTIPLAYER ; <nl> + <nl> + // Need to set this in the constructor , pre_show () is too late <nl> + set_allow_plugin_skip ( false ); <nl> } <nl>  <nl> void tmp_create_game :: pre_show ( twindow & window ) <nl> void tmp_create_game :: pre_show ( twindow & window ) <nl> // <nl> // Set up the Lua plugin context <nl> // <nl> - set_allow_plugin_skip ( false ); <nl> plugins_context_ . reset ( new plugins_context (" Multiplayer Create ")); <nl>  <nl> plugins_context_ -> set_callback (" create ", [& window ]( const config &) { window . set_retval ( twindow :: OK ); }, false );mmm src / gui / dialogs / title_screen . cpp <nl> ppp src / gui / dialogs / title_screen . cpp <nl> tlobby_main :: tlobby_main ( const config & game_config , <nl> { <nl> // Need to set this in the constructor , pre_show () is too late <nl> set_show_even_without_video ( true ); <nl> + set_allow_plugin_skip ( false ); <nl> } <nl>  <nl> struct lobby_delay_gamelist_update_guard <nl> void tlobby_main :: pre_show ( twindow & window ) <nl> game_config :: lobby_network_timer , std :: bind (& tlobby_main :: network_handler , this ), true ); <nl>  <nl> // Set up Lua plugin context <nl> - set_allow_plugin_skip ( false ); <nl> plugins_context_ . reset ( new plugins_context (" Multiplayer Lobby ")); <nl>  <nl> plugins_context_ -> set_callback (" join ", [&, this ]( const config &) { <nl> tmp_create_game :: tmp_create_game ( const config & cfg , ng :: create_engine & create_en <nl>  <nl> create_engine_ . get_state () = saved_game (); <nl> create_engine_ . get_state (). classification (). campaign_type = game_classification :: CAMPAIGN_TYPE :: MULTIPLAYER ; <nl> + <nl> + // Need to set this in the constructor , pre_show () is too late <nl> + set_allow_plugin_skip ( false ); <nl> } <nl>  <nl> void tmp_create_game :: pre_show ( twindow & window ) <nl> void tmp_create_game :: pre_show ( twindow & window ) <nl> // <nl> // Set up the Lua plugin context <nl> // <nl> - set_allow_plugin_skip ( false ); <nl> plugins_context_ . reset ( new plugins_context (" Multiplayer Create ")); <nl>  <nl> plugins_context_ -> set_callback (" create ", [& window ]( const config &) { window . set_retval ( twindow :: OK ); }, false ); <nl> void ttitle_screen :: basic_callback ( twindow & window , tresult res ) <nl>  <nl> ttitle_screen :: ttitle_screen ( game_launcher & game ) : result_ ( REDRAW_BACKGROUND ), game_ ( game ), debug_clock_ ( nullptr ) <nl> { <nl> + // Need to set this in the constructor , pre_show () / post_build () is too late <nl> + set_allow_plugin_skip ( false ); <nl> } <nl>  <nl> ttitle_screen ::~ ttitle_screen () <nl> debug_tooltip ( twindow & window , bool & handled , const tpoint & coordinate ) <nl> void ttitle_screen :: pre_show ( twindow & window ) <nl> { <nl> set_restore ( false ); <nl> - set_allow_plugin_skip ( false ); <nl> window . set_click_dismiss ( false ); <nl> window . set_enter_disabled ( true ); <nl> window . set_escape_disabled ( true );
mmm src / actions . cpp <nl> ppp src / actions . cpp <nl> void calculate_healing ( display & disp , const gamemap & map , <nl>  <nl> int pos_max = i -> second . max_hitpoints () - i -> second . hitpoints (); <nl> int neg_max = -( i -> second . hitpoints () - 1 ); <nl> + if ( healing > 0 && pos_max <= 0 ) { <nl> + // Do not try to " heal " if HP >= max HP <nl> + continue ; <nl> + } <nl> if ( healing > pos_max ) { <nl> healing = pos_max ; <nl> } else if ( healing < neg_max ) {
mmm src / game_events . cpp <nl> ppp src / game_events . cpp <nl> bool event_handler :: handle_event_command ( const queued_event & event_info , <nl> const int side = lexical_cast_default < int >( side_str . value (), - 1 ); <nl>  <nl> // Select advancement if it is on the playing side and the player is a human <nl> - const bool sel = ( side == u . side () && (* teams )[ side - 1 ]. is_human ()); <nl> + const bool sel = ( side == static_cast < int >( u . side ()) <nl> + && (* teams )[ side - 1 ]. is_human ()); <nl>  <nl> // The code in dialogs :: advance_unit tests whether the unit can advance <nl> dialogs :: advance_unit (* game_data_ptr , * game_map , * units , loc , * screen , ! sel , true );
mmm src / terrain_filter . cpp <nl> ppp src / terrain_filter . cpp <nl> namespace { <nl> bool terrain_matches_filter ( const gamemap & map , const gamemap :: location & loc , const vconfig & cfg , <nl> const gamestatus & game_status , const unit_map & units , const bool flat_tod , <nl> const size_t max_loop ) <nl> -{ <nl> +{ <nl> + if (! map . on_board ( loc )) return false ; <nl> + <nl> // handle radius <nl> const size_t radius = minimum < size_t >( max_loop , <nl> lexical_cast_default < size_t >( cfg [" radius "], 0 ));
mmm src / image . cpp <nl> ppp src / image . cpp <nl> static void precache_file_existence_internal ( const std :: string & dir , const std :: <nl> return ; <nl> precached_dirs . insert ( checked_dir ); <nl>  <nl> + if (! filesystem :: is_directory ( checked_dir )) <nl> + return ; <nl> + <nl> std :: vector < std :: string > files_found ; <nl> std :: vector < std :: string > dirs_found ; <nl> filesystem :: get_files_in_dir ( checked_dir , & files_found , & dirs_found ,
mmm src / savegame . cpp <nl> ppp src / savegame . cpp <nl> # include " foreach . hpp " <nl> # include " game_end_exceptions . hpp " <nl> # include " game_events . hpp " <nl> -# include " game_preferences . hpp " // FIXME : get rid of this one <nl> # include " gettext . hpp " <nl> # include " gui / dialogs / game_save . hpp " <nl> # include " gui / widgets / window . hpp " <nl> bool savegame :: save_game_interactive ( display & gui , const std :: string & message , <nl> } <nl>  <nl> std :: string filename = filename_ ; <nl> - if ( res == gui2 :: twindow :: OK && savegame_manager :: save_game_exists ( filename , preferences :: compress_saves ())) { <nl> + if ( res == gui2 :: twindow :: OK && savegame_manager :: save_game_exists ( filename , compress_saves_ )) { <nl> std :: stringstream s ; <nl> s << _ (" Save already exists . Do you want to overwrite it ?") <nl> << std :: endl << _ (" Name : ") << filename ;
mmm src / hotkey / hotkey_command . cpp <nl> ppp src / hotkey / hotkey_command . cpp <nl> hotkey :: hotkey_command_temp hotkey_list_ [] = { <nl> { hotkey :: HOTKEY_CLEAR_MSG , " clearmessages ", N_ (" Clear Messages "), false , hotkey :: SCOPE_GAME , "" }, <nl>  <nl> { hotkey :: HOTKEY_LANGUAGE , " changelanguage ", N_ (" Change Language "), false , hotkey :: SCOPE_MAIN_MENU , "" }, <nl> - { hotkey :: TITLE_SCREEN__RELOAD_WML , " title_screen__reload_wml ", N_ (" Refresh WML "), true , hotkey :: SCOPE_MAIN_MENU , "" }, <nl> + { hotkey :: TITLE_SCREEN__RELOAD_WML , " title_screen__reload_wml ", N_ (" Refresh WML "), true , hotkey :: SCOPE_GENERAL , "" }, <nl> { hotkey :: TITLE_SCREEN__NEXT_TIP , " title_screen__next_tip ", N_ (" Next Tip of the Day "), false , hotkey :: SCOPE_MAIN_MENU , "" }, <nl> { hotkey :: TITLE_SCREEN__PREVIOUS_TIP , " title_screen__previous_tip ", N_ (" Previous Tip of the Day "), false , hotkey :: SCOPE_MAIN_MENU , "" }, <nl> { hotkey :: TITLE_SCREEN__TUTORIAL , " title_screen__tutorial ", N_ (" Start Tutorial "), false , hotkey :: SCOPE_MAIN_MENU , "" },
mmm src / gui / dialogs / network_transmission . cpp <nl> ppp src / gui / dialogs / network_transmission . cpp <nl> void tnetwork_transmission :: pump_monitor :: process ( events :: pump_info &) <nl> window_ . get (). set_retval ( twindow :: OK ); <nl> } else { <nl> if ( connection_ . bytes_to_read ()) { <nl> - size_t total = connection_ . bytes_to_read (). get (); <nl> + size_t total = connection_ . bytes_to_read (); <nl> size_t completed = connection_ . bytes_read (); <nl> find_widget < tprogress_bar >(&( window_ . get ()), " progress ", false ) <nl> . set_percentage (( completed * 100 )/ total );mmm src / network_asio . cpp <nl> ppp src / network_asio . cpp <nl> void tnetwork_transmission :: pump_monitor :: process ( events :: pump_info &) <nl> window_ . get (). set_retval ( twindow :: OK ); <nl> } else { <nl> if ( connection_ . bytes_to_read ()) { <nl> - size_t total = connection_ . bytes_to_read (). get (); <nl> + size_t total = connection_ . bytes_to_read (); <nl> size_t completed = connection_ . bytes_read (); <nl> find_widget < tprogress_bar >(&( window_ . get ()), " progress ", false ) <nl> . set_percentage (( completed * 100 )/ total ); <nl> connection :: connection ( const std :: string & host , const std :: string & service ) <nl> , write_buf_ () <nl> , read_buf_ () <nl> , handshake_response_ () <nl> - , bytes_to_read_ () <nl> + , bytes_to_read_ ( 0 ) <nl> , bytes_read_ ( 0 ) <nl> { <nl> resolver_ . async_resolve ( <nl> std :: size_t connection :: is_read_complete ( <nl> bytes_to_read_ = ntohl ( data_size . num ) + 4 ; <nl> } <nl> # if BOOST_VERSION >= 103700 <nl> - return bytes_to_read_ . get () - bytes_transferred ; <nl> + return bytes_to_read_ - bytes_transferred ; <nl> # else <nl> - return bytes_to_read_ . get () == bytes_transferred ; <nl> + return bytes_to_read_ == bytes_transferred ; <nl> # endif <nl> } <nl> } <nl> void connection :: handle_read ( <nl> ) <nl> { <nl> std :: cout << " Read " << bytes_transferred << " bytes .\ n "; <nl> - bytes_to_read_ . reset (); <nl> + bytes_to_read_ = 0 ; <nl> done_ = true ; <nl> if ( ec && ec != boost :: asio :: error :: eof ) <nl> throw error ( ec );mmm src / network_asio . hpp <nl> ppp src / network_asio . hpp <nl> void tnetwork_transmission :: pump_monitor :: process ( events :: pump_info &) <nl> window_ . get (). set_retval ( twindow :: OK ); <nl> } else { <nl> if ( connection_ . bytes_to_read ()) { <nl> - size_t total = connection_ . bytes_to_read (). get (); <nl> + size_t total = connection_ . bytes_to_read (); <nl> size_t completed = connection_ . bytes_read (); <nl> find_widget < tprogress_bar >(&( window_ . get ()), " progress ", false ) <nl> . set_percentage (( completed * 100 )/ total ); <nl> connection :: connection ( const std :: string & host , const std :: string & service ) <nl> , write_buf_ () <nl> , read_buf_ () <nl> , handshake_response_ () <nl> - , bytes_to_read_ () <nl> + , bytes_to_read_ ( 0 ) <nl> , bytes_read_ ( 0 ) <nl> { <nl> resolver_ . async_resolve ( <nl> std :: size_t connection :: is_read_complete ( <nl> bytes_to_read_ = ntohl ( data_size . num ) + 4 ; <nl> } <nl> # if BOOST_VERSION >= 103700 <nl> - return bytes_to_read_ . get () - bytes_transferred ; <nl> + return bytes_to_read_ - bytes_transferred ; <nl> # else <nl> - return bytes_to_read_ . get () == bytes_transferred ; <nl> + return bytes_to_read_ == bytes_transferred ; <nl> # endif <nl> } <nl> } <nl> void connection :: handle_read ( <nl> ) <nl> { <nl> std :: cout << " Read " << bytes_transferred << " bytes .\ n "; <nl> - bytes_to_read_ . reset (); <nl> + bytes_to_read_ = 0 ; <nl> done_ = true ; <nl> if ( ec && ec != boost :: asio :: error :: eof ) <nl> throw error ( ec ); <nl> class connection <nl> std :: size_t bytes_transferred , <nl> config & response <nl> ); <nl> - boost :: optional < std :: size_t > bytes_to_read_ ; <nl> + std :: size_t bytes_to_read_ ; <nl> std :: size_t bytes_read_ ; <nl>  <nl> public : <nl> class connection <nl> /** True if connected and no high - level operation is in progress */ <nl> bool done () const { return done_ ; } <nl>  <nl> - const boost :: optional < std :: size_t >& bytes_to_read () const <nl> + std :: size_t bytes_to_read () const <nl> { <nl> return bytes_to_read_ ; <nl> }
mmm src / filesystem_boost . cpp <nl> ppp src / filesystem_boost . cpp <nl> static bool is_legal_file ( const std :: string & filename ) <nl> return false ; <nl> } <nl>  <nl> - if ( ends_with ( filename , ". pbl ")) { <nl> + if ( looks_like_pbl ( filename )) { <nl> ERR_FS << " Illegal path '" << filename << "' (. pbl files are not allowed )." << std :: endl ; <nl> return false ; <nl> }mmm src / filesystem . cpp <nl> ppp src / filesystem . cpp <nl> static bool is_legal_file ( const std :: string & filename ) <nl> return false ; <nl> } <nl>  <nl> - if ( ends_with ( filename , ". pbl ")) { <nl> + if ( looks_like_pbl ( filename )) { <nl> ERR_FS << " Illegal path '" << filename << "' (. pbl files are not allowed )." << std :: endl ; <nl> return false ; <nl> } <nl> std :: string get_wml_location ( const std :: string & filename , const std :: string & cur <nl> return result ; <nl> } <nl>  <nl> - if ( ends_with ( filename , ". pbl ")) { <nl> + if ( looks_like_pbl ( filename )) { <nl> ERR_FS << " Illegal path '" << filename << "' (. pbl files are not allowed )." << std :: endl ; <nl> return result ; <nl> }
mmm src / formula_ai . cpp <nl> ppp src / formula_ai . cpp <nl> public : <nl> class fallback_function : public function_expression { <nl> public : <nl> explicit fallback_function ( const args_list & args ) <nl> - : function_expression (" fallback ", args , 1 , 1 ) <nl> + : function_expression (" fallback ", args , 0 , 1 ) <nl> {} <nl> private : <nl> variant execute ( const formula_callable & variables ) const { <nl> + if ( args (). size () == 0 ) <nl> + return variant ( new fallback_callable ("")); <nl> return variant ( new fallback_callable ( args ()[ 0 ]-> evaluate ( variables ). as_string ())); <nl> } <nl> };
mmm src / playlevel . cpp <nl> ppp src / playlevel . cpp <nl> redo_turn : <nl> info [" type "] = " termination "; <nl> info [" condition "] = " game over "; <nl> network :: send_data ( cfg ); <nl> - } else <nl> + } else { <nl> gui :: show_dialog ( gui , NULL , _ (" Game Over "), <nl> _ (" The game is over ."), gui :: OK_ONLY ); <nl> + return QUIT ; <nl> + } <nl> } <nl>  <nl> if ( end_level . result == QUIT ) {
mmm src / pathfind . cpp <nl> ppp src / pathfind . cpp <nl> static void find_routes ( const gamemap & map , const unit_map & units , <nl> if ( old_move_left >= new_turns_moves + new_move_left ) <nl> continue ; <nl>  <nl> + paths :: route & src_route = routes [ loc ]; <nl> + <nl> if (! ignore_units ) { <nl> // we can not traverse enemies <nl> const unit_map :: const_iterator unit_it = <nl> static void find_routes ( const gamemap & map , const unit_map & units , <nl> && enemy_zoc ( map , units , teams , currentloc , viewing_team , u . side (), see_all ) <nl> && ! u . get_ability_bool (" skirmisher ", currentloc )) { <nl> new_move_left = 0 ; <nl> - // Recheck if we already have a better route , but now with the ZoC effect <nl> - if ( old_move_left >= new_turns_moves + 0 ) <nl> + // Recheck if we already have a better route , but now with the ZoC effect . <nl> + // Since the ZOC is cancelling the remaining move points , the game cannot <nl> + // notice a difference between a short and a long path . So check the path <nl> + // length too in case of equality . <nl> + if ( old_move_left > new_turns_moves + 0 || <nl> + ( old_move_left == new_turns_moves + 0 && <nl> + old_rt -> second . steps . size () <= src_route . steps . size () + 1 )) <nl> continue ; <nl> } <nl> } <nl>  <nl> - paths :: route & src_route = routes [ loc ]; <nl> paths :: route & new_route = routes [ currentloc ]; <nl> new_route . steps = src_route . steps ; <nl> new_route . steps . push_back ( loc );
mmm src / sdl / surface . hpp <nl> ppp src / sdl / surface . hpp <nl> public : <nl> return * this ; <nl> } <nl>  <nl> + // Intended to be used when SDL has already freed the surface <nl> + void clear_without_free () { surface_ = nullptr ; } <nl> + <nl> operator SDL_Surface *() const { return surface_ ; } <nl>  <nl> SDL_Surface * get () const { return surface_ ; }mmm src / video . cpp <nl> ppp src / video . cpp <nl> public : <nl> return * this ; <nl> } <nl>  <nl> + // Intended to be used when SDL has already freed the surface <nl> + void clear_without_free () { surface_ = nullptr ; } <nl> + <nl> operator SDL_Surface *() const { return surface_ ; } <nl>  <nl> SDL_Surface * get () const { return surface_ ; } <nl> void CVideo :: update_framebuffer () <nl> if (! frameBuffer ) { <nl> frameBuffer = fb ; <nl> } else { <nl> + // Because SDL has already freed the old framebuffer , <nl> + // ensure that we won ' t attempt to free it . <nl> + frameBuffer . clear_without_free (); <nl> frameBuffer . assign ( fb ); <nl> } <nl> }
mmm src / unit_display . cpp <nl> ppp src / unit_display . cpp <nl> void unit_attack ( <nl> int damage_left = damage ; <nl> while ( damage_left > 0 && ! animator . would_end ()) { <nl> int step_left = ( animator . get_end_time () - animator . get_animation_time () )/ 50 ; <nl> - int removed_hp = damage_left / step_left ; <nl> + int removed_hp = step_left ? damage_left / step_left : 1 ; <nl> if ( removed_hp < 1 ) removed_hp = 1 ; <nl> if ( step_left < 1 ) step_left = 1 ; <nl> defender . take_hit ( removed_hp );
mmm src / mouse_events . cpp <nl> ppp src / mouse_events . cpp <nl> paths :: route mouse_handler :: get_route ( unit_map :: const_iterator un , map_location <nl>  <nl> void mouse_handler :: mouse_press ( const SDL_MouseButtonEvent & event , const bool browse ) <nl> { <nl> - if ( attackmove_ ) return ; <nl> mouse_handler_base :: mouse_press ( event , browse ); <nl> } <nl>  <nl> bool mouse_handler :: left_click ( int x , int y , const bool browse ) <nl>  <nl> gui (). unhighlight_reach (); <nl> move_unit_along_current_route ( check_shroud ); <nl> - } else { <nl> + } else if (! attackmove_ ) { <nl> + // we block selection during attack + move ( because motion is blocked ) <nl> + // FIXME : deal with selected event when commands_disabled <nl> // we select a ( maybe empty ) hex <nl> select_hex ( hex , browse ); <nl> }
mmm src / network_worker . cpp <nl> ppp src / network_worker . cpp <nl> SOCKET_STATE receive_buf ( TCPsocket sock , std :: vector < char >& buf ) <nl> } <nl> } <nl>  <nl> - const ssize_t res = SDLNet_TCP_Recv ( sock , beg , end - beg ); <nl> + const int res = SDLNet_TCP_Recv ( sock , beg , end - beg ); <nl> if ( res <= 0 ) { <nl> if ( SDLNet_CheckSockets ( set , 15000 ) <= 0 ) { <nl> ERR_NW << " SDLNet_CheckSockets : " << strerror ( errno ) << "\ n ";
mmm src / network_worker . cpp <nl> ppp src / network_worker . cpp <nl> manager ::~ manager () <nl> cond [ shard ]-> notify_all (); <nl>  <nl> for ( std :: map < Uint32 , threading :: thread *>:: const_iterator i = threads [ shard ]. begin (); i != threads [ shard ]. end (); ++ i ) { <nl> + <nl> DBG_NW << " waiting for thread " << i -> first << " to exit ...\ n "; <nl> delete i -> second ; <nl> DBG_NW << " thread exited ...\ n "; <nl> manager ::~ manager () <nl> // will access memory already freed by way of <nl> // stale mutex . Bad things will follow . ;) <nl> threads [ shard ]. clear (); <nl> + // Have to clean up to_clear so no bogus clearing of threads <nl> + to_clear [ shard ]. clear (); <nl> delete cond [ shard ]; <nl> cond [ shard ] = NULL ; <nl> delete shard_mutexes [ shard ];
mmm src / image . cpp <nl> ppp src / image . cpp <nl> surface locator :: load_image_sub_file () const <nl> } <nl> } <nl> else { <nl> - // Deprecated 1 . 6 palette switch syntax <nl> + ///@ Deprecated 1 . 6 palette switch syntax <nl> if ( field . find ('=') != std :: string :: npos ) { <nl> lg :: wml_error << " the ~ RC () image function cannot be used for palette switch ( A = B ) in 1 . 7 . x ; use ~ PAL ( A > B ) instead \ n "; <nl> }
mmm src / menu_events . cpp <nl> ppp src / menu_events . cpp <nl> void console_handler :: do_set_var () { <nl> } <nl> } <nl> void console_handler :: do_show_var () { <nl> - gui2 :: show_transient_message ((* menu_handler_ . gui_ ). video (),"", resources :: gamedata -> get_variable ( get_data ())); <nl> + gui2 :: show_transient_message ((* menu_handler_ . gui_ ). video (),"", resources :: gamedata -> get_variable_const ( get_data ())); <nl> } <nl>  <nl> 
mmm src / actions / attack . cpp <nl> ppp src / actions / attack . cpp <nl> int battle_context :: choose_attacker_weapon ( const unit & attacker , <nl> attacker_combatant_ = new combatant (* attacker_stats_ ); <nl> defender_combatant_ = new combatant (* defender_stats_ , prev_def ); <nl> attacker_combatant_ -> fight (* defender_combatant_ ); <nl> + } else { <nl> + if ( attacker_stats_ -> disable ) { <nl> + delete attacker_stats_ ; <nl> + attacker_stats_ = nullptr ; <nl> + continue ; <nl> + } <nl> } <nl> if (! best_att_comb || better_combat (* attacker_combatant_ , * defender_combatant_ , <nl> * best_att_comb , * best_def_comb , harm_weight )) {
mmm src / multiplayer_lobby . cpp <nl> ppp src / multiplayer_lobby . cpp <nl> void gamebrowser :: draw_row ( const size_t index , const SDL_Rect & item_rect , ROW_TY <nl> xpos += vision_icon -> w + h_padding_ ; <nl>  <nl> const surface status_text ( font :: get_rendered_text ( game . status , font :: SIZE_NORMAL , font_color )); <nl> - const surface vision_text ( font :: get_rendered_text ( font :: make_text_ellipsis ( game . vision , font :: SIZE_NORMAL , maximum < int >(( item_rect . x + item_rect . w - margin_ - status_text -> w - 2 * h_padding_ ) - xpos , 0 )), font :: SIZE_NORMAL , font :: NORMAL_COLOUR )); <nl> + <nl> + const int status_text_width = status_text ? status_text -> w : 0 ; <nl> + const surface vision_text ( font :: get_rendered_text ( font :: make_text_ellipsis ( game . vision , font :: SIZE_NORMAL , maximum < int >(( item_rect . x + item_rect . w - margin_ - status_text_width - 2 * h_padding_ ) - xpos , 0 )), font :: SIZE_NORMAL , font :: NORMAL_COLOUR )); <nl> // draw vision text <nl> video (). blit_surface ( xpos , ypos , vision_text ); <nl>  <nl> // draw status text <nl> - xpos = item_rect . x + item_rect . w - margin_ - status_text -> w ; <nl> - video (). blit_surface ( xpos , ypos , status_text ); <nl> + xpos = item_rect . x + item_rect . w - margin_ - status_text_width ; <nl> + if ( status_text ) { <nl> + video (). blit_surface ( xpos , ypos , status_text ); <nl> + } <nl>  <nl> // if ( selected_ == index ) <nl> // draw_solid_tinted_rectangle ( item_rect . x , item_rect . y , item_rect . w , item_rect . h , 153 , 0 , 0 , 0 . 3 , video (). getSurface ());
mmm src / gui / widgets / scrollbar_container . cpp <nl> ppp src / gui / widgets / scrollbar_container . cpp <nl> static void set_scrollbar_mode ( tgrid * scrollbar_grid , tscrollbar_ * scrollbar , <nl> return ; <nl> } <nl>  <nl> - <nl> scrollbar -> set_item_count ( items ); <nl> + scrollbar -> set_item_position ( 0 ); <nl> scrollbar -> set_visible_items ( visible_items ); <nl>  <nl> if ( scrollbar_mode == tscrollbar_container :: auto_visible ) {
mmm src / gui / widgets / widget . cpp <nl> ppp src / gui / widgets / widget . cpp <nl> void widget :: set_visible ( const visibility visible ) <nl> visible_ = visible ; <nl>  <nl> if ( need_resize ) { <nl> - if ( new_widgets ) { <nl> + if ( visible == visibility :: visible && new_widgets ) { <nl> event :: message message ; <nl> fire ( event :: REQUEST_PLACEMENT , * this , message ); <nl> } else {
mmm src / mouse_handler_base . hpp <nl> ppp src / mouse_handler_base . hpp <nl> public : <nl> * @ returns true when the click should not process the event further . <nl> * This means do not treat the call as a start of drag movement . <nl> */ <nl> - virtual bool right_click ( int /* x */, int /* y */, const bool /* browse */) <nl> + virtual bool right_click ( int x , int y , const bool browse ) <nl> { <nl> - return true ; <nl> + return right_click_show_menu ( x , y , browse ); <nl> } <nl>  <nl> /**
mmm src / upload_log . cpp <nl> ppp src / upload_log . cpp <nl> upload_log ::~ upload_log () <nl> if ( game_finished ( game_ )) <nl> config_ . add_child (" game ", * game_ ); <nl>  <nl> + if ( game_ ) <nl> + delete game_ ; <nl> + <nl> if ( enabled_ && ! config_ . empty () && ! game_config :: debug ) { <nl> config_ [" version "] = VERSION ; <nl> config_ [" format_version "] = " 1 "; <nl> void upload_log :: start ( game_state & state , const team & team , <nl> if ( game_finished ( game_ )) <nl> config_ . add_child (" game ", * game_ ); <nl>  <nl> + <nl> + if ( game_ ) <nl> + delete game_ ; <nl> game_ = new config (); <nl> (* game_ )[" time "] = lexical_cast < std :: string >( SDL_GetTicks () / 1000 ); <nl> (* game_ )[" campaign "] = state . campaign_define ;
mmm src / image . cpp <nl> ppp src / image . cpp <nl> static bool localized_file_uptodate ( const std :: string & loc_file ) <nl> // First call , parse track index to collect fuzzy files by path . <nl> std :: string fsep = "\ xC2 \ xA6 "; // UTF - 8 for " broken bar " <nl> std :: string trackpath = filesystem :: get_binary_file_location ("", " l10n - track "); <nl> + <nl> + // l10n - track file not present . Assume image is up - to - date . <nl> + if ( trackpath . empty ()) { <nl> + return true ; <nl> + } <nl> + <nl> std :: string contents = filesystem :: read_file ( trackpath ); <nl>  <nl> for ( const std :: string & line : utils :: split ( contents , '\ n ')) {
mmm src / sdl / alpha . cpp <nl> ppp src / sdl / alpha . cpp <nl> int SDL_SetAlpha ( SDL_Surface * surface , Uint32 flag , Uint8 alpha ) <nl> { <nl> if ( flag & SDL_SRCALPHA ) { <nl> + // Need to specify the alpha blend mode if not setting alpha as opaque <nl> + int blendModeResult = SDL_SetSurfaceBlendMode ( surface , SDL_BLENDMODE_BLEND ); <nl> + if ( blendModeResult != 0 ) <nl> + return blendModeResult ; <nl> + <nl> return SDL_SetSurfaceAlphaMod ( surface , alpha ); <nl> } else { <nl> return SDL_SetSurfaceAlphaMod ( surface , SDL_ALPHA_OPAQUE );
mmm src / multiplayer_wait . cpp <nl> ppp src / multiplayer_wait . cpp <nl> void wait :: start_game () <nl>  <nl> LOG_NW << " starting game \ n "; <nl> sound :: play_UI_sound ( game_config :: sounds :: mp_game_begins ); <nl> + game_display :: get_singleton ()-> send_notification ( _ (" Wesnoth "), _ (" Game has begun !")); <nl> } <nl>  <nl> void wait :: layout_children ( const SDL_Rect & rect )
mmm src / unit_display . cpp <nl> ppp src / unit_display . cpp <nl> void unit_attack ( <nl> int swing , std :: string hit_text ) <nl> { <nl> game_display * disp = game_display :: get_singleton (); <nl> - if (! disp ) return ; <nl> + if (! disp || preferences :: show_combat () == false ) return ; <nl> unit_map & units = disp -> get_units (); <nl> disp -> select_hex ( gamemap :: location :: null_location ); <nl> - const bool hide = disp -> video (). update_locked () || disp -> fogged ( a ) && disp -> fogged ( b ) <nl> - || preferences :: show_combat () == false ; <nl> + const bool hide = disp -> video (). update_locked () || disp -> fogged ( a ) && disp -> fogged ( b ); <nl>  <nl> if (! hide ) { <nl> disp -> scroll_to_tiles ( a , b , game_display :: ONSCREEN ); <nl> void unit_attack ( <nl> } <nl> } <nl>  <nl> - <nl> - <nl> - <nl> - <nl> animator . start_animations (); <nl> animator . wait_for_end (); <nl> 
mmm src / hotkey / hotkey_command . cpp <nl> ppp src / hotkey / hotkey_command . cpp <nl> hotkey :: hotkey_command_temp hotkey_list_ [] = { <nl> // These are not really hotkey items but menu entries to get expanded . <nl> // They need to have their own hotkey to control their active state . <nl> { hotkey :: HOTKEY_EDITOR_PLAYLIST , " editor - playlist ", N_ (" Switch Time of Day "), true , scope_editor , "" }, <nl> + { hotkey :: HOTKEY_EDITOR_SCHEDULE , " menu - editor - schedule ", "", true , hotkey :: SCOPE_EDITOR , "" }, <nl> { hotkey :: HOTKEY_EDITOR_MAP_SWITCH , " editor - switch - map ", N_ (" Switch Map "), true , scope_editor , "" }, <nl> { hotkey :: HOTKEY_EDITOR_LOCAL_TIME , " menu - editor - local - time ", N_ (" Assign Local Time "), true , scope_editor , "" }, <nl> mmm src / editor / editor_controller . cpp <nl> ppp src / editor / editor_controller . cpp <nl> hotkey :: hotkey_command_temp hotkey_list_ [] = { <nl> // These are not really hotkey items but menu entries to get expanded . <nl> // They need to have their own hotkey to control their active state . <nl> { hotkey :: HOTKEY_EDITOR_PLAYLIST , " editor - playlist ", N_ (" Switch Time of Day "), true , scope_editor , "" }, <nl> + { hotkey :: HOTKEY_EDITOR_SCHEDULE , " menu - editor - schedule ", "", true , hotkey :: SCOPE_EDITOR , "" }, <nl> { hotkey :: HOTKEY_EDITOR_MAP_SWITCH , " editor - switch - map ", N_ (" Switch Map "), true , scope_editor , "" }, <nl> { hotkey :: HOTKEY_EDITOR_LOCAL_TIME , " menu - editor - local - time ", N_ (" Assign Local Time "), true , scope_editor , "" }, <nl>  <nl> bool editor_controller :: can_execute_command ( const hotkey :: hotkey_command & cmd , i <nl> std :: string dummy ; <nl> return context_manager_ -> modified_maps ( dummy ) > 1 ; <nl> } <nl> - case HOTKEY_EDITOR_MAP_SWITCH : <nl> case HOTKEY_EDITOR_PLAYLIST : <nl> + case HOTKEY_EDITOR_SCHEDULE : <nl> + return ! context_manager_ -> get_map_context (). is_pure_map (); <nl> + case HOTKEY_EDITOR_MAP_SWITCH : <nl> case HOTKEY_EDITOR_MAP_CLOSE : <nl> return true ; <nl> case HOTKEY_EDITOR_MAP_REVERT :mmm src / hotkey / hotkey_command . hpp <nl> ppp src / hotkey / hotkey_command . hpp <nl> hotkey :: hotkey_command_temp hotkey_list_ [] = { <nl> // These are not really hotkey items but menu entries to get expanded . <nl> // They need to have their own hotkey to control their active state . <nl> { hotkey :: HOTKEY_EDITOR_PLAYLIST , " editor - playlist ", N_ (" Switch Time of Day "), true , scope_editor , "" }, <nl> + { hotkey :: HOTKEY_EDITOR_SCHEDULE , " menu - editor - schedule ", "", true , hotkey :: SCOPE_EDITOR , "" }, <nl> { hotkey :: HOTKEY_EDITOR_MAP_SWITCH , " editor - switch - map ", N_ (" Switch Map "), true , scope_editor , "" }, <nl> { hotkey :: HOTKEY_EDITOR_LOCAL_TIME , " menu - editor - local - time ", N_ (" Assign Local Time "), true , scope_editor , "" }, <nl>  <nl> bool editor_controller :: can_execute_command ( const hotkey :: hotkey_command & cmd , i <nl> std :: string dummy ; <nl> return context_manager_ -> modified_maps ( dummy ) > 1 ; <nl> } <nl> - case HOTKEY_EDITOR_MAP_SWITCH : <nl> case HOTKEY_EDITOR_PLAYLIST : <nl> + case HOTKEY_EDITOR_SCHEDULE : <nl> + return ! context_manager_ -> get_map_context (). is_pure_map (); <nl> + case HOTKEY_EDITOR_MAP_SWITCH : <nl> case HOTKEY_EDITOR_MAP_CLOSE : <nl> return true ; <nl> case HOTKEY_EDITOR_MAP_REVERT : <nl> enum HOTKEY_COMMAND { <nl> HOTKEY_EDITOR_PALETTE_GROUPS , HOTKEY_EDITOR_PALETTE_UPSCROLL , HOTKEY_EDITOR_PALETTE_DOWNSCROLL , <nl>  <nl> HOTKEY_EDITOR_PLAYLIST , <nl> + HOTKEY_EDITOR_SCHEDULE , <nl> HOTKEY_EDITOR_LOCAL_TIME , <nl> HOTKEY_EDITOR_UNIT_FACING , <nl> 
mmm src / config_adapter . cpp <nl> ppp src / config_adapter . cpp <nl> void get_player_info ( const config & cfg , game_state & gamestate , std :: string save_ <nl> LOG_NG << " found gold : '" << gold << "'\ n "; <nl>  <nl> int ngold = lexical_cast_default < int >( gold ); <nl> - if ( player != NULL && player -> gold >= ngold ) { <nl> + if ( ( player != NULL && player -> gold >= ngold ) || snapshot ) { <nl> ngold = player -> gold ; <nl> } <nl> 
mmm src / team . cpp <nl> ppp src / team . cpp <nl> void team :: team_info :: write ( config & cfg ) const <nl> cfg [" hidden "] = hidden ; <nl> cfg [" suppress_end_turn_confirmation "] = no_turn_confirmation ; <nl> cfg [" scroll_to_leader "] = scroll_to_leader ; <nl> - cfg [" controller "] = controller_string (); <nl> + cfg [" controller "] = ( controller == IDLE ? " human " : controller_string ()); <nl>  <nl> std :: stringstream can_recruit_str ; <nl> for ( std :: set < std :: string >:: const_iterator cr = can_recruit . begin (); cr != can_recruit . end (); ++ cr ) {
mmm src / serialization / schema_validator . cpp <nl> ppp src / serialization / schema_validator . cpp <nl> std :: string at ( const std :: string & file , int line ){ <nl>  <nl> void extra_tag_error ( const std :: string & file , int line , <nl> const std :: string & name ){ <nl> - WRN_VL << at ( file , line ) << ": extra tag "<< name << "\ n "; <nl> + ERR_VL << at ( file , line ) << ": extra tag "<< name << "\ n "; <nl> } <nl> void wrong_tag_error ( const std :: string & file , int line , <nl> const std :: string & name ){ <nl> std :: ostringstream ss ; <nl> ss << at ( file , line ) << ": wrong tag "<< name << "\ n "; <nl> - WRN_VL << ss . str (); <nl> + ERR_VL << ss . str (); <nl> // throw twml_exception (" Validation error ", ss . str ()); <nl> } <nl> void missing_tag_error ( const std :: string & file , int line , <nl> const std :: string & name ){ <nl> - WRN_VL << at ( file , line ) << ": missing tag "<< name << "\ n "; <nl> + ERR_VL << at ( file , line ) << ": missing tag "<< name << "\ n "; <nl> } <nl> void extra_key_error ( const std :: string & file , int line , <nl> const std :: string & tag , const std :: string & key <nl> ){ <nl> - WRN_VL << at ( file , line ) << ": In tag "<< tag <nl> + ERR_VL << at ( file , line ) << ": In tag "<< tag <nl> << " which begins here , " << " key "<< key << " wasn ' t allowed \ n "; <nl> } <nl> void missing_key_error ( const std :: string & file , int line , <nl> const std :: string & tag , const std :: string & key <nl> ){ <nl> - WRN_VL << at ( file , line ) << ": In tag "<< tag <nl> + ERR_VL << at ( file , line ) << ": In tag "<< tag <nl> << " which begins here , " << " missing key "<< key << "\ n "; <nl> } <nl> void wrong_value_error ( const std :: string & file , int line , <nl> const std :: string & tag , const std :: string & key , <nl> const std :: string & value ){ <nl> - WRN_VL << at ( file , line ) << ": In tag "<< tag <nl> + ERR_VL << at ( file , line ) << ": In tag "<< tag <nl> << " which begins here , " << " key "<< key << " have wrong value " <nl> << value << "\ n "; <nl> }
mmm src / ai / default / ai . cpp <nl> ppp src / ai / default / ai . cpp <nl> bool ai_default_recruitment_stage :: recruit_usage ( const std :: string & usage ) <nl>  <nl> if ( imc != maximum_counts_ . end ()) { <nl> int count_active = 0 ; <nl> - for ( unit_map :: iterator u = get_info (). units . begin (); u != get_info (). units . end (); u ++) { <nl> + for ( unit_map :: iterator u = get_info (). units . begin (); u != get_info (). units . end (); ++ u ) { <nl> if (( u -> second . side ()== get_side ()) && (! u -> second . incapacitated ()) && ( u -> second . type_id () == name )) { <nl> - count_active ++; <nl> + ++ count_active ; <nl> } <nl> } <nl> 
mmm src / upload_log . cpp <nl> ppp src / upload_log . cpp <nl> void upload_log :: start ( game_state & state , const team & team , <nl> if ( uploader_settings :: new_uploader ) { <nl> // replace newlines in map definition with semicolons so that braindead server - side wml parser doesn ' t get confused <nl> std :: string encoded_map ( map_data ); <nl> - for ( int idx = 0 ; idx < encoded_map . length (); idx ++) { <nl> + for ( size_t idx = 0 ; idx < encoded_map . length (); idx ++) { <nl> if ( encoded_map [ idx ] == '\ n ') <nl> encoded_map [ idx ] = ';'; <nl> }
mmm src / gui / dialogs / drop_down_menu . cpp <nl> ppp src / gui / dialogs / drop_down_menu . cpp <nl> namespace <nl> */ <nl> grid * row_grid = list . get_row_grid ( list . get_selected_row ()); <nl> if ( toggle_button * checkbox = find_widget < toggle_button >( row_grid , " checkbox ", false , false )) { <nl> - checkbox -> set_value_bool (! checkbox -> get_value_bool ()); <nl> + checkbox -> set_value_bool (! checkbox -> get_value_bool (), true ); <nl> } <nl> } <nl> 
mmm src / gamestatus . cpp <nl> ppp src / gamestatus . cpp <nl> void game_state :: get_player_info ( const config & side_cfg , <nl> for ( std :: vector < unit >:: iterator it = player -> available_units . begin (); <nl> it != player -> available_units . end (); ++ it ) { <nl> if ( it -> can_recruit ()) { <nl> - new_unit = * it ; <nl> - new_unit . set_game_context (& units , & map , & tod_mng , & teams ); <nl> player -> available_units . erase ( it ); <nl> break ; <nl> } <nl> } <nl> + } <nl> + <nl> + if ( player_cfg != NULL ) { <nl> for ( std :: vector < unit >:: iterator it = teams . back (). recall_list (). begin (); <nl> it != teams . back (). recall_list (). end (); ++ it ) { <nl> if ( it -> can_recruit ()) { <nl> + new_unit = * it ; <nl> + new_unit . set_game_context (& units , & map , & tod_mng , & teams ); <nl> teams . back (). recall_list (). erase ( it ); <nl> break ; <nl> }
mmm src / display . cpp <nl> ppp src / display . cpp <nl> # include " units / drawer . hpp " <nl> # include " whiteboard / manager . hpp " <nl> # include " show_dialog . hpp " <nl> +# include " gui / dialogs / loadscreen . hpp " <nl>  <nl> # include < SDL_image . h > <nl>  <nl> void display :: handle_window_event ( const SDL_Event & event ) { <nl> } <nl>  <nl> void display :: handle_event ( const SDL_Event & event ) { <nl> + if ( gui2 :: tloadscreen :: displaying ()) { <nl> + return ; <nl> + } <nl> if ( event . type == DRAW_ALL_EVENT ) { <nl> draw (); <nl> }
mmm src / synced_commands . cpp <nl> ppp src / synced_commands . cpp <nl> SYNCED_COMMAND_HANDLER_FUNCTION ( attack , child , /* use_undo */, show , error_handler <nl> } <nl> } <nl>  <nl> - if ( size_t ( weapon_num ) >= u -> attacks (). size ()) { <nl> + if ( static_cast < unsigned >( weapon_num ) >= u -> attacks (). size ()) { <nl> error_handler (" illegal weapon type in attack \ n ", true ); <nl> return false ; <nl> }
mmm src / widgets / scrollpane . cpp <nl> ppp src / widgets / scrollpane . cpp <nl> void scrollpane :: draw () <nl>  <nl> void scrollpane :: scroll ( unsigned int pos ) <nl> { <nl> - if (( int ) pos == content_pos_ . y ) <nl> + if ( static_cast < int >( pos ) == content_pos_ . y ) <nl> return ; <nl>  <nl> content_pos_ . y = pos ;
mmm src / multiplayer_connect . cpp <nl> ppp src / multiplayer_connect . cpp <nl> int mp_connect :: load_map ( const std :: string & era , int map , int num_turns , int vil <nl>  <nl> load_game (* data_ , game , * state_ ); <nl>  <nl> - state_ -> gold = - 10000 ; <nl> state_ -> available_units . clear (); <nl> state_ -> can_recruit . clear (); <nl>  <nl> int mp_connect :: load_map ( const std :: string & era , int map , int num_turns , int vil <nl>  <nl> level_ = level_ptr ; <nl> state_ -> label = level_ -> values [" name "]; <nl> + state_ -> gold = - 10000 ; <nl>  <nl> std :: map < int , std :: string > res_to_id ; <nl> for ( config :: child_list :: const_iterator i = levels . begin (); i != levels . end (); ++ i ){
mmm src / gui / widgets / grid . hpp <nl> ppp src / gui / widgets / grid . hpp <nl> class grid : public widget <nl> public : <nl> explicit grid ( const unsigned rows = 0 , const unsigned cols = 0 ); <nl>  <nl> + /** Delete the copy constructor . */ <nl> + grid ( const grid &) = delete ; <nl> + <nl> + /** Delete the move assignment operator . */ <nl> + grid & operator =( const grid &) = delete ; <nl> + <nl> virtual ~ grid (); <nl>  <nl> /***** ***** ***** ***** LAYOUT FLAGS ***** ***** ***** *****/
mmm src / about . cpp <nl> ppp src / about . cpp <nl> std :: vector < std :: string > get_text () { <nl> " _ " N_ ("+ Catalan Translation "), <nl> "- Carles Company ( brrr )", <nl> "- Dan Rosàs Garcia ( focks )", <nl> + "- Jonatan Alamà ( tin )", <nl> "- Jordà Polo ( ettin )", <nl> "- Mark Recasens ", <nl> "- Pau Rul · lan Ferragut ",
mmm src / widgets / menu . cpp <nl> ppp src / widgets / menu . cpp <nl> size_t menu :: get_item_height ( int ) const <nl>  <nl> void menu :: process_help_string ( int mousex , int mousey ) <nl> { <nl> + if ( hidden ()) return ; <nl> + <nl> const std :: pair < int , int > loc ( hit ( mousex , mousey ), hit_column ( mousex )); <nl> if ( loc == cur_help_ ) { <nl> return ; <nl> void menu :: process_help_string ( int mousex , int mousey ) <nl> help_string_ = - 1 ; <nl> } <nl> if ( size_t ( loc . first ) < items_ . size ()) { <nl> - const std :: vector < std :: string >& row = items_ [ loc . first ]. help ; <nl> + const std :: vector < std :: string >& row = items_ [ item_pos_ [ loc . first ]]. help ; <nl> if ( size_t ( loc . second ) < row . size ()) { <nl> const std :: string & help = row [ loc . second ]; <nl> if ( help . empty () == false ) {
mmm src / events . cpp <nl> ppp src / events . cpp <nl> void pump () <nl> SDL_UserEvent user_event ; <nl> user_event . type = DOUBLE_CLICK_EVENT ; <nl> user_event . code = 0 ; <nl> - user_event . data1 = reinterpret_cast < void *>( event . button . x ); <nl> - user_event . data2 = reinterpret_cast < void *>( event . button . y ); <nl> + user_event . data1 = new int ( event . button . x ); <nl> + user_event . data2 = new int ( event . button . y ); <nl> :: SDL_PushEvent ( reinterpret_cast < SDL_Event *>(& user_event )); <nl> } <nl>  <nl> void raise_draw_event () <nl> } <nl> } <nl>  <nl> -} <nl> \ No newline at end of file <nl> +}mmm src / widgets / menu . cpp <nl> ppp src / widgets / menu . cpp <nl> void pump () <nl> SDL_UserEvent user_event ; <nl> user_event . type = DOUBLE_CLICK_EVENT ; <nl> user_event . code = 0 ; <nl> - user_event . data1 = reinterpret_cast < void *>( event . button . x ); <nl> - user_event . data2 = reinterpret_cast < void *>( event . button . y ); <nl> + user_event . data1 = new int ( event . button . x ); <nl> + user_event . data2 = new int ( event . button . y ); <nl> :: SDL_PushEvent ( reinterpret_cast < SDL_Event *>(& user_event )); <nl> } <nl>  <nl> void raise_draw_event () <nl> } <nl> } <nl>  <nl> -} <nl> \ No newline at end of file <nl> +} <nl> void menu :: handle_event ( const SDL_Event & event ) <nl> x = event . button . x ; <nl> y = event . button . y ; <nl> } else { <nl> - x = reinterpret_cast < int >( event . user . data1 ); <nl> - y = reinterpret_cast < int >( event . user . data2 ); <nl> + x = *( reinterpret_cast < int *>( event . user . data1 )); <nl> + y = *( reinterpret_cast < int *>( event . user . data2 )); <nl> + delete reinterpret_cast < int *>( event . user . data1 ); <nl> + delete reinterpret_cast < int *>( event . user . data2 ); <nl> } <nl>  <nl> const int item = hit ( x , y );
mmm src / game . cpp <nl> ppp src / game . cpp <nl> void game_controller :: reset_game_cfg () <nl> defines_map_ [" APPLE "] = preproc_define (); <nl> # endif <nl>  <nl> - defines_map_ [" NORMAL "] = preproc_define (); <nl> - defines_map_ [" MEDIUM "] = preproc_define (); <nl> - <nl> if ( multiplayer_mode_ ) { <nl> defines_map_ [" MULTIPLAYER "] = preproc_define (); <nl> + } else { <nl> + defines_map_ [" NORMAL "] = preproc_define (); <nl> + defines_map_ [" MEDIUM "] = preproc_define (); <nl> } <nl>  <nl> refresh_game_cfg ();
mmm src / map . cpp <nl> ppp src / map . cpp <nl> bool gamemap :: filter_location ( const gamemap :: location & loc , const config & /* con * <nl> void gamemap :: write_terrain ( const gamemap :: location & loc , config & cfg ) const <nl> { <nl> // will need to be updated for multi - letter terrain -- Sapient <nl> - char * loc_terrain = " "; <nl> + char loc_terrain [] = " "; <nl> * loc_terrain = get_terrain ( loc ); <nl> cfg [" terrain "] = loc_terrain ; <nl> }
mmm src / filesystem . cpp <nl> ppp src / filesystem . cpp <nl> std :: string get_wml_location ( const std :: string & filename , const std :: string & cur <nl> return result ; <nl> } <nl>  <nl> + if ( ends_with ( filename , ". pbl ")) { <nl> + ERR_FS << " Illegal path '" << filename << "' (. pbl files are not allowed )." << std :: endl ; <nl> + return result ; <nl> + } <nl> + <nl> bool already_found = false ; <nl>  <nl> if ( filename [ 0 ] == '~')mmm src / filesystem_boost . cpp <nl> ppp src / filesystem_boost . cpp <nl> std :: string get_wml_location ( const std :: string & filename , const std :: string & cur <nl> return result ; <nl> } <nl>  <nl> + if ( ends_with ( filename , ". pbl ")) { <nl> + ERR_FS << " Illegal path '" << filename << "' (. pbl files are not allowed )." << std :: endl ; <nl> + return result ; <nl> + } <nl> + <nl> bool already_found = false ; <nl>  <nl> if ( filename [ 0 ] == '~') <nl> static bool is_legal_file ( const std :: string & filename ) <nl> return false ; <nl> } <nl>  <nl> + if ( ends_with ( filename , ". pbl ")) { <nl> + ERR_FS << " Illegal path '" << filename << "' (. pbl files are not allowed )." << std :: endl ; <nl> + return false ; <nl> + } <nl> + <nl> return true ; <nl> } <nl> 
mmm src / editor / palette / editor_palettes . cpp <nl> ppp src / editor / palette / editor_palettes . cpp <nl> template < class Item > <nl> void editor_palette < Item >:: swap () <nl> { <nl> std :: swap ( selected_fg_item_ , selected_bg_item_ ); <nl> + select_fg_item ( selected_fg_item_ ); <nl> + select_bg_item ( selected_bg_item_ ); <nl> + set_dirty (); <nl> } <nl> template void editor_palette < t_translation :: t_terrain >:: swap (); <nl> template void editor_palette < unit_type >:: swap ();mmm src / editor / editor_controller . cpp <nl> ppp src / editor / editor_controller . cpp <nl> template < class Item > <nl> void editor_palette < Item >:: swap () <nl> { <nl> std :: swap ( selected_fg_item_ , selected_bg_item_ ); <nl> + select_fg_item ( selected_fg_item_ ); <nl> + select_bg_item ( selected_bg_item_ ); <nl> + set_dirty (); <nl> } <nl> template void editor_palette < t_translation :: t_terrain >:: swap (); <nl> template void editor_palette < unit_type >:: swap (); <nl> bool editor_controller :: execute_command ( hotkey :: HOTKEY_COMMAND command , int inde <nl> return true ; <nl> case HOTKEY_EDITOR_PALETTE_ITEM_SWAP : <nl> toolkit_ -> get_palette_manager ()-> active_palette (). swap (); <nl> - toolkit_ -> set_mouseover_overlay (); <nl> return true ; <nl> case HOTKEY_EDITOR_PARTIAL_UNDO : <nl> if ( dynamic_cast < const editor_action_chain *>( context_manager_ -> get_map_context (). last_undo_action ()) != NULL ) {
mmm src / widgets / textbox . cpp <nl> ppp src / widgets / textbox . cpp <nl> void textbox :: draw_cursor ( int pos ) const <nl>  <nl> void textbox :: draw () const <nl> { <nl> - if ( location (). h == 0 ) <nl> + if ( location (). x == 0 ) <nl> return ; <nl>  <nl> if ( buffer_ . get () != NULL ) { <nl> void textbox :: draw () const <nl>  <nl> void textbox :: handle_event ( const SDL_Event & event ) <nl> { <nl> + if ( location (). x == 0 ) <nl> + return ; <nl> + <nl> int mousex , mousey ; <nl> SDL_GetMouseState (& mousex ,& mousey ); <nl> 
mmm src / extracts . cpp <nl> ppp src / extracts . cpp <nl> void APar_Print_TrackDetails ( TrackInfo * track_info ) { <nl> } <nl>  <nl> void APar_ExtractDetails ( FILE * isofile , uint8_t optional_output ) { <nl> - char uint32_buffer [ 5 ]; <nl> + char uint32_buffer [ 8 ]; <nl> Trackage track = { 0 }; <nl>  <nl> AtomicInfo * mvhdAtom = APar_FindAtom (" moov . mvhd ", false , VERSIONED_ATOM , 0 );
mmm source / resource / TextsCore . h <nl> ppp source / resource / TextsCore . h <nl> # define S3_STATUS_ACCESS_DENIED 746 <nl> # define UNKNOWN_FILE_ENCRYPTION 747 <nl> # define INVALID_ENCRYPT_KEY 748 <nl> +# define UNREQUESTED_FILE 749 <nl>  <nl> # define CORE_CONFIRMATION_STRINGS 300 <nl> # define CONFIRM_PROLONG_TIMEOUT3 301mmm source / core / ScpFileSystem . cpp <nl> ppp source / core / ScpFileSystem . cpp <nl> # define S3_STATUS_ACCESS_DENIED 746 <nl> # define UNKNOWN_FILE_ENCRYPTION 747 <nl> # define INVALID_ENCRYPT_KEY 748 <nl> +# define UNREQUESTED_FILE 749 <nl>  <nl> # define CORE_CONFIRMATION_STRINGS 300 <nl> # define CONFIRM_PROLONG_TIMEOUT3 301 <nl> void __fastcall TSCPFileSystem :: SCPSink ( const UnicodeString TargetDir , <nl> { <nl> FTerminal -> LogEvent ( FORMAT ( L " Warning : Remote host set a compound pathname '% s '", ( Line ))); <nl> } <nl> + if (( Level == 0 ) && ( OnlyFileName != UnixExtractFileName ( FileName ))) <nl> + { <nl> + SCPError ( LoadStr ( UNREQUESTED_FILE ), False ); <nl> + } <nl>  <nl> FullFileName = SourceDir + OnlyFileName ; <nl> OperationProgress -> SetFile ( FullFileName );
mmm wsutil / filesystem . c <nl> ppp wsutil / filesystem . c <nl> create_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) <nl> * doing a " stat ()" on it . If it ' s a drive letter , <nl> * or if the " stat ()" succeeds , we assume it exists . <nl> */ <nl> - pf_dir_path_copy = pf_dir_path ; <nl> + pf_dir_path_copy = g_strdup ( pf_dir_path ); <nl> pf_dir_parent_path = get_dirname ( pf_dir_path_copy ); <nl> pf_dir_parent_path_len = strlen ( pf_dir_parent_path ); <nl> if ( pf_dir_parent_path_len > 0 <nl> create_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) <nl> save_errno = errno ; <nl> * pf_dir_path_return = pf_dir_path ; <nl> errno = save_errno ; <nl> + g_free ( pf_dir_path_copy ); <nl> return - 1 ; <nl> } <nl> /* <nl> create_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) <nl> ret = ws_mkdir ( pf_dir_parent_path , 0755 ); <nl> if ( ret == - 1 ) { <nl> * pf_dir_path_return = pf_dir_parent_path ; <nl> + g_free ( pf_dir_path ); <nl> return - 1 ; <nl> } <nl> }
mmm epan / dissectors / packet - gtpv2 . c <nl> ppp epan / dissectors / packet - gtpv2 . c <nl> dissect_gtpv2_mm_context_utms_qq ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tr <nl> proto_tree_add_item ( tree , hf_gtpv2_ik , tvb , offset , 16 , ENC_NA ); <nl> offset += 16 ; <nl>  <nl> - if ( nr_qua ) <nl> - { <nl> - offset = dissect_gtpv2_authentication_quadruplets ( tvb , tree , offset , nr_qui ); <nl> + if ( nr_qua ) { <nl> + offset = dissect_gtpv2_authentication_quadruplets ( tvb , tree , offset , nr_qua ); <nl> } <nl>  <nl> if ( nr_qui ) {
mmm epan / dissectors / packet - ipsec . c <nl> ppp epan / dissectors / packet - ipsec . c <nl> dissect_esp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> /* Copy back the Authentication which was not encrypted */ <nl> if ( decrypted_len >= esp_auth_len ) <nl> { <nl> - tvb_memcpy ( tvb , decrypted_data + decrypted_len - esp_auth_len , sizeof ( struct newesp )+ decrypted_len - esp_auth_len , esp_auth_len ); <nl> + tvb_memcpy ( tvb , decrypted_data + decrypted_len - esp_auth_len , ( gint )( sizeof ( struct newesp )+ decrypted_len - esp_auth_len ), esp_auth_len ); <nl> } <nl>  <nl> /* Decryption has finished */
mmm packet - smb - browse . c <nl> ppp packet - smb - browse . c <nl> * Routines for SMB Browser packet dissection <nl> * Copyright 1999 , Richard Sharpe < rsharpe @ ns . aus . com > <nl> * <nl> - * $ Id : packet - smb - browse . c , v 1 . 15 2001 / 08 / 01 03 : 47 : 00 guy Exp $ <nl> + * $ Id : packet - smb - browse . c , v 1 . 16 2001 / 08 / 01 08 : 12 : 15 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> dissect_mailslot_browse ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent_tr <nl> proto_tree_add_item ( tree , hf_update_count , tvb , offset , 1 , TRUE ); <nl> offset += 1 ; <nl>  <nl> - /* periodicity */ <nl> + /* periodicity ( in milliseconds ) */ <nl> periodicity = tvb_get_letohl ( tvb , offset ); <nl> proto_tree_add_uint_format ( tree , hf_periodicity , tvb , offset , 4 , <nl> periodicity , <nl> dissect_mailslot_browse ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent_tr <nl> * <nl> * The document at <nl> * <nl> - * http :// www . samba . org / samba / ftp / specs / smbpub . txt <nl> + * http :// www . samba . org / samba / ftp / specs / brow_rev . txt <nl> * <nl> * gives both formats of host announcement packets , saying that <nl> * "[ The first ] format seems wrong ", that one being what appears to <nl> dissect_mailslot_lanman ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent_tr <nl> proto_tree_add_item ( tree , hf_os_minor , tvb , offset , 1 , TRUE ); <nl> offset += 1 ; <nl>  <nl> - /* periodicity */ <nl> - periodicity = tvb_get_letohs ( tvb , offset ); <nl> + /* periodicity ( in seconds ; convert to milliseconds ) */ <nl> + periodicity = tvb_get_letohs ( tvb , offset )* 1000 ; <nl> proto_tree_add_uint_format ( tree , hf_periodicity , tvb , offset , 2 , <nl> periodicity , <nl> " Update Periodicity : % s ",
mmm packet - esis . c <nl> ppp packet - esis . c <nl> * Routines for ISO / OSI End System to Intermediate System <nl> * Routing Exchange Protocol ISO 9542 . <nl> * <nl> - * $ Id : packet - esis . c , v 1 . 27 2002 / 08 / 28 21 : 00 : 13 jmayer Exp $ <nl> + * $ Id : packet - esis . c , v 1 . 28 2003 / 02 / 25 19 : 07 : 07 guy Exp $ <nl> * Ralf Schneider < Ralf . Schneider @ t - online . de > <nl> * <nl> * Ethereal - Network traffic analyzer <nl> proto_reg_handoff_esis ( void ) <nl> dissector_handle_t esis_handle ; <nl>  <nl> esis_handle = create_dissector_handle ( dissect_esis , proto_esis ); <nl> + register_dissector (" esis ", dissect_esis , proto_esis ); <nl> dissector_add (" osinl ", NLPID_ISO9542_ESIS , esis_handle ); <nl> }
mmm gtk / uat_gui . c <nl> ppp gtk / uat_gui . c <nl> static void uat_edit_dialog ( uat_t * uat , gint row , gboolean copy ) { <nl> if ( copy && row >= 0 ) { <nl> dd -> rec = g_malloc0 ( uat -> record_size ); <nl> if ( uat -> copy_cb ) { <nl> - uat -> copy_cb ( dd -> rec , UAT_INDEX_PTR ( uat , row ), uat -> record_size ); <nl> + uat -> copy_cb ( dd -> rec , UAT_INDEX_PTR ( uat , row ), ( unsigned int ) uat -> record_size ); <nl> } <nl> dd -> is_new = TRUE ; <nl> } else if ( row >= 0 ) {
mmm epan / dissectors / packet - 6lowpan . c <nl> ppp epan / dissectors / packet - 6lowpan . c <nl> dissect_6lowpan_iphc_nhc ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , gi <nl> /* Get and display the checksum . */ <nl> if (!( udp_flags & LOWPAN_NHC_UDP_CHECKSUM )) { <nl> /* Parse the checksum . */ <nl> - udp . checksum = tvb_get_ntohs ( tvb , offset ); <nl> + tvb_memcpy ( tvb , & udp . checksum , offset , sizeof ( udp . checksum )); <nl> proto_tree_add_checksum ( tree , tvb , offset , hf_6lowpan_udp_checksum , - 1 , NULL , pinfo , 0 , ENC_BIG_ENDIAN , PROTO_CHECKSUM_NO_FLAGS ); <nl> offset += 2 ; <nl> }
mmm epan / dissectors / packet - rlc . c <nl> ppp epan / dissectors / packet - rlc . c <nl> translate_hex_key ( gchar * char_key ){ <nl> key_in = g_malloc0 ( sizeof ( guint8 )* 16 ); <nl> /* memset ( key_in , 0 , 16 ); <nl> */ <nl> - j = ( strlen ( char_key )/ 2 )- 1 ; <nl> + j = ( int )( strlen ( char_key )/ 2 )- 1 ; <nl> /* Translate " hex - string " into a byte aligned block */ <nl> - for ( i = strlen ( char_key ); i > 0 ; i -= 2 ){ <nl> + for ( i = ( int ) strlen ( char_key ); i > 0 ; i -= 2 ){ <nl>  <nl> key_in [ j ] = ( ( guint8 ) ( strtol ( & char_key [ i - 2 ], NULL , 16 ) )); <nl> char_key [ i - 2 ] = '\ 0 '; <nl> translate_hex_key ( gchar * char_key ){ <nl> * @ return tvb Returns a deciphered tvb <nl> */ <nl>  <nl> - static tvbuff_t * rlc_decipher_tvb ( tvbuff_t * tvb , packet_info * pinfo , guint32 counter , guint8 rbid , gboolean dir ){ <nl> # if ! HAVE_UMTS_KASUMI <nl> + static tvbuff_t * rlc_decipher_tvb ( tvbuff_t * tvb _U_ , packet_info * pinfo , guint32 counter _U_ , guint8 rbid _U_ , gboolean dir _U_ ){ <nl> /* Check if we have a KASUMI implementatation */ <nl> expert_add_info_format ( pinfo , NULL , PI_UNDECODED , PI_WARN , " Unable to decipher packet since KASUMI implementation is missing ."); <nl> return NULL ; <nl> # else <nl> + static tvbuff_t * rlc_decipher_tvb ( tvbuff_t * tvb , packet_info * pinfo , guint32 counter , guint8 rbid , gboolean dir ){ <nl> guint64 i ; <nl> guint8 * out = NULL ,* key_in = NULL ; <nl> tvbuff_t * t ;
mmm ui / qt / progress_frame . cpp <nl> ppp ui / qt / progress_frame . cpp <nl> # include " wireshark_application . h " <nl>  <nl> // To do : <nl> -// - Use a different icon ? <nl> // - Add an NSProgressIndicator to the dock icon on OS X . <nl> // - Start adding the progress bar to dialogs . <nl> // - Don ' t complain so loudly when the user stops a capture . <nl> static const int app_update_freq_ = 100 ; // ms <nl> void <nl> update_progress_dlg ( progdlg_t * dlg , gfloat percentage , const gchar *) <nl> { <nl> - if (! dlg || dlg -> elapsed_timer -> elapsed () < app_update_freq_ ) return ; <nl> + if (! dlg ) return ; <nl> + if ( dlg -> elapsed_timer -> isValid () && ! dlg -> elapsed_timer -> hasExpired ( app_update_freq_ )) return ; <nl> + dlg -> elapsed_timer -> restart (); <nl>  <nl> dlg -> progress_frame -> setValue ( percentage * 100 ); <nl>  <nl> update_progress_dlg ( progdlg_t * dlg , gfloat percentage , const gchar *) <nl> * Flush out the update and process any input events . <nl> */ <nl> WiresharkApplication :: processEvents (); <nl> - dlg -> elapsed_timer -> restart (); <nl>  <nl> /* Redraw so the progress bar shows the update */ <nl> dlg -> progress_frame -> update (); <nl> struct progdlg * ProgressFrame :: showProgress ( bool animate , bool terminate_is_stop <nl> { <nl> setMaximumValue ( 100 ); <nl> ui -> progressBar -> setValue ( value ); <nl> - progress_dialog_ . elapsed_timer -> start (); <nl> + progress_dialog_ . elapsed_timer -> invalidate (); <nl> emit showRequested ( animate , terminate_is_stop , stop_flag ); <nl> return & progress_dialog_ ; <nl> }
mmm epan / dissectors / packet - csn1 . c <nl> ppp epan / dissectors / packet - csn1 . c <nl> csnStreamDissector ( proto_tree * tree , csnStream_t * ar , const CSN_DESCR * pDescr , t <nl> proto_tree * test_tree ; <nl>  <nl> descr [ 0 ] = pChoice -> descr ; <nl> + memset (& descr [ 1 ], 0x00 , sizeof ( CSN_DESCR )); <nl> descr [ 1 ]. type = CSN_END ; <nl> pui8 = pui8DATA ( data , pDescr -> offset ); <nl> * pui8 = i ;
mmm wiretap / file_access . c <nl> ppp wiretap / file_access . c <nl> cleanup_open_routines ( void ) <nl> guint i ; <nl> struct open_info * i_open ; <nl>  <nl> - for ( i = 0 , i_open = open_routines ; i < open_info_arr -> len ; i ++, i_open ++) { <nl> - if ( i_open -> extensions != NULL ) <nl> - g_strfreev ( i_open -> extensions_set ); <nl> - } <nl> + if ( open_routines != NULL ) { <nl> + for ( i = 0 , i_open = open_routines ; i < open_info_arr -> len ; i ++, i_open ++) { <nl> + if ( i_open -> extensions != NULL ) <nl> + g_strfreev ( i_open -> extensions_set ); <nl> + } <nl>  <nl> - g_array_free ( open_info_arr , TRUE ); <nl> + g_array_free ( open_info_arr , TRUE ); <nl> + } <nl> } <nl>  <nl> /*
mmm epan / dissectors / packet - vtp . c <nl> ppp epan / dissectors / packet - vtp . c <nl> dissect_vtp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> while ( tvb_reported_length_remaining ( tvb , offset ) > 0 ) { <nl> vlan_info_len = <nl> dissect_vlan_info ( tvb , pinfo , offset , vtp_tree ); <nl> - if ( vlan_info_len < 0 ) <nl> + if ( vlan_info_len <= 0 ) <nl> break ; <nl> offset += vlan_info_len ; <nl> }
mmm gtk / main . c <nl> ppp gtk / main . c <nl> main ( int argc , char * argv []) <nl> /* read in rc file from global and personal configuration paths . */ <nl> rc_file = get_datafile_path ( RC_FILE ); <nl> gtk_rc_parse ( rc_file ); <nl> + g_free ( rc_file ); <nl> rc_file = get_persconffile_path ( RC_FILE , FALSE , FALSE ); <nl> gtk_rc_parse ( rc_file ); <nl> + g_free ( rc_file ); <nl>  <nl> font_init (); <nl>  <nl> main ( int argc , char * argv []) <nl> u3_deregister_pid (); <nl>  <nl> epan_cleanup (); <nl> - g_free ( rc_file ); <nl>  <nl> # ifdef HAVE_AIRPDCAP <nl> /* Davide Schiera ( 2006 - 11 - 18 ): destroy AirPDcap context */
mmm file . c <nl> ppp file . c <nl> /* file . c <nl> * File I / O routines <nl> * <nl> - * $ Id : file . c , v 1 . 219 2000 / 09 / 11 22 : 43 : 02 sharpe Exp $ <nl> + * $ Id : file . c , v 1 . 220 2000 / 09 / 12 03 : 27 : 00 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> rescan_packets ( capture_file * cf , const char * action , gboolean refilter , <nl>  <nl> if ( redissect ) { <nl> /* Since all state for the frame was destroyed , mark the frame <nl> - * as not visited , and null out the pointer to the per - frame <nl> + * as not visited , free the GSList referring to the state <nl> * data ( the per - frame data itself was freed by <nl> - * " init_all_protocols ()"). */ <nl> + * " init_all_protocols ()"), and null out the GSlist pointer . */ <nl> fdata -> flags . visited = 0 ; <nl> - <nl> - /* If there is any per - frame data , delete that , as what it points to <nl> - * has gone as well . <nl> - */ <nl> - <nl> if ( fdata -> pfd ) { <nl> g_slist_free ( fdata -> pfd ); <nl> } <nl> rescan_packets ( capture_file * cf , const char * action , gboolean refilter , <nl> until it finishes . Should we just stick them with that ? */ <nl> for (; fdata != NULL ; fdata = fdata -> next ) { <nl> fdata -> flags . visited = 0 ; <nl> + if ( fdata -> pfd ) { <nl> + g_slist_free ( fdata -> pfd ); <nl> + } <nl> fdata -> pfd = NULL ; <nl> } <nl> }
mmm ui / capture . c <nl> ppp ui / capture . c <nl> capture_start ( capture_options * capture_opts , capture_session * cap_session , void ( <nl> GString * source ; <nl>  <nl> cap_session -> state = CAPTURE_PREPARING ; <nl> + cap_session -> count = 0 ; <nl> g_log ( LOG_DOMAIN_CAPTURE , G_LOG_LEVEL_MESSAGE , " Capture Start ..."); <nl> source = get_iface_list_string ( capture_opts , IFLIST_SHOW_FILTER ); <nl> cf_set_tempfile_source (( capture_file *) cap_session -> cf , source -> str );
mmm epan / register . c <nl> ppp epan / register . c <nl> register_all_protocols ( register_cb cb , gpointer cb_data ) <nl> } <nl> g_thread_join ( rapw_thread ); <nl> if ( cb && ! called_back ) { <nl> - cb ( RA_REGISTER , " Registration finished ", cb_data ); <nl> + cb ( RA_REGISTER , " finished ", cb_data ); <nl> } <nl> } <nl>  <nl> register_all_protocol_handoffs ( register_cb cb , gpointer cb_data ) <nl> } <nl> g_thread_join ( raphw_thread ); <nl> if ( cb && ! called_back ) { <nl> - cb ( RA_HANDOFF , " Registration finished ", cb_data ); <nl> + cb ( RA_HANDOFF , " finished ", cb_data ); <nl> } <nl> g_async_queue_unref ( register_cb_done_q ); <nl> 
mmm epan / wslua / wslua_pinfo . c <nl> ppp epan / wslua / wslua_pinfo . c <nl> WSLUA_METAMETHOD Columns__newindex ( lua_State * L ) { <nl>  <nl> for ( cn = colnames ; cn -> name ; cn ++) { <nl> if ( g_str_equal ( cn -> name , colname ) ) { <nl> - col_set_str ( cols -> cinfo , cn -> id , text ); <nl> + col_add_str ( cols -> cinfo , cn -> id , text ); <nl> return 0 ; <nl> } <nl> }
mmm asn1 / tcap / packet - tcap - template . c <nl> ppp asn1 / tcap / packet - tcap - template . c <nl> proto_register_tcap ( void ) <nl> /* we will fake a ssn subfield which has the same value obtained from sccp */ <nl> tcap_itu_ssn_dissector_table = register_dissector_table (" tcap . itu_ssn ", " ITU TCAP SSN ", FT_UINT8 , BASE_DEC ); <nl> tcap_ansi_ssn_dissector_table = register_dissector_table (" tcap . ansi_ssn ", " ANSI TCAP SSN ", FT_UINT8 , BASE_DEC ); <nl> + <nl> + /* ' globally ' register dissector */ <nl> + register_dissector (" tcap ", dissect_tcap , proto_tcap ); <nl> + <nl> } <nl>  <nl> 
mmm epan / dissectors / packet - gprs - llc . c <nl> ppp epan / dissectors / packet - gprs - llc . c <nl> proto_register_llcgprs ( void ) <nl> void <nl> proto_reg_handoff_llcgprs ( void ) <nl> { <nl> - dissector_handle_t llcgprs_handle ; <nl> - <nl> - llcgprs_handle = create_dissector_handle ( dissect_llcgprs , <nl> - proto_llcgprs ); <nl> -/* dissector_add (" PARENT_SUBFIELD ", ID_VALUE , llcgprs_handle ); <nl> -*/ <nl> data_handle = find_dissector (" data "); <nl> }
mmm ui / qt / utils / field_information . cpp <nl> ppp ui / qt / utils / field_information . cpp <nl> field_info * FieldInformation :: fieldInfo () const <nl> FieldInformation :: HeaderInfo FieldInformation :: headerInfo () const <nl> { <nl> HeaderInfo header ; <nl> - header . isValid = false ; <nl>  <nl> if ( fi_ && fi_ -> hfinfo ) <nl> { <nl> - header . isValid = true ; <nl> header . name = fi_ -> hfinfo -> name ; <nl> header . description = fi_ -> hfinfo -> blurb ; <nl> header . abbreviation = fi_ -> hfinfo -> abbrev ; <nl> + header . isValid = true ; <nl> header . type = fi_ -> hfinfo -> type ; <nl> header . parent = fi_ -> hfinfo -> parent ; <nl> header . id = fi_ -> hfinfo -> id ; <nl> } <nl> + else <nl> + { <nl> + header . name = ""; <nl> + header . description = ""; <nl> + header . abbreviation = ""; <nl> + header . isValid = false ; <nl> + header . type = FT_NONE ; <nl> + header . parent = 0 ; <nl> + header . id = 0 ; <nl> + } <nl>  <nl> return header ; <nl> }
mmm epan / dissectors / packet - wsp . c <nl> ppp epan / dissectors / packet - wsp . c <nl> add_content_type ( proto_tree * tree , tvbuff_t * tvb , guint32 val_start , <nl> So we have to disable that one and become " slow " by pretending that <nl> the tree is " visible ". <nl> */ <nl> - PTREE_DATA ( tree )-> visible = 1 ; <nl> + if ( tree ) <nl> + PTREE_DATA ( tree )-> visible = 1 ; <nl>  <nl> * textual_content = NULL ; <nl> * well_known_content = 0 ;
mmm wiretap / netscreen . c <nl> ppp wiretap / netscreen . c <nl> static gboolean <nl> parse_netscreen_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl> char * line , int * err , gchar ** err_info ) <nl> { <nl> + int pkt_len ; <nl> int sec ; <nl> int dsec ; <nl> char cap_int [ NETSCREEN_MAX_INT_NAME_LENGTH ]; <nl> char direction [ 2 ]; <nl> - guint pkt_len ; <nl> char cap_src [ 13 ]; <nl> char cap_dst [ 13 ]; <nl> guint8 * pd ; <nl> gchar * p ; <nl> int n , i = 0 ; <nl> - guint offset = 0 ; <nl> + int offset = 0 ; <nl> gchar dststr [ 13 ]; <nl>  <nl> phdr -> rec_type = REC_TYPE_PACKET ; <nl> phdr -> presence_flags = WTAP_HAS_TS | WTAP_HAS_CAP_LEN ; <nl>  <nl> - if ( sscanf ( line , "% 9d .% 9d : % 15 [ a - z0 - 9 /:.-](% 1 [ io ]) len =% 9u :% 12s ->% 12s /", <nl> + if ( sscanf ( line , "% 9d .% 9d : % 15 [ a - z0 - 9 /:.-](% 1 [ io ]) len =% 9d :% 12s ->% 12s /", <nl> & sec , & dsec , cap_int , direction , & pkt_len , cap_src , cap_dst ) < 5 ) { <nl> * err = WTAP_ERR_BAD_FILE ; <nl> * err_info = g_strdup (" netscreen : Can ' t parse packet - header "); <nl> return - 1 ; <nl> } <nl> + if ( pkt_len < 0 ) { <nl> + * err = WTAP_ERR_BAD_FILE ; <nl> + * err_info = g_strdup (" netscreen : packet header has a negative packet length "); <nl> + return FALSE ; <nl> + } <nl> if ( pkt_len > WTAP_MAX_PACKET_SIZE ) { <nl> /* <nl> * Probably a corrupt capture file ; don ' t blow up trying
mmm epan / dissectors / packet - gsm_a_bssmap . c <nl> ppp epan / dissectors / packet - gsm_a_bssmap . c <nl> static const value_string bssap_speech_codec_values [] = { <nl> static guint8 <nl> be_speech_codec_lst ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len _U_ , gchar * add_string _U_ , int string_len _U_ ) <nl> { <nl> - guint32 curr_offset , consumed ; <nl> + guint32 curr_offset , consumed = 0 ; <nl> guint8 codec ; <nl> guint8 number = 0 ; <nl> proto_item * item = NULL ;
mmm epan / dissectors / packet - sbus . c <nl> ppp epan / dissectors / packet - sbus . c <nl> dissect_sbus ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ <nl> } <nl> offset += 2 ; /* now at the end of the telegram */ <nl> } <nl> - return tvb_length ( tvb ); <nl> + return offset ; <nl> /* End of dissect_sbus */ <nl> } <nl> 
mmm capture . c <nl> ppp capture . c <nl> /* capture . c <nl> * Routines for packet capture windows <nl> * <nl> - * $ Id : capture . c , v 1 . 102 2000 / 05 / 18 09 : 05 : 25 guy Exp $ <nl> + * $ Id : capture . c , v 1 . 103 2000 / 05 / 19 19 : 53 : 48 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> do_capture ( char * capfile_name ) <nl> error = errno ; <nl> close ( sync_pipe [ 1 ]); <nl> close ( sync_pipe [ 0 ]); <nl> + close ( cf . save_file_fd ); <nl> unlink ( cf . save_file ); <nl> g_free ( cf . save_file ); <nl> cf . save_file = NULL ; <nl> do_capture ( char * capfile_name ) <nl> return ; <nl> } <nl>  <nl> + close ( cf . save_file_fd ); <nl> + <nl> /* Parent process - read messages from the child process over the <nl> sync pipe . */ <nl> close ( sync_pipe [ 1 ]); <nl> do_capture ( char * capfile_name ) <nl> } else { <nl> /* Not sync mode . */ <nl> capture_succeeded = capture (); <nl> + close ( cf . save_file_fd ); <nl> if ( quit_after_cap ) { <nl> /* DON ' T unlink the save file . Presumably someone wants it . */ <nl> gtk_exit ( 0 );
mmm epan / wslua / wslua_dumper . c <nl> ppp epan / wslua / wslua_dumper . c <nl> WSLUA_METHOD Dumper_dump ( lua_State * L ) { <nl> pkthdr . len = ba -> len ; <nl> pkthdr . caplen = ba -> len ; <nl> pkthdr . pkt_encap = DUMPER_ENCAP ( d ); <nl> - pkthdr . pseudo_header = * ph -> wph ; <nl> + if ( ph -> wph ) { <nl> + pkthdr . pseudo_header = * ph -> wph ; <nl> + } <nl>  <nl> /* TODO : Can we get access to pinfo -> pkt_comment here somehow ? We <nl> * should be copying it to pkthdr . opt_comment if we can . */
mmm epan / prefs . c <nl> ppp epan / prefs . c <nl> prefs_get_string_list ( const gchar * str ) <nl> slstr [ j ] = '\ 0 '; <nl> if ( j > 0 ) <nl> sl = g_list_append ( sl , slstr ); <nl> + else <nl> + g_free ( slstr ); <nl> break ; <nl> } <nl> if ( cur_c == '"' && ! backslash ) { <nl> prefs_get_string_list ( const gchar * str ) <nl> and it wasn ' t preceded by a backslash ; it ' s the end of <nl> the string we were working on ... */ <nl> slstr [ j ] = '\ 0 '; <nl> - if ( j > 0 ) <nl> + if ( j > 0 ) { <nl> sl = g_list_append ( sl , slstr ); <nl> + slstr = ( gchar *) g_malloc ( sizeof ( gchar ) * COL_MAX_LEN ); <nl> + } <nl>  <nl> /* ... and the beginning of a new string . */ <nl> state = PRE_STRING ; <nl> - slstr = ( gchar *) g_malloc ( sizeof ( gchar ) * COL_MAX_LEN ); <nl> j = 0 ; <nl> } else if (! g_ascii_isspace ( cur_c ) || state != PRE_STRING ) { <nl> /* Either this isn ' t a white - space character , or we ' ve started a
mmm ui / gtk / stats_tree_stat . c <nl> ppp ui / gtk / stats_tree_stat . c <nl> clear_node_pr ( stat_node * n ) <nl> clear_node_pr ( c ); <nl> } <nl>  <nl> - if ( n -> pr -> iter ) { <nl> + if ( n -> pr && n -> pr -> iter ) { <nl> gtk_tree_store_remove ( n -> st -> pr -> store , n -> pr -> iter ); <nl> n -> pr -> iter = NULL ; <nl> }
mmm epan / dissectors / packet - mac - lte . c <nl> ppp epan / dissectors / packet - mac - lte . c <nl> static void dissect_ulsch_or_dlsch ( tvbuff_t * tvb , packet_info * pinfo , proto_tree <nl> case PADDING_LCID : <nl> /* No payload , unless its the last subheader , in which case <nl> it extends to the end of the PDU */ <nl> - if ( n == ( number_of_headers - 1 )) { <nl> + if ( n == ( number_of_headers - 1 ) && ( tvb_length_remaining ( tvb , offset ) > 0 )) { <nl> proto_tree_add_item ( tree , hf_mac_lte_padding_data , <nl> tvb , offset , - 1 , FALSE ); <nl> }
mmm tshark . c <nl> ppp tshark . c <nl> print_usage ( gboolean print_ver ) <nl> fprintf ( output , " - I capture in monitor mode , if available \ n "); <nl> # endif <nl> # if defined ( _WIN32 ) || defined ( HAVE_PCAP_CREATE ) <nl> - fprintf ( output , " - B < buffer size > size of kernel buffer ( def : 2MB )\ n "); <nl> + fprintf ( output , " - B < buffer size > size of kernel buffer ( def : % dMB )\ n ", DEFAULT_CAPTURE_BUFFER_SIZE ); <nl> # endif <nl> fprintf ( output , " - y < link type > link layer type ( def : first appropriate )\ n "); <nl> fprintf ( output , " - D print list of interfaces and exit \ n ");mmm ui / gtk / main . c <nl> ppp ui / gtk / main . c <nl> print_usage ( gboolean print_ver ) <nl> fprintf ( output , " - I capture in monitor mode , if available \ n "); <nl> # endif <nl> # if defined ( _WIN32 ) || defined ( HAVE_PCAP_CREATE ) <nl> - fprintf ( output , " - B < buffer size > size of kernel buffer ( def : 2MB )\ n "); <nl> + fprintf ( output , " - B < buffer size > size of kernel buffer ( def : % dMB )\ n ", DEFAULT_CAPTURE_BUFFER_SIZE ); <nl> # endif <nl> fprintf ( output , " - y < link type > link layer type ( def : first appropriate )\ n "); <nl> fprintf ( output , " - D print list of interfaces and exit \ n "); <nl> print_usage ( gboolean print_ver ) { <nl> fprintf ( output , " - I capture in monitor mode , if available \ n "); <nl> # endif <nl> # if defined ( _WIN32 ) || defined ( HAVE_PCAP_CREATE ) <nl> - fprintf ( output , " - B < buffer size > size of kernel buffer ( def : 2MB )\ n "); <nl> + fprintf ( output , " - B < buffer size > size of kernel buffer ( def : % dMB )\ n ", DEFAULT_CAPTURE_BUFFER_SIZE ); <nl> # endif <nl> fprintf ( output , " - y < link type > link layer type ( def : first appropriate )\ n "); <nl> fprintf ( output , " - D print list of interfaces and exit \ n ");mmm ui / qt / main . cpp <nl> ppp ui / qt / main . cpp <nl> print_usage ( gboolean print_ver ) <nl> fprintf ( output , " - I capture in monitor mode , if available \ n "); <nl> # endif <nl> # if defined ( _WIN32 ) || defined ( HAVE_PCAP_CREATE ) <nl> - fprintf ( output , " - B < buffer size > size of kernel buffer ( def : 2MB )\ n "); <nl> + fprintf ( output , " - B < buffer size > size of kernel buffer ( def : % dMB )\ n ", DEFAULT_CAPTURE_BUFFER_SIZE ); <nl> # endif <nl> fprintf ( output , " - y < link type > link layer type ( def : first appropriate )\ n "); <nl> fprintf ( output , " - D print list of interfaces and exit \ n "); <nl> print_usage ( gboolean print_ver ) { <nl> fprintf ( output , " - I capture in monitor mode , if available \ n "); <nl> # endif <nl> # if defined ( _WIN32 ) || defined ( HAVE_PCAP_CREATE ) <nl> - fprintf ( output , " - B < buffer size > size of kernel buffer ( def : 2MB )\ n "); <nl> + fprintf ( output , " - B < buffer size > size of kernel buffer ( def : % dMB )\ n ", DEFAULT_CAPTURE_BUFFER_SIZE ); <nl> # endif <nl> fprintf ( output , " - y < link type > link layer type ( def : first appropriate )\ n "); <nl> fprintf ( output , " - D print list of interfaces and exit \ n "); <nl> print_usage ( gboolean print_ver ) { <nl> fprintf ( output , " - S update packet display when new packets are captured \ n "); <nl> fprintf ( output , " - l turn on automatic scrolling while - S is in use \ n "); <nl> # if defined ( _WIN32 ) || defined ( HAVE_PCAP_CREATE ) <nl> - fprintf ( output , " - B < buffer size > size of kernel buffer ( def : 2MB )\ n "); <nl> + fprintf ( output , " - B < buffer size > size of kernel buffer ( def : % dMB )\ n ", DEFAULT_CAPTURE_BUFFER_SIZE ); <nl> # endif <nl> fprintf ( output , " - y < link type > link layer type ( def : first appropriate )\ n "); <nl> fprintf ( output , " - D print list of interfaces and exit \ n ");
mmm epan / dissectors / packet - rtp . c <nl> ppp epan / dissectors / packet - rtp . c <nl> dissect_rtp_hext_rfc5215_onebyte ( tvbuff_t * tvb , packet_info * pinfo , <nl> return ; <nl>  <nl> ext_length = ( ext_hdr_hdr & 0x0F ) + 1 ; <nl> + <nl> + /* Exit on malformed extension headers */ <nl> + if ( ext_offset + ext_length + 1 > tvb_captured_length ( tvb )) { <nl> + return ; <nl> + } <nl> + <nl> if ( rtp_hext_tree ) { <nl> rtp_hext_rfc5285_tree = proto_tree_add_subtree ( rtp_hext_tree , tvb , ext_offset , ext_length + 1 , <nl> ett_hdr_ext_rfc5285 , NULL , " RFC 5285 Header Extension ( One - Byte Header )");
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> tvb_captured_length ( const tvbuff_t * tvb ) <nl> static inline gint <nl> _tvb_captured_length_remaining ( const tvbuff_t * tvb , const gint offset ) <nl> { <nl> - guint abs_offset , rem_length ; <nl> + guint abs_offset = 0 , rem_length ; <nl> int exception ; <nl>  <nl> exception = compute_offset_and_remaining ( tvb , offset , & abs_offset , & rem_length );
mmm epan / column - utils . c <nl> ppp epan / column - utils . c <nl> col_set_addr ( packet_info * pinfo , int col , address * addr , gboolean is_res , <nl> g_strlcpy ( pinfo -> cinfo -> col_expr . col_expr [ col ], " ipv6 . src ", COL_MAX_LEN ); <nl> else <nl> g_strlcpy ( pinfo -> cinfo -> col_expr . col_expr [ col ], " ipv6 . dst ", COL_MAX_LEN ); <nl> + memcpy (& ipv6_addr . bytes , addr -> data , sizeof ipv6_addr . bytes ); <nl> g_strlcpy ( pinfo -> cinfo -> col_expr . col_expr_val [ col ], ip6_to_str (& ipv6_addr ), COL_MAX_LEN ); <nl> break ; <nl> 
mmm gtk / main . c <nl> ppp gtk / main . c <nl> /* main . c <nl> * <nl> - * $ Id : main . c , v 1 . 315 2003 / 09 / 15 23 : 20 : 34 guy Exp $ <nl> + * $ Id : main . c , v 1 . 316 2003 / 09 / 23 06 : 25 : 10 oabad Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> packet_list_button_pressed_cb ( GtkWidget * w , GdkEvent * event , gpointer data _U_ ) <nl> set_frame_mark (! fdata -> flags . marked , fdata , row ); <nl> return TRUE ; <nl> } <nl> - else if ( event_button -> button == 1 ) { <nl> - gtk_clist_select_row ( GTK_CLIST ( w ), row , column ); <nl> - return TRUE ; <nl> - } <nl> } <nl> return FALSE ; <nl> }
mmm epan / dissectors / packet - kafka . c <nl> ppp epan / dissectors / packet - kafka . c <nl> dissect_kafka_message ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , int s <nl> offset += 4 ; <nl>  <nl> if ( raw ) { <nl> - payload = tvb_child_uncompress ( tvb , raw , 0 , tvb_length ( raw )); <nl> + payload = tvb_child_uncompress ( tvb , raw , 0 , tvb_captured_length ( raw )); <nl> if ( payload ) { <nl> add_new_data_source ( pinfo , payload , " Uncompressed Message "); <nl> dissect_kafka_message_set ( payload , pinfo , subtree , 0 , FALSE ); <nl> dissect_kafka_message ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , int s <nl> decrypt_item = proto_tree_add_item ( subtree , hf_kafka_message_value , raw , 0 , - 1 , ENC_NA ); <nl> expert_add_info ( pinfo , decrypt_item , & ei_kafka_message_decompress ); <nl> } <nl> - offset += tvb_length ( raw ); <nl> + offset += tvb_captured_length ( raw ); <nl> } <nl> else { <nl> proto_tree_add_bytes ( subtree , hf_kafka_message_value , tvb , offset , 0 , NULL ); <nl> dissect_kafka ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U <nl> if ( matcher == NULL || matcher -> request_frame >= PINFO_FD_NUM ( pinfo )) { <nl> col_set_str ( pinfo -> cinfo , COL_INFO , " Kafka Response ( Unknown API , Missing Request )"); <nl> /* TODO : expert info , don ' t have request , can ' t dissect */ <nl> - return tvb_length ( tvb ); <nl> + return tvb_captured_length ( tvb ); <nl> } <nl>  <nl> wmem_queue_pop ( match_queue ); <nl> dissect_kafka ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U <nl>  <nl> } <nl>  <nl> - return tvb_length ( tvb ); <nl> + return tvb_captured_length ( tvb ); <nl> } <nl>  <nl> static int <nl> dissect_kafka_tcp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> tcp_dissect_pdus ( tvb , pinfo , tree , TRUE , 4 , <nl> get_kafka_pdu_len , dissect_kafka , data ); <nl>  <nl> - return tvb_length ( tvb ); <nl> + return tvb_captured_length ( tvb ); <nl> } <nl>  <nl> void <nl> proto_register_kafka ( void ) <nl> }, <nl> { & hf_kafka_request_frame , <nl> { " Request Frame ", " kafka . request_frame ", <nl> - FT_FRAMENUM , BASE_NONE , 0 , 0 , <nl> + FT_FRAMENUM , BASE_NONE , FRAMENUM_TYPE ( FT_FRAMENUM_REQUEST ), 0 , <nl> NULL , HFILL } <nl> }, <nl> { & hf_kafka_broker_nodeid , <nl> proto_register_kafka ( void ) <nl> }, <nl> { & hf_kafka_response_frame , <nl> { " Response Frame ", " kafka . reponse_frame ", <nl> - FT_FRAMENUM , BASE_NONE , 0 , 0 , <nl> + FT_FRAMENUM , BASE_NONE , FRAMENUM_TYPE ( FT_FRAMENUM_RESPONSE ), 0 , <nl> NULL , HFILL } <nl> } <nl> };
mmm gtk / recent . c <nl> ppp gtk / recent . c <nl> write_recent ( void ) <nl> g_free ( rf_path ); <nl> return FALSE ; <nl> } <nl> + g_free ( rf_path ); <nl>  <nl> fputs ("# Recent settings file for Wireshark " VERSION ".\ n " <nl> "#\ n "
mmm epan / dissectors / packet - bgp . c <nl> ppp epan / dissectors / packet - bgp . c <nl> static int decode_bgp_link_nlri_prefix_descriptors ( tvbuff_t * tvb , <nl> break ; <nl>  <nl> case BGP_NLRI_TLV_IP_REACHABILITY_INFORMATION : <nl> - decode_prefix4 ( tlv_sub_tree , pinfo , tlv_sub_item , hf_bgp_ls_nlri_ip_reachability_prefix_ip , <nl> - tvb , offset + 4 , 0 , " Reachability "); <nl> + if ( decode_prefix4 ( tlv_sub_tree , pinfo , tlv_sub_item , hf_bgp_ls_nlri_ip_reachability_prefix_ip , <nl> + tvb , offset + 4 , 0 , " Reachability ") == - 1 ) <nl> + return diss_length ; <nl> break ; <nl> } <nl> 
mmm epan / dissectors / packet - capwap . c <nl> ppp epan / dissectors / packet - capwap . c <nl> dissect_capwap_data ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl>  <nl> if ( global_capwap_reassemble && fragment_is ) <nl> { <nl> + gint len_rem = tvb_length_remaining ( tvb , offset ); <nl> + if ( len_rem <= 0 ) <nl> + return ; <nl> + <nl> pinfo -> fragmented = TRUE ; <nl>  <nl> frag_msg = fragment_add_check ( tvb , offset , pinfo , fragment_id , <nl> capwap_fragment_table , <nl> capwap_reassembled_table , <nl> fragment_offset , <nl> - tvb_length_remaining ( tvb , offset ), <nl> + len_rem , <nl> fragment_more ); <nl>  <nl> next_tvb = process_reassembled_data ( tvb , offset , pinfo ,
mmm epan / dissectors / packet - smb - mailslot . c <nl> ppp epan / dissectors / packet - smb - mailslot . c <nl> dissect_mailslot_smb ( tvbuff_t * mshdr_tvb , tvbuff_t * setup_tvb , <nl> } <nl>  <nl> smb_info = pinfo -> private_data ; <nl> - if ( smb_info -> sip != NULL && smb_info -> sip -> extra_info_type == SMB_EI_TRI ) <nl> + if ( smb_info != NULL && smb_info -> sip != NULL && smb_info -> sip -> extra_info_type == SMB_EI_TRI ) <nl> tri = smb_info -> sip -> extra_info ; <nl> else <nl> tri = NULL ;
mmm epan / dissectors / packet - mle . c <nl> ppp epan / dissectors / packet - mle . c <nl> dissect_mle_decrypt ( tvbuff_t * tvb , <nl>  <nl> DISSECTOR_ASSERT ( pinfo -> src . len == 16 ); <nl> DISSECTOR_ASSERT ( pinfo -> dst . len == 16 ); <nl> - memcpy ( d_a , ( guint8 *) pinfo -> src . data , pinfo -> src . len ); <nl> - memcpy ( d_a + 16 , ( guint8 *) pinfo -> dst . data , pinfo -> dst . len ); <nl> + memcpy ( d_a , ( const guint8 *) pinfo -> src . data , pinfo -> src . len ); <nl> + memcpy ( d_a + 16 , ( const guint8 *) pinfo -> dst . data , pinfo -> dst . len ); <nl>  <nl> tvb_memcpy ( tvb , d_a + 32 , payload_info -> aux_offset , payload_info -> aux_length ); <nl> l_a = 32 + payload_info -> aux_length ;
mmm ui / qt / capture_interfaces_dialog . cpp <nl> ppp ui / qt / capture_interfaces_dialog . cpp <nl> bool InterfaceTreeWidgetItem :: operator < ( const QTreeWidgetItem & other ) const { <nl> # include < QComboBox > <nl>  <nl> InterfaceTreeDelegate :: InterfaceTreeDelegate ( QObject * parent ) <nl> - : QStyledItemDelegate ( parent ) <nl> + : QStyledItemDelegate ( parent ), tree_ ( NULL ) <nl> { <nl> } <nl> 
mmm epan / dissectors / packet - icmpv6 . c <nl> ppp epan / dissectors / packet - icmpv6 . c <nl> dissect_icmpv6_nd_opt ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree <nl>  <nl> /* 6LBR Address */ <nl> proto_tree_add_item ( icmp6opt_tree , hf_icmpv6_opt_abro_6lbr_address , tvb , opt_offset , 16 , ENC_NA ); <nl> - proto_item_append_text ( ti , " : Version % d .% d , Valid Lifetime : % d , 6LBR : % s ", version_high , version_low , valid_lifetime , tvb_ip6_to_str ( tvb , opt_offset )); <nl> + proto_item_append_text ( ti , " : Version % d .% d , Valid Lifetime : % d , 6LBR : % s ", version_high , version_low , valid_lifetime , tvb_ip6_to_str ( tvb , opt_offset )); <nl> opt_offset += 16 ; <nl>  <nl> }
mmm dumpcap . c <nl> ppp dumpcap . c <nl> capture_loop_init_output ( capture_options * capture_opts , loop_data * ld , char * err <nl> - 1 , /* section_length */ <nl> & ld -> bytes_written , <nl> & err ); <nl> + g_string_free ( cpu_info_str , TRUE ); <nl> g_free ( appname ); <nl>  <nl> for ( i = 0 ; successful && ( i < capture_opts -> ifaces -> len ); i ++) { <nl> do_file_switch_or_stop ( capture_options * capture_opts , <nl> - 1 , /* section_length */ <nl> &( global_ld . bytes_written ), <nl> & global_ld . err ); <nl> + g_string_free ( cpu_info_str , TRUE ); <nl> g_free ( appname ); <nl>  <nl> for ( i = 0 ; successful && ( i < capture_opts -> ifaces -> len ); i ++) {
mmm epan / dissectors / packet - mpeg - descriptor . c <nl> ppp epan / dissectors / packet - mpeg - descriptor . c <nl> proto_mpeg_descriptor_dissect_extension ( tvbuff_t * tvb , guint offset , guint8 len , <nl> proto_tree_add_text ( tree , tvb , offset , len - already_dissected , " Private data "); <nl> break ; <nl> default : <nl> - proto_tree_add_item ( tree , hf_mpeg_descr_extension_data , tvb , offset , len , ENC_NA ); <nl> + already_dissected = offset - offset_start ; <nl> + if ( already_dissected < len ) <nl> + proto_tree_add_item ( tree , hf_mpeg_descr_extension_data , tvb , offset , len - already_dissected , ENC_NA ); <nl> break ; <nl> } <nl> 
mmm print . c <nl> ppp print . c <nl> proto_tree_write_node_pdml ( proto_node * node , gpointer data ) <nl> label_ptr = ""; <nl> } <nl>  <nl> - fputs ("< field show =\"", pdata -> fh ); <nl> + /* Show empty name since it is a required field */ <nl> + fputs ("< field name =\"", pdata -> fh ); <nl> + fputs ("\" show =\"", pdata -> fh ); <nl> print_escaped_xml ( pdata -> fh , label_ptr ); <nl>  <nl> fprintf ( pdata -> fh , "\" size =\"% d ", fi -> length );
mmm epan / dissectors / packet - e100 . c <nl> ppp epan / dissectors / packet - e100 . c <nl> proto_reg_handoff_e100 ( void ) <nl> /* Check all UDP traffic , as the specific UDP port is configurable */ <nl> heur_dissector_add (" udp ", dissect_e100 , " E100 over UDP ", " e100_udp ", proto_e100 , HEURISTIC_ENABLE ); <nl> /* e100 traffic encapsulates traffic from the ethernet frame on */ <nl> - eth_handle = find_dissector (" eth "); <nl> + eth_handle = find_dissector (" eth_withoutfcs "); <nl> } <nl>  <nl> /*
mmm epan / dissectors / packet - dcerpc . c <nl> ppp epan / dissectors / packet - dcerpc . c <nl> dissect_dcerpc_cn_bs_body ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> * it was just too short to tell and ask the TCP layer for more <nl> * data . */ <nl> pinfo -> desegment_offset = offset ; <nl> - pinfo -> desegment_len = sizeof ( e_dce_cn_common_hdr_t ) - tvb_length_remaining ( tvb , offset ); <nl> + pinfo -> desegment_len = ( guint32 )( sizeof ( e_dce_cn_common_hdr_t ) - tvb_length_remaining ( tvb , offset )); <nl> } else { <nl> /* Really not DCE - RPC */ <nl> break ;
mmm gtk / packet_list_store . c <nl> ppp gtk / packet_list_store . c <nl> packet_list_sortable_set_sort_column_id ( GtkTreeSortable * sortable , <nl> packet_list -> sort_order == order ) <nl> return ; <nl>  <nl> + if (! col_based_on_frame_data (& cfile . cinfo , sort_col_id )) { <nl> + g_warning (" Sorting on column % u not supported ", sort_col_id ); <nl> + return ; <nl> + } <nl> + <nl> packet_list -> sort_id = sort_col_id ; <nl> packet_list -> sort_order = order ; <nl> 
mmm epan / dissectors / packet - ieee80211 . c <nl> ppp epan / dissectors / packet - ieee80211 . c <nl> static void init_wepkeys ( void ) { <nl>  <nl> # ifdef USE_ENV <nl> buf = ep_alloc ( 128 ); <nl> - sprintf ( buf , 128 , " ETHEREAL_WEPKEY % d ", i + 1 ); <nl> + g_snprintf ( buf , 128 , " ETHEREAL_WEPKEY % d ", i + 1 ); <nl> tmp = getenv ( buf ); <nl> # else <nl> tmp = wep_keystr [ i ];
mmm epan / dissectors / packet - gsm_map . c <nl> ppp epan / dissectors / packet - gsm_map . c <nl> /* Do not modify this file . */ <nl> /* It is created automatically by the ASN . 1 to Ethereal dissector compiler */ <nl> -/* .\ packet - gsm_map . c */ <nl> +/* ./ packet - gsm_map . c */ <nl> /* ../../ tools / asn2eth . py - X - b - e - p gsm_map - c gsmmap . cnf - s packet - gsm_map - template GSMMAP . asn */ <nl>  <nl> /* Input file : packet - gsm_map - template . c */ <nl> static int dissect_returnResultData ( packet_info * pinfo , proto_tree * tree , tvbuff <nl> break ; <nl> case 56 : <nl> offset = dissect_gsm_map_SendAuthenticationInfoRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> + break ; <nl> case 57 : /* restoreData */ <nl> offset = dissect_gsm_map_RestoreDataRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> break ;mmm epan / dissectors / packet - gsm_map . h <nl> ppp epan / dissectors / packet - gsm_map . h <nl> /* Do not modify this file . */ <nl> /* It is created automatically by the ASN . 1 to Ethereal dissector compiler */ <nl> -/* .\ packet - gsm_map . c */ <nl> +/* ./ packet - gsm_map . c */ <nl> /* ../../ tools / asn2eth . py - X - b - e - p gsm_map - c gsmmap . cnf - s packet - gsm_map - template GSMMAP . asn */ <nl>  <nl> /* Input file : packet - gsm_map - template . c */ <nl> static int dissect_returnResultData ( packet_info * pinfo , proto_tree * tree , tvbuff <nl> break ; <nl> case 56 : <nl> offset = dissect_gsm_map_SendAuthenticationInfoRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> + break ; <nl> case 57 : /* restoreData */ <nl> offset = dissect_gsm_map_RestoreDataRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> break ; <nl> /* Do not modify this file . */ <nl> /* It is created automatically by the ASN . 1 to Ethereal dissector compiler */ <nl> -/* .\ packet - gsm_map . h */ <nl> +/* ./ packet - gsm_map . h */ <nl> /* ../../ tools / asn2eth . py - X - b - e - p gsm_map - c gsmmap . cnf - s packet - gsm_map - template GSMMAP . asn */ <nl>  <nl> /* Input file : packet - gsm_map - template . h */mmm asn1 / gsmmap / packet - gsm_map - template . c <nl> ppp asn1 / gsmmap / packet - gsm_map - template . c <nl> /* Do not modify this file . */ <nl> /* It is created automatically by the ASN . 1 to Ethereal dissector compiler */ <nl> -/* .\ packet - gsm_map . c */ <nl> +/* ./ packet - gsm_map . c */ <nl> /* ../../ tools / asn2eth . py - X - b - e - p gsm_map - c gsmmap . cnf - s packet - gsm_map - template GSMMAP . asn */ <nl>  <nl> /* Input file : packet - gsm_map - template . c */ <nl> static int dissect_returnResultData ( packet_info * pinfo , proto_tree * tree , tvbuff <nl> break ; <nl> case 56 : <nl> offset = dissect_gsm_map_SendAuthenticationInfoRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> + break ; <nl> case 57 : /* restoreData */ <nl> offset = dissect_gsm_map_RestoreDataRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> break ; <nl> /* Do not modify this file . */ <nl> /* It is created automatically by the ASN . 1 to Ethereal dissector compiler */ <nl> -/* .\ packet - gsm_map . h */ <nl> +/* ./ packet - gsm_map . h */ <nl> /* ../../ tools / asn2eth . py - X - b - e - p gsm_map - c gsmmap . cnf - s packet - gsm_map - template GSMMAP . asn */ <nl>  <nl> /* Input file : packet - gsm_map - template . h */ <nl> static int dissect_returnResultData ( packet_info * pinfo , proto_tree * tree , tvbuff <nl> break ; <nl> case 56 : <nl> offset = dissect_gsm_map_SendAuthenticationInfoRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> + break ; <nl> case 57 : /* restoreData */ <nl> offset = dissect_gsm_map_RestoreDataRes ( FALSE , tvb , offset , pinfo , tree , - 1 ); <nl> break ;
mmm ui / win32 / file_dlg_win32 . c <nl> ppp ui / win32 / file_dlg_win32 . c <nl> build_file_save_type_list ( GArray * savable_file_types ) { <nl> ft = g_array_index ( savable_file_types , int , i ); <nl> append_file_type ( sa , ft ); <nl> } <nl> - g_array_free ( savable_file_types , TRUE ); <nl> } <nl>  <nl> /* terminate the array */
mmm wiretap / toshiba . c <nl> ppp wiretap / toshiba . c <nl> parse_toshiba_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl> union wtap_pseudo_header * pseudo_header = & phdr -> pseudo_header ; <nl> char line [ TOSHIBA_LINE_LENGTH ]; <nl> int num_items_scanned ; <nl> - guint pkt_len ; <nl> - int pktnum , hr , min , sec , csec ; <nl> + int pkt_len , pktnum , hr , min , sec , csec ; <nl> char channel [ 10 ], direction [ 10 ]; <nl> int i , hex_lines ; <nl> guint8 * pd ; <nl> parse_toshiba_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl>  <nl> } while ( strcmp ( line , " OFFSET 0001 - 0203 ") != 0 ); <nl>  <nl> - num_items_scanned = sscanf ( line + 64 , " LEN =% 9u ", & pkt_len ); <nl> + num_items_scanned = sscanf ( line + 64 , " LEN =% 9d ", & pkt_len ); <nl> if ( num_items_scanned != 1 ) { <nl> * err = WTAP_ERR_BAD_FILE ; <nl> * err_info = g_strdup (" toshiba : OFFSET line doesn ' t have valid LEN item "); <nl> return FALSE ; <nl> } <nl> + if ( pkt_len < 0 ) { <nl> + * err = WTAP_ERR_BAD_FILE ; <nl> + * err_info = g_strdup (" toshiba : packet header has a negative packet length "); <nl> + return FALSE ; <nl> + } <nl> if ( pkt_len > WTAP_MAX_PACKET_SIZE ) { <nl> /* <nl> * Probably a corrupt capture file ; don ' t blow up trying
mmm epan / dissectors / packet - sigcomp . c <nl> ppp epan / dissectors / packet - sigcomp . c <nl> dissect_sigcomp_tcp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * _ <nl>  <nl> col_clear ( pinfo -> cinfo , COL_INFO ); <nl>  <nl> - length = tvb_captured_length_remaining ( tvb , offset ); <nl> + length = tvb_reported_length ( tvb ); <nl>  <nl> try_again : <nl> /* create display subtree for the protocol */
mmm file . c <nl> ppp file . c <nl> cf_print_packets ( capture_file * cf , print_args_t * print_args , <nl> } <nl>  <nl> /* if num_visible_col is 0 , we are done */ <nl> - if ( num_visible_col == 0 ) <nl> + if ( num_visible_col == 0 ) { <nl> + g_free ( callback_args . header_line_buf ); <nl> return CF_PRINT_OK ; <nl> + } <nl>  <nl> /* Find the widths for each of the columns - maximum of the <nl> width of the title and the width of the data - and construct
mmm capture_sync . c <nl> ppp capture_sync . c <nl> sync_pipe_start ( capture_options * capture_opts ) { <nl> execv ( argv [ 0 ], ( gpointer ) argv ); <nl> g_snprintf ( errmsg , sizeof errmsg , " Couldn ' t run % s in child process : % s ", <nl> argv [ 0 ], strerror ( errno )); <nl> - sync_pipe_errmsg_to_parent ( errmsg , ""); <nl> + sync_pipe_errmsg_to_parent ( 1 , errmsg , ""); <nl>  <nl> /* Exit with " _exit ()", so that we don ' t close the connection <nl> to the X server ( and cause stuff buffered up by our parent but <nl> sync_interface_stats_open ( int * read_fd , int * fork_child , gchar ** msg ) { <nl>  <nl> /* Close down the stats process */ <nl> int <nl> - sync_interface_stats_close ( int * read_fd , int * fork_child , gchar ** msg ) { <nl> + sync_interface_stats_close ( int * read_fd , int * fork_child <nl> +# ifndef _WIN32 <nl> + _U_ <nl> +# endif <nl> +, gchar ** msg ) { <nl> # ifdef _WIN32 <nl> return sync_pipe_close_command ( read_fd , fork_child , msg ); <nl> # else
mmm epan / dissectors / packet - kerberos . c <nl> ppp epan / dissectors / packet - kerberos . c <nl> static int wrap_dissect_gss_kerb ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl>  <nl> auth_tvb = tvb_new_subset ( <nl> tvb , offset , tvb_length_remaining ( tvb , offset ), <nl> - tvb_length_remaining ( tvb , offset )); <nl> + tvb_reported_length_remaining ( tvb , offset )); <nl>  <nl> dissect_kerberos_main ( auth_tvb , pinfo , tree , FALSE , NULL ); <nl> mmm epan / dissectors / packet - ber . c <nl> ppp epan / dissectors / packet - ber . c <nl> static int wrap_dissect_gss_kerb ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl>  <nl> auth_tvb = tvb_new_subset ( <nl> tvb , offset , tvb_length_remaining ( tvb , offset ), <nl> - tvb_length_remaining ( tvb , offset )); <nl> + tvb_reported_length_remaining ( tvb , offset )); <nl>  <nl> dissect_kerberos_main ( auth_tvb , pinfo , tree , FALSE , NULL ); <nl>  <nl> call_ber_oid_callback ( char * oid , tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> { <nl> tvbuff_t * next_tvb ; <nl>  <nl> - next_tvb = tvb_new_subset ( tvb , offset , tvb_length_remaining ( tvb , offset ), tvb_length_remaining ( tvb , offset )); <nl> + next_tvb = tvb_new_subset ( tvb , offset , tvb_length_remaining ( tvb , offset ), tvb_reported_length_remaining ( tvb , offset )); <nl> if (! dissector_try_string ( ber_oid_dissector_table , oid , next_tvb , pinfo , tree )){ <nl> proto_item * item = NULL ; <nl> proto_tree * next_tree = NULL ; <nl> printf (" OCTET STRING dissect_ber_octet_string (% s ) entered \ n ", name ); <nl> if ( len <=( guint32 ) tvb_length_remaining ( tvb , offset )){ <nl> * out_tvb = tvb_new_subset ( tvb , offset , len , len ); <nl> } else { <nl> - * out_tvb = tvb_new_subset ( tvb , offset , tvb_length_remaining ( tvb , offset ), tvb_length_remaining ( tvb , offset )); <nl> + * out_tvb = tvb_new_subset ( tvb , offset , tvb_length_remaining ( tvb , offset ), tvb_reported_length_remaining ( tvb , offset )); <nl> } <nl> } <nl> } <nl> ber_sequence_try_again : <nl> * length ) of if the tvb is short , then just <nl> * give it all of the tvb and hope for the best . <nl> */ <nl> - next_tvb = tvb_new_subset ( tvb , hoffset , tvb_length_remaining ( tvb , hoffset ), tvb_length_remaining ( tvb , hoffset )); <nl> + next_tvb = tvb_new_subset ( tvb , hoffset , tvb_length_remaining ( tvb , hoffset ), tvb_reported_length_remaining ( tvb , hoffset )); <nl> } else { <nl> next_tvb = tvb_new_subset ( tvb , hoffset , eoffset - hoffset , eoffset - hoffset ); <nl> } <nl> int dissect_ber_bitstring ( gboolean implicit_tag , packet_info * pinfo , proto_tree <nl> if ( len <=( guint32 ) tvb_length_remaining ( tvb , offset )){ <nl> * out_tvb = tvb_new_subset ( tvb , offset , len , len ); <nl> } else { <nl> - * out_tvb = tvb_new_subset ( tvb , offset , tvb_length_remaining ( tvb , offset ), tvb_length_remaining ( tvb , offset )); <nl> + * out_tvb = tvb_new_subset ( tvb , offset , tvb_length_remaining ( tvb , offset ), tvb_reported_length_remaining ( tvb , offset )); <nl> } <nl> } <nl> }
mmm epan / dissectors / packet - nsip . c <nl> ppp epan / dissectors / packet - nsip . c <nl> decode_pdu_sns_delete ( build_info_t * bi ) { <nl> { NSIP_IE_IP4_ELEMENTS , NSIP_IE_PRESENCE_C , NSIP_IE_FORMAT_TLV , 0 , 0 }, <nl> { NSIP_IE_IP6_ELEMENTS , NSIP_IE_PRESENCE_C , NSIP_IE_FORMAT_TLV , 0 , 0 }, <nl> }; <nl> - decode_iei_transaction_id ( ies , bi , bi -> offset ); <nl> - decode_pdu_general (& ies [ 1 ], 3 , bi ); <nl> + decode_pdu_general ( ies , 1 , bi ); <nl> + decode_iei_transaction_id (& ies [ 1 ], bi , bi -> offset ); <nl> + decode_pdu_general (& ies [ 2 ], 3 , bi ); <nl> } <nl>  <nl> static void
mmm epan / dissectors / packet - cip . c <nl> ppp epan / dissectors / packet - cip . c <nl> static int dissect_cip_attribute ( packet_info * pinfo , proto_tree * tree , proto_ite <nl> /* Convert to nstime epoch */ <nl> computed_time = CIP_TIMEBASE +( temp_data * 60 * 60 * 24 ); <nl> date = gmtime (& computed_time ); <nl> - strftime ( date_str , 20 , "% b % d , % Y ", date ); <nl> + if ( date != NULL ) <nl> + strftime ( date_str , 20 , "% b % d , % Y ", date ); <nl> + else <nl> + g_strlcpy ( date_str , " Not representable ", sizeof date_str ); <nl> proto_tree_add_uint_format_value ( tree , *( attr -> phf ), tvb , offset , 2 , temp_data , "% s ", date_str ); <nl> consumed = 2 ; <nl> break ;
mmm epan / dissectors / packet - quic . c <nl> ppp epan / dissectors / packet - quic . c <nl> dissect_quic_common ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl>  <nl> /* Diversification Nonce */ <nl> if ( puflags & PUFLAGS_DNONCE && quic_info -> version >= 33 ){ <nl> - proto_tree_add_item ( quic_tree , hf_quic_diversification_nonce , tvb , offset , 32 , ENC_NA ); <nl> - offset += 32 ; <nl> + if ( pinfo -> srcport == 443 ){ /* Diversification nonce is only present from server to client */ <nl> + proto_tree_add_item ( quic_tree , hf_quic_diversification_nonce , tvb , offset , 32 , ENC_NA ); <nl> + offset += 32 ; <nl> + } <nl> } <nl>  <nl> - <nl> /* Packet Number */ <nl>  <nl> /* Get len of packet number ( and packet number ), may be a more easy function to get the length ... */
mmm epan / dissectors / packet - imf . c <nl> ppp epan / dissectors / packet - imf . c <nl> header_fields_initialize_cb ( void ) <nl> guint i ; <nl> gchar * header_name ; <nl>  <nl> - if ( custom_field_table ) { <nl> + if ( custom_field_table && hf ) { <nl> guint hf_size = g_hash_table_size ( custom_field_table ); <nl> /* Unregister all fields */ <nl> for ( i = 0 ; i < hf_size ; i ++) {mmm epan / dissectors / packet - http . c <nl> ppp epan / dissectors / packet - http . c <nl> header_fields_initialize_cb ( void ) <nl> guint i ; <nl> gchar * header_name ; <nl>  <nl> - if ( custom_field_table ) { <nl> + if ( custom_field_table && hf ) { <nl> guint hf_size = g_hash_table_size ( custom_field_table ); <nl> /* Unregister all fields */ <nl> for ( i = 0 ; i < hf_size ; i ++) { <nl> header_fields_initialize_cb ( void ) <nl> guint i ; <nl> gchar * header_name ; <nl>  <nl> - if ( header_fields_hash ) { <nl> + if ( header_fields_hash && hf ) { <nl> guint hf_size = g_hash_table_size ( header_fields_hash ); <nl> /* Unregister all fields */ <nl> for ( i = 0 ; i < hf_size ; i ++) {
mmm epan / prefs . c <nl> ppp epan / prefs . c <nl> set_pref ( gchar * pref_name , gchar * value , void * private_data _U_ , <nl> find_index_from_string_array ( value , gui_layout_content_text , 0 ); <nl> } else if ( strcmp ( pref_name , PRS_CONSOLE_LOG_LEVEL ) == 0 ) { <nl> prefs . console_log_level = strtoul ( value , NULL , 10 ); <nl> - if ( prefs . console_log_level & G_LOG_LEVEL_INFO | G_LOG_LEVEL_DEBUG ) { <nl> + if ( prefs . console_log_level & ( G_LOG_LEVEL_INFO | G_LOG_LEVEL_DEBUG )) { <nl> /* <nl> * GLib >= 2 . 32 drops INFO and DEBUG messages by default . Tell <nl> * it not to do that .
mmm epan / dissectors / packet - usb . c <nl> ppp epan / dissectors / packet - usb . c <nl> try_dissect_next_protocol ( proto_tree * parent , tvbuff_t * next_tvb , gint offset , p <nl>  <nl> if ( try_heuristics && dissector_try_heuristic ( heur_subdissector_list , next_tvb , pinfo , parent , usb_conv_info )) { <nl> offset += tvb_length ( next_tvb ); <nl> - } else if ( dissector_try_uint_new ( usb_dissector_table , usb_conv_info -> interfaceClass , next_tvb , pinfo , parent , TRUE , usb_conv_info )) { <nl> + } else if ( usb_dissector_table && <nl> + dissector_try_uint_new ( usb_dissector_table , usb_conv_info -> interfaceClass , next_tvb , pinfo , parent , TRUE , usb_conv_info )) { <nl> offset += tvb_length ( next_tvb ); <nl> } <nl> }
mmm epan / dissectors / packet - gtpv2 . c <nl> ppp epan / dissectors / packet - gtpv2 . c <nl> dissect_gtpv2_pres_rep_area_action ( tvbuff_t * tvb , packet_info * pinfo , proto_tree <nl> if ( length == 1 ) <nl> return ; <nl> /* Octet 6 to 8 Presence Reporting Area Identifier */ <nl> - proto_tree_add_item ( tree , hf_gtpv2_pres_rep_area_id , tvb , offset , 2 , ENC_BIG_ENDIAN ); <nl> - offset += 2 ; <nl> - if ( length == 3 ) <nl> + proto_tree_add_item ( tree , hf_gtpv2_pres_rep_area_id , tvb , offset , 3 , ENC_BIG_ENDIAN ); <nl> + offset += 3 ; <nl> + if ( length == 4 ) <nl> return ; <nl>  <nl> - new_tvb = tvb_new_subset_length ( tvb , offset , length - 3 ); <nl> + new_tvb = tvb_new_subset_length ( tvb , offset , length - 4 ); <nl>  <nl> /* Share the rest of the dissection with the AVP dissector */ <nl> dissect_diameter_3gpp_presence_reporting_area_elements_list ( new_tvb , pinfo , tree , NULL ); <nl> void proto_register_gtpv2 ( void ) <nl> }, <nl> { & hf_gtpv2_pres_rep_area_id , <nl> {" Presence Reporting Area Identifier ", " gtpv2 . pres_rep_area_action . pres_rep_area_id ", <nl> - FT_UINT16 , BASE_HEX , NULL , 0x0 , <nl> + FT_UINT24 , BASE_HEX , NULL , 0x0 , <nl> NULL , HFILL } <nl> }, <nl> { & hf_gtpv2_pres_rep_area_act_no_tai ,
mmm ui / gtk / profile_dlg . c <nl> ppp ui / gtk / profile_dlg . c <nl> fill_list ( GtkWidget * main_w ) <nl> * and use it later without any crashes . This may not be a <nl> * valid assumption . <nl> */ <nl> + g_free ( l_select ); <nl> l_select = ( GtkTreeIter *) g_memdup (& iter , sizeof ( iter )); <nl> } <nl> fl_entry = g_list_next ( fl_entry );
mmm epan / dissectors / packet - catapult - dct2000 . c <nl> ppp epan / dissectors / packet - catapult - dct2000 . c <nl> static void parse_outhdr_string ( const guchar * outhdr_string , gint outhdr_string_ <nl> guint d ; <nl>  <nl> /* Find digits */ <nl> - for ( ; n < outhdr_string_len ; n ++) { <nl> + for ( ; ( n < outhdr_string_len ) && ( number_digits < MAX_OUTHDR_VALUES ); n ++) { <nl> if (! g_ascii_isdigit ( outhdr_string [ n ])) { <nl> break ; <nl> }
mmm plugins / mgcp / packet - mgcp . c <nl> ppp plugins / mgcp / packet - mgcp . c <nl> * PKT - SP - EC - MGCP - I09 - 040113 , January 13 , 2004 , Cable Television <nl> * Laboratories , Inc ., http :// www . PacketCable . com / <nl> * <nl> - * $ Id : packet - mgcp . c , v 1 . 46 2004 / 05 / 30 17 : 58 : 35 etxrab Exp $ <nl> + * $ Id : packet - mgcp . c , v 1 . 47 2004 / 05 / 31 19 : 31 : 14 etxrab Exp $ <nl> * <nl> * Copyright ( c ) 2000 by Ed Warnicke < hagbard @ physics . rutgers . edu > <nl> * Copyright ( c ) 2004 by Thomas Anders < thomas . anders [ AT ] blue - cable . de > <nl> dissect_mgcp_connectionparams ( proto_tree * parent_tree , tvbuff_t * tvb , gint offse <nl> } <nl> offset += tokenlen + 1 ; /* 1 extra for the delimiter */ <nl> } <nl> + g_strfreev ( typval ); <nl> + g_strfreev ( tokens ); <nl> + <nl> } <nl>  <nl> /*
mmm epan / dissectors / packet - corosync - totemnet . c <nl> ppp epan / dissectors / packet - corosync - totemnet . c <nl> dissect_corosynec_totemnet ( tvbuff_t * tvb , <nl> return call_dissector ( corosync_totemsrp_handle , tvb , pinfo , parent_tree ); <nl> } <nl>  <nl> + static void <nl> + corosync_totemnet_shutdown ( void ) <nl> +{ <nl> + g_strfreev ( corosync_totemnet_private_keys_list ); <nl> +} <nl>  <nl> void <nl> proto_register_corosync_totemnet ( void ) <nl> proto_register_corosync_totemnet ( void ) <nl> prefs_register_string_preference ( corosync_totemnet_module , " private_keys ", " Private keys ", <nl> " Semicolon - separated list of keys for decryption ( e . g . key1 ; key2 ;..." , <nl> ( const gchar **)& corosync_totemnet_private_keys ); <nl> + <nl> + register_shutdown_routine ( corosync_totemnet_shutdown ); <nl> } <nl>  <nl> void
mmm epan / dissectors / packet - gsm_a_bssmap . c <nl> ppp epan / dissectors / packet - gsm_a_bssmap . c <nl> be_field_element_dissect ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint <nl> str = match_strval_idx (( guint32 ) oct , bssmap_field_element_ids , & idx ); <nl> ie_len = tvb_get_guint8 ( tvb , curr_offset ++); <nl>  <nl> + if (! str ) <nl> + str = " Unknown "; <nl> + <nl> /* <nl> * add Field Element name <nl> */
mmm packet - dcerpc - mapi . c <nl> ppp packet - dcerpc - mapi . c <nl> * Routines for MS Exchange MAPI <nl> * Copyright 2002 , Ronnie Sahlberg <nl> * <nl> - * $ Id : packet - dcerpc - mapi . c , v 1 . 5 2002 / 05 / 25 09 : 19 : 45 sahlberg Exp $ <nl> + * $ Id : packet - dcerpc - mapi . c , v 1 . 6 2002 / 05 / 25 10 : 25 : 27 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> mapi_decrypt_pdu ( tvbuff_t * tvb , int offset , <nl> proto_tree_add_item ( tr , hf_mapi_decrypted_data , mmd -> tvb , 2 , pdu_len , FALSE ); <nl>  <nl> proto_tree_add_item ( tr , hf_mapi_pdu_trailer , mmd -> tvb , pdu_len , 4 , FALSE ); <nl> - if ( len >( pdu_len + 4 )){ <nl> + if ( len >(( guint32 ) pdu_len + 4 )){ <nl> proto_tree_add_item ( tr , hf_mapi_pdu_extra_trailer , mmd -> tvb , pdu_len + 4 , len -( pdu_len + 4 ), FALSE ); <nl> } <nl> 
mmm epan / dissectors / packet - sua . c <nl> ppp epan / dissectors / packet - sua . c <nl> proto_register_sua ( void ) <nl> " This may affect TCAP ' s ability to recognize which messages belong to which TCAP session .", & set_addresses ); <nl>  <nl> heur_subdissector_list = register_heur_dissector_list (" sua "); <nl> - sua_parameter_table = register_dissector_table (" sua . prop . tags ", " SUA Proprietary Tags ", FT_UINT16 , BASE_DEC , DISSECTOR_TABLE_NOT_ALLOW_DUPLICATE ); <nl> + sua_parameter_table = register_dissector_table (" sua . prop . tags ", " SUA Proprietary Tags ", FT_UINT16 , BASE_DEC , DISSECTOR_TABLE_ALLOW_DUPLICATE ); <nl> sua_tap = register_tap (" sua "); <nl>  <nl> assocs = wmem_tree_new_autoreset ( wmem_epan_scope (), wmem_file_scope ());
mmm wiretap / netmon . c <nl> ppp wiretap / netmon . c <nl> netmon_process_record ( wtap * wth , FILE_T fh , struct wtap_pkthdr * phdr , <nl> switch ( network ) <nl> { <nl> case 0xE080 : // " WiFi Message " <nl> + pkt_encap = WTAP_ENCAP_IEEE_802_11 ; <nl> + break ; <nl> case 0xE081 : // " Ndis Etw WiFi Channel Message " <nl> case 0xE082 : // " Fiddler Netmon Message " <nl> case 0xE089 : // " Pef Ndis Msg ";
mmm epan / dissectors / packet - ssl - utils . c <nl> ppp epan / dissectors / packet - ssl - utils . c <nl> ssl_find_private_key ( SslDecryptSession * ssl_session , GHashTable * key_hash , GTree <nl> ssl_debug_printf (" ssl_find_private_key server % s :% u \ n ", <nl> ep_address_to_str (& dummy . addr ), dummy . port ); <nl>  <nl> + if ( g_hash_table_size ( key_hash ) == 0 ) { <nl> + ssl_debug_printf (" ssl_find_private_key : no keys found \ n "); <nl> + return ; <nl> + } else { <nl> + ssl_debug_printf (" ssl_find_private_key : testing % i keys \ n ", <nl> + g_hash_table_size ( key_hash )); <nl> + } <nl> + <nl> /* try to retrieve private key for this service . Do it now ' cause pinfo <nl> * is not always available <nl> * Note that with HAVE_LIBGNUTLS undefined private_key is allways 0
mmm epan / wslua / wslua_internals . c <nl> ppp epan / wslua / wslua_internals . c <nl> WSLUA_API void wslua_setfuncs ( lua_State * L , const luaL_Reg * l , int nup ) { <nl> } <nl>  <nl> /* identical to lua_getfield but without triggering metamethods */ <nl> - WSLUA_API void lua_rawgetfield ( lua_State * L , int index , const char * k ) { <nl> + WSLUA_API void lua_rawgetfield ( lua_State * L , int idx , const char * k ) { <nl> lua_pushstring ( L , k ); <nl> - lua_rawget ( L , index ); <nl> + lua_rawget ( L , idx ); <nl> } <nl>  <nl> /* identical to lua_setfield but without triggering metamethods */ <nl> - WSLUA_API void lua_rawsetfield ( lua_State * L , int index , const char * k ) { <nl> + WSLUA_API void lua_rawsetfield ( lua_State * L , int idx , const char * k ) { <nl> lua_pushstring ( L , k ); <nl> lua_insert ( L , - 2 ); <nl> - lua_rawset ( L , index ); <nl> + lua_rawset ( L , idx ); <nl> } <nl>  <nl> WSLUA_API void wslua_print_stack ( char * s , lua_State * L ) {
mmm epan / dissectors / packet - gtp . c <nl> ppp epan / dissectors / packet - gtp . c <nl> * Copyright 2011 , Grzegorz Szczytowski < grzegorz . szczytowski @ gmail . com > <nl> * <nl> * Updates and corrections : <nl> - * Copyright 2011 - 2012 , Anders Broman < anders . broman @ ericsson . com > <nl> + * Copyright 2011 - 2013 , Anders Broman < anders . broman @ ericsson . com > <nl> * <nl> * PDCP PDU number extension header support added by Martin Isaksson < martin . isaksson @ ericsson . com > <nl> * <nl> decode_gtp_priv_ext ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , proto_t <nl> offset = offset + 2 ; <nl>  <nl> if ( length > 2 ) { <nl> - next_tvb = tvb_new_subset_remaining ( tvb , offset ); <nl> + next_tvb = tvb_new_subset ( tvb , offset , length - 2 , length - 2 ); <nl> if (! dissector_try_uint ( gtp_priv_ext_dissector_table , ext_id , next_tvb , pinfo , ext_tree_priv_ext )){ <nl> proto_tree_add_item ( ext_tree_priv_ext , hf_gtp_ext_val , tvb , offset , length - 2 , ENC_NA ); <nl> }
mmm epan / dissectors / packet - xot . c <nl> ppp epan / dissectors / packet - xot . c <nl> proto_register_xot ( void ) <nl> proto_xot = proto_register_protocol (" X . 25 over TCP ", " XOT ", " xot "); <nl> proto_register_field_array ( proto_xot , hf , array_length ( hf )); <nl> proto_register_subtree_array ( ett , array_length ( ett )); <nl> + register_dissector (" xot ", dissect_xot , proto_xot ); <nl>  <nl> xot_module = prefs_register_protocol ( proto_xot , NULL ); <nl> prefs_register_bool_preference ( xot_module , " desegment ",
mmm epan / crypt / airpdcap . c <nl> ppp epan / crypt / airpdcap . c <nl> AirPDcapDecryptWPABroadcastKey ( const EAPOL_RSN_KEY * pEAPKey , guint8 * decryption <nl> } else if ( key_version == AIRPDCAP_WPA_KEY_VER_AES_CCMP ){ <nl> /* AES */ <nl> key_bytes_len = pntoh16 ( pEAPKey -> key_data_len ); <nl> + <nl> + /* AES keys must be at least 128 bits = 16 bytes . */ <nl> + if ( key_bytes_len < 16 ) { <nl> + return ; <nl> + } <nl> } <nl>  <nl> if ( key_bytes_len > TKIP_GROUP_KEYBYTES_LEN_MAX || key_bytes_len == 0 ) { /* Don ' t read past the end of pEAPKey -> ie */
mmm epan / dissectors / packet - ssl - utils . c <nl> ppp epan / dissectors / packet - ssl - utils . c <nl> ssl_association_remove ( GTree * associations , SslAssociation * assoc ) <nl> if ( assoc -> handle ) <nl> dissector_delete (( assoc -> tcp )?" tcp . port ":" udp . port ", assoc -> ssl_port , assoc -> handle ); <nl>  <nl> + g_free ( assoc -> info ); <nl> + <nl> g_tree_remove ( associations , assoc ); <nl> g_free ( assoc ); <nl> }
mmm wiretap / netscreen . c <nl> ppp wiretap / netscreen . c <nl> parse_netscreen_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl>  <nl> phdr -> rec_type = REC_TYPE_PACKET ; <nl> phdr -> presence_flags = WTAP_HAS_TS | WTAP_HAS_CAP_LEN ; <nl> + /* Suppress compiler warnings */ <nl> + memset ( cap_int , 0 , sizeof ( cap_int )); <nl> + memset ( cap_dst , 0 , sizeof ( cap_dst )); <nl>  <nl> if ( sscanf ( line , "% 9d .% 9d : % 15 [ a - z0 - 9 /:.-](% 1 [ io ]) len =% 9d :% 12s ->% 12s /", <nl> & sec , & dsec , cap_int , direction , & pkt_len , cap_src , cap_dst ) < 5 ) {
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> * the data of a backing tvbuff , or can be a composite of <nl> * other tvbuffs . <nl> * <nl> - * $ Id : tvbuff . c , v 1 . 63 2004 / 05 / 06 17 : 40 : 52 obiot Exp $ <nl> + * $ Id : tvbuff . c , v 1 . 64 2004 / 05 / 07 18 : 15 : 24 obiot Exp $ <nl> * <nl> * Copyright ( c ) 2000 by Gilbert Ramirez < gram @ alumni . rice . edu > <nl> * <nl> tvb_uncompress ( tvbuff_t * tvb , int offset , int comprlen ) <nl> if ( uncompr != NULL ) { <nl> uncompr_tvb = tvb_new_real_data (( guint8 *) uncompr , bytes_out , <nl> bytes_out ); <nl> + tvb_set_free_cb ( uncompr_tvb , g_free ); <nl> } <nl> g_free ( compr ); <nl> return uncompr_tvb ;
mmm epan / emem . c <nl> ppp epan / emem . c <nl> emem_scrub_memory ( char * buf , size_t size , gboolean alloc ) <nl>  <nl> } <nl>  <nl> - static void <nl> - emem_create_chunk ( emem_chunk_t ** free_list , gboolean use_canary ) { <nl> + static emem_chunk_t * <nl> + emem_create_chunk ( gboolean use_canary ) { <nl> # if defined ( _WIN32 ) <nl> BOOL ret ; <nl> char * buf_end , * prot1 , * prot2 ; <nl> emem_create_chunk ( emem_chunk_t ** free_list , gboolean use_canary ) { <nl> # endif /* _WIN32 / USE_GUARD_PAGES */ <nl> emem_chunk_t * npc ; <nl>  <nl> - /* we dont have any free data , so we must allocate a new one */ <nl> - DISSECTOR_ASSERT (!* free_list ); <nl> - <nl> npc = g_new ( emem_chunk_t , 1 ); <nl> npc -> next = NULL ; <nl> if ( use_canary ) { <nl> emem_create_chunk ( emem_chunk_t ** free_list , gboolean use_canary ) { <nl> else <nl> npc -> canary_info = NULL ; <nl>  <nl> - * free_list = npc ; <nl> - <nl> # if defined ( _WIN32 ) <nl> /* <nl> * MSDN documents VirtualAlloc / VirtualProtect at <nl> emem_create_chunk ( emem_chunk_t ** free_list , gboolean use_canary ) { <nl> # endif <nl>  <nl> if ( npc -> buf == NULL ) { <nl> + g_free ( npc ); <nl> THROW ( OutOfMemoryError ); <nl> } <nl>  <nl> emem_create_chunk ( emem_chunk_t ** free_list , gboolean use_canary ) { <nl>  <nl> npc -> amount_free = npc -> amount_free_init ; <nl> npc -> free_offset = npc -> free_offset_init ; <nl> + return npc ; <nl> } <nl>  <nl> static void * <nl> emem_alloc_chunk ( size_t size , emem_header_t * mem ) <nl> DISSECTOR_ASSERT ( size <( EMEM_PACKET_CHUNK_SIZE >> 2 )); <nl>  <nl> if (! mem -> free_list ) <nl> - emem_create_chunk (& mem -> free_list , use_canary ); <nl> + mem -> free_list = emem_create_chunk ( use_canary ); <nl>  <nl> /* oops , we need to allocate more memory to serve this request <nl> * than we have free . move this node to the used list and try again <nl> emem_alloc_chunk ( size_t size , emem_header_t * mem ) <nl> mem -> used_list = npc ; <nl>  <nl> if (! mem -> free_list ) <nl> - emem_create_chunk (& mem -> free_list , use_canary ); <nl> + mem -> free_list = emem_create_chunk ( use_canary ); <nl> } <nl>  <nl> free_list = mem -> free_list ;
mmm epan / dissectors / packet - etsi_card_app_toolkit . c <nl> ppp epan / dissectors / packet - etsi_card_app_toolkit . c <nl> dissect_cat ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> break ; <nl> case 0x05 : /* alpha identifier */ <nl> break ; <nl> + case 0x06 : /* address */ <nl> + de_cld_party_bcd_num ( tvb , elem_tree , pinfo , pos , len , NULL , 0 ); <nl> + break ; <nl> case 0x0b : /* sms tpdu */ <nl> new_tvb = tvb_new_subset ( tvb , pos , len , len ); <nl> if ( new_tvb ) {
mmm epan / dissectors / packet - zebra . c <nl> ppp epan / dissectors / packet - zebra . c <nl> static const value_string families [] = { <nl>  <nl> # define PSIZE ( a ) ((( a ) + 7 ) / ( 8 )) <nl>  <nl> - static void <nl> + static int <nl> dissect_zebra_request ( proto_tree * tree , gboolean request , tvbuff_t * tvb , <nl> int offset , guint16 len , guint8 command ) <nl> { <nl> dissect_zebra_request ( proto_tree * tree , gboolean request , tvbuff_t * tvb , <nl> /* Not yet implemeted in ZEBRA */ <nl> break ; <nl> } <nl> + return offset ; <nl> } <nl>  <nl> static void
mmm epan / wslua / wslua_util . c <nl> ppp epan / wslua / wslua_util . c <nl> WSLUA_METAMETHOD Dir__call ( lua_State * L ) { <nl> const gchar * filename ; <nl> const char * ext ; <nl>  <nl> - if (! dir ) <nl> + if (! dir ) { <nl> luaL_argerror ( L , 1 ," must be a Dir "); <nl> + return 0 ; <nl> + } <nl>  <nl> if (! dir -> dir ) { <nl> return 0 ;
mmm epan / dissectors / packet - mongo . c <nl> ppp epan / dissectors / packet - mongo . c <nl> dissect_bson_document ( tvbuff_t * tvb , packet_info * pinfo , guint offset , proto_tre <nl>  <nl> return document_length ; <nl> } <nl> + <nl> static int <nl> dissect_mongo_reply ( tvbuff_t * tvb , packet_info * pinfo , guint offset , proto_tree * tree ) <nl> { <nl> dissect_mongo_reply ( tvbuff_t * tvb , packet_info * pinfo , guint offset , proto_tree <nl> } <nl> return offset ; <nl> } <nl> + <nl> static int <nl> dissect_mongo_msg ( tvbuff_t * tvb , guint offset , proto_tree * tree ) <nl> { <nl> dissect_mongo_kill_cursors ( tvbuff_t * tvb , guint offset , proto_tree * tree ) <nl> } <nl> return offset ; <nl> } <nl> + <nl> static int <nl> dissect_mongo_pdu ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ ) <nl> { <nl> proto_register_mongo ( void ) <nl>  <nl> proto_mongo = proto_register_protocol (" Mongo Wire Protocol ", " MONGO ", " mongo "); <nl>  <nl> + /* Allow dissector to find be found by name . */ <nl> + new_register_dissector (" mongo ", dissect_mongo , proto_mongo ); <nl> + <nl> proto_register_field_array ( proto_mongo , hf , array_length ( hf )); <nl> proto_register_subtree_array ( ett , array_length ( ett )); <nl> expert_mongo = expert_register_protocol ( proto_mongo );
mmm plugins / megaco / packet - megaco . c <nl> ppp plugins / megaco / packet - megaco . c <nl> static gint tvb_skip_wsp ( tvbuff_t * tvb , gint offset ){ <nl>  <nl> for ( counter = offset ; counter < end && <nl> (( tempchar = tvb_get_guint8 ( tvb , counter )) == ' ' || <nl> - tempchar == '\ t '|| tempchar == '\ n '); counter ++); <nl> + tempchar == '\ t ' || tempchar == '\ n ' || tempchar == '\ r '); counter ++); <nl> return ( counter ); <nl> } <nl> static gint tvb_skip_wsp_return ( tvbuff_t * tvb , gint offset ){ <nl> static gint tvb_skip_wsp_return ( tvbuff_t * tvb , gint offset ){ <nl>  <nl> for ( counter = offset ; counter > end && <nl> (( tempchar = tvb_get_guint8 ( tvb , counter )) == ' ' || <nl> - tempchar == '\ t '|| tempchar == '\ n '); counter --); <nl> + tempchar == '\ t ' || tempchar == '\ n ' || tempchar == '\ r '); counter --); <nl> counter ++; <nl> return ( counter ); <nl> }
mmm epan / dissectors / packet - websocket . c <nl> ppp epan / dissectors / packet - websocket . c <nl> dissect_websocket_frame ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , voi <nl> if ( http_conv ) { <nl> websocket_conv -> subprotocol = http_conv -> websocket_protocol ; <nl> websocket_conv -> server_port = http_conv -> server_port ; <nl> - websocket_parse_extensions ( websocket_conv , http_conv -> websocket_extensions ); <nl> + if ( http_conv -> websocket_extensions ) { <nl> + websocket_parse_extensions ( websocket_conv , http_conv -> websocket_extensions ); <nl> + } <nl> } <nl>  <nl> conversation_add_proto_data ( conv , proto_websocket , websocket_conv );
mmm epan / dissectors / packet - manolito . c <nl> ppp epan / dissectors / packet - manolito . c <nl> dissect_manolito ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * diss <nl> 4 + length , str , "% s (% s ): % s ", ( char *) field_name_str , longname , str ); <nl> offset += length ; <nl> } else if ( dtype == MANOLITO_INTEGER ) { <nl> + gboolean len_ok = TRUE ; <nl> guint64 n = 0 ; <nl>  <nl> /* integers can be up to 5 bytes */ <nl> dissect_manolito ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * diss <nl> case 1 : <nl> n = tvb_get_guint8 ( tvb , offset ); <nl> break ; <nl> + <nl> + default : <nl> + len_ok = FALSE ; <nl> } <nl>  <nl> - ti = proto_tree_add_uint64_format ( manolito_tree , hf_manolito_integer , tvb , start , <nl> - 4 + length , n , "% s (% s ): %" G_GINT64_MODIFIER " u ", <nl> - ( char *) field_name_str , longname , n ); <nl> + if ( len_ok ) { <nl> + ti = proto_tree_add_uint64_format ( manolito_tree , hf_manolito_integer , tvb , start , <nl> + 4 + length , n , "% s (% s ): %" G_GINT64_MODIFIER " u ", <nl> + ( char *) field_name_str , longname , n ); <nl> + } <nl> + else { <nl> + /* XXX - expert info */ <nl> + } <nl> offset += length ; <nl> } else { <nl> proto_tree_add_expert_format ( manolito_tree , pinfo , & ei_manolito_type ,
mmm packet - zebra . c <nl> ppp packet - zebra . c <nl> * <nl> * Jochen Friedrich < jochen @ scram . de > <nl> * <nl> - * $ Id : packet - zebra . c , v 1 . 20 2002 / 01 / 24 09 : 20 : 54 guy Exp $ <nl> + * $ Id : packet - zebra . c , v 1 . 21 2002 / 04 / 02 01 : 32 : 11 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> dissect_zebra_request ( proto_tree * tree , gboolean request , tvbuff_t * tvb , <nl> guint32 prefix4 ; <nl> guint16 i ; <nl> guint8 buffer6 [ 16 ], prefixlen , message ; <nl> - const guint8 * prefix ; <nl> proto_item * ti ; <nl> proto_tree * msg_tree ; <nl>  <nl> dissect_zebra_request ( proto_tree * tree , gboolean request , tvbuff_t * tvb , <nl> offset , 1 , prefixlen ); <nl> offset += 1 ; <nl>  <nl> - prefix = tvb_get_ptr ( tvb , offset , PSIZE ( prefixlen )); <nl> prefix4 = 0 ; <nl> - memcpy (& prefix4 , prefix , <nl> + tvb_memcpy ( tvb , ( guint8 *)& prefix4 , offset , <nl> MIN (( unsigned ) PSIZE ( prefixlen ), sizeof prefix4 )); <nl> proto_tree_add_ipv4 ( tree , hf_zebra_prefix4 , <nl> tvb , offset , PSIZE ( prefixlen ), prefix4 ); <nl> dissect_zebra_request ( proto_tree * tree , gboolean request , tvbuff_t * tvb , <nl> offset , 1 , prefixlen ); <nl> offset += 1 ; <nl>  <nl> - prefix = tvb_get_ptr ( tvb , offset , PSIZE ( prefixlen )); <nl> memset ( buffer6 , '\ 0 ', sizeof buffer6 ); <nl> - memcpy ( buffer6 , prefix , <nl> + tvb_memcpy ( tvb , buffer6 , offset , <nl> MIN (( unsigned ) PSIZE ( prefixlen ), sizeof buffer6 )); <nl> proto_tree_add_ipv6 ( tree , hf_zebra_prefix6 , <nl> tvb , offset , PSIZE ( prefixlen ), buffer6 );
mmm epan / dissectors / packet - ieee80211 - radiotap - iter . c <nl> ppp epan / dissectors / packet - ieee80211 - radiotap - iter . c <nl> int ieee80211_radiotap_iterator_init ( <nl>  <nl> /* find payload start allowing for extended bitmap ( s ) */ <nl> if ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> + if (! ITERATOR_VALID ( iterator , sizeof ( guint32 ))) <nl> + return - EINVAL ; <nl> while ( get_unaligned_le32 ( iterator -> _arg ) & <nl> ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> iterator -> _arg += sizeof ( guint32 );
mmm ui / win32 / file_dlg_win32 . c <nl> ppp ui / win32 / file_dlg_win32 . c <nl> gboolean win32_save_as_statstree ( HWND h_wnd , GString * file_name , int * file_type ) <nl> return gsfn_ok ; <nl> } <nl>  <nl> - <nl> + <nl> gboolean <nl> win32_export_specified_packets_file ( HWND h_wnd , capture_file * cf , <nl> GString * file_name , <nl> win32_export_sslkeys_file ( HWND h_wnd ) { <nl> OPENFILENAME * ofn ; <nl> TCHAR file_name [ MAX_PATH ] = _T (""); <nl> char * dirname ; <nl> - gchar * keylist ; <nl> + gchar * keylist = NULL ; <nl> char * file_name8 ; <nl> int fd ; <nl> int ofnsize ;
mmm epan / dissectors / packet - mim . c <nl> ppp epan / dissectors / packet - mim . c <nl> proto_reg_handoff_fabricpath ( void ) <nl> /* <nl> dissector_handle_t fp_handle ; <nl> fp_handle = new_create_dissector_handle ( dissect_fp , proto_fp ); <nl> - dissector_add (" ethertype ", ETHERTYPE_DCE , fp_handle ); <nl> + dissector_add_uint (" ethertype ", ETHERTYPE_DCE , fp_handle ); <nl> */ <nl> static gboolean prefs_initialized = FALSE ; <nl> 
mmm ui / gtk / simple_dialog . c <nl> ppp ui / gtk / simple_dialog . c <nl> do_simple_message_box ( ESD_TYPE_E type , gboolean * notagain , <nl> if ( notagain != NULL ) { <nl> checkbox = gtk_check_button_new_with_label (" Don ' t show this message again ."); <nl> gtk_container_set_border_width ( GTK_CONTAINER ( checkbox ), 12 ); <nl> - gtk_box_pack_start ( GTK_BOX ( gtk_message_dialog_get_message_area ( GTK_MESSAGE_DIALOG ( msg_dialog ))), checkbox , <nl> - TRUE , TRUE , 0 ); <nl> + gtk_box_pack_start ( GTK_BOX ( gtk_dialog_get_content_area ( GTK_DIALOG ( msg_dialog ))), <nl> + checkbox , TRUE , TRUE , 0 ); <nl> gtk_widget_show ( checkbox ); <nl> } <nl> 
mmm epan / epan . h <nl> ppp epan / epan . h <nl> typedef struct _epan_dissect_t epan_dissect_t ; <nl> # include " dfilter / dfilter . h " <nl>  <nl> /* init the whole epan module , this is used to be called only once in a program */ <nl> - void epan_init ( void (* register_all_protocols )( register_cb cb , gpointer client_data ), <nl> - void (* register_all_handoffs )( register_cb cb , gpointer client_data ), <nl> + void epan_init ( void (* register_all_protocols_func )( register_cb cb , gpointer client_data ), <nl> + void (* register_all_handoffs_func )( register_cb cb , gpointer client_data ), <nl> register_cb cb , <nl> void * client_data , <nl> void (* report_failure )( const char *, va_list ),mmm epan / epan . c <nl> ppp epan / epan . c <nl> typedef struct _epan_dissect_t epan_dissect_t ; <nl> # include " dfilter / dfilter . h " <nl>  <nl> /* init the whole epan module , this is used to be called only once in a program */ <nl> - void epan_init ( void (* register_all_protocols )( register_cb cb , gpointer client_data ), <nl> - void (* register_all_handoffs )( register_cb cb , gpointer client_data ), <nl> + void epan_init ( void (* register_all_protocols_func )( register_cb cb , gpointer client_data ), <nl> + void (* register_all_handoffs_func )( register_cb cb , gpointer client_data ), <nl> register_cb cb , <nl> void * client_data , <nl> void (* report_failure )( const char *, va_list ), <nl> epan_get_version ( void ) { <nl> } <nl>  <nl> void <nl> - epan_init ( void (* register_all_protocols )( register_cb cb , gpointer client_data ), <nl> - void (* register_all_handoffs )( register_cb cb , gpointer client_data ), <nl> + epan_init ( void (* register_all_protocols_func )( register_cb cb , gpointer client_data ), <nl> + void (* register_all_handoffs_func )( register_cb cb , gpointer client_data ), <nl> register_cb cb , <nl> gpointer client_data , <nl> void (* report_failure )( const char *, va_list ), <nl> epan_init ( void (* register_all_protocols )( register_cb cb , gpointer client_data ), <nl> tvbuff_init (); <nl> tap_init (); <nl> prefs_init (); <nl> - proto_init ( register_all_protocols , register_all_handoffs , cb , client_data ); <nl> + proto_init ( register_all_protocols_func , register_all_handoffs_func , <nl> + cb , client_data ); <nl> packet_init (); <nl> dfilter_init (); <nl> final_registration_all_protocols ();
mmm ui / gtk / capture_dlg . c <nl> ppp ui / gtk / capture_dlg . c <nl> capture_all_filter_check_syntax_cb ( GtkWidget * w _U_ , gpointer user_data _U_ ) <nl> } <nl> # ifdef HAVE_EXTCAP <nl> /* Can ' t verify extcap capture filters */ <nl> - if ( device . if_info . extcap != NULL ) <nl> + if ( device . if_info . extcap != NULL && strlen ( device . if_info . extcap ) > 0 ) <nl> continue ; <nl> # endif <nl> filter_text = gtk_combo_box_text_get_active_text ( GTK_COMBO_BOX_TEXT ( filter_cm ));
mmm plugins / profinet / packet - dcerpc - pn - io . c <nl> ppp plugins / profinet / packet - dcerpc - pn - io . c <nl> static expert_field ei_pn_io_error_code2 = EI_INIT ; <nl> static expert_field ei_pn_io_ar_info_not_found = EI_INIT ; <nl> static expert_field ei_pn_io_iocr_type = EI_INIT ; <nl> static expert_field ei_pn_io_frame_id = EI_INIT ; <nl> + static expert_field ei_pn_io_nr_of_tx_port_groups = EI_INIT ; <nl>  <nl> static e_uuid_t uuid_pn_io_device = { 0xDEA00001 , 0x6C97 , 0x11D1 , { 0x82 , 0x71 , 0x00 , 0xA0 , 0x24 , 0x42 , 0xDF , 0x7D } }; <nl> static guint16 ver_pn_io_device = 1 ; <nl> dissect_PDIRFrameData_block ( tvbuff_t * tvb , int offset , <nl> offset = dissect_dcerpc_uint8 ( tvb , offset , pinfo , sub_tree , drep , <nl> hf_pn_io_frame_details_reserved , & u8FrameDetails ); <nl> /* TxPortGroup */ <nl> - offset = dissect_dcerpc_uint8 ( tvb , offset , pinfo , ir_frame_data_tree , drep , <nl> - hf_pn_io_nr_of_tx_port_groups , & u8NumberOfTxPortGroups ); <nl> + u8NumberOfTxPortGroups = tvb_get_guint8 ( tvb , offset ); <nl> + sub_item = proto_tree_add_uint ( ir_frame_data_tree , hf_pn_io_nr_of_tx_port_groups , <nl> + tvb , offset , 1 , u8NumberOfTxPortGroups ); <nl> + offset ++; <nl> if (( u8NumberOfTxPortGroups > 21 ) || (( u8NumberOfTxPortGroups & 0x1 ) != 1 )) { <nl> - proto_tree_add_text ( ir_frame_data_tree , tvb , offset - 1 , 1 , " Not allowed value of NumberOfTxPortGroups "); <nl> + expert_add_info ( pinfo , sub_item , & ei_pn_io_nr_of_tx_port_groups ); <nl> } <nl>  <nl> /* TxPortArray */ <nl> proto_register_pn_io ( void ) <nl> { & ei_pn_io_frame_id , { " pn_io . frame_id . changed ", PI_UNDECODED , PI_WARN , " FrameID changed ", EXPFILL }}, <nl> { & ei_pn_io_iocr_type , { " pn_io . iocr_type . unknown ", PI_UNDECODED , PI_WARN , " IOCRType undecoded !", EXPFILL }}, <nl> { & ei_pn_io_localalarmref , { " pn_io . localalarmref . changed ", PI_UNDECODED , PI_WARN , " AlarmCRBlockReq : local alarm ref changed ", EXPFILL }}, <nl> + { & ei_pn_io_nr_of_tx_port_groups , { " pn_io . nr_of_tx_port_groups . not_allowed ", PI_PROTOCOL , PI_WARN , " Not allowed value of NumberOfTxPortGroups ", EXPFILL }}, <nl> }; <nl>  <nl> expert_module_t * expert_pn_io ;
mmm epan / dissectors / packet - snmp . c <nl> ppp epan / dissectors / packet - snmp . c <nl> extern int dissect_snmp_VarBind ( gboolean implicit_tag _U_ , <nl>  <nl> add_oid_debug_subtree ( oid_info , pt_name ); <nl>  <nl> - if ( subids && oid_matched + oid_left ) { <nl> + if (! subids ) { <nl> + proto_item * pi = proto_tree_add_text ( pt_name , tvb , 0 , 0 , " invalid oid : % s ", oid_bytes ); <nl> + pt = proto_item_add_subtree ( pi , ett_decoding_error ); <nl> + expert_add_info_format ( actx -> pinfo , pi , PI_MALFORMED , PI_WARN , " invalid oid : % s ", oid_bytes ); <nl> + return dissect_unknown_ber ( actx -> pinfo , tvb , name_offset , pt ); <nl> + } <nl> + <nl> + if ( oid_matched + oid_left ) { <nl> oid_string = oid_subid2string ( subids , oid_matched + oid_left ); <nl> } <nl> 
mmm ui / qt / packet_list . cpp <nl> ppp ui / qt / packet_list . cpp <nl> void PacketList :: columnsChanged () <nl> setColumnVisibility (); <nl> create_far_overlay_ = true ; <nl> packet_list_model_ -> resetColumns (); <nl> + applyRecentColumnWidths (); <nl> columns_changed_ = false ; <nl> } <nl>  <nl> void PacketList :: setCaptureFile ( capture_file * cf ) <nl> cap_file_ = cf ; <nl> if ( cap_file_ && columns_changed_ ) { <nl> columnsChanged (); <nl> - applyRecentColumnWidths (); <nl> } <nl> packet_list_model_ -> setCaptureFile ( cf ); <nl> create_near_overlay_ = true ;
mmm gtk / gui_utils . c <nl> ppp gtk / gui_utils . c <nl> str_ptr_data_func ( GtkTreeViewColumn * column _U_ , <nl> GtkTreeModel * model , <nl> GtkTreeIter * iter , <nl> gpointer user_data ) <nl> - { <nl> + { <nl> const gchar * str = NULL ; <nl>  <nl> /* The col to get data from is in userdata */ <nl> str_ptr_sort_func ( GtkTreeModel * model , <nl> gtk_tree_model_get ( model , a , data_column , & str_a , - 1 ); <nl> gtk_tree_model_get ( model , b , data_column , & str_b , - 1 ); <nl>  <nl> - if ( str_a == NULL || str_b == NULL ){ <nl> - if ( str_a == NULL && str_b == NULL ) <nl> - return 0 ; <nl> + if ( str_a == str_b ) { <nl> + /* it ' s worth testing because a lot of row point to <nl> + the same data */ <nl> + return 0 ; <nl> + } <nl> + else if ( str_a == NULL || str_b == NULL ) { <nl> ret = ( str_a == NULL ) ? - 1 : 1 ; <nl> - } else { <nl> + } <nl> + else { <nl> ret = g_ascii_strcasecmp ( str_a , str_b ); <nl> } <nl> return ret ;
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> tvb_uncompress ( tvbuff_t * tvb , int offset , int comprlen ) <nl> compr = tvb_memdup ( tvb , offset , comprlen ); <nl>  <nl> if (! compr ) { <nl> + g_free ( strm ); <nl> return NULL ; <nl> } <nl>  <nl> tvb_uncompress ( tvbuff_t * tvb , int offset , int comprlen ) <nl>  <nl> if ( strmbuf == NULL ) { <nl> g_free ( compr ); <nl> + g_free ( strm ); <nl> return NULL ; <nl> } <nl> 
mmm epan / dissectors / packet - usb . c <nl> ppp epan / dissectors / packet - usb . c <nl> dissect_usb_common ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent , <nl> guint8 header_info ) <nl> { <nl> gint offset = 0 ; <nl> - gint new_offset ; <nl> int endpoint ; <nl> gint type_2 = 0 ; <nl> guint8 urb_type ; <nl> dissect_usb_common ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent , <nl> default : <nl> /* Try to find a non - standard specific dissector */ <nl> if ( tvb_reported_length_remaining ( tvb , offset ) != 0 ) { <nl> - next_tvb = tvb_new_subset_remaining ( tvb , offset ); <nl> - new_offset = try_dissect_next_protocol ( tree , parent , next_tvb , offset , pinfo , usb_conv_info , type_2 , urb_type , NULL , NULL ); <nl> - if ( new_offset > offset ) <nl> - offset = new_offset ; <nl> + gint new_offset ; <nl> + next_tvb = tvb_new_subset_remaining ( tvb , offset ); <nl> + new_offset = try_dissect_next_protocol ( tree , parent , next_tvb , offset , pinfo , usb_conv_info , type_2 , urb_type , NULL , NULL ); <nl> + if ( new_offset > offset ) <nl> + offset = new_offset ; <nl> } <nl>  <nl> if ( tvb_reported_length_remaining ( tvb , offset ) != 0 ) {
mmm capture_loop . c <nl> ppp capture_loop . c <nl> capture_loop_start ( capture_options * capture_opts , gboolean * stats_known , struct <nl> /* We haven ' t yet gotten the capture statistics . */ <nl> * stats_known = FALSE ; <nl>  <nl> -# ifndef _WIN32 <nl> +# ifdef _WIN32 <nl> + /* get the initial state of the signal pipe */ <nl> + /* ( if it ' s already stopped here , ignore it later ) */ <nl> + signal_pipe_enabled = ! signal_pipe_stopped (); <nl> +# else <nl> /* <nl> * Catch SIGUSR1 , so that we exit cleanly if the parent process <nl> * kills us with it due to the user selecting " Capture -> Stop ". <nl> capture_loop_start ( capture_options * capture_opts , gboolean * stats_known , struct <nl> signal ( SIGUSR1 , capture_loop_stop_signal_handler ); <nl> # endif <nl>  <nl> - /* get the initial state of the signal pipe */ <nl> - /* ( if it ' s already stopped here , ignore it later ) */ <nl> - signal_pipe_enabled = ! signal_pipe_stopped (); <nl> - <nl> g_log ( LOG_DOMAIN_CAPTURE_CHILD , G_LOG_LEVEL_INFO , " Capture child starting ..."); <nl> capture_opts_log ( LOG_DOMAIN_CAPTURE_CHILD , G_LOG_LEVEL_DEBUG , capture_opts ); <nl> 
mmm proto . c <nl> ppp proto . c <nl> /* proto . c <nl> * Routines for protocol tree <nl> * <nl> - * $ Id : proto . c , v 1 . 59 2000 / 04 / 04 06 : 17 : 29 guy Exp $ <nl> + * $ Id : proto . c , v 1 . 60 2000 / 04 / 04 17 : 07 : 07 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> proto_tree_add_bytes_format ( proto_tree * tree , int hfindex , gint start , gint leng <nl> static void <nl> proto_tree_set_bytes ( field_info * fi , const guint8 * start_ptr , gint length ) <nl> { <nl> - <nl> + g_assert ( start_ptr != NULL ); <nl> + g_assert ( length > 0 ); <nl> /* This g_malloc ' ed memory is freed in <nl> proto_tree_free_node () */ <nl> fi -> value . bytes = g_malloc ( length ); <nl> proto_tree_add_field_info ( int hfindex , gint start , gint length , int visible ) <nl>  <nl> fi = g_mem_chunk_alloc ( gmc_field_info ); <nl>  <nl> + g_assert ( hfindex >= 0 && hfindex < gpa_hfinfo -> len ); <nl> fi -> hfinfo = proto_registrar_get_nth ( hfindex ); <nl> g_assert ( fi -> hfinfo != NULL ); <nl> fi -> start = start ;
mmm epan / dissectors / packet - telnet . c <nl> ppp epan / dissectors / packet - telnet . c <nl> unescape_and_tvbuffify_telnet_option ( packet_info * pinfo , tvbuff_t * tvb , int offs <nl> return NULL ; <nl>  <nl> spos = tvb_get_ptr ( tvb , offset , len ); <nl> - /* XXX we never g_free () this one . This is done automagically <nl> - when the parent tvb is destroyed ? <nl> - */ <nl> buf = g_malloc ( len ); <nl> dpos = buf ; <nl> skip = 0 ; <nl> unescape_and_tvbuffify_telnet_option ( packet_info * pinfo , tvbuff_t * tvb , int offs <nl> l --; <nl> } <nl> krb5_tvb = tvb_new_real_data ( buf , len - skip , len - skip ); <nl> + tvb_set_free_cb ( krb5_tvb , g_free ); <nl> tvb_set_child_real_data_tvbuff ( tvb , krb5_tvb ); <nl> add_new_data_source ( pinfo , krb5_tvb , " Unpacked Telnet Uption "); <nl> 
mmm epan / dissectors / packet - umts_fp . c <nl> ppp epan / dissectors / packet - umts_fp . c <nl> check_payload_crc_for_heur ( tvbuff_t * tvb , guint16 header_length ) <nl> static guint32 <nl> generate_ue_id_for_heur ( packet_info * pinfo ) <nl> { <nl> - if ( pinfo -> ptype != PT_UDP && pinfo -> src . type == AT_IPv4 && pinfo -> dst . type == AT_IPv4 ) { <nl> + if ( pinfo -> ptype == PT_UDP && pinfo -> src . type == AT_IPv4 && pinfo -> dst . type == AT_IPv4 ) { <nl> /* This logic assumes FP is delivered over IP / UDP */ <nl> /* Will return the same ID even if the address and ports are reversed */ <nl> 
mmm epan / crypt / dot11decrypt . c <nl> ppp epan / crypt / dot11decrypt . c <nl> Dot11DecryptDecryptWPABroadcastKey ( const EAPOL_RSN_KEY * pEAPKey , guint8 * decrypt <nl> DEBUG_DUMP (" FullDecrKey :", new_key , 32 ); <nl>  <nl> if ( gcry_cipher_open (& rc4_handle , GCRY_CIPHER_ARCFOUR , GCRY_CIPHER_MODE_STREAM , 0 )) { <nl> + g_free ( szEncryptedKey ); <nl> return DOT11DECRYPT_RET_NO_VALID_HANDSHAKE ; <nl> } <nl> if ( gcry_cipher_setkey ( rc4_handle , new_key , sizeof ( new_key ))) { <nl> gcry_cipher_close ( rc4_handle ); <nl> + g_free ( szEncryptedKey ); <nl> return DOT11DECRYPT_RET_NO_VALID_HANDSHAKE ; <nl> } <nl> 
mmm epan / dissectors / packet - ssl - utils . c <nl> ppp epan / dissectors / packet - ssl - utils . c <nl> static const char * ciphers []={ <nl> " RC2 ", <nl> " IDEA ", <nl> " AES ", <nl> - " AES256 " <nl> + " AES256 ", <nl> + "* UNKNOWN *" <nl> }; <nl>  <nl> /* look in openssl / ssl / ssl_lib . c for a complete list of available cipersuite */ <nl> ssl_create_decoder ( SslDecoder * dec , SslCipherSuite * cipher_suite , <nl> } <nl> if ( ciph == 0 ) { <nl> ssl_debug_printf (" ssl_create_decoder can ' t find cipher % s \ n ", <nl> - ciphers [ cipher_suite -> enc - 0x30 ]); <nl> + ciphers [( cipher_suite -> enc - 0x30 ) > 7 ? 7 : ( cipher_suite -> enc - 0x30 )]); <nl> return - 1 ; <nl> } <nl> 
mmm epan / dissectors / packet - ntlmssp . c <nl> ppp epan / dissectors / packet - ntlmssp . c <nl> dissect_ntlmssp_payload ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , voi <nl> /* Encrypted body */ <nl> proto_tree_add_item ( ntlmssp_tree , hf_ntlmssp_verf_body , <nl> tvb , offset , ntlm_signature_size + ntlm_seq_size , ENC_NA ); <nl> + memset ( key , 0 , sizeof ( key )); <nl> tvb_memcpy ( tvb , key , offset , ntlm_signature_size + ntlm_seq_size ); <nl> /* Try to decrypt */ <nl> decrypt_data_payload ( tvb , offset +( ntlm_signature_size + ntlm_seq_size ), encrypted_block_length -( ntlm_signature_size + ntlm_seq_size ), pinfo , ntlmssp_tree , key );
mmm packet - icmpv6 . c <nl> ppp packet - icmpv6 . c <nl> /* packet - icmpv6 . c <nl> * Routines for ICMPv6 packet disassembly <nl> * <nl> - * $ Id : packet - icmpv6 . c , v 1 . 57 2002 / 01 / 09 19 : 13 : 03 guy Exp $ <nl> + * $ Id : packet - icmpv6 . c , v 1 . 58 2002 / 01 / 10 09 : 49 : 35 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> again : <nl> ND_OPT_MAP_FLAG_P , 8 , " P ", " No P ")); <nl> proto_tree_add_text ( icmp6opt_tree , tvb , <nl> offset + offsetof ( struct nd_opt_map_info , nd_opt_map_lifetime ), <nl> - 4 , " Lifetime : % d ", pntohl (& map -> nd_opt_map_lifetime )); <nl> + 4 , " Lifetime : % u ", pntohl (& map -> nd_opt_map_lifetime )); <nl>  <nl> proto_tree_add_text ( icmp6opt_tree , tvb , <nl> offset + offsetof ( struct nd_opt_map_info , nd_opt_map_address ), 16 ,
mmm ui / qt / uat_dialog . cpp <nl> ppp ui / qt / uat_dialog . cpp <nl> void UatDialog :: on_uatTreeWidget_itemActivated ( QTreeWidgetItem * item , int column <nl> case PT_TXTMOD_FILENAME : <nl> { <nl> QString cur_path = fieldString ( row , column ); <nl> - const QByteArray & new_path = QFileDialog :: getSaveFileName ( this , <nl> + const QByteArray & new_path = QFileDialog :: getOpenFileName ( this , <nl> field -> title , cur_path , QString (), NULL , fd_opt ). toUtf8 (); <nl> field -> cb . set ( rec , new_path . constData (), ( unsigned ) new_path . size (), field -> cbdata . set , field -> fld_data ); <nl> updateItem (* item );mmm epan / uat . h <nl> ppp epan / uat . h <nl> void UatDialog :: on_uatTreeWidget_itemActivated ( QTreeWidgetItem * item , int column <nl> case PT_TXTMOD_FILENAME : <nl> { <nl> QString cur_path = fieldString ( row , column ); <nl> - const QByteArray & new_path = QFileDialog :: getSaveFileName ( this , <nl> + const QByteArray & new_path = QFileDialog :: getOpenFileName ( this , <nl> field -> title , cur_path , QString (), NULL , fd_opt ). toUtf8 (); <nl> field -> cb . set ( rec , new_path . constData (), ( unsigned ) new_path . size (), field -> cbdata . set , field -> fld_data ); <nl> updateItem (* item ); <nl> static void basename ## _ ## field_name ## _tostr_cb ( void * rec , const char ** out <nl> */ <nl> # define UAT_FILENAME_CB_DEF ( basename , field_name , rec_t ) UAT_CSTRING_CB_DEF ( basename , field_name , rec_t ) <nl>  <nl> +/* XXX UAT_FLD_FILENAME is currently unused . */ <nl> # define UAT_FLD_FILENAME ( basename , field_name , title , desc ) \ <nl> {# field_name , title , PT_TXTMOD_FILENAME ,{ uat_fld_chk_str , basename ## _ ## field_name ## _set_cb , basename ## _ ## field_name ## _tostr_cb },{ 0 , 0 , 0 }, 0 , desc , FLDFILL } <nl>  <nl> +/* <nl> + * Both the Qt and GTK + UIs assume that we ' re opening a preexisting <nl> + * file . We might want to split the ... _FILENAME defines into <nl> + * ... _FILE_OPEN and ... _FILE_SAVE if we ever need to specify a <nl> + * file that we ' re creating . <nl> + */ <nl> # define UAT_FLD_FILENAME_OTHER ( basename , field_name , title , chk , desc ) \ <nl> {# field_name , title , PT_TXTMOD_FILENAME ,{ chk , basename ## _ ## field_name ## _set_cb , basename ## _ ## field_name ## _tostr_cb },{ 0 , 0 , 0 }, 0 , desc , FLDFILL } <nl> 
mmm gtk / main . c <nl> ppp gtk / main . c <nl> main_filter_packets ( capture_file * cf , const gchar * dftext , gboolean force ) <nl> char * s ; <nl> cf_status_t cf_status ; <nl>  <nl> + /* we ' ll crash later on if dftext is NULL */ <nl> + g_assert ( dftext != NULL ); <nl> + <nl> s = g_strdup ( dftext ); <nl>  <nl> /* GtkCombos don ' t let us get at their list contents easily , so we maintain
mmm text2pcap . c <nl> ppp text2pcap . c <nl> parse_options ( int argc , char * argv []) <nl> {" version ", no_argument , NULL , ' v '}, <nl> { 0 , 0 , 0 , 0 } <nl> }; <nl> + struct tm * now_tm ; <nl>  <nl> # ifdef _WIN32 <nl> arg_list_utf_16to8 ( argc , argv ); <nl> parse_options ( int argc , char * argv []) <nl> } <nl>  <nl> ts_sec = time ( 0 ); /* initialize to current time */ <nl> - /* We trust the OS to return a time after the Epoch . */ <nl> - timecode_default = * localtime (& ts_sec ); <nl> + now_tm = localtime (& ts_sec ); <nl> + if ( now_tm == NULL ) { <nl> + /* <nl> + * This shouldn ' t happen - on UN * X , this should Just Work , and <nl> + * on Windows , it won ' t work if ts_sec is before the Epoch , <nl> + * but it ' s long after 1970 , so .... <nl> + */ <nl> + fprintf ( stderr , " localtime ( right now ) failed \ n "); <nl> + return EXIT_FAILURE ; <nl> + } <nl> + timecode_default = * now_tm ; <nl> timecode_default . tm_isdst = - 1 ; /* Unknown for now , depends on time given to the strptime () function */ <nl>  <nl> /* Display summary of our state */
mmm ui / qt / extcap_argument . h <nl> ppp ui / qt / extcap_argument . h <nl> private Q_SLOTS : <nl> }; <nl>  <nl> Q_DECLARE_METATYPE ( ExtcapArgument ) <nl> + Q_DECLARE_METATYPE ( ExtcapArgument *) <nl>  <nl> class ExtArgText : public ExtcapArgument <nl> {
mmm packet - dcerpc . c <nl> ppp packet - dcerpc . c <nl> * Copyright 2001 , Todd Sabin < tas @ webspan . net > <nl> * Copyright 2003 , Tim Potter < tpot @ samba . org > <nl> * <nl> - * $ Id : packet - dcerpc . c , v 1 . 151 2003 / 11 / 06 07 : 44 : 13 sahlberg Exp $ <nl> + * $ Id : packet - dcerpc . c , v 1 . 152 2003 / 11 / 06 09 : 13 : 26 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> dcerpc_try_handoff ( packet_info * pinfo , proto_tree * tree , <nl> pinfo -> current_proto = saved_proto ; <nl> pinfo -> private_data = saved_private_data ; <nl> } else { <nl> - /* No subdissector - show it as * decrypted * stub data . */ <nl> + /* No subdissector - show it as stub data . */ <nl> if ( decrypted_tvb ){ <nl> show_stub_data ( decrypted_tvb , 0 , tree , auth_info , FALSE ); <nl> } else { <nl> dissect_dcerpc_cn_stub ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> thus we must reassemble it . <nl> */ <nl>  <nl> + /* Do we have any non - encrypted data to reassemble ? */ <nl> + if ( decrypted_tvb == NULL ) { <nl> + /* No . We can ' t even try to reassemble . */ <nl> + goto end_cn_stub ; <nl> + } <nl> + <nl> /* if this is the first fragment we need to start reassembly <nl> */ <nl> if ( hdr -> flags & PFC_FIRST_FRAG ){
mmm epan / dissectors / packet - slowprotocols . c <nl> ppp epan / dissectors / packet - slowprotocols . c <nl> dissect_oampdu_event_notification ( tvbuff_t * tvb , proto_tree * tree ) <nl>  <nl> offset += OAMPDU_EVENT_LENGTH_SZ ; <nl>  <nl> - offset += ( raw_word - 2 ); <nl> + offset += ( raw_octet - 2 ); <nl> break ; <nl> } <nl> default :
mmm epan / proto . c <nl> ppp epan / proto . c <nl> proto_tree_add_subtree_format ( proto_tree * tree , tvbuff_t * tvb , gint start , gint <nl> va_list ap ; <nl> header_field_info * hfinfo ; <nl>  <nl> + /* Make sure pi is initialized in case TRY_TO_FAKE_THIS_ITEM bails */ <nl> + if ( tree_item != NULL ) <nl> + * tree_item = NULL ; <nl> + <nl> TRY_TO_FAKE_THIS_ITEM ( tree , hf_text_only , hfinfo ); <nl>  <nl> pi = proto_tree_add_text_node ( tree , tvb , start , length );
mmm epan / dissectors / packet - ber . c <nl> ppp epan / dissectors / packet - ber . c <nl> reassemble_octet_string ( asn1_ctx_t * actx , proto_tree * tree , gint hf_id , tvbuff_t <nl>  <nl> /* so we need to consume octet strings for the given length */ <nl>  <nl> - /* not sure we need this */ <nl> - actx -> pinfo -> fragmented = TRUE ; <nl> - <nl> if ( out_tvb ) <nl> * out_tvb = NULL ; <nl>  <nl> + if ( con_len == 0 ) /* Zero encodings ( 8 . 7 . 3 ) */ <nl> + return offset ; <nl> + <nl> + /* not sure we need this */ <nl> + actx -> pinfo -> fragmented = TRUE ; <nl> + <nl> while (! fd_head ) { <nl>  <nl> offset = dissect_ber_octet_string ( FALSE , actx , NULL , tvb , offset , hf_id , & next_tvb );
mmm epan / dissectors / packet - rtps . c <nl> ppp epan / dissectors / packet - rtps . c <nl> static void dissect_HEARTBEAT_VIRTUAL ( tvbuff_t * tvb , packet_info * pinfo _U_ , gin <nl> if (!( flags & FLAG_VIRTUAL_HEARTBEAT_N )) { <nl> proto_tree_add_item ( sil_tree_writer , hf_rtps_virtual_heartbeat_num_virtual_guids , tvb , <nl> offset , 4 , little_endian ? ENC_LITTLE_ENDIAN : ENC_BIG_ENDIAN ); <nl> + num_virtual_guids = NEXT_guint32 ( tvb , offset , little_endian ); <nl> offset += 4 ; <nl> } else { <nl> num_virtual_guids = 0 ;
mmm wiretap / netscaler . c <nl> ppp wiretap / netscaler . c <nl> static gboolean nstrace_read_v20 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> if (( nstrace -> nstrace_buflen - nstrace_buf_offset ) < sizeof * fp ) {\ <nl> * err = WTAP_ERR_BAD_FILE ;\ <nl> * err_info = g_strdup (" nstrace : record header crosses page boundary ");\ <nl> + g_free ( nstrace_tmpbuff );\ <nl> return FALSE ;\ <nl> }\ <nl> ( phdr )-> rec_type = REC_TYPE_PACKET ;\ <nl> static gboolean nstrace_read_v20 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> if (( phdr )-> caplen < sizeof * fp ) {\ <nl> * err = WTAP_ERR_BAD_FILE ;\ <nl> * err_info = g_strdup (" nstrace : record size is less than record header size ");\ <nl> + g_free ( nstrace_tmpbuff );\ <nl> return FALSE ;\ <nl> }\ <nl> ws_buffer_assure_space ( wth -> frame_buffer , ( phdr )-> caplen );\ <nl> static gboolean nstrace_read_v20 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> /* Read the next page */\ <nl> bytes_read = file_read ( nstrace_buf , NSPR_PAGESIZE_TRACE , wth -> fh );\ <nl> if ( ! file_eof ( wth -> fh ) && bytes_read != NSPR_PAGESIZE_TRACE ) {\ <nl> + g_free ( nstrace_tmpbuff );\ <nl> return FALSE ;\ <nl> } else {\ <nl> nstrace_buf_offset = 0 ;\ <nl> static gboolean nstrace_read_v20 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> nstrace -> nstrace_buf_offset = nstrace_buf_offset ;\ <nl> nstrace -> nstrace_buflen = nstrace_buflen ;\ <nl> nstrace -> nsg_creltime = nsg_creltime ;\ <nl> + g_free ( nstrace_tmpbuff );\ <nl> return TRUE ;\ <nl> } while ( 0 ) <nl>  <nl> static gboolean nstrace_read_v30 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> gchar * nstrace_buf = nstrace -> pnstrace_buf ; <nl> guint32 nstrace_buf_offset = nstrace -> nstrace_buf_offset ; <nl> guint32 nstrace_buflen = nstrace -> nstrace_buflen ; <nl> - guint8 nstrace_tmpbuff [ 65536 ]; <nl> + guint8 * nstrace_tmpbuff ; <nl> guint32 nstrace_tmpbuff_off = 0 , nst_dataSize = 0 , rec_size = 0 , nsg_nextPageOffset = 0 ; <nl> nspr_hd_v20_t * hdp ; <nl> int bytes_read = 0 ; <nl> static gboolean nstrace_read_v30 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> return FALSE ; /* Reached End Of File */ <nl> } <nl>  <nl> + nstrace_tmpbuff = ( guint8 *) g_malloc ( 65536 ); <nl> + <nl> do <nl> { <nl> if (! nstrace_buf [ nstrace_buf_offset ] && nstrace_buf_offset <= NSPR_PAGESIZE_TRACE ){ <nl> static gboolean nstrace_read_v30 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> if ( nspr_getv20recordsize ( hdp ) == 0 ) { <nl> * err = WTAP_ERR_BAD_FILE ; <nl> * err_info = g_strdup (" nstrace : zero size record found "); <nl> + g_free ( nstrace_tmpbuff ); <nl> return FALSE ; <nl> } <nl> switch ( hdp -> phd_RecordType ) <nl> static gboolean nstrace_read_v30 ( wtap * wth , int * err , gchar ** err_info , gint64 * <nl> nstrace_buflen = NSPR_PAGESIZE_TRACE ; <nl> } while (( nstrace_buflen > 0 ) && ( nstrace_read_buf ( wth -> fh , nstrace_buf , nstrace_buflen , err , err_info ))); <nl>  <nl> + g_free ( nstrace_tmpbuff ); <nl> return FALSE ; <nl> } <nl> 
mmm wiretap / pppdump . c <nl> ppp wiretap / pppdump . c <nl> /* pppdump . c <nl> * <nl> - * $ Id : pppdump . c , v 1 . 5 2000 / 11 / 19 03 : 47 : 36 guy Exp $ <nl> + * $ Id : pppdump . c , v 1 . 6 2000 / 11 / 19 20 : 56 : 17 gerald Exp $ <nl> * <nl> * Copyright ( c ) 2000 by Gilbert Ramirez < gram @ xiexie . org > <nl> * <nl> process_data ( pppdump_t * state , FILE_T fh , pkt_t * pkt , int n , guint8 * pd , int * er <nl> return 0 ; <nl> } <nl>  <nl> + if ( num_written > sizeof ( pd )) { <nl> + * err = WTAP_ERR_UNC_OVERFLOW ; <nl> + return - 1 ; <nl> + } <nl> + <nl> memcpy ( pd , pkt -> buf , num_written ); <nl>  <nl> num_bytes --;
mmm wiretap / erf . c <nl> ppp wiretap / erf . c <nl> static void erf_write_wtap_option_to_capture_tag ( wtap_block_t block _U_ , <nl> break ; <nl> default : <nl> erf_meta_tag_free ( tag_ptr ); <nl> - return ; <nl> + tag_ptr = NULL ; <nl> + break ; <nl> } <nl>  <nl> - g_ptr_array_add ( section_ptr -> tags , tag_ptr ); <nl> + if ( tag_ptr ) <nl> + g_ptr_array_add ( section_ptr -> tags , tag_ptr ); <nl> } <nl>  <nl> static void erf_write_wtap_option_to_host_tag ( wtap_block_t block _U_ , <nl> static void erf_write_wtap_option_to_host_tag ( wtap_block_t block _U_ , <nl> break ; <nl> default : <nl> erf_meta_tag_free ( tag_ptr ); <nl> - return ; <nl> + tag_ptr = NULL ; <nl> + break ; <nl> } <nl>  <nl> - g_ptr_array_add ( section_ptr -> tags , tag_ptr ); <nl> + if ( tag_ptr ) <nl> + g_ptr_array_add ( section_ptr -> tags , tag_ptr ); <nl> } <nl>  <nl> static void erf_write_wtap_option_to_interface_tag ( wtap_block_t block _U_ ,
mmm epan / dissectors / packet - ssl - utils . c <nl> ppp epan / dissectors / packet - ssl - utils . c <nl> ssl_keylog_lookup ( SslDecryptSession * ssl_session , <nl> line [ bytes_read - 1 ] = 0 ; <nl> bytes_read --; <nl> } <nl> + if ( bytes_read > 0 && line [ bytes_read - 1 ] == '\ r ') { <nl> + line [ bytes_read - 1 ] = 0 ; <nl> + bytes_read --; <nl> + } <nl>  <nl> ssl_debug_printf (" checking keylog line : % s \ n ", line ); <nl> 
mmm epan / dissectors / packet - tcp . c <nl> ppp epan / dissectors / packet - tcp . c <nl> dissect_tcpopt_mptcp ( const ip_tcp_opt * optp _U_ , tvbuff_t * tvb , <nl> guint8 indx ; <nl> guint8 flags ; <nl> guint8 ipver ; <nl> + int start_offset = offset ; <nl>  <nl> mptcp_tree = proto_tree_add_subtree ( opt_tree , tvb , offset , optlen , ett_tcp_option_mptcp , & ti , " Multipath TCP "); <nl>  <nl> dissect_tcpopt_mptcp ( const ip_tcp_opt * optp _U_ , tvbuff_t * tvb , <nl> 2 , ENC_BIG_ENDIAN ); <nl> offset += 2 ; <nl>  <nl> - proto_tree_add_item ( mptcp_tree , <nl> - hf_tcp_option_mptcp_checksum , tvb , offset , <nl> - 2 , ENC_BIG_ENDIAN ); <nl> + if (( int ) optlen >= offset - start_offset + 4 ) <nl> + { <nl> + proto_tree_add_item ( mptcp_tree , <nl> + hf_tcp_option_mptcp_checksum , tvb , offset , <nl> + 2 , ENC_BIG_ENDIAN ); <nl> + } <nl> } <nl> break ; <nl> 
mmm ui / gtk / main_menubar . c <nl> ppp ui / gtk / main_menubar . c <nl> set_menus_for_selected_packet ( capture_file * cf ) <nl>  <nl> set_menu_sensitivity ( ui_manager_main_menubar , path , <nl> menu_dissector_filter_spe_cb (/* frame_data * fd _U_ */ NULL , cf -> edt , filter_entry )); <nl> + g_free ( path ); <nl> i ++; <nl> list_entry = g_list_next ( list_entry ); <nl> }
mmm ui / cli / tap - rtp . c <nl> ppp ui / cli / tap - rtp . c <nl> rtp_streams_stat_draw ( void * arg _U_ ) <nl>  <nl> list = g_list_next ( list ); <nl>  <nl> - g_free ( payload_type ); <nl> wmem_free ( NULL , src_addr ); <nl> wmem_free ( NULL , dst_addr ); <nl> wmem_free ( NULL , payload_type );
mmm randpkt . c <nl> ppp randpkt . c <nl> main ( int argc , char ** argv ) <nl> pkthdr . ts . tv_sec = i ; /* just for variety */ <nl>  <nl> for ( j = example -> sample_length ; j < len_random ; j ++) { <nl> - buffer [ j ] = ( rand () % 0x100 ); <nl> + /* Add format strings here and there */ <nl> + if (( int ) ( 100 . 0 * rand ()/( RAND_MAX + 1 . 0 )) < 3 && j < ( len_random - 3 )) { <nl> + memcpy (& buffer [ j ], "% s ", 3 ); <nl> + j += 2 ; <nl> + } else { <nl> + buffer [ j ] = ( rand () % 0x100 ); <nl> + } <nl> } <nl>  <nl> wtap_dump ( dump , & pkthdr , & ps_header , & buffer [ 0 ], & err );
mmm gtk / capture_file_dlg . c <nl> ppp gtk / capture_file_dlg . c <nl> color_global_cb ( GtkWidget * widget _U_ , gpointer data ) <nl>  <nl> gtk_file_chooser_select_filename ( GTK_FILE_CHOOSER ( fs_widget ), path ); <nl>  <nl> - g_free (( gchar *) path ); <nl> + g_free ( path ); <nl> } <nl>  <nl> /* Import color filters */
mmm epan / dissectors / packet - sdp . c <nl> ppp epan / dissectors / packet - sdp . c <nl> static void dissect_sdp_media_attribute ( tvbuff_t * tvb , packet_info * pinfo , proto <nl> if ( port_offset != - 1 ) { <nl> /* Port ends with '/' */ <nl> port_end_offset = tvb_find_guint8 ( tvb , port_offset , - 1 , '/'); <nl> - <nl> + if ( port_end_offset == - 1 ) { <nl> + /* No "/" look for the ";" */ <nl> + port_end_offset = tvb_find_guint8 ( tvb , port_offset , - 1 , ';');; <nl> + } <nl> /* Attempt to convert address */ <nl> if ( inet_pton ( AF_INET , <nl> ( char *) tvb_get_ephemeral_string ( tvb , address_offset , port_offset - address_offset ),
mmm ui / qt / packet_list . cpp <nl> ppp ui / qt / packet_list . cpp <nl> PacketList :: PacketList ( QWidget * parent ) : <nl> decode_as_ ( NULL ), <nl> ctx_column_ (- 1 ), <nl> capture_in_progress_ ( false ), <nl> - tail_timer_id_ ( 0 ) <nl> + tail_timer_id_ ( 0 ), <nl> + rows_inserted_ ( false ) <nl> { <nl> QMenu * submenu , * subsubmenu ; <nl> QAction * action ;
mmm epan / dissectors / packet - uts . c <nl> ppp epan / dissectors / packet - uts . c <nl> dissect_uts ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree * tree ) <nl> else <nl> proto_tree_add_uint_format ( uts_header_tree , hf_sid , tvb , 2 , 1 , sid , " SID (% 02X )", sid ); <nl>  <nl> - if ( sid == GDID ) <nl> + if ( did == GDID ) <nl> proto_tree_add_uint_format ( uts_header_tree , hf_did , tvb , 3 , 1 , did , " DID (% 02X ) ( General )", did ); <nl> else <nl> proto_tree_add_uint_format ( uts_header_tree , hf_did , tvb , 3 , 1 , did , " DID (% 02X )", did );
mmm editcap . c <nl> ppp editcap . c <nl> main ( int argc , char * argv []) <nl> filename = g_strdup ( argv [ optind + 1 ]); <nl>  <nl> /* If we don ' t have an application name add Editcap */ <nl> - if ( shb_hdr -> shb_user_appl == NULL ) <nl> + if ( shb_hdr -> shb_user_appl == NULL ) { <nl> g_snprintf ( appname , sizeof ( appname ), " Editcap " VERSION ); <nl> + shb_hdr -> shb_user_appl = appname ; <nl> + } <nl>  <nl> pdh = wtap_dump_open_ng ( filename , out_file_type , out_frame_type , <nl> snaplen ? MIN ( snaplen , wtap_snapshot_length ( wth )) : wtap_snapshot_length ( wth ),mmm tshark . c <nl> ppp tshark . c <nl> main ( int argc , char * argv []) <nl> filename = g_strdup ( argv [ optind + 1 ]); <nl>  <nl> /* If we don ' t have an application name add Editcap */ <nl> - if ( shb_hdr -> shb_user_appl == NULL ) <nl> + if ( shb_hdr -> shb_user_appl == NULL ) { <nl> g_snprintf ( appname , sizeof ( appname ), " Editcap " VERSION ); <nl> + shb_hdr -> shb_user_appl = appname ; <nl> + } <nl>  <nl> pdh = wtap_dump_open_ng ( filename , out_file_type , out_frame_type , <nl> snaplen ? MIN ( snaplen , wtap_snapshot_length ( wth )) : wtap_snapshot_length ( wth ), <nl> load_cap_file ( capture_file * cf , char * save_file , int out_file_type , <nl> snapshot_length = WTAP_MAX_PACKET_SIZE ; <nl> } <nl> /* If we don ' t have an application name add Tshark */ <nl> - if ( shb_hdr -> shb_user_appl == NULL ) <nl> + if ( shb_hdr -> shb_user_appl == NULL ) { <nl> g_snprintf ( appname , sizeof ( appname ), " TShark " VERSION "% s ", wireshark_svnversion ); <nl> + shb_hdr -> shb_user_appl = appname ; <nl> + } <nl>  <nl> pdh = wtap_dump_open_ng ( save_file , out_file_type , linktype , snapshot_length , <nl> FALSE /* compressed */, shb_hdr , idb_inf , & err );
mmm epan / dissectors / packet - pdcp - lte . c <nl> ppp epan / dissectors / packet - pdcp - lte . c <nl> UAT_CSTRING_CB_DEF ( uat_ue_keys_records , rrcIntegrityKeyString , uat_ue_keys_reco <nl>  <nl> static gboolean global_pdcp_decipher_signalling = FALSE ; <nl> static gboolean global_pdcp_decipher_userplane = FALSE ; <nl> - static gboolean global_pdcp_check_integrity = FALSE ; <nl> # endif <nl> + static gboolean global_pdcp_check_integrity = FALSE ; <nl>  <nl> static const value_string direction_vals [] = <nl> {
mmm epan / dissectors / packet - nfs . c <nl> ppp epan / dissectors / packet - nfs . c <nl> dissect_nfs_acemask4 ( tvbuff_t * tvb , int offset , proto_tree * tree ) <nl>  <nl> if ( acemask & ACE4_APPEND_DATA ) <nl> proto_tree_add_text ( acemask_tree , tvb , offset , 4 , <nl> - " ACE4_ADD_FILE / ACE4_ADD_SUBDIRECTORY ( 0x % 08x )", <nl> + " ACE4_APPEND_DATA / ACE4_ADD_SUBDIRECTORY ( 0x % 08x )", <nl> ACE4_APPEND_DATA ); <nl>  <nl> if ( acemask & ACE4_READ_NAMED_ATTRS )
mmm ui / tap - sequence - analysis . c <nl> ppp ui / tap - sequence - analysis . c <nl> sequence_analysis_list_free ( seq_analysis_info_t * sainfo ) <nl> while ( list ) <nl> { <nl> sequence_analysis_item_free ( list -> data ); <nl> + list = g_list_next ( list ); <nl> } <nl> g_queue_free ( sainfo -> items ); <nl> }
mmm epan / dissectors / packet - isup_thin . c <nl> ppp epan / dissectors / packet - isup_thin . c <nl> # include < epan / packet . h > <nl> # include " prefs . h " <nl>  <nl> - static int ISUP_thinTCPPort = 0 ; <nl> + static guint ISUP_thinTCPPort = 0 ; <nl>  <nl> /* Initialize the protocol and registered fields */ <nl> static int proto_isup_thin = - 1 ; <nl> dissect_isup_thin ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> void <nl> proto_reg_handoff_isup_thin ( void ) <nl> { <nl> - static int Initialized = FALSE ; <nl> + static gboolean Initialized = FALSE ; <nl> static dissector_handle_t isup_thin_handle ; <nl> - static int saved_tcp_port ; <nl> + static guint saved_tcp_port ; <nl>  <nl> if (! Initialized ) { <nl> isup_thin_handle = find_dissector (" isup_thin ");
mmm epan / dissectors / packet - gsm_a_dtap . c <nl> ppp epan / dissectors / packet - gsm_a_dtap . c <nl> proto_register_gsm_a_dtap ( void ) <nl> NULL , HFILL } <nl> }, <nl> { & hf_gsm_a_dtap_bearer_cap_coding_standard , <nl> - { " Coding standard ", " gsm_a . dtap . coding_standard ", <nl> + { " Coding standard ", " gsm_a . dtap . cap_coding_standard ", <nl> FT_BOOLEAN , 8 , TFS (& tfs_bearer_cap_coding_standard ), 0x10 , <nl> NULL , HFILL } <nl> },mmm epan / dissectors / packet - ieee80211 . c <nl> ppp epan / dissectors / packet - ieee80211 . c <nl> proto_register_gsm_a_dtap ( void ) <nl> NULL , HFILL } <nl> }, <nl> { & hf_gsm_a_dtap_bearer_cap_coding_standard , <nl> - { " Coding standard ", " gsm_a . dtap . coding_standard ", <nl> + { " Coding standard ", " gsm_a . dtap . cap_coding_standard ", <nl> FT_BOOLEAN , 8 , TFS (& tfs_bearer_cap_coding_standard ), 0x10 , <nl> NULL , HFILL } <nl> }, <nl> dissect_rm_enabled_capabilities_ie ( packet_info * pinfo , proto_tree * tree , <nl>  <nl> if ( tag_len != 5 ) <nl> { <nl> - expert_add_info_format ( pinfo , ti_len , & ei_ieee80211_tag_length , " RM Enabled Capabilities length % u wrong , must = 4 ", tag_len ); <nl> + expert_add_info_format ( pinfo , ti_len , & ei_ieee80211_tag_length , " RM Enabled Capabilities length % u wrong , must = 5 ", tag_len ); <nl> return offset ; <nl> } <nl> proto_item_append_text ( ti , " (% d octets )", tag_len );
mmm epan / dissectors / packet - smb2 . c <nl> ppp epan / dissectors / packet - smb2 . c <nl> dissect_smb2_read_request ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , i <nl>  <nl> /* minimum count */ <nl> proto_tree_add_item ( tree , hf_smb2_min_count , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); <nl> + offset += 4 ; <nl>  <nl> /* channel */ <nl> proto_tree_add_item ( tree , hf_smb2_channel , tvb , offset , 4 , ENC_LITTLE_ENDIAN );
mmm wiretap / catapult_dct2000 . c <nl> ppp wiretap / catapult_dct2000 . c <nl> gboolean catapult_dct2000_dump ( wtap_dumper * wdh , const struct wtap_pkthdr * phdr , <nl> gboolean read_new_line ( FILE_T fh , gint64 * offset , gint * length , <nl> gchar * linebuff , size_t linebuffsize ) <nl> { <nl> - char * result ; <nl> - <nl> /* Read in a line */ <nl> - result = file_gets ( linebuff , ( int ) linebuffsize - 1 , fh ); <nl> + char * result = file_gets ( linebuff , ( int ) linebuffsize - 1 , fh ); <nl> if ( result == NULL ) { <nl> /* No characters found , or error */ <nl> return FALSE ; <nl> static gboolean parse_line ( gchar * linebuff , gint line_length , <nl> return FALSE ; <nl> } <nl>  <nl> - /* Reset strings ( that won ' t be set be comments ) */ <nl> - g_strlcpy ( variant_name , " 0 ", MAX_VARIANT_DIGITS ); <nl> - g_strlcpy ( outhdr_name , "", MAX_OUTHDR_NAME ); <nl> - g_strlcpy ( port_number_string , " 0 ", MAX_PORT_DIGITS ); <nl> + /* Reset strings ( that won ' t be set by comments ) */ <nl> + variant_name [ 0 ] = '\ 0 '; <nl> + outhdr_name [ 0 ] = '\ 0 '; <nl> + port_number_string [ 0 ] = '\ 0 '; <nl>  <nl> if (!(* is_comment )) { <nl> /* '.' must follow context name */ <nl> static gboolean parse_line ( gchar * linebuff , gint line_length , <nl> ( strcmp ( protocol_name , " fp_r4 ") == 0 ) || <nl> ( strcmp ( protocol_name , " fp_r5 ") == 0 ) || <nl> ( strcmp ( protocol_name , " fp_r6 ") == 0 ) || <nl> - ( strcmp ( protocol_name , " fp_r7 ") == 0 )) { <nl> + ( strcmp ( protocol_name , " fp_r7 ") == 0 ) || <nl> + ( strcmp ( protocol_name , " fp_r8 ") == 0 )) { <nl>  <nl> if (( variant > 256 ) && ( variant % 256 == 3 )) { <nl> /* FP over udp is contained in IPPrim ... */
mmm ui / qt / overlay_scroll_bar . cpp <nl> ppp ui / qt / overlay_scroll_bar . cpp <nl> void OverlayScrollBar :: paintEvent ( QPaintEvent * event ) <nl> pm_painter . setPen ( border_color ); <nl> pm_painter . drawLine ( near_dest . topLeft (), near_dest . bottomLeft ()); <nl> pm_painter . drawLine ( near_dest . topRight (), near_dest . bottomRight ()); <nl> + pm_painter . drawLine ( near_dest . bottomLeft (), near_dest . bottomRight ()); <nl> pm_painter . restore (); <nl>  <nl> // Draw the map .
mmm epan / dissectors / packet - zbee - nwk . c <nl> ppp epan / dissectors / packet - zbee - nwk . c <nl> dissect_zbee_nwk_heur ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void <nl> ieee802154_packet * packet = ( ieee802154_packet *) data ; <nl>  <nl> /* All ZigBee frames must always have a 16 - bit source address . */ <nl> - if ( packet -> src_addr_mode != IEEE802154_FCF_ADDR_SHORT ) { <nl> + if ( ( packet == NULL ) || <nl> + ( packet -> src_addr_mode != IEEE802154_FCF_ADDR_SHORT ) ) { <nl> return FALSE ; <nl> } <nl> /* ZigBee MAC frames must always contain a 16 - bit destination address . */
mmm packet - lpd . c <nl> ppp packet - lpd . c <nl> * Routines for LPR and LPRng packet disassembly <nl> * Gilbert Ramirez < gram @ xiexie . org > <nl> * <nl> - * $ Id : packet - lpd . c , v 1 . 17 2000 / 04 / 08 07 : 07 : 28 guy Exp $ <nl> + * $ Id : packet - lpd . c , v 1 . 18 2000 / 04 / 20 15 : 24 : 41 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> dissect_lpd ( const u_char * pd , int offset , frame_data * fd , proto_tree * tree ) <nl> RFC 1179 . http :// www . astart . com / lprng / LPRng - HOWTO . html */ <nl> char * lpd_client_code [] = { <nl> " Unknown command ", <nl> - " LPC : start print ", <nl> - " LPR : transfer a printer job ", <nl> - " LPQ : print short form of queue status ", <nl> + " LPC : start print / jobcmd : abort ", <nl> + " LPR : transfer a printer job / jobcmd : receive control file ", <nl> + " LPQ : print short form of queue status / jobcmd : receive data file ", <nl> " LPQ : print long form of queue status ", <nl> " LPRM : remove jobs ", <nl> " LPRng lpc : do control operation ", <nl> dissect_lpd ( const u_char * pd , int offset , frame_data * fd , proto_tree * tree ) <nl> " Bad job format , do not retry " <nl> }; <nl>  <nl> - <nl> - if ( pd [ offset + 1 ] == '\ n ') { <nl> + /* rfc1179 states that all responses are 1 byte long */ <nl> + if ( END_OF_FRAME == 1 ) { <nl> lpr_packet_type = response ; <nl> } <nl> else if ( pd [ offset ] <= 9 ) { <nl> dissect_lpd ( const u_char * pd , int offset , frame_data * fd , proto_tree * tree ) <nl> int response = pd [ offset ]; <nl>  <nl> if ( response <= 3 ) { <nl> - proto_tree_add_text ( lpd_tree , offset , 2 , " Response : % s ", <nl> + proto_tree_add_text ( lpd_tree , offset , 1 , " Response : % s ", <nl> lpd_server_code [ response ]); <nl> } <nl> else {
mmm gtk / main . c <nl> ppp gtk / main . c <nl> /* main . c <nl> * <nl> - * $ Id : main . c , v 1 . 386 2004 / 02 / 01 20 : 28 : 11 ulfl Exp $ <nl> + * $ Id : main . c , v 1 . 387 2004 / 02 / 01 22 : 43 : 34 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> main_window_delete_event_cb ( GtkWidget * widget _U_ , GdkEvent * event _U_ , gpointer <nl> } <nl>  <nl> static void <nl> - main_load_window_geometry ( GtkWidget * widget ) <nl> + main_load_window_geometry ( GtkWidget * widget <nl> +# if GTK_MAJOR_VERSION < 2 <nl> + _U_ <nl> +# endif <nl> +) <nl> { <nl> /* as we now have the geometry from the recent file , set it */ <nl> if ( prefs . gui_geometry_save_position ) {
mmm epan / dissectors / packet - mq - pcf . c <nl> ppp epan / dissectors / packet - mq - pcf . c <nl> static void dissect_mqpcf ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , m <nl>  <nl> static gboolean dissect_mqpcf_heur ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data ) <nl> { <nl> - if ( tvb_length ( tvb ) >= 36 ) <nl> + if ( data && tvb_length ( tvb ) >= 36 ) <nl> { <nl> mq_parm_t * p_mq_parm = ( mq_parm_t *) data ; <nl> if ( strncmp (( const char *) p_mq_parm -> mq_format , MQ_MQFMT_ADMIN , 8 ) == 0
mmm epan / dissectors / packet - dcerpc - mgmt . c <nl> ppp epan / dissectors / packet - dcerpc - mgmt . c <nl> static e_guid_t uuid_mgmt = { 0xafa8bd80 , 0x7d8a , 0x11c9 , { 0xbe , 0xf4 , 0x08 , 0x <nl> static guint16 ver_mgmt = 1 ; <nl>  <nl> static int <nl> - mgmtrpc_dissect_inq_princ_name_response ( tvbuff_t * tvb _U_ , int offset _U_ , packet_info * pinfo _U_ , proto_tree * tree _U_ , dcerpc_info * di _U_ , guint8 * drep _U_ ) <nl> + mgmtrpc_dissect_inq_princ_name_response ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree * tree , dcerpc_info * di , guint8 * drep ) <nl> { <nl>  <nl> offset = dissect_ndr_cvstring ( tvb , offset , pinfo , tree , di , drep , <nl> mgmtrpc_dissect_inq_princ_name_response ( tvbuff_t * tvb _U_ , int offset _U_ , packe <nl> return offset ; <nl> } <nl> static int <nl> - mgmtrpc_dissect_inq_princ_name_request ( tvbuff_t * tvb _U_ , int offset _U_ , packet_info * pinfo _U_ , proto_tree * tree _U_ , dcerpc_info * di _U_ , guint8 * drep _U_ ) <nl> + mgmtrpc_dissect_inq_princ_name_request ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree * tree , dcerpc_info * di , guint8 * drep ) <nl> { <nl> offset = dissect_ndr_uint32 ( tvb , offset , pinfo , tree , di , drep , hf_mgmt_proto , NULL ); <nl> offset = dissect_ndr_uint32 ( tvb , offset , pinfo , tree , di , drep , hf_mgmt_princ_size , NULL );
mmm epan / dissectors / packet - umts_fp . c <nl> ppp epan / dissectors / packet - umts_fp . c <nl> fp_set_per_packet_inf_from_conv ( umts_fp_conversation_info_t * p_conv_data , <nl>  <nl> /* Peek at C / T , different RLC params for different logical channels */ <nl> /* C / T is 4 bits according to 3GPP TS 25 . 321 , paragraph 9 . 2 . 1 , from MAC header ( not FP )*/ <nl> - c_t = tvb_get_bits8 ( tvb , tb_bit_off /*( 2 + p_conv_data -> num_dch_in_flow )* 8 */, 4 ); /* c_t = tvb_get_guint8 ( tvb , offset );*/ <nl> - macinf -> lchid [ j + chan ] = c_t + 1 ; <nl> + c_t = ( tvb_get_bits8 ( tvb , tb_bit_off /*( 2 + p_conv_data -> num_dch_in_flow )* 8 */, 4 ) + 1 ) % 0xf ; /* c_t = tvb_get_guint8 ( tvb , offset );*/ <nl> + macinf -> lchid [ j + chan ] = c_t ; <nl>  <nl> - macinf -> content [ j + chan ] = lchId_type_table [ c_t + 1 ]; /* Base MAC content on logical channel id ( Table is in packet - nbap . h )*/ <nl> - rlcinf -> mode [ j + chan ] = lchId_rlc_map [ c_t + 1 ]; /* Based RLC mode on logical channel id */ <nl> + macinf -> content [ j + chan ] = lchId_type_table [ c_t ]; /* Base MAC content on logical channel id ( Table is in packet - nbap . h )*/ <nl> + rlcinf -> mode [ j + chan ] = lchId_rlc_map [ c_t ]; /* Based RLC mode on logical channel id */ <nl> } <nl> } else { <nl> fake_lchid = make_fake_lchid ( pinfo , p_conv_data -> dchs_in_flow_list [ chan ]);
mmm epan / dissectors / packet - h264 . c <nl> ppp epan / dissectors / packet - h264 . c <nl> dissect_h264_exp_golomb_code ( proto_tree * tree , int hf_index , tvbuff_t * tvb , gint <nl> codenum = 1 ; <nl> codenum = codenum << leading_zero_bits ; <nl> mask = codenum >> 1 ; <nl> - if ( leading_zero_bits > 8 ) <nl> + if ( leading_zero_bits > 16 ) <nl> + value = tvb_get_bits32 ( tvb , bit_offset , leading_zero_bits , FALSE ); <nl> + else if ( leading_zero_bits > 8 ) <nl> value = tvb_get_bits16 ( tvb , bit_offset , leading_zero_bits , FALSE ); <nl> else <nl> value = tvb_get_bits8 ( tvb , bit_offset , leading_zero_bits );
mmm file . c <nl> ppp file . c <nl> /* file . c <nl> * File I / O routines <nl> * <nl> - * $ Id : file . c , v 1 . 59 1999 / 08 / 10 04 : 13 : 36 guy Exp $ <nl> + * $ Id : file . c , v 1 . 60 1999 / 08 / 10 06 : 54 : 12 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> wtap_dispatch_cb ( u_char * user , const struct wtap_pkthdr * phdr , int offset , <nl> /* Allocate the next list entry , and add it to the list . */ <nl> fdata = ( frame_data *) g_malloc ( sizeof ( frame_data )); <nl>  <nl> + fdata -> next = NULL ; <nl> fdata -> pkt_len = phdr -> len ; <nl> fdata -> cap_len = phdr -> caplen ; <nl> fdata -> file_off = offset ;
mmm ui / qt / column_preferences_frame . cpp <nl> ppp ui / qt / column_preferences_frame . cpp <nl> const int custom_occurrence_col_ = 4 ; <nl> ColumnPreferencesFrame :: ColumnPreferencesFrame ( QWidget * parent ) : <nl> QFrame ( parent ), <nl> ui ( new Ui :: ColumnPreferencesFrame ), <nl> + cur_column_ ( 0 ), <nl> cur_line_edit_ ( NULL ), <nl> cur_combo_box_ ( NULL ), <nl> + saved_combo_idx_ ( 0 ), <nl> saved_custom_combo_idx_ (- 1 ) <nl> { <nl> ui -> setupUi ( this );
mmm epan / plugin_if . c <nl> ppp epan / plugin_if . c <nl> typedef struct _ext_toolbar_update_list_t <nl> GList * entries ; <nl> } ext_toolbar_update_list_t ; <nl>  <nl> - extern gint <nl> + static gint <nl> ext_toolbar_find_item ( gconstpointer a , gconstpointer b ) <nl> { <nl> if ( a == 0 || b == 0 )
mmm plugins / mate / mate_util . c <nl> ppp plugins / mate / mate_util . c <nl> extern void avp_init ( void ) { <nl> extern AVP * new_avp_from_finfo ( const gchar * name , field_info * finfo ) { <nl> AVP * new = ( AVP *) g_slice_new ( any_avp_type ); <nl> gchar * value ; <nl> + gchar * repr = NULL ; <nl>  <nl> new -> n = scs_subscribe ( avp_strings , name ); <nl>  <nl> if ( finfo -> value . ftype -> val_to_string_repr ) { <nl> - value = scs_subscribe ( avp_strings , fvalue_to_string_repr (& finfo -> value , FTREPR_DISPLAY , NULL )); <nl> + repr = fvalue_to_string_repr (& finfo -> value , FTREPR_DISPLAY , NULL ); <nl> + } <nl> + <nl> + if ( repr ) { <nl> + value = scs_subscribe ( avp_strings , repr ); <nl> # ifdef _AVP_DEBUGGING <nl> dbg_print ( dbg_avp , 2 , dbg_fp ," new_avp_from_finfo : from string : % s ", value ); <nl> # endif
mmm epan / dissectors / packet - rtacser . c <nl> ppp epan / dissectors / packet - rtacser . c <nl> dissect_rtacser_data ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl>  <nl> p_add_proto_data ( pinfo -> pool , pinfo , proto_rtacser , 0 , GUINT_TO_POINTER ( global_rtacser_payload_proto )); <nl>  <nl> - if ( tvb_reported_length_remaining ( tvb , RTACSER_HEADER_LEN ) > 0 ) { <nl> + if ( tvb_reported_length_remaining ( tvb , offset ) > 0 ) { <nl> payload_tvb = tvb_new_subset_remaining ( tvb , RTACSER_HEADER_LEN ); <nl> if (! dissector_try_uint ( subdissector_table , global_rtacser_payload_proto , payload_tvb , pinfo , tree )){ <nl> call_dissector ( data_handle , payload_tvb , pinfo , tree );
mmm gtk / proto_draw . c <nl> ppp gtk / proto_draw . c <nl> /* proto_draw . c <nl> * Routines for GTK + packet display <nl> * <nl> - * $ Id : proto_draw . c , v 1 . 24 2001 / 01 / 02 01 : 32 : 21 guy Exp $ <nl> + * $ Id : proto_draw . c , v 1 . 25 2001 / 01 / 11 05 : 51 : 10 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> packet_hex_print ( GtkText * bv , guint8 * pd , frame_data * fd , field_info * finfo ) <nl> if ( bstart > 0 ) { <nl> int lineheight , linenum ; <nl> float scrollval ; <nl> - linenum = bstart / BYTE_VIEW_WIDTH ; <nl>  <nl> - /* need to change to some way of getting that offset instead of + 4 */ <nl> - lineheight = gdk_string_height ( m_b_font , " 0 ") + 4 ; <nl> + linenum = bstart / BYTE_VIEW_WIDTH ; <nl> + /* This is the lineheight that the GtkText widget uses when drawing text . */ <nl> + lineheight = m_b_font -> ascent + m_b_font -> descent ; <nl> scrollval = MIN ( linenum * lineheight , bv -> vadj -> upper - bv -> vadj -> page_size ); <nl>  <nl> gtk_adjustment_set_value ( bv -> vadj , scrollval );
mmm epan / dissectors / packet - iax2 . c <nl> ppp epan / dissectors / packet - iax2 . c <nl> static guint iax_circuit_lookup ( const address * address , <nl> new_key -> addr . type = address -> type ; <nl> new_key -> addr . len = MIN ( address -> len , MAX_ADDRESS ); <nl> new_key -> addr . data = new_key -> address_data ; <nl> - memmove ( new_key -> address_data , address -> data , new_key -> addr . len ); <nl> + memcpy ( new_key -> address_data , address -> data , new_key -> addr . len ); <nl> new_key -> ptype = ptype ; <nl> new_key -> port = port ; <nl> new_key -> callno = callno ;
mmm epan / decode_as . c <nl> ppp epan / decode_as . c <nl> save_decode_as_entries ( gchar ** err ) <nl>  <nl> dissector_all_tables_foreach_changed ( decode_as_write_entry , da_file ); <nl> fclose ( da_file ); <nl> + g_free ( daf_path ); <nl> return 0 ; <nl> } <nl> 
mmm epan / dissectors / packet - gsm_bssmap_le . c <nl> ppp epan / dissectors / packet - gsm_bssmap_le . c <nl> bssmap_le_perf_loc_resp ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint l <nl> /* Deciphering Keys 9 . 2 . 3 C ( note 2 ) 3 - n */ <nl> ELEM_OPT_TLV ( gsm_bssmap_le_elem_strings [ DE_BMAPLE_DECIPH_KEYS ]. value , GSM_PDU_TYPE_BSSMAP_LE , DE_BMAPLE_DECIPH_KEYS , ""); <nl> /* LCS Cause 9 . 2 . 4 C ( note 3 ) 3 - n */ <nl> - ELEM_OPT_TLV ( gsm_bssmap_le_elem_strings [ DE_BMAPLE_LCS_CAUSE ]. value , GSM_PDU_TYPE_BSSMAP_LE , BSSMAP_LE_LCS_CAUSE , ""); <nl> + ELEM_OPT_TLV ( gsm_bssmap_le_elem_strings [ DE_BMAPLE_LCS_CAUSE ]. value , GSM_PDU_TYPE_BSSMAP_LE , DE_BMAPLE_LCS_CAUSE , ""); <nl> /* Velocity Estimate 9 . 2 . 5 O 3 - n */ <nl> ELEM_OPT_TLV ( gsm_bssmap_elem_strings [ BE_VEL_EST ]. value , BSSAP_PDU_TYPE_BSSMAP , BE_VEL_EST , ""); <nl> /* GANSS Positioning Data 9 . 2 . 6 O 3 - n */
mmm epan / wslua / wslua_byte_array . c <nl> ppp epan / wslua / wslua_byte_array . c <nl> WSLUA_CONSTRUCTOR ByteArray_tvb ( lua_State * L ) { <nl> data = ( guint8 *) g_memdup ( ba -> data , ba -> len ); <nl>  <nl> tvb = ( Tvb ) g_malloc ( sizeof ( struct _wslua_tvb )); <nl> - tvb -> ws_tvb = tvb_new_real_data ( data , ba -> len , ba -> len ); <nl> + tvb -> ws_tvb = tvb_new_child_real_data ( lua_tvb , data , ba -> len , ba -> len ); <nl> tvb -> expired = FALSE ; <nl> - tvb -> need_free = TRUE ; <nl> + tvb -> need_free = FALSE ; <nl> tvb_set_free_cb ( tvb -> ws_tvb , g_free ); <nl>  <nl> add_new_data_source ( lua_pinfo , tvb -> ws_tvb , name );
mmm gtk / gui_utils . c <nl> ppp gtk / gui_utils . c <nl> window_new_with_geom ( GtkWindowType type , const gchar * title , const gchar * geom_n <nl> } <nl>  <nl>  <nl> -/* Create a new window for a splash screen ; it ' s a main window , with no title , <nl> +/* Create a new window for a splash screen ; it ' s a main window , without decoration , <nl> positioned in the center of the screen . */ <nl> GtkWidget * <nl> splash_window_new ( void ) <nl> { <nl> GtkWidget * win ; <nl>  <nl> - win = gtk_window_new ( GTK_WINDOW_TOPLEVEL ); <nl> + win = window_new ( GTK_WINDOW_TOPLEVEL , " Wireshark "); <nl> gtk_window_set_decorated ( GTK_WINDOW ( win ), FALSE ); <nl>  <nl> /* set the initial position ( must be done , before show is called !) */
mmm wiretap / snoop . c <nl> ppp wiretap / snoop . c <nl> /* snoop . c <nl> * <nl> - * $ Id : snoop . c , v 1 . 65 2003 / 11 / 11 20 : 49 : 46 guy Exp $ <nl> + * $ Id : snoop . c , v 1 . 66 2003 / 12 / 19 22 : 23 : 05 guy Exp $ <nl> * <nl> * Wiretap Library <nl> * Copyright ( c ) 1998 by Gilbert Ramirez < gram @ alumni . rice . edu > <nl> static gboolean snoop_read ( wtap * wth , int * err , long * data_offset ) <nl> * err = WTAP_ERR_BAD_RECORD ; <nl> return FALSE ; <nl> } <nl> + if ( packet_size > rec_size ) { <nl> + /* <nl> + * Probably a corrupt capture file . <nl> + */ <nl> + g_message (" snoop : File has % u - byte packet , bigger than record size % u ", <nl> + packet_size , rec_size ); <nl> + * err = WTAP_ERR_BAD_RECORD ; <nl> + return FALSE ; <nl> + } <nl>  <nl> * data_offset = wth -> data_offset ; <nl> 
mmm gtk / wlan_stat_dlg . c <nl> ppp gtk / wlan_stat_dlg . c <nl> csv_handle ( GtkTreeModel * model , GtkTreePath * path _U_ , GtkTreeIter * iter , <nl> i == PERCENT_COLUMN || i == PROTECTION_COLUMN ) { <nl> gtk_tree_model_get ( model , iter , i , & table_text , - 1 ); <nl> g_string_append ( CSV_str , table_text ); <nl> + g_free ( table_text ); <nl> } else { <nl> gtk_tree_model_get ( model , iter , i , & table_value , - 1 ); <nl> g_string_append_printf ( CSV_str , "% u ", table_value );
mmm epan / prefs . c <nl> ppp epan / prefs . c <nl> prefs_register_protocol_subtree ( const char * subtree , int id , void (* apply_cb )( vo <nl>  <nl> } <nl>  <nl> - /* g_free ( csubtree ); */ <nl> + g_free ( csubtree ); <nl>  <nl> } <nl> 
mmm epan / dissectors / packet - rtp . h <nl> ppp epan / dissectors / packet - rtp . h <nl> struct _rtp_conversation_info <nl> { <nl> gchar method [ MAX_RTP_SETUP_METHOD_SIZE + 1 ]; <nl> guint32 frame_number ; <nl> - guint32 rtp_event_pt ; /* this is payload type for dynamic RTP events ( RFC2833 ) */ <nl> + GHashTable * rtp_dyn_payload ; /* a hash table with the dynamic RTP payload */ <nl> }; <nl>  <nl> /* Add an RTP conversation with the given details */ <nl> void rtp_add_address ( packet_info * pinfo , <nl> int other_port , <nl> gchar * setup_method , <nl> guint32 setup_frame_number , <nl> - int rtp_event_pt ); <nl> + GHashTable * rtp_dyn_payload ); <nl> + <nl> +/* Free and destroy the dyn_payload hash table */ <nl> + void rtp_free_hash_dyn_payload ( GHashTable * rtp_dyn_payload ); <nl> +
mmm gtk / gui_utils . c <nl> ppp gtk / gui_utils . c <nl> GtkWidget * xpm_to_widget_from_parent ( GtkWidget * parent , const char ** xpm ) { <nl> } <nl>  <nl>  <nl> -/* convert an xpm to a GtkWidget , using the top_level window settings */ <nl> -/* ( be sure that the top_level window is already being displayed ) */ <nl> +/* convert an xpm to a GtkWidget */ <nl> GtkWidget * xpm_to_widget ( const char ** xpm ) { <nl> - return xpm_to_widget_from_parent ( top_level , xpm ); <nl> + GdkPixbuf * pixbuf ; <nl> + <nl> + pixbuf = gdk_pixbuf_new_from_xpm_data ( xpm ); <nl> + return gtk_image_new_from_pixbuf ( pixbuf ); <nl> } <nl>  <nl> /* Convert an pixbuf data to a GtkWidget */
mmm epan / emem . c <nl> ppp epan / emem . c <nl> emem_alloc ( size_t size , emem_header_t * mem , gboolean use_chunks , guint8 * canary ) <nl> /* There ' s no padding / alignment involved ( from our point of view ) when <nl> * we fetch the memory directly from the system pool , so WYSIWYG */ <nl> npc -> free_offset = npc -> free_offset_init = 0 ; <nl> - npc -> amount_free = npc -> amount_free_init = size ; <nl> + npc -> amount_free = npc -> amount_free_init = ( unsigned int ) size ; <nl> } <nl>  <nl> return buf ;
mmm gtk / packet_win . c <nl> ppp gtk / packet_win . c <nl> finfo_integer_changed ( GtkSpinButton * spinbutton , gpointer user_data ) <nl>  <nl> else if ( finfo_type == FT_UINT8 || finfo_type == FT_UINT16 || finfo_type == FT_UINT24 || finfo_type == FT_UINT32 || finfo_type == FT_UINT64 ) <nl> u_val = ( guint64 ) val ; <nl> + else { <nl> + g_assert_not_reached (); <nl> + return ; <nl> + } <nl>  <nl> if ( FI_GET_FLAG ( finfo , FI_LITTLE_ENDIAN )) { <nl> while ( finfo_length ) {
mmm epan / dissectors / packet - dcerpc - netlogon . c <nl> ppp epan / dissectors / packet - dcerpc - netlogon . c <nl> static const true_false_string get_dcname_request_flags_force_rediscovery = { <nl> " You may return cached data " <nl> }; <nl> static const true_false_string get_dcname_request_flags_directory_service_required = { <nl> - " DIRECRTORY SERVICE is REQUIRED on the server ", <nl> + " DIRECTORY SERVICE is REQUIRED on the server ", <nl> " We do NOT require directory service servers " <nl> }; <nl> static const true_false_string get_dcname_request_flags_directory_service_preferred = { <nl> static const true_false_string get_dcname_request_flags_timeserv_required = { <nl> " timeserv service is NOT required " <nl> }; <nl> static const true_false_string get_dcname_request_flags_writable_required = { <nl> - " the requrned dc MUST be WRITEABLE ", <nl> + " the returned dc MUST be WRITEABLE ", <nl> " a read - only dc may be returned " <nl> }; <nl> static const true_false_string get_dcname_request_flags_good_timeserv_preferred = {
mmm text2pcap . c <nl> ppp text2pcap . c <nl> write_current_packet ( void ) <nl> ( guint32 ) ts_sec , ts_usec , <nl> length , length , <nl> 0 , <nl> - 6 , <nl> + 1000000 , <nl> packet_buf , 0 , <nl> & bytes_written , & err ); <nl> } else { <nl> write_file_header ( void ) <nl> 102400 , <nl> & bytes_written , <nl> 0 , <nl> - 6 , <nl> + 0 , <nl> & err ); <nl> } <nl> } else {
mmm packet - ip . c <nl> ppp packet - ip . c <nl> /* packet - ip . c <nl> * Routines for IP and miscellaneous IP protocol packet disassembly <nl> * <nl> - * $ Id : packet - ip . c , v 1 . 66 1999 / 12 / 09 21 : 58 : 04 guy Exp $ <nl> + * $ Id : packet - ip . c , v 1 . 67 1999 / 12 / 13 05 : 09 : 05 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> dissect_ip_tcp_options ( const u_char * opd , int offset , guint length , <nl> option length . */ <nl> proto_tree_add_text ( opt_tree , offset , 2 , <nl> "% s ( with too - short option length = % u byte % s )", name , <nl> - plurality ( len , "", " s ")); <nl> + len , plurality ( len , "", " s ")); <nl> return ; <nl> } else if ( len - 2 > length ) { <nl> /* Bogus - option goes past the end of the header . */
mmm wsutil / strtoi . c <nl> ppp wsutil / strtoi . c <nl> gboolean ws_strtoi64 ( const gchar * str , const gchar ** endptr , gint64 * cint ) <nl> gchar * end ; <nl> gint64 val ; <nl>  <nl> + g_assert ( cint ); <nl> + <nl> + if (! str ) { <nl> + errno = EINVAL ; <nl> + return FALSE ; <nl> + } <nl> + <nl> errno = 0 ; <nl> val = g_ascii_strtoll ( str , & end , 10 ); <nl> if (( val == 0 && end == str ) || ( endptr == NULL && * end != '\ 0 ')) { <nl> static gboolean ws_basestrtou64 ( const gchar * str , const gchar ** endptr , guint64 * <nl> gchar * end ; <nl> guint64 val ; <nl>  <nl> + g_assert ( cint ); <nl> + <nl> + if (! str ) { <nl> + errno = EINVAL ; <nl> + return FALSE ; <nl> + } <nl> + <nl> if ( str [ 0 ] == '-' || str [ 0 ] == '+') { <nl> /* <nl> * Unsigned numbers don ' t have a sign .
mmm epan / dissectors / packet - erf . c <nl> ppp epan / dissectors / packet - erf . c <nl> dissect_erf ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ ) <nl> atm_info . vpi = (( atm_hdr & 0x0ff00000 ) >> 20 ); <nl> atm_info . vci = (( atm_hdr & 0x000ffff0 ) >> 4 ); <nl> atm_info . channel = ( flags & 0x03 ); <nl> + atm_info . aal2_cid = aal2_cid ; <nl> atm_info . type = TRAF_UNKNOWN ; <nl> atm_info . subtype = TRAF_ST_UNKNOWN ; <nl> 
mmm epan / dissectors / packet - pppoe . c <nl> ppp epan / dissectors / packet - pppoe . c <nl> void proto_register_pppoed ( void ) <nl> } <nl> }, <nl> { & hf_pppoed_tag_host_uniq , <nl> - { " Host - Uniq ", " pppoed . tags . host_uniq ", FT_STRING , BASE_NONE , <nl> + { " Host - Uniq ", " pppoed . tags . host_uniq ", FT_BYTES , BASE_NONE , <nl> NULL , 0x0 , "", HFILL <nl> } <nl> }, <nl> { & hf_pppoed_tag_ac_cookie , <nl> - { " AC - Cookie ", " pppoed . tags . ac_cookie ", FT_BYTES , BASE_HEX , <nl> + { " AC - Cookie ", " pppoed . tags . ac_cookie ", FT_BYTES , BASE_NONE , <nl> NULL , 0x0 , "", HFILL <nl> } <nl> }, <nl> void proto_register_pppoed ( void ) <nl> } <nl> }, <nl> { & hf_pppoed_tag_relay_session_id , <nl> - { " Relay - Session - Id ", " pppoed . tags . relay_session_id ", FT_BYTES , BASE_HEX , <nl> + { " Relay - Session - Id ", " pppoed . tags . relay_session_id ", FT_BYTES , BASE_NONE , <nl> NULL , 0x0 , "", HFILL <nl> } <nl> },
mmm wsutil / strtoi . c <nl> ppp wsutil / strtoi . c <nl> gboolean ws_strtou64 ( const gchar * str , guint64 * cint ) <nl> gchar * endptr ; <nl> guint64 val ; <nl>  <nl> + if ( str [ 0 ] == '-' || str [ 0 ] == '+') { <nl> + /* <nl> + * Unsigned numbers don ' t have a sign . <nl> + */ <nl> + errno = EINVAL ; <nl> + return FALSE ; <nl> + } <nl> errno = 0 ; <nl> val = g_ascii_strtoull ( str , & endptr , 10 ); <nl> if (( val == 0 && endptr == str ) || (* endptr != 0 )) {
mmm epan / dissectors / packet - slowprotocols . c <nl> ppp epan / dissectors / packet - slowprotocols . c <nl> dissect_oampdu_information ( tvbuff_t * tvb , proto_tree * tree ) <nl> else <nl> state_tree = proto_item_add_subtree ( state_item , ett_oampdu_remote_info_state ); <nl>  <nl> - proto_tree_add_boolean ( state_tree , hf_oampdu_info_state_parser , <nl> + proto_tree_add_uint ( state_tree , hf_oampdu_info_state_parser , <nl> tvb , offset , 1 , raw_octet ); <nl>  <nl> proto_tree_add_boolean ( state_tree , hf_oampdu_info_state_mux , <nl> proto_register_slow_protocols ( void ) <nl>  <nl> { & hf_oampdu_info_state_parser , <nl> { " Parser Action ", " oam . info . state . parser ", <nl> - FT_BOOLEAN , 8 , VALS (& parser_vals ), 0x03 , <nl> + FT_UINT8 , 8 , VALS (& parser_vals ), 0x03 , <nl> " Parser Action ", HFILL }}, <nl>  <nl> { & hf_oampdu_info_state_mux ,
mmm dumpcap . c <nl> ppp dumpcap . c <nl> capture_loop_dispatch ( capture_options * capture_opts _U_ , loop_data * ld , <nl> inpkts = pcap_dispatch ( ld -> pcap_h , 1 , capture_loop_packet_cb , <nl> ( u_char *) ld ); <nl> if ( inpkts < 0 ) { <nl> - ld -> pcap_err = TRUE ; <nl> + if ( inpkts == - 1 ) { <nl> + /* Error , rather than pcap_breakloop (). */ <nl> + ld -> pcap_err = TRUE ; <nl> + } <nl> ld -> go = FALSE ; /* error or pcap_breakloop () - stop capturing */ <nl> } <nl> } else {
mmm epan / dissectors / packet - infiniband . c <nl> ppp epan / dissectors / packet - infiniband . c <nl> create_conv_and_add_proto_data ( packet_info * pinfo , guint64 service_id , <nl> conversation_add_proto_data ( conv , proto_infiniband , proto_data ); <nl>  <nl> /* next , register the conversation using the LIDs */ <nl> - set_address ( addr , AT_IB , sizeof ( guint16 ), & lid ); <nl> + set_address ( addr , AT_IB , sizeof ( guint16 ), wmem_memdup ( pinfo -> pool , & lid , sizeof lid )); <nl> conv = conversation_new ( pinfo -> num , addr , addr , <nl> PT_IBQP , port , port , options ); <nl> conversation_add_proto_data ( conv , proto_infiniband , proto_data );
mmm epan / oids . c <nl> ppp epan / oids . c <nl> static void register_mibs ( void ) { <nl> hf_register_info hf ; <nl>  <nl> hf . p_id = &( oid_data -> value_hfid ); <nl> - hf . hfinfo . name = oid_data -> name ; <nl> + hf . hfinfo . name = g_strdup ( oid_data -> name ); <nl> hf . hfinfo . abbrev = alnumerize ( oid_data -> name ); <nl> hf . hfinfo . type = typedata -> ft_type ; <nl> hf . hfinfo . display = typedata -> display ;
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> mktime_utc ( struct tm * tm ) <nl> { <nl> 0 , 31 , 59 , 90 , 120 , 151 , 181 , 212 , 243 , 273 , 304 , 334 <nl> }; <nl> + <nl> + int yr ; <nl> # endif <nl>  <nl> # ifndef HAVE_TIMEGM <nl> mktime_utc ( struct tm * tm ) <nl> return ( time_t ) - 1 ; <nl>  <nl> retval = ( tm -> tm_year - 70 ) * 365 ; <nl> - retval += ( tm -> tm_year - 68 ) / 4 ; <nl> - retval += days_before [ tm -> tm_mon ] + tm -> tm_mday - 1 ; <nl>  <nl> - if ( tm -> tm_year % 4 == 0 && tm -> tm_mon < 2 ) <nl> - retval -= 1 ; <nl> + /* count number of leap years */ <nl> + yr = tm -> tm_year + 1900 ; <nl> + if ( tm -> tm_mon + 1 < 3 && ( yr % 4 ) == 0 && (( yr % 100 ) != 0 || ( yr % 400 ) == 0 )) <nl> + yr --; <nl> + retval += ((( yr / 4 ) - ( yr / 100 ) + ( yr / 400 )) - 477 ); /* 477 = (( 1970 / 4 ) - ( 1970 / 100 ) + ( 1970 / 400 )) */ <nl> + <nl> + retval += days_before [ tm -> tm_mon ] + tm -> tm_mday - 1 ; <nl>  <nl> retval = (((( retval * 24 ) + tm -> tm_hour ) * 60 ) + tm -> tm_min ) * 60 + tm -> tm_sec ; <nl> # else
mmm gtk / main . c <nl> ppp gtk / main . c <nl> main_widgets_show_or_hide ( void ) <nl> } else { <nl> gtk_widget_hide ( welcome_pane ); <nl> } <nl> + <nl> + /* workaround for bug in GtkCList to ensure packet list scrollbar is updated */ <nl> + packet_list_freeze (); <nl> + packet_list_thaw (); <nl> } <nl>  <nl> 
mmm epan / dissectors / packet - gsm_a . c <nl> ppp epan / dissectors / packet - gsm_a . c <nl> be_cell_id_aux ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len , gchar <nl>  <nl> case 0x01 : <nl> case 0x05 : <nl> - case 0x0a : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl> + case 0x0a : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl>  <nl> /* LAC */ <nl>  <nl> be_cell_id_aux ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len , gchar <nl> if ( add_string ) <nl> g_snprintf ( add_string , string_len , " - LAC ( 0x % 04x )", value ); <nl>  <nl> - case 0x09 : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl> + /* FALLTHRU */ <nl> + <nl> + case 0x09 : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl>  <nl> if (( disc == 0x08 ) ||( disc == 0x09 ) || ( disc == 0x0a )){ <nl> /* RNC - ID */
mmm pcapio . c <nl> ppp pcapio . c <nl> pcapng_write_enhanced_packet_block ( FILE * pfile , <nl> sizeof ( guint32 )); <nl> } <nl> /* If we have options add size of end - of - options */ <nl> - /* If we have options add size of end - of - options */ <nl> if ( options_length != 0 ) { <nl> options_length += ( guint32 ) sizeof ( struct option ); <nl> } <nl> pcapng_write_enhanced_packet_block ( FILE * pfile , <nl> option . value_length = 0 ; <nl> if (! write_to_file ( pfile , ( const guint8 *)& option , sizeof ( struct option ), bytes_written , err )) <nl> return FALSE ; <nl> - } <nl> + } <nl> + if ( options_length != 0 ) { <nl> + /* write end of options */ <nl> + option . type = OPT_ENDOFOPT ; <nl> + option . value_length = 0 ; <nl> + if (! write_to_file ( pfile , ( const guint8 *)& option , sizeof ( struct option ), bytes_written , err )) <nl> + return FALSE ; <nl> + } <nl>  <nl> return write_to_file ( pfile , ( const guint8 *)& block_total_length , sizeof ( guint32 ), bytes_written , err ); <nl> }
mmm packet - tcp . c <nl> ppp packet - tcp . c <nl> /* packet - tcp . c <nl> * Routines for TCP packet disassembly <nl> * <nl> - * $ Id : packet - tcp . c , v 1 . 184 2003 / 03 / 03 23 : 20 : 57 sahlberg Exp $ <nl> + * $ Id : packet - tcp . c , v 1 . 185 2003 / 03 / 04 04 : 36 : 44 sharpe Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> dissect_tcpopt_sack ( const ip_tcp_opt * optp , tvbuff_t * tvb , <nl> if ( field_tree == NULL ) { <nl> /* Haven ' t yet made a subtree out of this option . Do so . */ <nl> field_tree = proto_item_add_subtree ( tf , * optp -> subtree_index ); <nl> + proto_tree_add_boolean_hidden ( field_tree , hf_tcp_option_sack , tvb , <nl> + offset , optlen , TRUE ); <nl> } <nl> if ( optlen < 4 ) { <nl> proto_tree_add_text ( field_tree , tvb , offset , optlen , <nl> dissect_tcpopt_sack ( const ip_tcp_opt * optp , tvbuff_t * tvb , <nl> break ; <nl> } <nl> leftedge = tvb_get_ntohl ( tvb , offset ); <nl> + proto_tree_add_uint_format ( field_tree , hf_tcp_option_sack_sle , tvb , <nl> + offset , 4 , leftedge , <nl> + " left edge = % u ", leftedge ); <nl> optlen -= 4 ; <nl> if ( optlen < 4 ) { <nl> proto_tree_add_text ( field_tree , tvb , offset , optlen , <nl> dissect_tcpopt_sack ( const ip_tcp_opt * optp , tvbuff_t * tvb , <nl> /* XXX - check whether it goes past end of packet */ <nl> rightedge = tvb_get_ntohl ( tvb , offset + 4 ); <nl> optlen -= 4 ; <nl> - proto_tree_add_boolean_hidden ( field_tree , hf_tcp_option_sack , tvb , <nl> - offset , 8 , TRUE ); <nl> - proto_tree_add_uint_format ( field_tree , hf_tcp_option_sack_sle , tvb , <nl> - offset , 8 , leftedge , <nl> - " left edge = % u ", leftedge ); <nl> proto_tree_add_uint_format ( field_tree , hf_tcp_option_sack_sre , tvb , <nl> - offset , 8 , rightedge , <nl> + offset + 4 , 4 , rightedge , <nl> " right edge = % u ", rightedge ); <nl> tcp_info_append_uint ( pinfo , " SLE ", leftedge ); <nl> tcp_info_append_uint ( pinfo , " SRE ", rightedge );
mmm packet - nbns . c <nl> ppp packet - nbns . c <nl> * Gilbert Ramirez < gram @ xiexie . org > <nl> * Much stuff added by Guy Harris < guy @ alum . mit . edu > <nl> * <nl> - * $ Id : packet - nbns . c , v 1 . 61 2001 / 09 / 30 23 : 14 : 43 guy Exp $ <nl> + * $ Id : packet - nbns . c , v 1 . 62 2001 / 10 / 12 01 : 41 : 03 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> dissect_nbss ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> * there should be no compression ), and we <nl> * shouldn ' t have more than 128 bytes ( actually , <nl> * we shouldn ' t have that many ). <nl> + * <nl> + * XXX - actually , MacOS X 10 . 1 ( yes , that ' s <nl> + * redundant , but that ' s what Apple calls it , <nl> + * not MacOS X . 1 ) puts names longer than 16 <nl> + * characters into session request messages , <nl> + * so we can have more than 32 bytes of <nl> + * name value , so we can have more than 128 <nl> + * bytes of data . <nl> */ <nl> - if ( length < 2 || length > 128 ) <nl> + if ( length < 2 || length > 256 ) <nl> goto continuation ; <nl> break ; <nl> 
mmm epan / crypt / airpdcap . c <nl> ppp epan / crypt / airpdcap . c <nl> static INT AirPDcapScanForKeys ( <nl>  <nl> /* get and check the body length ( IEEE 802 . 1X - 2004 , pg . 25 ) */ <nl> bodyLength = pntoh16 ( data + offset + 2 ); <nl> - if (( tot_len - offset - 4 ) < bodyLength ) { /* Only check if frame is long enough for eapol header , ignore tailing garbage , see bug 9065 */ <nl> + if ((( tot_len - offset - 4 ) < bodyLength ) || ( bodyLength < sizeof ( EAPOL_RSN_KEY ))) { /* Only check if frame is long enough for eapol header , ignore tailing garbage , see bug 9065 */ <nl> AIRPDCAP_DEBUG_PRINT_LINE (" AirPDcapScanForKeys ", " EAPOL body too short ", AIRPDCAP_DEBUG_LEVEL_3 ); <nl> return AIRPDCAP_RET_NO_VALID_HANDSHAKE ; <nl> }
mmm epan / epan . c <nl> ppp epan / epan . c <nl> epan_init ( void (* register_all_protocols_func )( register_cb cb , gpointer client_da <nl> register_cb cb , <nl> gpointer client_data ) <nl> { <nl> - gboolean status = TRUE ; <nl> + volatile gboolean status = TRUE ; <nl>  <nl> /* initialize memory allocation subsystem */ <nl> wmem_init ();
mmm epan / dissectors / packet - spnego . c <nl> ppp epan / dissectors / packet - spnego . c <nl> dissect_spnego_supportedMech ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , <nl> proto_tree_add_text ( tree , tvb , offset , nbytes , " supportedMech : % s ", <nl> oid_string ); <nl>  <nl> - g_free ( oid_string ); <nl> - <nl> offset += nbytes ; <nl>  <nl> /* Should check for an unrecognized OID ... */
mmm plugins / megaco / packet - megaco . c <nl> ppp plugins / megaco / packet - megaco . c <nl> * Routines for megaco packet disassembly <nl> * RFC 3015 <nl> * <nl> -* $ Id : packet - megaco . c , v 1 . 15 2004 / 04 / 21 19 : 58 : 14 etxrab Exp $ <nl> +* $ Id : packet - megaco . c , v 1 . 16 2004 / 04 / 23 03 : 20 : 58 guy Exp $ <nl> * <nl> * Christian Falckenberg , 2002 / 10 / 17 <nl> * Copyright ( c ) 2002 by Christian Falckenberg <nl> dissect_megaco_text ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> if ( tree ) <nl> len = tvb_len - tvb_previous_offset ; <nl> proto_tree_add_text ( megaco_tree , tvb , tvb_previous_offset , - 1 , <nl> - "% s ", tvb_format_text ( tvb , tvb_previous_offset , len ), tvb_len , <nl> - tvb_previous_offset ); <nl> + "% s ", tvb_format_text ( tvb , tvb_previous_offset , len )); <nl> if ( global_megaco_raw_text ){ <nl> tvb_raw_text_add ( tvb , megaco_tree ); <nl> }
mmm wiretap / libpcap . c <nl> ppp wiretap / libpcap . c <nl> /* libpcap . c <nl> * <nl> - * $ Id : libpcap . c , v 1 . 16 1999 / 08 / 28 01 : 19 : 44 guy Exp $ <nl> + * $ Id : libpcap . c , v 1 . 17 1999 / 08 / 31 22 : 36 : 20 guy Exp $ <nl> * <nl> * Wiretap Library <nl> * Copyright ( c ) 1998 by Gilbert Ramirez < gram @ verdict . uthscsa . edu > <nl> ((( x )& 0x00FF )<< 8 )) <nl>  <nl> /* On some systems , the FDDI MAC addresses are bit - swapped . */ <nl> -# if ! defined ( ultrix ) && ! defined ( __alpha ) && ! defined ( __bsdi ) <nl> +# if ! defined ( ultrix ) && ! defined ( __alpha ) && ! defined ( __bsdi__ ) <nl> # define BIT_SWAPPED_MAC_ADDRS <nl> # endif <nl> 
mmm ui / gtk / wlan_stat_dlg . c <nl> ppp ui / gtk / wlan_stat_dlg . c <nl> wlanstat_launch ( GtkAction * action _U_ , gpointer user_data _U_ ) <nl> void <nl> register_tap_listener_wlanstat ( void ) <nl> { <nl> - static const char src [ 6 ] = { 0xff , 0xff , 0xff , 0xff , 0xff , 0xff }; <nl> + static const unsigned char src [ 6 ] = { 0xff , 0xff , 0xff , 0xff , 0xff , 0xff }; <nl>  <nl> SET_ADDRESS (& broadcast , AT_ETHER , 6 , src ); <nl> }mmm epan / dissectors / packet - adwin - config . c <nl> ppp epan / dissectors / packet - adwin - config . c <nl> wlanstat_launch ( GtkAction * action _U_ , gpointer user_data _U_ ) <nl> void <nl> register_tap_listener_wlanstat ( void ) <nl> { <nl> - static const char src [ 6 ] = { 0xff , 0xff , 0xff , 0xff , 0xff , 0xff }; <nl> + static const unsigned char src [ 6 ] = { 0xff , 0xff , 0xff , 0xff , 0xff , 0xff }; <nl>  <nl> SET_ADDRESS (& broadcast , AT_ETHER , 6 , src ); <nl> } <nl> dissect_TCPFlashUpdate ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree * adwin <nl> } <nl>  <nl> /* 00 : 50 : c2 : 0a : 2 *:** */ <nl> - static char mac_iab_start [] = { 0x00 , 0x50 , 0xc2 , 0x0a , 0x20 , 0x00 }; <nl> - static char mac_iab_end [] = { 0x00 , 0x50 , 0xc2 , 0x0a , 0x2f , 0xff }; <nl> + static const unsigned char mac_iab_start [] = { 0x00 , 0x50 , 0xc2 , 0x0a , 0x20 , 0x00 }; <nl> + static const unsigned char mac_iab_end [] = { 0x00 , 0x50 , 0xc2 , 0x0a , 0x2f , 0xff }; <nl>  <nl> /* 00 : 22 : 71 :**:**:** */ <nl> - static char mac_oui_start [] = { 0x00 , 0x22 , 0x71 , 0x00 , 0x00 , 0x00 }; <nl> - static char mac_oui_end [] = { 0x00 , 0x22 , 0x71 , 0xff , 0xff , 0xff }; <nl> + static const unsigned char mac_oui_start [] = { 0x00 , 0x22 , 0x71 , 0x00 , 0x00 , 0x00 }; <nl> + static const unsigned char mac_oui_end [] = { 0x00 , 0x22 , 0x71 , 0xff , 0xff , 0xff }; <nl>  <nl> /* ff : ff : ff : ff : ff : ff */ <nl> - static char mac_broadcast [] = { 0xff , 0xff , 0xff , 0xff , 0xff , 0xff }; <nl> + static const unsigned char mac_broadcast [] = { 0xff , 0xff , 0xff , 0xff , 0xff , 0xff }; <nl>  <nl> /* return TRUE if mac is in mac address range assigned to ADwin or if <nl> * mac is broadcast */
mmm epan / dissectors / packet - vmlab . c <nl> ppp epan / dissectors / packet - vmlab . c <nl> dissect_vmlab ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> guint8 attributes ; <nl> guint8 portgroup ; <nl>  <nl> - guint16 encap_proto ; <nl> + volatile guint16 encap_proto ; <nl>  <nl> col_set_str ( pinfo -> cinfo , COL_PROTOCOL , " VMLAB "); <nl> col_clear ( pinfo -> cinfo , COL_INFO );
mmm epan / dissectors / packet - isakmp . c <nl> ppp epan / dissectors / packet - isakmp . c <nl> static struct strfunc { <nl> {" Delete ", dissect_delete }, <nl> {" Vendor ID ", dissect_vid }, <nl> {" Attrib ", dissect_config }, <nl> - {" NAT - Discovery ", dissect_nat_discovery }, /* draft - ietf - ipsec - nat - t - ike */ <nl> + {" NAT - Discovery ", dissect_nat_discovery }, /* draft - ietf - ipsec - nat - t - ike - 04 */ <nl> {" NAT - Original Address ", dissect_nat_original_address } /* draft - ietf - ipsec - nat - t - ike */ <nl> }; <nl>  <nl> payloadtype2str ( guint8 type ) { <nl> if ( type < 128 ) <nl> return " RESERVED "; <nl> if ( type == 130 ) <nl> - return " NAT - D ( draft - ietf - ipsec - nat - t - ike - 01 to 04 )"; <nl> + return " NAT - D ( draft - ietf - ipsec - nat - t - ike - 01 to 03 )"; <nl> if ( type == 131 ) <nl> return " NAT - OA ( draft - ietf - ipsec - nat - t - ike - 01 to 04 )"; <nl> return " Private USE ";
mmm packet - smb . c <nl> ppp packet - smb . c <nl> * Copyright 1999 , Richard Sharpe < rsharpe @ ns . aus . com > <nl> * 2001 Rewrite by Ronnie Sahlberg and Guy Harris <nl> * <nl> - * $ Id : packet - smb . c , v 1 . 327 2003 / 04 / 14 17 : 38 : 49 guy Exp $ <nl> + * $ Id : packet - smb . c , v 1 . 328 2003 / 04 / 17 00 : 13 : 26 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> proto_reg_handoff_smb ( void ) <nl> ntlmssp_handle = find_dissector (" ntlmssp "); <nl>  <nl> heur_dissector_add (" netbios ", dissect_smb_heur , proto_smb ); <nl> + heur_dissector_add (" cotp ", dissect_smb_heur , proto_smb ); <nl> smb_handle = create_dissector_handle ( dissect_smb , proto_smb ); <nl> dissector_add (" ipx . socket ", IPX_SOCKET_NWLINK_SMB_SERVER , smb_handle ); <nl> dissector_add (" ipx . socket ", IPX_SOCKET_NWLINK_SMB_REDIR , smb_handle );
mmm epan / dissectors / packet - nfs . c <nl> ppp epan / dissectors / packet - nfs . c <nl> dissect_nfs_argop4 ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> } <nl> } <nl>  <nl> + for ( ops_counter = 0 ; ops_counter < ops ; ops_counter ++) <nl> + { <nl> + g_string_free ( op_summary [ ops_counter ]. optext , TRUE ); <nl> + } <nl> + <nl> + g_free ( op_summary ); <nl>  <nl> return offset ; <nl> } <nl> dissect_nfs_resop4 ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> } <nl> } <nl>  <nl> + for ( ops_counter = 0 ; ops_counter < ops ; ops_counter ++) <nl> + { <nl> + g_string_free ( op_summary [ ops_counter ]. optext , TRUE ); <nl> + } <nl> + <nl> + g_free ( op_summary ); <nl>  <nl> return offset ; <nl> }
mmm simple_dialog . h <nl> ppp simple_dialog . h <nl> * Definitions for alert box routines with toolkit - independent APIs but <nl> * toolkit - dependent implementations . <nl> * <nl> - * $ Id : simple_dialog . h , v 1 . 14 2004 / 06 / 04 20 : 04 : 34 ulfl Exp $ <nl> + * $ Id : simple_dialog . h , v 1 . 15 2004 / 06 / 04 21 : 12 : 01 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> extern gpointer simple_dialog ( ESD_TYPE_E type , gint btn_mask , <nl> * @ param ap parameters <nl> * @ return the newly created dialog <nl> */ <nl> - extern gpointer vsimple_dialog ( gint type , gint btn_mask , <nl> + extern gpointer vsimple_dialog ( ESD_TYPE_E type , gint btn_mask , <nl> const gchar * msg_format , va_list ap ); <nl> # else <nl> /** Create and show a simple dialog .mmm gtk / simple_dialog . c <nl> ppp gtk / simple_dialog . c <nl> * Definitions for alert box routines with toolkit - independent APIs but <nl> * toolkit - dependent implementations . <nl> * <nl> - * $ Id : simple_dialog . h , v 1 . 14 2004 / 06 / 04 20 : 04 : 34 ulfl Exp $ <nl> + * $ Id : simple_dialog . h , v 1 . 15 2004 / 06 / 04 21 : 12 : 01 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> extern gpointer simple_dialog ( ESD_TYPE_E type , gint btn_mask , <nl> * @ param ap parameters <nl> * @ return the newly created dialog <nl> */ <nl> - extern gpointer vsimple_dialog ( gint type , gint btn_mask , <nl> + extern gpointer vsimple_dialog ( ESD_TYPE_E type , gint btn_mask , <nl> const gchar * msg_format , va_list ap ); <nl> # else <nl> /** Create and show a simple dialog . <nl> /* simple_dialog . c <nl> * Simple message dialog box routines . <nl> * <nl> - * $ Id : simple_dialog . c , v 1 . 35 2004 / 05 / 26 03 : 49 : 24 ulfl Exp $ <nl> + * $ Id : simple_dialog . c , v 1 . 36 2004 / 06 / 04 21 : 12 : 01 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> display_queued_messages ( void ) <nl> */ <nl>  <nl> gpointer <nl> - vsimple_dialog ( gint type , gint btn_mask , const gchar * msg_format , va_list ap ) <nl> + vsimple_dialog ( ESD_TYPE_E type , gint btn_mask , const gchar * msg_format , va_list ap ) <nl> { <nl> gchar * message ; <nl> queued_message_t * queued_message ; <nl> vsimple_dialog ( gint type , gint btn_mask , const gchar * msg_format , va_list ap ) <nl> } <nl>  <nl> gpointer <nl> - simple_dialog ( gint type , gint btn_mask , const gchar * msg_format , ...) <nl> + simple_dialog ( ESD_TYPE_E type , gint btn_mask , const gchar * msg_format , ...) <nl> { <nl> va_list ap ; <nl> gpointer ret ;
mmm epan / dissectors / packet - rsvd . c <nl> ppp epan / dissectors / packet - rsvd . c <nl> static const value_string rsvd_disk_type_vals [] = { <nl>  <nl> static const value_string rsvd_disk_format_vals [] = { <nl> { 0x03 , " VIRTUAL_STORAGE_TYPE_DEVICE_VHDX " }, <nl> + { 0x04 , " VIRTUAL_STORAGE_TYPE_DEVICE_VHDSET " }, <nl> { 0 , NULL } <nl> }; <nl>  <nl> dissect_RSVD_GET_INITIAL_INFO ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree <nl> return offset ; <nl> } <nl>  <nl> + static const value_string rsvd_data_in_vals [] = { <nl> + { 0x00 , " Client is requesting data from the server " }, <nl> + { 0x01 , " Client is sending data to the server " }, <nl> + { 0x02 , " Client is neither sending nor requesting an additional data buffer " }, <nl> + { 0 , NULL } <nl> +}; <nl> + <nl> /* <nl> * Dissect a tunnelled SCSI request and call the SCSI dissector where <nl> * needed . <nl> proto_register_rsvd ( void ) <nl> NULL , 0 , NULL , HFILL }}, <nl>  <nl> { & hf_svhdx_tunnel_scsi_data_in , <nl> - { " DataIn ", " rsvd . svhdx_scsi_data_in ", FT_BOOLEAN , 8 , <nl> - NULL , 0 , NULL , HFILL }}, <nl> + { " DataIn ", " rsvd . svhdx_scsi_data_in ", FT_UINT8 , BASE_HEX , <nl> + VALS ( rsvd_data_in_vals ), 0 , " SCSI CDB transfer type ", HFILL }}, <nl>  <nl> { & hf_svhdx_tunnel_scsi_reserved2 , <nl> { " Reserved2 ", " rsvd . svhdx_scsi_reserved2 ", FT_UINT8 , BASE_HEX ,mmm epan / dissectors / packet - smb2 . c <nl> ppp epan / dissectors / packet - smb2 . c <nl> static const value_string rsvd_disk_type_vals [] = { <nl>  <nl> static const value_string rsvd_disk_format_vals [] = { <nl> { 0x03 , " VIRTUAL_STORAGE_TYPE_DEVICE_VHDX " }, <nl> + { 0x04 , " VIRTUAL_STORAGE_TYPE_DEVICE_VHDSET " }, <nl> { 0 , NULL } <nl> }; <nl>  <nl> dissect_RSVD_GET_INITIAL_INFO ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree <nl> return offset ; <nl> } <nl>  <nl> + static const value_string rsvd_data_in_vals [] = { <nl> + { 0x00 , " Client is requesting data from the server " }, <nl> + { 0x01 , " Client is sending data to the server " }, <nl> + { 0x02 , " Client is neither sending nor requesting an additional data buffer " }, <nl> + { 0 , NULL } <nl> +}; <nl> + <nl> /* <nl> * Dissect a tunnelled SCSI request and call the SCSI dissector where <nl> * needed . <nl> proto_register_rsvd ( void ) <nl> NULL , 0 , NULL , HFILL }}, <nl>  <nl> { & hf_svhdx_tunnel_scsi_data_in , <nl> - { " DataIn ", " rsvd . svhdx_scsi_data_in ", FT_BOOLEAN , 8 , <nl> - NULL , 0 , NULL , HFILL }}, <nl> + { " DataIn ", " rsvd . svhdx_scsi_data_in ", FT_UINT8 , BASE_HEX , <nl> + VALS ( rsvd_data_in_vals ), 0 , " SCSI CDB transfer type ", HFILL }}, <nl>  <nl> { & hf_svhdx_tunnel_scsi_reserved2 , <nl> { " Reserved2 ", " rsvd . svhdx_scsi_reserved2 ", FT_UINT8 , BASE_HEX , <nl> static const value_string smb2_ioctl_shared_virtual_disk_vals [] = { <nl> static const value_string smb2_ioctl_shared_virtual_disk_hstate_vals [] = { <nl> { 0x00 , " HandleStateNone " }, <nl> { 0x01 , " HandleStateFileShared " }, <nl> - { 0x02 , " HandleStateShared " }, <nl> + { 0x03 , " HandleStateShared " }, <nl> { 0 , NULL } <nl> }; <nl> 
mmm epan / dissectors / packet - infiniband . c <nl> ppp epan / dissectors / packet - infiniband . c <nl> dissect_infiniband ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_transport_header_version , tvb , offset , 1 , FALSE ); offset += 1 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_partition_key , tvb , offset , 2 , FALSE ); offset += 2 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_reserved8 , tvb , offset , 1 , FALSE ); offset += 1 ; <nl> - proto_tree_add_item ( base_transport_header_tree , hf_infiniband_destination_qp , tvb , offset , 3 , FALSE ); offset += 3 ; <nl> + proto_tree_add_item ( base_transport_header_tree , hf_infiniband_destination_qp , tvb , offset , 3 , FALSE ); <nl> + dst_qp = tvb_get_ntoh24 ( tvb , offset ); offset += 3 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_acknowledge_request , tvb , offset , 1 , FALSE ); <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_reserved7 , tvb , offset , 1 , FALSE ); offset += 1 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_packet_sequence_number , tvb , offset , 3 , FALSE ); offset += 3 ;
mmm gtk / gtkvumeter . c <nl> ppp gtk / gtkvumeter . c <nl> static void gtk_vumeter_size_calculate ( GtkWidget * widget , GtkRequisition * requi <nl> PangoLayout * layout = gtk_widget_create_pango_layout ( widget , item -> label ); <nl> pango_layout_get_pixel_size ( layout , & layout_width , & layout_height ); <nl> /* XXX - memleak */ <nl> + } else { <nl> + layout_width = 0 ; <nl> + layout_height = 0 ; <nl> } <nl>  <nl> if ( vumeter -> vertical == TRUE ) {
mmm gtk / dlg_utils . c <nl> ppp gtk / dlg_utils . c <nl> dlg_button_row_new ( const gchar * stock_id_first , ...) <nl> gtk_box_pack_end ( GTK_BOX ( hbox ), button_hbox , TRUE , TRUE , 0 ); <nl> g_object_set_data ( G_OBJECT ( hbox ), BUTTON_HBOX_KEY , button_hbox ); <nl> gtk_widget_show ( button_hbox ); <nl> + gtk_button_box_set_spacing ( GTK_BUTTON_BOX ( button_hbox ), 5 ); <nl>  <nl> help_hbox = gtk_hbutton_box_new (); <nl> gtk_box_pack_end ( GTK_BOX ( hbox ), help_hbox , FALSE , FALSE , 0 ); <nl> gtk_widget_show ( help_hbox ); <nl> + gtk_button_box_set_spacing ( GTK_BUTTON_BOX ( help_hbox ), 5 ); <nl>  <nl> if ( buttons == 0 ) { <nl> /* if no buttons wanted , simply do nothing */ <nl> dlg_button_row_new ( const gchar * stock_id_first , ...) <nl> /* if more than one button , sort buttons from left to right */ <nl> /* ( the whole button cluster will then be right aligned ) */ <nl> gtk_button_box_set_layout ( GTK_BUTTON_BOX ( button_hbox ), GTK_BUTTONBOX_END ); <nl> - gtk_button_box_set_spacing ( GTK_BUTTON_BOX ( button_hbox ), 5 ); <nl>  <nl> /* GTK + 1 . 3 and later - on Win32 , we use 1 . 3 [. x ] or 2 . x , not 1 . 2 [. x ] */ <nl> # if ! defined ( _WIN32 ) <nl> dlg_button_row_new ( const gchar * stock_id_first , ...) <nl> if ( close != NULL ) dlg_button_new ( hbox , button_hbox , close ); <nl> if ( cancel != NULL ) dlg_button_new ( hbox , button_hbox , cancel ); <nl>  <nl> - /* GTK2 : we don ' t know that button combination , add it to the above list ! */ <nl> - /* g_assert_not_reached (); */ <nl> return hbox ; <nl> } <nl> 
mmm ui / qt / io_graph_dialog . cpp <nl> ppp ui / qt / io_graph_dialog . cpp <nl> static uat_field_t io_graph_fields [] = { <nl> UAT_END_FIELDS <nl> }; <nl>  <nl> - static void * io_graph_copy_cb ( void * dst_ptr , const void * src_ptr , size_t len _U_ ) { <nl> + static void * io_graph_copy_cb ( void * dst_ptr , const void * src_ptr , size_t len ) { <nl> + Q_UNUSED ( len ); <nl> io_graph_settings_t * dst = ( io_graph_settings_t *) dst_ptr ; <nl> const io_graph_settings_t * src = ( const io_graph_settings_t *) src_ptr ; <nl> 
mmm epan / reassemble . c <nl> ppp epan / reassemble . c <nl> fragment_add_work ( fragment_data * fd_head , tvbuff_t * tvb , const int offset , <nl> fragment_data * fd_i ; <nl> guint32 max , dfpos , fraglen ; <nl> tvbuff_t * old_tvb_data ; <nl> - char * data ; <nl> + guint8 * data ; <nl>  <nl> /* create new fd describing this fragment */ <nl> fd = g_slice_new ( fragment_data ); <nl> fragment_add_work ( fragment_data * fd_head , tvbuff_t * tvb , const int offset , <nl> */ <nl> /* store old data just in case */ <nl> old_tvb_data = fd_head -> tvb_data ; <nl> - data = g_malloc ( fd_head -> datalen ); <nl> + data = ( guint8 *) g_malloc ( fd_head -> datalen ); <nl> fd_head -> tvb_data = tvb_new_real_data ( data , fd_head -> datalen , fd_head -> datalen ); <nl> tvb_set_free_cb ( fd_head -> tvb_data , g_free ); <nl>  <nl> fragment_defragment_and_free ( fragment_data * fd_head , const packet_info * pinfo ) <nl> fragment_data * last_fd = NULL ; <nl> guint32 dfpos = 0 , size = 0 ; <nl> tvbuff_t * old_tvb_data = NULL ; <nl> - char * data ; <nl> + guint8 * data ; <nl>  <nl> for ( fd_i = fd_head -> next ; fd_i ; fd_i = fd_i -> next ) { <nl> if (! last_fd || last_fd -> offset != fd_i -> offset ){ <nl> fragment_defragment_and_free ( fragment_data * fd_head , const packet_info * pinfo ) <nl>  <nl> /* store old data in case the fd_i -> data pointers refer to it */ <nl> old_tvb_data = fd_head -> tvb_data ; <nl> - data = g_malloc ( size ); <nl> + data = ( guint8 *) g_malloc ( size ); <nl> fd_head -> tvb_data = tvb_new_real_data ( data , size , size ); <nl> tvb_set_free_cb ( fd_head -> tvb_data , g_free ); <nl> fd_head -> len = size ; /* record size for caller */
mmm tshark . c <nl> ppp tshark . c <nl> print_usage ( gboolean print_ver ) <nl>  <nl> /* fprintf ( output , "\ n ");*/ <nl> fprintf ( output , " Output :\ n "); <nl> - fprintf ( output , " - w < outfile |-> set the output filename ( or '-' for stdout )\ n "); <nl> + fprintf ( output , " - w < outfile |-> write packets to a pcap - format file named \" outfile \"\ n "); <nl> + fprintf ( output , " ( or to the standard output for \"-\")\ n "); <nl> fprintf ( output , " - C < config profile > start with specified configuration profile \ n "); <nl> fprintf ( output , " - F < output file type > set the output file type , default is libpcap \ n "); <nl> fprintf ( output , " an empty \"- F \" option will list the file types \ n ");
mmm epan / dissectors / packet - icq . c <nl> ppp epan / dissectors / packet - icq . c <nl> dissect_icqv5Client ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> * bytes in the buffer . <nl> */ <nl> rounded_size = (((( capturedsize - ICQ5_CL_SESSIONID ) + 3 )/ 4 )* 4 ) + ICQ5_CL_SESSIONID ; <nl> - decr_pd = tvb_memdup ( tvb , 0 , capturedsize ); <nl> + /* rounded_size might exceed the tvb bounds so we can ' t just use tvb_memdup here . */ <nl> + decr_pd = g_malloc ( rounded_size ); <nl> + tvb_memcpy ( tvb , decr_pd , 0 , capturedsize ); <nl> decrypt_v5 ( decr_pd , rounded_size , key ); <nl>  <nl> /* Allocate a new tvbuff , referring to the decrypted data . */
mmm epan / dissectors / packet - prp . c <nl> ppp epan / dissectors / packet - prp . c <nl> dissect_prp_redundancy_control_trailer ( tvbuff_t * tvb , packet_info * pinfo _U_ , pr <nl> if ( length < 14 ) <nl> return 0 ; <nl>  <nl> + /* <nl> + * This is horribly broken . It assumes the frame is an Ethernet <nl> + * frame , with a type field at an offset of 12 bytes from the header . <nl> + * That is not guaranteed to be true . <nl> + */ <nl> + if (! tvb_bytes_exist ( tvb , 12 , 2 )) <nl> + return 0 ; <nl> if ( ETHERTYPE_VLAN == tvb_get_ntohs ( tvb , 12 )) /* tagged frame */ <nl> { <nl> offset = 18 ; <nl> dissect_prp_redundancy_control_trailer ( tvbuff_t * tvb , packet_info * pinfo _U_ , pr <nl> if (! tree ) <nl> return tvb_captured_length ( tvb ); <nl>  <nl> + /* <nl> + * Is there enough data in the packet to every try to search for a <nl> + * trailer ? <nl> + */ <nl> + if (! tvb_bytes_exist ( tvb , ( length - 4 )+ 2 , 2 )) <nl> + return 0 ; /* no */ <nl> + <nl> /* search for PRP - 0 trailer */ <nl> /* If the frame is > 64 bytes , the PRP - 0 trailer is always at the end . */ <nl> /* If the frame is <= 64 bytes , the PRP - 0 trailer may be anywhere ( before the padding ) */
mmm epan / dissectors / packet - sip . c <nl> ppp epan / dissectors / packet - sip . c <nl> dissect_sip_contact_item ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , gi <nl> gint current_offset ; <nl> gint queried_offset ; <nl> gint contact_params_start_offset = - 1 ; <nl> - gint contact_param_end_offset = - 1 ; <nl> + /* gint contact_param_end_offset = - 1 ;*/ <nl> uri_offset_info uri_offsets ; <nl>  <nl> /* skip Spaces and Tabs */
mmm wiretap / cosine . c <nl> ppp wiretap / cosine . c <nl> parse_cosine_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl> { <nl> union wtap_pseudo_header * pseudo_header = & phdr -> pseudo_header ; <nl> int num_items_scanned ; <nl> - int yy , mm , dd , hr , min , sec , csec ; <nl> - guint pkt_len ; <nl> + int yy , mm , dd , hr , min , sec , csec , pkt_len ; <nl> int pro , off , pri , rm , error ; <nl> guint code1 , code2 ; <nl> char if_name [ COSINE_MAX_IF_NAME_LEN ] = "", direction [ 6 ] = ""; <nl> parse_cosine_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl> & yy , & mm , & dd , & hr , & min , & sec , & csec ) == 7 ) { <nl> /* appears to be output to a control blade */ <nl> num_items_scanned = sscanf ( line , <nl> - "% 4d -% 2d -% 2d ,% 2d :% 2d :% 2d .% 9d : % 5s (% 127 [ A - Za - z0 - 9 /:]), Length :% 9u , Pro :% 9d , Off :% 9d , Pri :% 9d , RM :% 9d , Err :% 9d [% 8x , % 8x ]", <nl> + "% 4d -% 2d -% 2d ,% 2d :% 2d :% 2d .% 9d : % 5s (% 127 [ A - Za - z0 - 9 /:]), Length :% 9d , Pro :% 9d , Off :% 9d , Pri :% 9d , RM :% 9d , Err :% 9d [% 8x , % 8x ]", <nl> & yy , & mm , & dd , & hr , & min , & sec , & csec , <nl> direction , if_name , & pkt_len , <nl> & pro , & off , & pri , & rm , & error , <nl> parse_cosine_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl> } else { <nl> /* appears to be output to PE */ <nl> num_items_scanned = sscanf ( line , <nl> - "% 5s (% 127 [ A - Za - z0 - 9 /:]), Length :% 9u , Pro :% 9d , Off :% 9d , Pri :% 9d , RM :% 9d , Err :% 9d [% 8x , % 8x ]", <nl> + "% 5s (% 127 [ A - Za - z0 - 9 /:]), Length :% 9d , Pro :% 9d , Off :% 9d , Pri :% 9d , RM :% 9d , Err :% 9d [% 8x , % 8x ]", <nl> direction , if_name , & pkt_len , <nl> & pro , & off , & pri , & rm , & error , <nl> & code1 , & code2 ); <nl> parse_cosine_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , <nl> } <nl> yy = mm = dd = hr = min = sec = csec = 0 ; <nl> } <nl> + if ( pkt_len < 0 ) { <nl> + * err = WTAP_ERR_BAD_FILE ; <nl> + * err_info = g_strdup (" cosine : packet header has a negative packet length "); <nl> + return FALSE ; <nl> + } <nl> if ( pkt_len > WTAP_MAX_PACKET_SIZE ) { <nl> /* <nl> * Probably a corrupt capture file ; don ' t blow up trying
mmm epan / filesystem . c <nl> ppp epan / filesystem . c <nl> file_open_error_message ( int err , gboolean for_writing ) <nl> break ; <nl> # endif <nl>  <nl> + case EINVAL : <nl> + errmsg = " The file \"% s \" could not be created because an invalid filename was specified ."; <nl> + break ; <nl> + <nl> default : <nl> g_snprintf ( errmsg_errno , sizeof ( errmsg_errno ), <nl> " The file \"%% s \" could not be % s : % s .",
mmm epan / crypt / airpdcap . c <nl> ppp epan / crypt / airpdcap . c <nl> AirPDcapGetStaAddress ( <nl> switch ( AIRPDCAP_DS_BITS ( frame -> fc [ 1 ])) { /* Bit 1 = FromDS , bit 0 = ToDS */ <nl> case 0 : <nl> case 1 : <nl> - case 3 : <nl> return frame -> addr2 ; <nl> case 2 : <nl> return frame -> addr1 ; <nl> + case 3 : <nl> + if ( memcmp ( frame -> addr1 , frame -> addr2 , AIRPDCAP_MAC_LEN ) < 0 ) <nl> + return frame -> addr1 ; <nl> + else <nl> + return frame -> addr2 ; <nl> + <nl> default : <nl> return NULL ; <nl> } <nl> AirPDcapGetBssidAddress ( <nl> case 0 : <nl> return frame -> addr3 ; <nl> case 1 : <nl> - case 3 : <nl> return frame -> addr1 ; <nl> case 2 : <nl> return frame -> addr2 ; <nl> + case 3 : <nl> + if ( memcmp ( frame -> addr1 , frame -> addr2 , AIRPDCAP_MAC_LEN ) > 0 ) <nl> + return frame -> addr1 ; <nl> + else <nl> + return frame -> addr2 ; <nl> + <nl> default : <nl> return NULL ; <nl> }
mmm epan / frame_data . c <nl> ppp epan / frame_data . c <nl> frame_data_init ( frame_data * fdata , guint32 num , <nl> fdata -> cum_bytes = cum_bytes + phdr -> len ; <nl> fdata -> cap_len = phdr -> caplen ; <nl> fdata -> file_off = offset ; <nl> - /* To save some memory , we coarcese it into a gint8 */ <nl> - g_assert ( phdr -> pkt_encap <= G_MAXINT8 ); <nl> - fdata -> lnk_t = ( gint8 ) phdr -> pkt_encap ; <nl> + /* To save some memory , we coerce it into a gint16 */ <nl> + g_assert ( phdr -> pkt_encap <= G_MAXINT16 ); <nl> + fdata -> lnk_t = ( gint16 ) phdr -> pkt_encap ; <nl> fdata -> abs_ts . secs = phdr -> ts . secs ; <nl> fdata -> abs_ts . nsecs = phdr -> ts . nsecs ; <nl> fdata -> flags . passed_dfilter = 0 ;mmm epan / frame_data . h <nl> ppp epan / frame_data . h <nl> frame_data_init ( frame_data * fdata , guint32 num , <nl> fdata -> cum_bytes = cum_bytes + phdr -> len ; <nl> fdata -> cap_len = phdr -> caplen ; <nl> fdata -> file_off = offset ; <nl> - /* To save some memory , we coarcese it into a gint8 */ <nl> - g_assert ( phdr -> pkt_encap <= G_MAXINT8 ); <nl> - fdata -> lnk_t = ( gint8 ) phdr -> pkt_encap ; <nl> + /* To save some memory , we coerce it into a gint16 */ <nl> + g_assert ( phdr -> pkt_encap <= G_MAXINT16 ); <nl> + fdata -> lnk_t = ( gint16 ) phdr -> pkt_encap ; <nl> fdata -> abs_ts . secs = phdr -> ts . secs ; <nl> fdata -> abs_ts . nsecs = phdr -> ts . nsecs ; <nl> fdata -> flags . passed_dfilter = 0 ; <nl> typedef struct _frame_data { <nl> guint32 pkt_len ; /* Packet length */ <nl> guint32 cap_len ; /* Amount actually captured */ <nl> guint32 cum_bytes ; /* Cumulative bytes into the capture */ <nl> - guint16 subnum ; /* subframe number , for protocols that require this */ <nl> gint64 file_off ; /* File offset */ <nl> - gint8 lnk_t ; /* Per - packet encapsulation / data - link type */ <nl> + guint16 subnum ; /* subframe number , for protocols that require this */ <nl> + gint16 lnk_t ; /* Per - packet encapsulation / data - link type */ <nl> struct { <nl> unsigned int passed_dfilter : 1 ; /* 1 = display , 0 = no display */ <nl> unsigned int encoding : 2 ; /* Character encoding ( ASCII , EBCDIC ...) */
mmm ui / gtk / rlc_lte_graph . c <nl> ppp ui / gtk / rlc_lte_graph . c <nl> # define MOUSE_BUTTON_MIDDLE 2 <nl> # define MOUSE_BUTTON_RIGHT 3 <nl>  <nl> -# define MAX_PIXELS_PER_SN 90 <nl> +# define MAX_PIXELS_PER_SN 90 <nl> +# define MAX_PIXELS_PER_SECOND 50000 <nl>  <nl> extern int proto_rlc_lte ; <nl>  <nl> static void do_zoom_common ( struct graph * g , GdkEventButton * event , <nl> } <nl> } else { <nl> /* Zoom in */ <nl> - if ( lock_horizontal ) { <nl> + if (( lock_horizontal ) || ( g -> geom . width >= ( g -> bounds . width * MAX_PIXELS_PER_SECOND ))) { <nl> factor . x = 1 . 0 ; <nl> } <nl> else { <nl> static void do_zoom_common ( struct graph * g , GdkEventButton * event , <nl> } <nl>  <nl> /* Don ' t zoom in too far vertically */ <nl> - if (( g -> geom . height >= ( g -> bounds . height * MAX_PIXELS_PER_SN )) || lock_vertical ) { <nl> + if ( lock_vertical || ( g -> geom . height >= ( g -> bounds . height * MAX_PIXELS_PER_SN ))) { <nl> factor . y = 1 . 0 ; <nl> } <nl> else {
mmm epan / dissectors / packet - rohc . c <nl> ppp epan / dissectors / packet - rohc . c <nl> start_over : <nl> } <nl> col_prepend_fstr ( pinfo -> cinfo , COL_PROTOCOL , " ROHC <"); <nl> col_append_str ( pinfo -> cinfo , COL_PROTOCOL , ">"); <nl> + pinfo -> private_data = save_private_data ; <nl> + return ; <nl> } <nl> else if ((( oct & 0x80 )== 0x00 ) && ( rohc_cid_context -> profile == ROHC_PROFILE_RTP )) { <nl> /* 5 . 7 . 1 . Packet type 0 : UO - 0 , R - 0 , R - 0 - CRC */ <nl> start_over : <nl> } <nl>  <nl> payload_tvb = tvb_new_subset_remaining ( tvb , offset ); <nl> - call_dissector_only ( data_handle , payload_tvb , pinfo , rohc_tree , NULL ); <nl> + call_dissector_only ( data_handle , payload_tvb , pinfo , tree , NULL ); <nl>  <nl> pinfo -> private_data = save_private_data ; <nl> }
mmm gtk / file_dlg . c <nl> ppp gtk / file_dlg . c <nl> /* file_dlg . c <nl> * Dialog boxes for handling files <nl> * <nl> - * $ Id : file_dlg . c , v 1 . 41 2001 / 08 / 21 06 : 39 : 18 guy Exp $ <nl> + * $ Id : file_dlg . c , v 1 . 42 2001 / 09 / 10 08 : 49 : 11 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> select_file_type_cb ( GtkWidget * w , gpointer data ) <nl> /* We can select only the filtered or marked packets to be saved if we can <nl> use Wiretap to save the file . */ <nl> gtk_widget_set_sensitive ( filter_cb , can_save_with_wiretap ( new_filetype )); <nl> + gtk_widget_set_sensitive ( mark_cb , can_save_with_wiretap ( new_filetype )); <nl> filetype = new_filetype ; <nl> } <nl> } <nl> file_save_as_cmd_cb ( GtkWidget * w , gpointer data ) <nl> main_vb , FALSE , FALSE , 0 ); <nl> gtk_widget_show ( main_vb ); <nl>  <nl> + /* <nl> + * XXX - should this be sensitive only if the current display filter <nl> + * has rejected some packets , so that not all packets are currently <nl> + * being displayed , and if it has accepted some packets , so that some <nl> + * packets are currently being displayed ? <nl> + */ <nl> filter_cb = gtk_check_button_new_with_label (" Save only packets currently being displayed "); <nl> gtk_container_add ( GTK_CONTAINER ( main_vb ), filter_cb ); <nl> gtk_toggle_button_set_state ( GTK_TOGGLE_BUTTON ( filter_cb ), FALSE ); <nl> file_save_as_cmd_cb ( GtkWidget * w , gpointer data ) <nl> gtk_widget_set_sensitive ( filter_cb , can_save_with_wiretap ( filetype )); <nl> gtk_widget_show ( filter_cb ); <nl>  <nl> + /* <nl> + * XXX - should this be sensitive only if at least one packet is <nl> + * marked , so that there are marked packets to save , and if not <nl> + * all packets are marked , so that " only marked packets " is different <nl> + * from " all packets "? <nl> + */ <nl> mark_cb = gtk_check_button_new_with_label (" Save only marked packets "); <nl> gtk_container_add ( GTK_CONTAINER ( main_vb ), mark_cb ); <nl> gtk_toggle_button_set_state ( GTK_TOGGLE_BUTTON ( mark_cb ), FALSE );
mmm epan / proto . c <nl> ppp epan / proto . c <nl> proto_item_set_len ( proto_item * pi , const gint length ) <nl> DISSECTOR_ASSERT ( length >= 0 ); <nl> fi -> length = length ; <nl>  <nl> - if ( fi -> value . ftype -> ftype == FT_BYTES ) <nl> + /* <nl> + * You cannot just make the " len " field of a GByteArray <nl> + * larger , if there ' s no data to back that length ; <nl> + * you can only make it smaller . <nl> + */ <nl> + if ( fi -> value . ftype -> ftype == FT_BYTES && length <= fi -> length ) <nl> fi -> value . value . bytes -> len = length ; <nl> } <nl> 
mmm ui / qt / multicast_statistics_dialog . cpp <nl> ppp ui / qt / multicast_statistics_dialog . cpp <nl> void MulticastStatisticsDialog :: updateMulticastParameters () <nl>  <nl> param = buffer_alarm_threshold_le_ -> text (). toInt (& ok ); <nl> if ( ok && param > 0 ) { <nl> - mcast_stream_trigger = param ; <nl> + mcast_stream_bufferalarm = param ; <nl> } <nl>  <nl> param = stream_empty_speed_le_ -> text (). toInt (& ok );
mmm epan / nghttp2 / nghttp2_hd . c <nl> ppp epan / nghttp2 / nghttp2_hd . c <nl> static nghttp2_hd_entry * add_hd_table_incremental ( nghttp2_hd_context * context , <nl>  <nl> if ( rv != 0 ) { <nl> -- new_ent -> ref ; <nl> + <nl> + /* nv -> name and nv -> value are managed by caller . */ <nl> + new_ent -> nv . name = NULL ; <nl> + new_ent -> nv . namelen = 0 ; <nl> + new_ent -> nv . value = NULL ; <nl> + new_ent -> nv . valuelen = 0 ; <nl> + <nl> nghttp2_hd_entry_free ( new_ent ); <nl> free ( new_ent ); <nl> 
mmm epan / dissectors / packet - pdcp - lte . c <nl> ppp epan / dissectors / packet - pdcp - lte . c <nl> static gint pdcp_channel_equal ( gconstpointer v , gconstpointer v2 ) <nl> static guint pdcp_channel_hash_func ( gconstpointer v ) <nl> { <nl> /* Just use pointer , as the fields are all in this value */ <nl> - return ( guint ) v ; <nl> + return GPOINTER_TO_UINT ( v ); <nl> } <nl>  <nl> 
mmm gtk / main . c <nl> ppp gtk / main . c <nl> create_main_window ( gint pl_size , gint tv_size , gint bv_size , e_prefs * prefs ) <nl> channel_list = g_list_append ( channel_list , ieee80211_mhz_to_str ( airpcap_if_active -> pSupportedChannels [ i ]. Frequency )); <nl> } <nl> gtk_combo_set_popdown_strings ( GTK_COMBO ( channel_cm ), channel_list ); <nl> + g_list_free ( channel_list ); <nl> } <nl>  <nl> gtk_tooltips_set_tip ( airpcap_tooltips , GTK_WIDGET ( GTK_COMBO ( channel_cm )-> entry ), <nl> create_main_window ( gint pl_size , gint tv_size , gint bv_size , e_prefs * prefs ) <nl> linktype_list = g_list_append ( linktype_list , AIRPCAP_VALIDATION_TYPE_NAME_CORRUPT ); <nl>  <nl> gtk_combo_set_popdown_strings ( GTK_COMBO ( wrong_crc_cm ), linktype_list ) ; <nl> + g_list_free ( linktype_list ); <nl> gtk_tooltips_set_tip ( airpcap_tooltips , GTK_WIDGET ( GTK_COMBO ( wrong_crc_cm )-> entry ), <nl> " Select the 802 . 11 FCS filter that the wireless adapter will apply .", <nl> NULL );
mmm epan / dissectors / packet - sdp . c <nl> ppp epan / dissectors / packet - sdp . c <nl> dissect_sdp_media ( tvbuff_t * tvb , proto_item * ti , <nl> proto_tree_add_string ( sdp_media_tree , hf_media_format , tvb , offset , <nl> tokenlen , val_to_str ( atol ( media_format ), rtp_payload_type_vals , "% u ")); <nl> transport_info -> media_pt [ transport_info -> media_pt_count ] = atol ( media_format ); <nl> - if ( transport_info -> media_pt_count < SDP_MAX_RTP_PAYLOAD_TYPES ) <nl> + if ( transport_info -> media_pt_count < SDP_MAX_RTP_PAYLOAD_TYPES - 1 ) <nl> transport_info -> media_pt_count ++; <nl> g_free ( media_format ); <nl> } else {
mmm packet - dns . c <nl> ppp packet - dns . c <nl> /* packet - dns . c <nl> * Routines for DNS packet disassembly <nl> * <nl> - * $ Id : packet - dns . c , v 1 . 99 2003 / 01 / 31 08 : 29 : 09 guy Exp $ <nl> + * $ Id : packet - dns . c , v 1 . 100 2003 / 05 / 05 08 : 14 : 31 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> add_opt_rr_to_tree ( proto_item * trr , int rr_type , tvbuff_t * tvb , int offset , <nl> const char * name , int namelen , const char * type_name , int class , <nl> guint ttl , gushort data_len ) <nl> { <nl> - proto_tree * rr_tree ; <nl> + proto_tree * rr_tree , * Z_tree ; <nl> + proto_item * Z_item = NULL ; <nl>  <nl> rr_tree = proto_item_add_subtree ( trr , rr_type ); <nl> proto_tree_add_text ( rr_tree , tvb , offset , namelen , " Name : % s ", name ); <nl> add_opt_rr_to_tree ( proto_item * trr , int rr_type , tvbuff_t * tvb , int offset , <nl> proto_tree_add_text ( rr_tree , tvb , offset , 1 , " EDNS0 version : % u ", <nl> ( ttl >> 16 ) & 0xff ); <nl> offset ++; <nl> - proto_tree_add_text ( rr_tree , tvb , offset , 2 , " Must be zero : 0x % x ", ttl & 0xffff ); <nl> + Z_item = proto_tree_add_text ( rr_tree , tvb , offset , 2 , " Z : 0x % x ", ttl & 0xffff ); <nl> + if ( ttl & 0x8000 ) { <nl> + Z_tree = proto_item_add_subtree ( Z_item , rr_type ); <nl> + proto_tree_add_text ( Z_tree , tvb , offset , 2 , " Bit 0 ( DO bit ): 1 ( Accepts DNSSEC security RRs )"); <nl> + proto_tree_add_text ( Z_tree , tvb , offset , 2 , " Bits 1 - 15 : 0x % x ( reserved )", ( ttl >> 17 ) & 0xff ); <nl> + } <nl> offset += 2 ; <nl> proto_tree_add_text ( rr_tree , tvb , offset , 2 , " Data length : % u ", data_len ); <nl> return rr_tree ;
mmm plugins / ethercat / packet - esl . c <nl> ppp plugins / ethercat / packet - esl . c <nl> typedef union _EslFlagsUnion <nl> guint16 extended : 1 ; <nl> guint16 port11 : 1 ; <nl> guint16 port10 : 1 ; <nl> - guint16 crcError : 1 ; <nl> guint16 alignError : 1 ; <nl> + guint16 crcError : 1 ; <nl> guint16 timeStampEna : 1 ; <nl> guint16 port9 : 1 ; <nl> guint16 port8 : 1 ; <nl> typedef union _EslFlagsUnion <nl> # define esl_extended_bitmask 0x0100 <nl> # define esl_port11_bitmask 0x0200 <nl> # define esl_port10_bitmask 0x0400 <nl> -# define esl_crcError_bitmask 0x0800 <nl> -# define esl_alignError_bitmask 0x1000 <nl> +# define esl_alignError_bitmask 0x0800 <nl> +# define esl_crcError_bitmask 0x1000 <nl> # define esl_timeStampEna_bitmask 0x2000 <nl> # define esl_port9_bitmask 0x4000 <nl> # define esl_port8_bitmask 0x8000 <nl> dissect_esl_header ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree * tree , void <nl> flags = tvb_get_letohs ( tvb , offset ); <nl> proto_tree_add_uint ( esl_header_tree , hf_esl_port , tvb , offset , 2 , flags_to_port ( flags )); <nl>  <nl> - proto_tree_add_item ( esl_header_tree , hf_esl_crcerror , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); <nl> proto_tree_add_item ( esl_header_tree , hf_esl_alignerror , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); <nl> + proto_tree_add_item ( esl_header_tree , hf_esl_crcerror , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); <nl> + <nl> offset += 2 ; <nl>  <nl> proto_tree_add_item ( esl_header_tree , hf_esl_timestamp , tvb , offset , 8 , ENC_LITTLE_ENDIAN );
mmm epan / dissectors / packet - tipc . c <nl> ppp epan / dissectors / packet - tipc . c <nl> void proto_register_tipc ( void ); <nl>  <nl> static int proto_tipc = - 1 ; <nl>  <nl> -/* dissector handles */ <nl> - static dissector_handle_t ip_handle ; <nl> - <nl> static int hf_tipc_msg_fragments = - 1 ; <nl> static int hf_tipc_msg_fragment = - 1 ; <nl> static int hf_tipc_msg_fragment_overlap = - 1 ; <nl> proto_reg_handoff_tipc ( void ) <nl> dissector_handle_t tipc_tcp_handle ; <nl>  <nl> tipc_tcp_handle = create_dissector_handle ( dissect_tipc_tcp , proto_tipc ); <nl> - ip_handle = find_dissector (" ip "); <nl>  <nl> dissector_add_uint (" ethertype ", ETHERTYPE_TIPC , tipc_handle ); <nl> dissector_add_for_decode_as_with_preference (" tcp . port ", tipc_tcp_handle );
mmm packet - dcerpc - spoolss . c <nl> ppp packet - dcerpc - spoolss . c <nl> * Routines for SMB \ PIPE \ spoolss packet disassembly <nl> * Copyright 2001 , Tim Potter < tpot @ samba . org > <nl> * <nl> - * $ Id : packet - dcerpc - spoolss . c , v 1 . 5 2002 / 03 / 19 22 : 09 : 23 guy Exp $ <nl> + * $ Id : packet - dcerpc - spoolss . c , v 1 . 6 2002 / 03 / 20 09 : 09 : 07 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> static int prs_uint16uni ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl>  <nl> /* Get remaining data in buffer as a string */ <nl>  <nl> - remaining = tvb_length_remaining ( tvb , offset ); <nl> + remaining = tvb_length_remaining ( tvb , offset )/ 2 ; <nl> text = fake_unicode ( tvb , offset , remaining ); <nl> len = strlen ( text ); <nl> 
mmm epan / dissectors / packet - rtps . c <nl> ppp epan / dissectors / packet - rtps . c <nl> static const struct Flag_definition DATA_FRAG_FLAGS [] = { <nl> { ' Q ', " Inline QoS " }, /* Bit 1 */ <nl> { ' E ', " Endianness bit " } /* Bit 0 */ <nl> }; <nl> +# if 0 <nl> /* Vendor specific : RTI */ <nl> static const struct Flag_definition NACK_FLAGS [] = { <nl> { RESERVEDFLAG_CHAR , RESERVEDFLAG_STRING }, /* Bit 7 */ <nl> static const struct Flag_definition NACK_FLAGS [] = { <nl> { ' F ', " Final flag " }, /* Bit 1 */ <nl> { ' E ', " Endianness bit " } /* Bit 0 */ <nl> }; <nl> +# endif <nl>  <nl>  <nl> /***************************************************************************/ <nl> static void dissect_DATA_FRAG ( tvbuff_t * tvb , packet_info * pinfo , gint offset , gu <nl> proto_item * octet_item ; <nl> guint32 wid ; <nl> gboolean from_builtin_writer ; <nl> - rtps_util_decode_flags ( tree , tvb , offset + 1 , flags , NOKEY_DATA_FRAG_FLAGS ); <nl> + rtps_util_decode_flags ( tree , tvb , offset + 1 , flags , DATA_FRAG_FLAGS ); <nl>  <nl> octet_item = proto_tree_add_item ( tree , hf_rtps_sm_octets_to_next_header , tvb , <nl> offset + 2 , 2 , little_endian ? ENC_LITTLE_ENDIAN : ENC_BIG_ENDIAN );
mmm plugins / profinet / packet - dcom - cba . c <nl> ppp plugins / profinet / packet - dcom - cba . c <nl> dissect_ICBAPhysicalDevice_get_LogicalDevice_rqst ( tvbuff_t * tvb , int offset , <nl>  <nl> offset = dissect_dcom_dcerpc_pointer ( tvb , offset , pinfo , tree , di , drep , <nl> & u32Pointer ); <nl> + <nl> + szStr [ 0 ] ='\ 0 '; <nl> + <nl> if ( u32Pointer ) { <nl> offset = dissect_dcom_BSTR ( tvb , offset , pinfo , tree , di , drep , <nl> hf_cba_name , szStr , u32MaxStr );
mmm epan / dissectors / packet - dcerpc - spoolss . c <nl> ppp epan / dissectors / packet - dcerpc - spoolss . c <nl> dissect_spoolss_uint16uni ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , <nl>  <nl> /* Get remaining data in buffer as a string */ <nl>  <nl> - remaining = tvb_captured_length_remaining ( tvb , offset ); <nl> + remaining = tvb_reported_length_remaining ( tvb , offset ); <nl> if ( remaining <= 0 ) { <nl> if ( data ) <nl> * data = g_strdup (""); <nl> dissect_spoolss_keybuffer ( tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> end_offset = tvb_reported_length_remaining ( tvb , offset ) + 1 ; <nl> } <nl>  <nl> - while ( offset < end_offset ) <nl> + while ( offset > 0 && offset < end_offset ) { <nl> offset = dissect_spoolss_uint16uni ( <nl> tvb , offset , pinfo , tree , drep , NULL , hf_keybuffer ); <nl> + } <nl>  <nl> return offset ; <nl> }
mmm epan / crypt / airpdcap . c <nl> ppp epan / crypt / airpdcap . c <nl> AirPDcapDecryptWPABroadcastKey ( const EAPOL_RSN_KEY * pEAPKey , guint8 * decryption_ <nl> } <nl> } <nl>  <nl> - if ( key_bytes_len < GROUP_KEY_MIN_LEN || key_bytes_len > eapol_len - sizeof ( EAPOL_RSN_KEY )) { <nl> + if (( key_bytes_len < GROUP_KEY_MIN_LEN ) || <nl> + ( eapol_len < sizeof ( EAPOL_RSN_KEY )) || <nl> + ( key_bytes_len > eapol_len - sizeof ( EAPOL_RSN_KEY ))) { <nl> return AIRPDCAP_RET_NO_VALID_HANDSHAKE ; <nl> } <nl> 
mmm plugins / megaco / packet - megaco . c <nl> ppp plugins / megaco / packet - megaco . c <nl> nextcontext : <nl> tvb_previous_offset = tvb_find_guint8 ( tvb , tvb_current_offset , <nl> tvb_len , '=')+ 1 ; <nl> tvb_previous_offset = tvb_skip_wsp ( tvb , tvb_previous_offset ); <nl> - tvb_current_offset = tvb_find_guint8 ( tvb , tvb_previous_offset , <nl> + tvb_next_offset = tvb_find_guint8 ( tvb , tvb_previous_offset , <nl> tvb_len , '{'); <nl> + if ( tvb_current_offset >= tvb_next_offset ) { <nl> + proto_tree_add_text ( megaco_tree , tvb , 0 , 0 , "[ Parse error : Invalid offset ]"); <nl> + return ; <nl> + } <nl> + tvb_current_offset = tvb_next_offset ; <nl>  <nl>  <nl> tokenlen = tvb_current_offset - tvb_previous_offset ;
mmm epan / dissectors / packet - netflow . c <nl> ppp epan / dissectors / packet - netflow . c <nl> v9_template_add ( struct v9_template * template ) <nl> template -> length += template -> entries [ i ]. length ; <nl> } <nl>  <nl> - memmove (& v9_template_cache [ v9_template_hash ( template -> id , <nl> + memcpy (& v9_template_cache [ v9_template_hash ( template -> id , <nl> & template -> source_addr , template -> source_id )], <nl> template , sizeof (* template )); <nl> }
mmm epan / dissectors / packet - dnp . c <nl> ppp epan / dissectors / packet - dnp . c <nl> static int <nl> dissect_dnp3_al ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> { <nl> guint8 al_ctl , al_seq , al_func , al_class = 0 , i ; <nl> - guint16 bytes , obj_type ; <nl> + guint16 bytes , obj_type = 0 ; <nl> guint data_len = 0 , offset = 0 ; <nl> proto_item * ti , * tc , * t_robj ; <nl> proto_tree * al_tree , * field_tree , * robj_tree ;
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> tvb_get_letohguid ( tvbuff_t * tvb , const gint offset , e_guid_t * guid ) <nl> guid -> data1 = pletohl ( ptr + 0 ); <nl> guid -> data2 = pletohs ( ptr + 4 ); <nl> guid -> data3 = pletohs ( ptr + 6 ); <nl> - memcpy ( guid -> data4 , offset + 8 , sizeof guid -> data4 ); <nl> + memcpy ( guid -> data4 , ptr + 8 , sizeof guid -> data4 ); <nl> } <nl>  <nl> /*
mmm epan / dissectors / packet - tds . c <nl> ppp epan / dissectors / packet - tds . c <nl> dissect_tds_resp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl>  <nl> length_remaining = tvb_ensure_length_remaining ( tvb , pos ); <nl>  <nl> + if (( int ) token_sz < 0 ) { <nl> + proto_tree_add_text ( tree , tvb , pos , 0 , " Bogus token size : % u ", <nl> + token_sz ); <nl> + break ; <nl> + } <nl> + if (( int ) token_len_field_size < 0 ) { <nl> + proto_tree_add_text ( tree , tvb , pos , 0 , " Bogus token length field size : % u ", <nl> + token_len_field_size ); <nl> + break ; <nl> + } <nl> token_item = proto_tree_add_text ( tree , tvb , pos , token_sz , <nl> " Token 0x % 02x % s ", token , <nl> val_to_str ( token , token_names , " Unknown Token Type "));
mmm extcap . c <nl> ppp extcap . c <nl> extcap_register_preferences_callback ( gpointer key , gpointer value _U_ , gpointer <nl>  <nl> void extcap_register_preferences ( void ) <nl> { <nl> + if ( prefs . capture_no_extcap ) <nl> + return ; <nl> + <nl> module_t * dev_module = prefs_find_module (" extcap "); <nl>  <nl> if (! dev_module ) <nl> extcap_load_interface_list ( void ) <nl> gchar * argv ; <nl> gchar * error ; <nl>  <nl> + if ( prefs . capture_no_extcap ) <nl> + return ; <nl> + <nl> if ( _toolbars ) <nl> { <nl> // Remove existing interface toolbars here instead of in extcap_clear_interfaces ()
mmm follow . c <nl> ppp follow . c <nl> /* follow . c <nl> * <nl> - * $ Id : follow . c , v 1 . 3 1998 / 10 / 10 03 : 32 : 09 gerald Exp $ <nl> + * $ Id : follow . c , v 1 . 4 1998 / 10 / 28 01 : 29 : 16 guy Exp $ <nl> * <nl> * Copyright 1998 Mike Hall < mlh @ io . com > <nl> * <nl> reassemble_tcp ( u_long sequence , u_long length , const char * data , int synflag , u <nl> tmp_frag -> data = ( u_char *) malloc ( length ); <nl> tmp_frag -> seq = sequence ; <nl> tmp_frag -> len = length ; <nl> - bcopy ( data , tmp_frag -> data , length ); <nl> + memcpy ( tmp_frag -> data , data , length ); <nl> if ( frags [ src_index ] ) { <nl> tmp_frag -> next = frags [ src_index ]; <nl> } else {
mmm packet - isis - clv . c <nl> ppp packet - isis - clv . c <nl> /* packet - isis - clv . c <nl> * Common CLV decode routines . <nl> * <nl> - * $ Id : packet - isis - clv . c , v 1 . 6 2000 / 06 / 19 08 : 33 : 47 guy Exp $ <nl> + * $ Id : packet - isis - clv . c , v 1 . 7 2000 / 08 / 10 14 : 21 : 09 deniel Exp $ <nl> * Stuart Stanley < stuarts @ mxmail . net > <nl> * <nl> * Ethereal - Network traffic analyzer <nl> isis_dissect_clvs ( const isis_clv_handle_t * opts , int len , int id_length , <nl> length = pd [ offset ++]; <nl> adj = ( sizeof ( code ) + sizeof ( length ) + length ); <nl> len -= adj ; <nl> - if ( len < 0 ) { <nl> + if ( len < 0 || ! BYTES_ARE_IN_FRAME ( offset , length ) ) { <nl> isis_dissect_unknown ( offset , adj , tree , fd , <nl> " Short CLV header (% d vs % d )", <nl> adj , len + adj );
mmm epan / dissectors / packet - mp2t . c <nl> ppp epan / dissectors / packet - mp2t . c <nl> typedef struct frame_analysis_data { <nl> static mp2t_analysis_data_t * <nl> init_mp2t_conversation_data ( void ) <nl> { <nl> - mp2t_analysis_data_t * mp2t_data = NULL ; <nl> + mp2t_analysis_data_t * mp2t_data ; <nl>  <nl> mp2t_data = wmem_new0 ( wmem_file_scope (), struct mp2t_analysis_data ); <nl>  <nl> init_mp2t_conversation_data ( void ) <nl> static mp2t_analysis_data_t * <nl> get_mp2t_conversation_data ( conversation_t * conv ) <nl> { <nl> - mp2t_analysis_data_t * mp2t_data = NULL ; <nl> + mp2t_analysis_data_t * mp2t_data ; <nl>  <nl> mp2t_data = ( mp2t_analysis_data_t *) conversation_get_proto_data ( conv , proto_mp2t ); <nl> if (! mp2t_data ) { <nl> get_mp2t_conversation_data ( conversation_t * conv ) <nl> static frame_analysis_data_t * <nl> init_frame_analysis_data ( mp2t_analysis_data_t * mp2t_data , packet_info * pinfo ) <nl> { <nl> - frame_analysis_data_t * frame_analysis_data_p = NULL ; <nl> + frame_analysis_data_t * frame_analysis_data_p ; <nl>  <nl> frame_analysis_data_p = wmem_new0 ( wmem_file_scope (), struct frame_analysis_data ); <nl> frame_analysis_data_p -> ts_table = wmem_tree_new ( wmem_file_scope ()); <nl> init_frame_analysis_data ( mp2t_analysis_data_t * mp2t_data , packet_info * pinfo ) <nl> static frame_analysis_data_t * <nl> get_frame_analysis_data ( mp2t_analysis_data_t * mp2t_data , packet_info * pinfo ) <nl> { <nl> - frame_analysis_data_t * frame_analysis_data_p = NULL ; <nl> + frame_analysis_data_t * frame_analysis_data_p ; <nl> frame_analysis_data_p = ( frame_analysis_data_t *) wmem_tree_lookup32 ( mp2t_data -> frame_table , pinfo -> fd -> num ); <nl> return frame_analysis_data_p ; <nl> } <nl> get_frame_analysis_data ( mp2t_analysis_data_t * mp2t_data , packet_info * pinfo ) <nl> static pid_analysis_data_t * <nl> get_pid_analysis ( mp2t_analysis_data_t * mp2t_data , guint32 pid ) <nl> { <nl> - pid_analysis_data_t * pid_data = NULL ; <nl> + pid_analysis_data_t * pid_data ; <nl>  <nl> pid_data = ( pid_analysis_data_t *) wmem_tree_lookup32 ( mp2t_data -> pid_table , pid ); <nl> if (! pid_data ) { <nl> static guint <nl> mp2t_get_packet_length ( tvbuff_t * tvb , guint offset , packet_info * pinfo , <nl> guint32 frag_id , enum pid_payload_type pload_type ) <nl> { <nl> - fragment_head * frag = NULL ; <nl> + fragment_head * frag ; <nl> tvbuff_t * len_tvb = NULL , * frag_tvb = NULL , * data_tvb = NULL ; <nl> gint pkt_len = 0 ; <nl> guint remaining_len ; <nl> save_state : <nl> static guint32 <nl> calc_skips ( gint32 curr , gint32 prev ) <nl> { <nl> - int res = 0 ; <nl> + int res ; <nl>  <nl> /* Only count the missing TS frames in between prev and curr . <nl> * The " prev " frame CC number seen is confirmed received , it ' s
mmm epan / dissectors / packet - smpp . c <nl> ppp epan / dissectors / packet - smpp . c <nl> dissect_smpp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> guint32 offset = 0 ; <nl> while ( tvb_reported_length_remaining ( tvb , offset ) > 0 ) { <nl> guint16 pdu_len = tvb_get_ntohl ( tvb , offset ); <nl> + if ( pdu_len < 1 ) <nl> + THROW ( ReportedBoundsError ); <nl> gint pdu_real_len = tvb_length_remaining ( tvb , offset ); <nl> tvbuff_t * pdu_tvb ; <nl> 
mmm epan / dissectors / packet - smb . c <nl> ppp epan / dissectors / packet - smb . c <nl> dissect_transaction_request ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl>  <nl> WORD_COUNT ; <nl>  <nl> - if ( wc == 8 ) { <nl> + if ( wc == 8 || ( wc == 9 && si -> cmd == SMB_COM_TRANSACTION2_SECONDARY )) { <nl> /* secondary client request */ <nl>  <nl> /* total param count , only a 16bit integer here */ <nl> dissect_transaction_request ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> proto_tree_add_uint ( tree , hf_smb_data_disp16 , tvb , offset , 2 , dd ); <nl> offset += 2 ; <nl>  <nl> - if ( si -> cmd == SMB_COM_TRANSACTION2 ) { <nl> + if ( si -> cmd == SMB_COM_TRANSACTION2 || si -> cmd == SMB_COM_TRANSACTION2_SECONDARY ) { <nl> guint16 fid ; <nl>  <nl> /* fid */
mmm epan / dissectors / packet - epon . c <nl> ppp epan / dissectors / packet - epon . c <nl> dissect_epon ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> guint dpoe_sec_byte ; <nl> gboolean dpoe_encrypted = FALSE ; <nl>  <nl> - /* Start_of_Packet delimiter (/ S /) can either happen in byte 1 or byte 2 , <nl> - * making the captured preamble either 7 or 6 bytes in length . If the <nl> + /* Start_of_Packet delimiter (/ S /) can happen in byte 1 , 2 or 3 , <nl> + * making the captured preamble 8 , 7 or 6 bytes in length . If the <nl> * preamble starts with 0x55 , then / S / happened in byte 1 , making the <nl> * captured preamble 7 bytes in length . <nl> */ <nl> - if ( tvb_get_ntoh24 ( tvb , 0 ) == 0x55D555 ) { <nl> + if ( tvb_get_ntohl ( tvb , 0 ) == 0x5555D555 ) { <nl> + offset += 2 ; <nl> + } else if ( tvb_get_ntoh24 ( tvb , 0 ) == 0x55D555 ) { <nl> offset += 1 ; <nl> } else if ( tvb_get_ntohs ( tvb , 0 ) == 0xD555 ) { <nl> offset += 0 ;
mmm epan / dissectors / packet - btobex . c <nl> ppp epan / dissectors / packet - btobex . c <nl> dissect_headers ( proto_tree * tree , tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> proto_item_append_text ( hdr_tree , " (\"% s \")", str ); <nl>  <nl> col_append_fstr ( pinfo -> cinfo , COL_INFO , " \"% s \"", str ); <nl> + offset += item_length - 3 ; <nl> } <nl> else { <nl> col_append_str ( pinfo -> cinfo , COL_INFO , " \"\""); <nl> } <nl> - <nl> - offset += item_length - 3 ; <nl> } <nl> break ; <nl> case 0x40 : /* byte sequence */ <nl> dissect_headers ( proto_tree * tree , tvbuff_t * tvb , int offset , packet_info * pinfo , <nl> col_append_fstr ( pinfo -> cinfo , COL_INFO , " \"% s \"", tvb_get_ephemeral_string ( tvb , offset , item_length - 3 )); <nl> } <nl>  <nl> - offset += item_length - 3 ; <nl> + if ( item_length >= 3 ) /* prevent infinite loops */ <nl> + offset += item_length - 3 ; <nl> break ; <nl> case 0x80 : /* 1 byte */ <nl> proto_item_append_text ( hdr_tree , " (% i )", tvb_get_ntohl ( tvb , offset ));
mmm epan / dissectors / packet - bacapp . c <nl> ppp epan / dissectors / packet - bacapp . c <nl> fAbstractSyntaxNType ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , guint <nl> offset = fReadAccessResult ( tvb , pinfo , tree , offset ); <nl> break ; <nl> } <nl> - /* intentially fall through here so don ' t reorder this case statement */ <nl> + /* intentionally fall through */ /* here so don ' t reorder this case statement */ <nl> default : <nl> if ( tag_info ) { <nl> if ( tag_is_opening ( tag_info )) { <nl> fPropertyReference ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , guint of <nl> case 1 : /* propertyArrayIndex */ <nl> offset = fPropertyArrayIndex ( tvb , pinfo , tree , offset ); <nl> if ( list != 0 ) break ; /* Continue decoding if this may be a list */ <nl> + break ; <nl> default : <nl> lastoffset = offset ; /* Set loop end condition */ <nl> break ; <nl> fBACnetObjectPropertyReference ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tr <nl> case 1 : /* PropertyIdentifier and propertyArrayIndex */ <nl> offset = fPropertyReference ( tvb , pinfo , tree , offset , 1 , 0 ); <nl> col_set_writable ( pinfo -> cinfo , COL_INFO , FALSE ); /* don ' t set all infos into INFO column */ <nl> + break ; <nl> default : <nl> lastoffset = offset ; /* Set loop end condition */ <nl> break ;
mmm epan / dissectors / packet - sctp . c <nl> ppp epan / dissectors / packet - sctp . c <nl> dissect_data_chunk ( tvbuff_t * chunk_tvb , <nl> */ <nl> if ( b_bit ) <nl> { <nl> - gboolean retval ; <nl> + gboolean retval = FALSE ; <nl>  <nl> /* <nl> * If this particular fragment happens to get a ReportedBoundsError
mmm gtk / uat_gui . c <nl> ppp gtk / uat_gui . c <nl> static gboolean uat_cancel_dlg_cb ( GtkWidget * win _U_ , gpointer user_data ) { <nl> if ( dd -> is_new ) g_free ( dd -> rec ); <nl> g_ptr_array_free ( dd -> entries , TRUE ); <nl> window_destroy ( GTK_WIDGET ( dd -> win )); <nl> - g_free ( dd ); <nl>  <nl> while ( dd -> tobe_freed -> len ) g_free ( g_ptr_array_remove_index_fast ( dd -> tobe_freed , dd -> tobe_freed -> len - 1 ) ); <nl>  <nl> + g_free ( dd ); <nl> + <nl> return TRUE ; <nl> } <nl> 
mmm epan / dissectors / packet - ltp . c <nl> ppp epan / dissectors / packet - ltp . c <nl> dissect_data_segment ( proto_tree * ltp_tree , tvbuff_t * tvb , packet_info * pinfo , int <nl> } <nl> } <nl> /* Adding size of the data */ <nl> + if (( segment_offset + ( int ) length < segment_offset ) || ( segment_offset + ( int ) length < ( int ) length )) { <nl> + /* Addition result has wrapped */ <nl> + return 0 ; <nl> + } <nl> segment_offset += ( int ) length ; <nl> + <nl> + if (( segment_offset + frame_offset < segment_offset ) || ( segment_offset + frame_offset < frame_offset )) { <nl> + /* Addition result has wrapped */ <nl> + return 0 ; <nl> + } <nl> if (( unsigned )( frame_offset + segment_offset ) > tvb_length ( tvb )){ <nl> /* This would mean the data segment is incomplete */ <nl> return 0 ;
mmm epan / dissectors / packet - bthci_evt . c <nl> ppp epan / dissectors / packet - bthci_evt . c <nl> dissect_bthci_evt_inq_result_with_rssi ( tvbuff_t * tvb , int offset , packet_info * p <nl> static int <nl> dissect_bthci_evt_eir_ad_data ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , proto_tree * tree , guint8 size ) <nl> { <nl> - guint16 i ; <nl> - guint8 j , length , type ; <nl> + guint16 i , j ; <nl> + guint8 length , type ; <nl> proto_item * ti_eir = NULL ; <nl> proto_item * ti_eir_subtree = NULL ; <nl> 
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> tvb_uncompress ( tvbuff_t * tvb , int offset , int comprlen ) <nl> inflateReset ( strm ); <nl> next = c ; <nl> strm -> next_in = next ; <nl> + if ( c - compr > comprlen ) { <nl> + g_free ( strm ); <nl> + g_free ( compr ); <nl> + g_free ( strmbuf ); <nl> + return NULL ; <nl> + } <nl> comprlen -= ( c - compr ); <nl>  <nl> err = inflateInit2 ( strm , wbits );
mmm plugins / profinet / packet - dcerpc - pn - io . c <nl> ppp plugins / profinet / packet - dcerpc - pn - io . c <nl> dissect_ExpectedSubmoduleBlockReq_block ( tvbuff_t * tvb , int offset , <nl> /* Initial */ <nl> io_data_object = wmem_new0 ( wmem_file_scope (), ioDataObject ); <nl> io_data_object -> profisafeSupported = FALSE ; <nl> - io_data_object -> moduleNameStr = wmem_strdup ( wmem_file_scope (), " Unknown "); <nl> + io_data_object -> moduleNameStr = ( gchar *) wmem_alloc ( wmem_file_scope (), MAX_NAMELENGTH ); <nl> + g_strlcpy ( io_data_object -> moduleNameStr , " Unknown ", MAX_NAMELENGTH ); <nl> vendorMatch = FALSE ; <nl> deviceMatch = FALSE ; <nl> gsdmlFoundFlag = FALSE ; <nl> dissect_ExpectedSubmoduleBlockReq_block ( tvbuff_t * tvb , int offset , <nl> /* Find a String with the saved TextID and with a fitting value for it in the same line . This value is the name of the Module ! */ <nl> if ((( strstr ( temp , tmp_moduletext )) != NULL ) && (( strstr ( temp , moduleValueInfo )) != NULL )) { <nl> pch = strstr ( temp , moduleValueInfo ); <nl> - if ( pch != NULL && sscanf ( pch , " Value =\"%[^\"]", io_data_object -> moduleNameStr ) == 1 ) <nl> + if ( pch != NULL && sscanf ( pch , " Value =\"% 199 [^\"]", io_data_object -> moduleNameStr ) == 1 ) <nl> break ; /* Found the name of the module */ <nl> } <nl> }
mmm capture_loop . c <nl> ppp capture_loop . c <nl> capture_loop_packet_cb ( guchar * user , const struct pcap_pkthdr * phdr , <nl> int err ; <nl>  <nl> /* if the user told us to stop after x packets , do we have enough ? */ <nl> - if (( ld -> packets_max > 0 ) && (++ ld -> counts . total >= ld -> packets_max )) <nl> + ld -> counts . total ++; <nl> + if (( ld -> packets_max > 0 ) && ( ld -> counts . total >= ld -> packets_max )) <nl> { <nl> ld -> go = FALSE ; <nl> }
mmm epan / dissectors / packet - dcm . c <nl> ppp epan / dissectors / packet - dcm . c <nl> dissect_dcm_pdv_fragmented ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> pdv_body_len , <nl> !( pdv -> is_last_fragment )); <nl>  <nl> - if (( head && ( head -> next == NULL )) || pdv -> is_last_fragment ) { <nl> + if ( head && ( head -> next == NULL )) { <nl> /* Was not really fragmented , therefore use ' conventional ' decoding <nl> fragment_add_seq_next () won ' t add any items to the list , when last fragment only <nl> */
mmm epan / dissectors / packet - geneve . c <nl> ppp epan / dissectors / packet - geneve . c <nl> /* packet - geneve . c <nl> * Routines for Geneve - Generic Network Virtualization Encapsulation <nl> - * http :// tools . ietf . org / html / draft - gross - geneve - 00 <nl> + * http :// tools . ietf . org / html / draft - ietf - nvo3 - geneve <nl> * <nl> * Copyright ( c ) 2014 VMware , Inc . All Rights Reserved . <nl> * Author : Jesse Gross < jesse @ nicira . com > <nl>  <nl> static const range_string class_id_names [] = { <nl> { 0 , 0xFF , " Standard " }, <nl> - { 0xFFFF , 0xFFFF , " Experimental " }, <nl> + { 0x0100 , 0x0100 , " Linux " }, <nl> + { 0x0101 , 0x0101 , " Open vSwitch " }, <nl> + { 0x0102 , 0x0102 , " Open Virtual Networking ( OVN )" }, <nl> + { 0x0103 , 0x0103 , " In - band Network Telemetry ( INT )" }, <nl> + { 0x0104 , 0x0104 , " VMware " }, <nl> + { 0xFFF0 , 0xFFFF , " Experimental " }, <nl> { 0 , 0 , NULL } <nl> }; <nl> 
mmm wiretap / pppdump . c <nl> ppp wiretap / pppdump . c <nl> /* pppdump . c <nl> * <nl> - * $ Id : pppdump . c , v 1 . 11 2001 / 12 / 13 05 : 49 : 12 gram Exp $ <nl> + * $ Id : pppdump . c , v 1 . 12 2001 / 12 / 13 05 : 50 : 51 gram Exp $ <nl> * <nl> * Copyright ( c ) 2000 by Gilbert Ramirez < gram @ alumni . rice . edu > <nl> * <nl> pppdump_close ( wtap * wth ) <nl> } <nl>  <nl> if ( state -> pids ) { /* should always be TRUE */ <nl> - int i ; <nl> + unsigned int i ; <nl> for ( i = 0 ; i < g_ptr_array_len ( state -> pids ); i ++) { <nl> g_free ( g_ptr_array_index ( state -> pids , i )); <nl> }
mmm epan / frame_data . c <nl> ppp epan / frame_data . c <nl> void <nl> frame_data_reset ( frame_data * fdata ) <nl> { <nl> fdata -> flags . visited = 0 ; <nl> + fdata -> subnum = 0 ; <nl>  <nl> if ( fdata -> pfd ) { <nl> g_slist_free ( fdata -> pfd );
mmm wiretap / pcapng . c <nl> ppp wiretap / pcapng . c <nl> pcapng_read_section_header_block ( FILE_T fh , pcapng_block_header_t * bh , <nl> bytes_read = pcapng_read_option ( fh , pn , & oh , option_content , opt_cont_buf_len , to_read , err , err_info , " section_header "); <nl> if ( bytes_read <= 0 ) { <nl> pcapng_debug (" pcapng_read_section_header_block : failed to read option "); <nl> + g_free ( option_content ); <nl> return PCAPNG_BLOCK_ERROR ; <nl> } <nl> to_read -= bytes_read ;
mmm wiretap / peektagged . c <nl> ppp wiretap / peektagged . c <nl> peektagged_read_packet ( wtap * wth , FILE_T fh , struct wtap_pkthdr * phdr , <nl>  <nl> case TAG_PEEKTAGGED_CENTER_FREQUENCY : <nl> /* XXX - also seen in an EtherPeek capture ; value unknown */ <nl> + ieee_802_11 . presence_flags |= PHDR_802_11_HAS_FREQUENCY ; <nl> + ieee_802_11 . frequency = pletoh32 (& tag_value [ 2 ]); <nl> break ; <nl>  <nl> case TAG_PEEKTAGGED_UNKNOWN_0x000E :
mmm epan / proto . c <nl> ppp epan / proto . c <nl> test_length ( header_field_info * hfinfo , proto_tree * tree , tvbuff_t * tvb , <nl> else { <nl> size += n ; <nl> } <nl> + } else if ( hfinfo -> type == FT_STRINGZ ) { <nl> + /* If we ' re fetching until the end of the TVB , only validate <nl> + * that the offset is within range . <nl> + */ <nl> + if ( length == - 1 ) <nl> + size = 0 ; <nl> } <nl> + <nl> tvb_ensure_bytes_exist ( tvb , start , size ); <nl> } <nl> 
mmm epan / dissectors / packet - ntlmssp . c <nl> ppp epan / dissectors / packet - ntlmssp . c <nl> dissect_ntlmssp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> col_append_sep_fstr ( pinfo -> cinfo , COL_INFO , ", ","% s ", <nl> val_to_str ( ntlmssph -> type , <nl> ntlmssp_message_types , <nl> - " Unknown message type ")); <nl> + " Unknown NTLMSSP message type ")); <nl>  <nl> /* Call the appropriate dissector based on the Message Type */ <nl> switch ( ntlmssph -> type ) {
mmm epan / dissectors / packet - rtcp . c <nl> ppp epan / dissectors / packet - rtcp . c <nl> static void calculate_roundtrip_delay ( tvbuff_t * tvb , packet_info * pinfo , <nl> p_add_proto_data ( pinfo -> fd , proto_rtcp , p_packet_data ); <nl> } <nl>  <nl> + /* Don ' t allow match seemingly calculated from same frame ! */ <nl> + if ( pinfo -> fd -> num == p_conv_data -> last_received_frame_number ) <nl> + { <nl> + return ; <nl> + } <nl> + <nl> /* Any previous report must match the lsr given here */ <nl> if ( p_conv_data -> last_received_ts == lsr ) <nl> { <nl> static void calculate_roundtrip_delay ( tvbuff_t * tvb , packet_info * pinfo , <nl> gint nseconds_between_packets = <nl> pinfo -> fd -> abs_ts . nsecs - p_conv_data -> last_received_timestamp . nsecs ; <nl>  <nl> - <nl> - gint total_gap = (( seconds_between_packets * 1000 ) + <nl> - nseconds_between_packets ) / 1000000 ; <nl> + gint total_gap = ( seconds_between_packets * 1000 ) + <nl> + ( nseconds_between_packets / 1000000 ); <nl> gint delay = total_gap - ( int )((( double ) dlsr /( double ) 65536 ) * 1000 . 0 ); <nl>  <nl> /* No useful calculation can be done if dlsr not set ... */
mmm gtk / follow_udp . c <nl> ppp gtk / follow_udp . c <nl> follow_udp_stream_cb ( GtkWidget * w , gpointer data _U_ ) <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Error creating filter for this stream .\ n " <nl> " A network layer header is needed "); <nl> + g_free ( follow_info ); <nl> return ; <nl> } <nl>  <nl> follow_udp_stream_cb ( GtkWidget * w , gpointer data _U_ ) <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t register udp_follow tap : % s \ n ", <nl> msg -> str ); <nl> + g_free ( follow_info ); <nl> return ; <nl> } <nl> 
mmm capture_opts . h <nl> ppp capture_opts . h <nl> typedef struct capture_options_tag { <nl>  <nl> /* GUI related */ <nl> gboolean real_time_mode ; /**< Update list of packets in real time */ <nl> - gboolean show_info ; /**< show the info dialog . GTK + only . */ <nl> + gboolean show_info ; /**< show the info dialog . */ <nl> gboolean restart ; /**< restart after closing is done */ <nl> gchar * orig_save_file ; /**< the original capture file name ( saved for a restart ) */ <nl> 
mmm wiretap / ngsniffer . c <nl> ppp wiretap / ngsniffer . c <nl> ng_file_seek_rand ( wtap * wth , long offset , int whence , int * err ) <nl> the uncompressed byte stream , starting with the blob <nl> following the current blob . */ <nl> new = g_list_next ( ngsniffer -> current_blob ); <nl> - for (;;) { <nl> + while ( new ) { <nl> next = g_list_next ( new ); <nl> if ( next == NULL ) { <nl> /* No more blobs ; the current one is it . */ <nl> ng_file_seek_rand ( wtap * wth , long offset , int whence , int * err ) <nl> the uncompressed byte stream , starting with the blob <nl> preceding the current blob . */ <nl> new = g_list_previous ( ngsniffer -> current_blob ); <nl> - for (;;) { <nl> + while ( new ) { <nl> /* Does this blob start at or before the target offset ? <nl> If so , the current blob is the one we want . */ <nl> new_blob = new -> data ;
mmm epan / dissectors / packet - hip . c <nl> ppp epan / dissectors / packet - hip . c <nl> dissect_hip_tlv ( tvbuff_t * tvb , packet_info * pinfo , int offset , proto_item * ti , i <nl> newoffset += ( 1 + tvb_get_guint8 ( tvb , newoffset + 2 )); <nl> tlv_len -= ( 1 + tvb_get_guint8 ( tvb , newoffset + 2 )); <nl> } <nl> - if ( ti_loc ) { <nl> + if ( locator_type <= 2 ) { <nl> ti_loc = proto_item_add_subtree ( ti_loc , ett_hip_locator_data ); <nl> /* Traffic type */ <nl> proto_tree_add_item ( ti_loc , hf_hip_tlv_locator_traffic_type , tvb ,
mmm packet - icq . c <nl> ppp packet - icq . c <nl> /* packet - icq . c <nl> * Routines for ICQ packet disassembly <nl> * <nl> - * $ Id : packet - icq . c , v 1 . 22 2000 / 11 / 19 08 : 53 : 58 guy Exp $ <nl> + * $ Id : packet - icq . c , v 1 . 23 2000 / 11 / 19 19 : 23 : 54 gerald Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Johan Feyaerts <nl> dissect_icqv5Client ( const u_char * pd , <nl> guint16 seqnum1 = 0 , seqnum2 = 0 ; <nl> guint32 uin = - 1 , sessionid = - 1 ; <nl> guint32 key = - 1 ; <nl> - guint16 pktsize = - 1 ; /* The size of the ICQ content */ <nl> - u_char decr_pd [ 1600 ]; /* Decrypted content , size should be dynamic */ <nl> + guint16 pktsize = - 1 ; /* The size of the ICQ content */ <nl> + static u_char * decr_pd = NULL ; /* Decrypted content */ <nl>  <nl> pktsize = END_OF_FRAME ; <nl> + <nl> + if ( decr_pd == NULL ) <nl> + decr_pd = ( u_char *) g_malloc ( sizeof ( u_char ) * 128 ); <nl> + <nl> + while ( sizeof ( decr_pd ) < pktsize + 3 ) <nl> + decr_pd = ( u_char *) g_realloc ( decr_pd , sizeof ( decr_pd ) * 2 ); <nl> + <nl> /* First copy the memory , we don ' t want to overwrite the old content */ <nl> memcpy ( decr_pd , & pd [ offset ], pktsize ); <nl> if ( pktsize > 0x14 ) {
mmm epan / dissectors / packet - ansi_a . c <nl> ppp epan / dissectors / packet - ansi_a . c <nl> elem_signal ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree * tree , guint32 off <nl> break ; <nl> } <nl>  <nl> + other_decode_bitfield_value ( a_bigbuf , oct , 0x03 , 8 ); <nl> proto_tree_add_text ( tree , <nl> tvb , curr_offset , 1 , <nl> "% s : Alert Pitch : % s ", <nl> elem_fwd_ms_info_recs ( tvbuff_t * tvb , packet_info * pinfo _U_ , proto_tree * tree , g <nl> curr_offset ++; <nl> break ; <nl>  <nl> + case ANSI_FWD_MS_INFO_REC_SIGNAL : <nl> + curr_offset += elem_signal ( tvb , pinfo , subtree , curr_offset , len , add_string , string_len ); <nl> + break ; <nl> + <nl> default : <nl> proto_tree_add_text ( subtree , <nl> tvb , curr_offset , oct_len ,
mmm epan / dissectors / packet - radius . c <nl> ppp epan / dissectors / packet - radius . c <nl> static void dissect_attribute_value_pairs ( proto_tree * tree , packet_info * pinfo , <nl> last_eap = TRUE ; <nl> } <nl>  <nl> - if ( last_eap ) { <nl> + if ( last_eap && eap_buffer ) { <nl> gboolean save_writable ; <nl>  <nl> proto_item_append_text ( avp_item ,
mmm ui / qt / tcp_stream_dialog . cpp <nl> ppp ui / qt / tcp_stream_dialog . cpp <nl> TCPStreamDialog :: TCPStreamDialog ( QWidget * parent , capture_file * cf , tcp_graph_ty <nl> graph_ . type = graph_type ; <nl>  <nl> QCustomPlot * sp = ui -> streamPlot ; <nl> + QCPPlotTitle * file_title = new QCPPlotTitle ( sp , cf_get_display_name ( cap_file_ )); <nl> + file_title -> setFont ( sp -> xAxis -> labelFont ()); <nl> title_ = new QCPPlotTitle ( sp ); <nl> tracer_ = new QCPItemTracer ( sp ); <nl> sp -> plotLayout ()-> insertRow ( 0 ); <nl> + sp -> plotLayout ()-> addElement ( 0 , 0 , file_title ); <nl> + sp -> plotLayout ()-> insertRow ( 0 ); <nl> sp -> plotLayout ()-> addElement ( 0 , 0 , title_ ); <nl> sp -> addGraph (); // 0 - All : Selectable segments <nl> sp -> addGraph ( sp -> xAxis , sp -> yAxis2 ); // 1 - Throughput : Moving average <nl> TCPStreamDialog :: TCPStreamDialog ( QWidget * parent , capture_file * cf , tcp_graph_ty <nl> sp -> graph ( 0 )-> setScatterStyle ( QCPScatterStyle ( QCPScatterStyle :: ssDisc , 5 )); <nl>  <nl> sp -> xAxis -> setLabel ( tr (" Time ( s )")); <nl> + sp -> yAxis -> setLabelColor ( QColor ( graph_color_1 )); <nl> sp -> yAxis -> setTickLabelColor ( QColor ( graph_color_1 )); <nl>  <nl> tracer_ -> setVisible ( false ); <nl> void TCPStreamDialog :: resetAxes () <nl>  <nl> void TCPStreamDialog :: initializeStevens () <nl> { <nl> - QString dlg_title = QString ( tr (" TCP Graph ")) + streamDescription (); <nl> + QString dlg_title = QString ( tr (" Sequence numbers ")) + streamDescription (); <nl> setWindowTitle ( dlg_title ); <nl> title_ -> setText ( dlg_title ); <nl>  <nl> void TCPStreamDialog :: initializeStevens () <nl>  <nl> void TCPStreamDialog :: initializeThroughput () <nl> { <nl> - QString dlg_title = QString ( tr (" Throughput ")) <nl> + QString dlg_title = QString ( tr (" Throughput ")) <nl> + streamDescription () <nl> + QString ( tr (" (% 1 segment MA )")). arg ( moving_avg_period_ ); <nl> setWindowTitle ( dlg_title ); <nl> void TCPStreamDialog :: initializeThroughput () <nl> sp -> yAxis -> setLabel ( tr (" Segment length ( B )")); <nl>  <nl> sp -> yAxis2 -> setLabel ( tr (" Avg througput ( bits / s )")); <nl> + sp -> yAxis2 -> setLabelColor ( QColor ( graph_color_2 )); <nl> sp -> yAxis2 -> setTickLabelColor ( QColor ( graph_color_2 )); <nl> sp -> yAxis2 -> setVisible ( true ); <nl> } <nl>  <nl> QString TCPStreamDialog :: streamDescription () <nl> { <nl> - return QString ( tr ("% 1 % 2 :% 3 % 4 % 5 :% 6 ")) <nl> - . arg ( cf_get_display_name ( cap_file_ )) <nl> + return QString ( tr (" for % 1 :% 2 % 3 % 4 :% 5 ")) <nl> . arg ( ep_address_to_str (& graph_ . src_address )) <nl> . arg ( graph_ . src_port ) <nl> . arg ( UTF8_RIGHTWARDS_ARROW )
mmm gtk / main . c <nl> ppp gtk / main . c <nl> main_cf_cb_file_closing ( capture_file * cf ) <nl> will there ever be more than one on the stack ? */ <nl> statusbar_pop_file_msg (); <nl>  <nl> - /* go back to " No packets " */ <nl> - packets_bar_update (); <nl> - <nl> /* Restore the standard title bar message . */ <nl> set_main_window_name (" The Ethereal Network Analyzer "); <nl>  <nl> main_cf_cb_file_closed ( capture_file * cf _U_ ) <nl> splash_destroy ( close_dlg ); <nl> close_dlg = NULL ; <nl> } <nl> + <nl> + /* go back to " No packets " */ <nl> + packets_bar_update (); <nl> } <nl>  <nl> static void
mmm wsutil / filesystem . c <nl> ppp wsutil / filesystem . c <nl> gboolean <nl> profile_exists ( const gchar * profilename , gboolean global ) <nl> { <nl> gchar * path = NULL , * global_path ; <nl> + if (! profilename ) <nl> + return FALSE ; <nl> if ( global ) { <nl> global_path = get_global_profiles_dir (); <nl> path = g_strdup_printf ("% s % s % s ", global_path ,
mmm epan / dissectors / packet - smb2 . c <nl> ppp epan / dissectors / packet - smb2 . c <nl> static const value_string smb2_class_vals [] = { <nl> { SMB2_CLASS_FILE_INFO , " FILE_INFO "}, <nl> { SMB2_CLASS_FS_INFO , " FS_INFO "}, <nl> { SMB2_CLASS_SEC_INFO , " SEC_INFO "}, <nl> + { SMB2_CLASS_QUOTA_INFO , " QUOTA_INFO "}, <nl> { SMB2_CLASS_POSIX_INFO , " POSIX_INFO "}, <nl> { 0 , NULL } <nl> }; <nl> dissect_smb2_class_infolevel ( packet_info * pinfo , tvbuff_t * tvb , int offset , prot <nl> hfindex = hf_smb2_infolevel_sec_info ; <nl> vsx = & smb2_sec_info_levels_ext ; <nl> break ; <nl> + case SMB2_CLASS_QUOTA_INFO : <nl> + /* infolevel is not being used for quota */ <nl> + hfindex = hf_smb2_infolevel ; <nl> + vsx = NULL ; <nl> + break ; <nl> case SMB2_CLASS_POSIX_INFO : <nl> hfindex = hf_smb2_infolevel_posix_info ; <nl> vsx = & smb2_posix_info_levels_ext ;
mmm epan / dissectors / packet - zbee - zcl - general . c <nl> ppp epan / dissectors / packet - zbee - zcl - general . c <nl> dissect_zcl_pwr_prof_enphsschednotif ( tvbuff_t * tvb , proto_tree * tree , guint * off <nl> * offset += 1 ; <nl>  <nl> /* Scheduled Energy Phases decoding */ <nl> - for ( i = 0 ; i < num_of_sched_phases ; i ++) { <nl> + for ( i = 0 ; ( i < num_of_sched_phases && i < ZBEE_ZCL_PWR_PROF_NUM_EN_PHS_ETT ); i ++) { <nl> /* Create subtree */ <nl> sub_tree = proto_tree_add_subtree_format ( tree , tvb , * offset , 1 , <nl> ett_zbee_zcl_pwr_prof_enphases [ i ], NULL , " Energy Phase #% u ", i ); <nl> dissect_zcl_pwr_prof_pwrprofnotif ( tvbuff_t * tvb , proto_tree * tree , guint * offset <nl> * offset += 1 ; <nl>  <nl> /* Energy Phases decoding */ <nl> - for ( i = 0 ; i < num_of_transferred_phases ; i ++) { <nl> + for ( i = 0 ; ( i < num_of_transferred_phases && i < ZBEE_ZCL_PWR_PROF_NUM_EN_PHS_ETT ); i ++) { <nl> /* Create subtree */ <nl> sub_tree = proto_tree_add_subtree_format ( tree , tvb , * offset , 1 , <nl> ett_zbee_zcl_pwr_prof_enphases [ i ], NULL , " Energy Phase #% u ", i );
mmm epan / wmem / wmem_allocator_block . c <nl> ppp epan / wmem / wmem_allocator_block . c <nl> wmem_block_split_used_chunk ( wmem_block_allocator_t * allocator , <nl> extra -> prev = ( guint32 ) ( aligned_size + sizeof ( wmem_block_chunk_t )); <nl> extra -> used = FALSE ; <nl>  <nl> + /* merge it to its right if possible ( it can ' t be merged left , obviously ) */ <nl> + wmem_block_merge_free ( allocator , extra ); <nl> + <nl> /* add it to the free list */ <nl> wmem_block_add_to_free_list ( allocator , extra ); <nl> }
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> tvb_skip_wsp ( tvbuff_t * tvb , const gint offset , const gint maxlength ) <nl> } <nl>  <nl> gint <nl> - tvb_skip_wsp_return ( tvbuff_t * tvb , const gint offset ) { <nl> + tvb_skip_wsp_return ( tvbuff_t * tvb , const gint offset ) <nl> +{ <nl> gint counter = offset ; <nl> guint8 tempchar ; <nl>  <nl> - for ( counter = offset ; counter > 0 && <nl> + DISSECTOR_ASSERT ( tvb && tvb -> initialized ); <nl> + <nl> + for ( counter = offset ; counter > 0 && <nl> (( tempchar = tvb_get_guint8 ( tvb , counter )) == ' ' || <nl> tempchar == '\ t ' || tempchar == '\ n ' || tempchar == '\ r '); counter --); <nl> counter ++; <nl> + <nl> return ( counter ); <nl> } <nl> 
mmm epan / dissectors / packet - ipsec . c <nl> ppp epan / dissectors / packet - ipsec . c <nl> static int <nl> dissect_ah ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data ) <nl> { <nl> proto_tree * ah_tree , * root_tree ; <nl> - proto_item * pi ; <nl> + proto_item * pi , * ti ; <nl> guint ah_nxt ; /* Next header */ <nl> guint8 ah_len ; /* Length of header in 32bit words minus 2 */ <nl> guint ah_hdr_len ; /* Length of header in octets */ <nl> dissect_ah ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data ) <nl> ah_tree = proto_item_add_subtree ( pi , ett_ah ); <nl>  <nl> proto_tree_add_item ( ah_tree , hf_ah_next_header , tvb , 0 , 1 , ENC_BIG_ENDIAN ); <nl> - proto_tree_add_item ( ah_tree , hf_ah_length , tvb , 1 , 1 , ENC_BIG_ENDIAN ); <nl> + ti = proto_tree_add_item ( ah_tree , hf_ah_length , tvb , 1 , 1 , ENC_BIG_ENDIAN ); <nl> + proto_item_append_text ( ti , " (% u bytes )", ah_hdr_len ); <nl> proto_tree_add_item ( ah_tree , hf_ah_reserved , tvb , 2 , 2 , ENC_NA ); <nl> proto_tree_add_item_ret_uint ( ah_tree , hf_ah_spi , tvb , 4 , 4 , ENC_BIG_ENDIAN , & ah_spi ); <nl>  <nl> proto_register_ipsec ( void ) <nl> { " Next header ", " ah . next_header ", FT_UINT8 , BASE_DEC | BASE_EXT_STRING , & ipproto_val_ext , 0x0 , <nl> NULL , HFILL }}, <nl> { & hf_ah_length , <nl> - { " Length ", " ah . length ", FT_UINT8 , BASE_DEC | BASE_UNIT_STRING , & units_byte_bytes , 0x0 , <nl> + { " Length ", " ah . length ", FT_UINT8 , BASE_DEC , NULL , 0x0 , <nl> NULL , HFILL }}, <nl> { & hf_ah_reserved , <nl> { " Reserved ", " ah . reserved ", FT_BYTES , BASE_NONE , NULL , 0x0 ,
mmm gtk / display_opts . c <nl> ppp gtk / display_opts . c <nl> /* display_opts . c <nl> * Routines for packet display windows <nl> * <nl> - * $ Id : display_opts . c , v 1 . 3 2000 / 05 / 08 01 : 11 : 46 guy Exp $ <nl> + * $ Id : display_opts . c , v 1 . 4 2000 / 05 / 08 01 : 23 : 16 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> # include " packet . h " <nl> # include " file . h " <nl> # include " display_opts . h " <nl> +# include " dlg_utils . h " <nl>  <nl> extern capture_file cf ; <nl> extern GtkWidget * packet_list ; <nl> display_opt_cb ( GtkWidget * w , gpointer d ) { <nl> gtk_box_pack_start ( GTK_BOX ( bbox ), cancel_bt , TRUE , TRUE , 0 ); <nl> gtk_widget_show ( cancel_bt ); <nl>  <nl> + /* Catch the " key_press_event " signal in the window , so that we can catch <nl> + the ESC key being pressed and act as if the " Cancel " button had <nl> + been selected . */ <nl> + dlg_set_cancel ( display_opt_w , cancel_bt ); <nl> + <nl> display_opt_window_active = TRUE ; <nl> gtk_widget_show ( display_opt_w ); <nl> }
mmm gtk / gtkclist . c <nl> ppp gtk / gtkclist . c <nl> * Copyright ( C ) 1995 - 1997 Peter Mattis , Spencer Kimball , Josh MacDonald , <nl> * Copyright ( C ) 1997 - 1998 Jay Painter < jpaint @ serv . net >< jpaint @ gimp . org > <nl> * <nl> - * $ Id : gtkclist . c , v 1 . 13 2002 / 09 / 09 20 : 32 : 30 jmayer Exp $ <nl> + * $ Id : gtkclist . c , v 1 . 14 2003 / 06 / 28 21 : 46 : 08 sahlberg Exp $ <nl> * <nl> * This library is free software ; you can redistribute it and / or <nl> * modify it under the terms of the GNU Library General Public <nl> * GTK + at ftp :// ftp . gtk . org / pub / gtk /. <nl> */ <nl>  <nl> +/* TODO : <nl> + * get rid of autoresize of the columns completely and just use some <nl> + * sane default widths instead <nl> + */ <nl> + <nl> # include " config . h " <nl> # include < stdlib . h > <nl> # include < string . h > <nl> LIST_WIDTH ( GtkCList * clist ) <nl> } G_STMT_END <nl>  <nl>  <nl> +/* maximum size in pxels that columns will be autosized to */ <nl> +# define MAX_COLUMN_AUTOSIZE_WIDTH 600 <nl> + <nl> /* Signals */ <nl> enum { <nl> SELECT_ROW , <nl> gtk_clist_set_column_auto_resize ( GtkCList * clist , <nl> { <nl> gint width ; <nl>  <nl> - width = gtk_clist_optimal_column_width ( clist , column ); <nl> + /* cap the auto - rezised width to something reasonable */ <nl> + width = MIN ( gtk_clist_optimal_column_width ( clist , column ), MAX_COLUMN_AUTOSIZE_WIDTH ); <nl> gtk_clist_set_column_width ( clist , column , width ); <nl> } <nl> }
mmm ui / gtk / rtp_analysis . c <nl> ppp ui / gtk / rtp_analysis . c <nl> void rtp_analysis ( <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t create temporary file for RTP analysis :\ n % s .", <nl> g_strerror ( errno )); <nl> + g_free ( user_data ); <nl> return ; <nl> } <nl> user_data -> f_tempname = g_strdup ( tempname ); <nl> void rtp_analysis ( <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t create temporary file for RTP analysis :\ n % s .", <nl> g_strerror ( errno )); <nl> + g_free ( user_data -> f_tempname ); <nl> + g_free ( user_data ); <nl> return ; <nl> } <nl> user_data -> r_tempname = g_strdup ( tempname );mmm ui / gtk / iax2_analysis . c <nl> ppp ui / gtk / iax2_analysis . c <nl> void rtp_analysis ( <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t create temporary file for RTP analysis :\ n % s .", <nl> g_strerror ( errno )); <nl> + g_free ( user_data ); <nl> return ; <nl> } <nl> user_data -> f_tempname = g_strdup ( tempname ); <nl> void rtp_analysis ( <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t create temporary file for RTP analysis :\ n % s .", <nl> g_strerror ( errno )); <nl> + g_free ( user_data -> f_tempname ); <nl> + g_free ( user_data ); <nl> return ; <nl> } <nl> user_data -> r_tempname = g_strdup ( tempname ); <nl> void iax2_analysis ( <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t create temporary file for IAX2 analysis :\ n % s .", <nl> g_strerror ( errno )); <nl> + g_free ( user_data ); <nl> return ; <nl> } <nl> user_data -> f_tempname = g_strdup ( tempname ); <nl> void iax2_analysis ( <nl> simple_dialog ( ESD_TYPE_ERROR , ESD_BTN_OK , <nl> " Can ' t create temporary file for IAX2 analysis :\ n % s .", <nl> g_strerror ( errno )); <nl> + g_free ( user_data -> f_tempname ); <nl> + g_free ( user_data ); <nl> return ; <nl> } <nl> user_data -> r_tempname = g_strdup ( tempname );
mmm epan / wmem / wmem_allocator_block . c <nl> ppp epan / wmem / wmem_allocator_block . c <nl> wmem_block_split_free_chunk ( wmem_block_allocator_t * allocator , <nl> available = chunk -> len ; <nl>  <nl> /* set new values for chunk */ <nl> - chunk -> len = aligned_size + sizeof ( wmem_block_chunk_t ); <nl> + chunk -> len = ( guint32 ) ( aligned_size + sizeof ( wmem_block_chunk_t )); <nl> chunk -> last = FALSE ; <nl>  <nl> /* with chunk ' s values set , we can use the standard macro to calculate <nl> wmem_block_split_free_chunk ( wmem_block_allocator_t * allocator , <nl>  <nl> /* Now that we ' ve copied over the free - list stuff ( which may have overlapped <nl> * with our new chunk header ) we can safely write our new chunk header . */ <nl> - extra -> len = available ; <nl> + extra -> len = ( guint32 ) available ; <nl> extra -> last = last ; <nl> - extra -> prev = aligned_size + sizeof ( wmem_block_chunk_t ); <nl> + extra -> prev = ( guint32 ) ( aligned_size + sizeof ( wmem_block_chunk_t )); <nl> extra -> used = FALSE ; <nl> } <nl>  <nl> wmem_block_split_used_chunk ( wmem_block_allocator_t * allocator , <nl> available = chunk -> len ; <nl>  <nl> /* set new values for chunk */ <nl> - chunk -> len = aligned_size + sizeof ( wmem_block_chunk_t ); <nl> + chunk -> len = ( guint32 ) ( aligned_size + sizeof ( wmem_block_chunk_t )); <nl> chunk -> last = FALSE ; <nl>  <nl> /* with chunk ' s values set , we can use the standard macro to calculate <nl> wmem_block_split_used_chunk ( wmem_block_allocator_t * allocator , <nl> available -= ( aligned_size + sizeof ( wmem_block_chunk_t )); <nl>  <nl> /* set the new values for the chunk */ <nl> - extra -> len = available ; <nl> + extra -> len = ( guint32 ) available ; <nl> extra -> last = last ; <nl> - extra -> prev = aligned_size + sizeof ( wmem_block_chunk_t ); <nl> + extra -> prev = ( guint32 ) ( aligned_size + sizeof ( wmem_block_chunk_t )); <nl> extra -> used = FALSE ; <nl>  <nl> /* add it to the free list */
mmm epan / dissectors / packet - user_encap . c <nl> ppp epan / dissectors / packet - user_encap . c <nl> static void dissect_user ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , guint <nl> call_dissector ( encap -> payload_handle , payload_tvb , pinfo , tree ); <nl>  <nl> if ( encap -> trailer_size ) { <nl> - tvbuff_t * trailer_tvb = tvb_new_subset ( tvb , 0 , encap -> trailer_size , encap -> trailer_size ); <nl> + tvbuff_t * trailer_tvb = tvb_new_subset ( tvb , encap -> header_size + len , encap -> trailer_size , encap -> trailer_size ); <nl> call_dissector ( encap -> trailer_handle , trailer_tvb , pinfo , tree ); <nl> offset = encap -> trailer_size ; <nl> } <nl> static void dissect_user ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , guint <nl>  <nl> void proto_reg_handoff_user_encap ( void ) <nl> { <nl> - int i = 0 ; <nl> + int i ; <nl> static dissector_handle_t data_handle ; <nl>  <nl> data_handle = find_dissector (" data "); <nl>  <nl> - do { <nl> + for ( i = 0 ; i < 16 ; i ++) { <nl> encaps [ i ]. handle = find_dissector ( encaps [ i ]. abbr ); <nl> dissector_add (" wtap_encap ", WTAP_ENCAP_USER0 + i , encaps [ i ]. handle ); <nl>  <nl> void proto_reg_handoff_user_encap ( void ) <nl> } <nl>  <nl> encaps [ i ]. encap_dissector = encap_dissectors [ encaps [ i ]. encap ]; <nl> - <nl> - i ++; <nl> - } while ( i < 16 ); <nl> - <nl> + } <nl> } <nl>  <nl> void proto_register_user_encap ( void )
mmm epan / dissectors / packet - q931 . c <nl> ppp epan / dissectors / packet - q931 . c <nl> dissect_q931_pdu ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> offset += call_ref_len ; <nl> } <nl> message_type = tvb_get_guint8 ( tvb , offset ); <nl> - if ( have_valid_q931_pi ) { <nl> + if ( have_valid_q931_pi && q931_pi ) { <nl> q931_pi -> message_type = message_type ; <nl> } <nl> col_add_str ( pinfo -> cinfo , COL_INFO , get_message_name ( prot_discr , message_type ));
mmm epan / dissectors / packet - rdt . c <nl> ppp epan / dissectors / packet - rdt . c <nl> # include < epan / packet . h > <nl> # include < epan / conversation . h > <nl> # include < epan / prefs . h > <nl> -# include < epan / emem . h > <nl> # include < epan / strutil . h > <nl> +# include < epan / wmem / wmem . h > <nl>  <nl> # include " packet - rdt . h " <nl>  <nl> void rdt_add_address ( packet_info * pinfo , <nl> if (! p_conv_data ) <nl> { <nl> /* Create conversation data */ <nl> - p_conv_data = se_new ( struct _rdt_conversation_info ); <nl> + p_conv_data = wmem_new ( wmem_file_scope (), struct _rdt_conversation_info ); <nl> conversation_add_proto_data ( p_conv , proto_rdt , p_conv_data ); <nl> } <nl>  <nl> static void show_setup_info ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> if ( p_conv_data ) <nl> { <nl> /* Save this conversation info into packet info */ <nl> - p_conv_packet_data = se_new ( struct _rdt_conversation_info ); <nl> + p_conv_packet_data = wmem_new ( wmem_file_scope (), struct _rdt_conversation_info ); <nl> g_strlcpy ( p_conv_packet_data -> method , p_conv_data -> method , MAX_RDT_SETUP_METHOD_SIZE ); <nl> p_conv_packet_data -> frame_number = p_conv_data -> frame_number ; <nl> p_conv_packet_data -> feature_level = p_conv_data -> feature_level ;
mmm epan / oids . c <nl> ppp epan / oids . c <nl> static oid_info_t * add_oid ( const char * name , oid_kind_t kind , const oid_value_ty <nl> if (! g_str_equal ( n -> name , name )) { <nl> D ( 2 ,(" Renaming Oid from : % s -> % s , this means the same oid is registered more than once ", n -> name , name )); <nl> } <nl> - /* XXX - Don ' t free n -> name here . It may be part of an hf_register_info <nl> - * struct that has been appended to the hfa GArray . */ <nl> + /* There used to be a comment here that claimed we couldn ' t free <nl> + * n -> name since it may be part of an hf_register_info struct <nl> + * that has been appended to the hfa GArray . I think that comment <nl> + * was wrong , because we only ever create oid_info_t ' s in this <nl> + * function , and we are always careful here to g_strdup the name . <nl> + * All that to justify freeing n -> name in the next line , since <nl> + * doing so fixes some memory leaks . */ <nl> + g_free ( n -> name ); <nl> } <nl>  <nl> n -> name = g_strdup ( name );
mmm plugins / gryphon / packet - gryphon . c <nl> ppp plugins / gryphon / packet - gryphon . c <nl> dissect_gryphon_message ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> /* <nl> * Indicate what kind of message this is . <nl> */ <nl> - col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str ( frmtyp , frame_type , "- Invalid -")); <nl> + col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str_const ( frmtyp , frame_type , "- Invalid -")); <nl> } <nl>  <nl> if ( tree == NULL )
mmm epan / tvbuff . c <nl> ppp epan / tvbuff . c <nl> tvb_get_ephemeral_unicode_stringz ( tvbuff_t * tvb , const gint offset , gint * length <nl>  <nl> size = tvb_unicode_strsize ( tvb , offset ); <nl>  <nl> - for ( i = 0 ; i < size ; i += 2 ) { /* XXX - make <= ??? */ <nl> + for ( i = 0 ; i < size ; i += 2 ) { <nl>  <nl> if ( encoding == ENC_BIG_ENDIAN ) <nl> uchar = tvb_get_ntohs ( tvb , offset + i ); <nl> else <nl> uchar = tvb_get_letohs ( tvb , offset + i ); <nl>  <nl> - /* Calculate how much space is needed to store UTF - 16 character in UTF - 8 */ <nl> + /* Calculate how much space is needed to store UTF - 16 character <nl> + * in UTF - 8 */ <nl> tmpbuf_len = g_unichar_to_utf8 ( uchar , NULL ); <nl>  <nl> - tmpbuf = g_malloc ( tmpbuf_len + 1 ); /* + 1 to make room for null terminator */ <nl> + tmpbuf = g_malloc ( tmpbuf_len + 1 ); /* + 1 to make room for null <nl> + * terminator */ <nl>  <nl> g_unichar_to_utf8 ( uchar , tmpbuf ); <nl>  <nl> - /* NULL terminate the tmpbuf so ep_strbuf_append knows where to stop */ <nl> + /* NULL terminate the tmpbuf so ep_strbuf_append knows where <nl> + * to stop */ <nl> tmpbuf [ tmpbuf_len ] = '\ 0 '; <nl>  <nl> ep_strbuf_append ( strbuf , tmpbuf );
mmm epan / dissectors / packet - mqtt . c <nl> ppp epan / dissectors / packet - mqtt . c <nl> static void * mqtt_message_decode_copy_cb ( void * dest , const void * orig , size_t le <nl> const mqtt_message_decode_t * o = ( const mqtt_message_decode_t *) orig ; <nl> mqtt_message_decode_t * d = ( mqtt_message_decode_t *) dest ; <nl>  <nl> + d -> match_criteria = o -> match_criteria ; <nl> d -> topic_pattern = g_strdup ( o -> topic_pattern ); <nl> d -> payload_proto_name = g_strdup ( o -> payload_proto_name ); <nl> 
mmm epan / dissectors / packet - sflow . c <nl> ppp epan / dissectors / packet - sflow . c <nl> static const value_string sflow_245_ipv4_precedence_types [] = { <nl> { SFLOW_245_IPV4_PRECEDENCE_CRITIC_ECP , " CRITIC / ECP "}, <nl> { SFLOW_245_IPV4_PRECEDENCE_INTERNETWORK_CONTROL , " Internetwork Control "}, <nl> { SFLOW_245_IPV4_PRECEDENCE_NETWORK_CONTROL , " Network Control "}, <nl> + { 0 , NULL } <nl> }; <nl>  <nl> /* sFlow v5 flow record formats */ <nl> dissect_sflow_5_extended_mpls_lvp_fec ( tvbuff_t * tvb , proto_tree * tree , gint offs <nl> guint32 length ; <nl>  <nl> length = tvb_get_ntohl ( tvb , offset ); <nl> - proto_tree_add_text ( tree , tvb , offset , 4 , " MPLS FEC Address Preﬁx Length : % u bytes ", length ); <nl> + proto_tree_add_text ( tree , tvb , offset , 4 , " MPLS FEC Address Prefix Length : % u bytes ", length ); <nl> offset += 4 ; <nl> return offset ; <nl> }
mmm gtk / ui_util . c <nl> ppp gtk / ui_util . c <nl> tree_view_new ( GtkTreeModel * model ) <nl>  <nl> # if GTK_MAJOR_VERSION < 2 <nl> GtkWidget * <nl> - ctree_new_with_titles ( gint columns , gint tree_column , gchar * titles []) <nl> + ctree_new_with_titles ( gint columns , gint tree_column , const gchar * titles []) <nl> { <nl> GtkWidget * tree ; <nl> mmm gtk / toolbar . c <nl> ppp gtk / toolbar . c <nl> tree_view_new ( GtkTreeModel * model ) <nl>  <nl> # if GTK_MAJOR_VERSION < 2 <nl> GtkWidget * <nl> - ctree_new_with_titles ( gint columns , gint tree_column , gchar * titles []) <nl> + ctree_new_with_titles ( gint columns , gint tree_column , const gchar * titles []) <nl> { <nl> GtkWidget * tree ; <nl>  <nl> static void toolbar_append_separator ( GtkWidget * toolbar ) { <nl>  <nl>  <nl> # define toolbar_icon ( new_icon , window , xpm ) { \ <nl> - icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , xpm ); \ <nl> + icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , ( gchar **) xpm ); \ <nl> new_icon = gtk_pixmap_new ( icon , mask ); \ <nl> } <nl> mmm gtk / tcp_graph . c <nl> ppp gtk / tcp_graph . c <nl> tree_view_new ( GtkTreeModel * model ) <nl>  <nl> # if GTK_MAJOR_VERSION < 2 <nl> GtkWidget * <nl> - ctree_new_with_titles ( gint columns , gint tree_column , gchar * titles []) <nl> + ctree_new_with_titles ( gint columns , gint tree_column , const gchar * titles []) <nl> { <nl> GtkWidget * tree ; <nl>  <nl> static void toolbar_append_separator ( GtkWidget * toolbar ) { <nl>  <nl>  <nl> # define toolbar_icon ( new_icon , window , xpm ) { \ <nl> - icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , xpm ); \ <nl> + icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , ( gchar **) xpm ); \ <nl> new_icon = gtk_pixmap_new ( icon , mask ); \ <nl> } <nl>  <nl> static void graph_destroy ( struct graph * g ) <nl> gdk_pixmap_unref ( g -> pixmap [ 1 ]); <nl> g_free ( g -> x_axis ); <nl> g_free ( g -> y_axis ); <nl> - g_free ( g -> title ); <nl> + g_free ( ( gpointer ) ( g -> title ) ); <nl> graph_segment_list_free ( g ); <nl> graph_element_lists_free ( g ); <nl> # if 0 <nl> static void axis_destroy ( struct axis * axis ) <nl> { <nl> gdk_pixmap_unref ( axis -> pixmap [ 0 ]); <nl> gdk_pixmap_unref ( axis -> pixmap [ 1 ]); <nl> - g_free ( axis -> label ); <nl> + g_free ( ( gpointer ) ( axis -> label ) ); <nl> } <nl>  <nl> static void axis_display ( struct axis * axis )mmm gtk / simple_dialog . c <nl> ppp gtk / simple_dialog . c <nl> tree_view_new ( GtkTreeModel * model ) <nl>  <nl> # if GTK_MAJOR_VERSION < 2 <nl> GtkWidget * <nl> - ctree_new_with_titles ( gint columns , gint tree_column , gchar * titles []) <nl> + ctree_new_with_titles ( gint columns , gint tree_column , const gchar * titles []) <nl> { <nl> GtkWidget * tree ; <nl>  <nl> static void toolbar_append_separator ( GtkWidget * toolbar ) { <nl>  <nl>  <nl> # define toolbar_icon ( new_icon , window , xpm ) { \ <nl> - icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , xpm ); \ <nl> + icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , ( gchar **) xpm ); \ <nl> new_icon = gtk_pixmap_new ( icon , mask ); \ <nl> } <nl>  <nl> static void graph_destroy ( struct graph * g ) <nl> gdk_pixmap_unref ( g -> pixmap [ 1 ]); <nl> g_free ( g -> x_axis ); <nl> g_free ( g -> y_axis ); <nl> - g_free ( g -> title ); <nl> + g_free ( ( gpointer ) ( g -> title ) ); <nl> graph_segment_list_free ( g ); <nl> graph_element_lists_free ( g ); <nl> # if 0 <nl> static void axis_destroy ( struct axis * axis ) <nl> { <nl> gdk_pixmap_unref ( axis -> pixmap [ 0 ]); <nl> gdk_pixmap_unref ( axis -> pixmap [ 1 ]); <nl> - g_free ( axis -> label ); <nl> + g_free ( ( gpointer ) ( axis -> label ) ); <nl> } <nl>  <nl> static void axis_display ( struct axis * axis ) <nl> display_simple_dialog ( gint type , gint btn_mask , char * message ) <nl> GdkBitmap * mask ; <nl> GtkStyle * style ; <nl> GdkColormap * cmap ; <nl> - gchar ** icon ; <nl> + const gchar ** icon ; <nl>  <nl> /* Main window */ <nl> switch ( type ) { <nl> display_simple_dialog ( gint type , gint btn_mask , char * message ) <nl> style = gtk_widget_get_style ( win ); <nl> cmap = gdk_colormap_get_system (); <nl> pixmap = gdk_pixmap_colormap_create_from_xpm_d ( NULL , cmap , & mask , <nl> - & style -> bg [ GTK_STATE_NORMAL ], icon ); <nl> + & style -> bg [ GTK_STATE_NORMAL ], ( gchar **) icon ); <nl> type_pm = gtk_pixmap_new ( pixmap , mask ); <nl> gtk_misc_set_alignment ( GTK_MISC ( type_pm ), 0 . 5 , 0 . 0 ); <nl> gtk_container_add ( GTK_CONTAINER ( top_hb ), type_pm );mmm gtk / ui_util . h <nl> ppp gtk / ui_util . h <nl> tree_view_new ( GtkTreeModel * model ) <nl>  <nl> # if GTK_MAJOR_VERSION < 2 <nl> GtkWidget * <nl> - ctree_new_with_titles ( gint columns , gint tree_column , gchar * titles []) <nl> + ctree_new_with_titles ( gint columns , gint tree_column , const gchar * titles []) <nl> { <nl> GtkWidget * tree ; <nl>  <nl> static void toolbar_append_separator ( GtkWidget * toolbar ) { <nl>  <nl>  <nl> # define toolbar_icon ( new_icon , window , xpm ) { \ <nl> - icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , xpm ); \ <nl> + icon = gdk_pixmap_create_from_xpm_d ( window -> window , & mask , & window -> style -> white , ( gchar **) xpm ); \ <nl> new_icon = gtk_pixmap_new ( icon , mask ); \ <nl> } <nl>  <nl> static void graph_destroy ( struct graph * g ) <nl> gdk_pixmap_unref ( g -> pixmap [ 1 ]); <nl> g_free ( g -> x_axis ); <nl> g_free ( g -> y_axis ); <nl> - g_free ( g -> title ); <nl> + g_free ( ( gpointer ) ( g -> title ) ); <nl> graph_segment_list_free ( g ); <nl> graph_element_lists_free ( g ); <nl> # if 0 <nl> static void axis_destroy ( struct axis * axis ) <nl> { <nl> gdk_pixmap_unref ( axis -> pixmap [ 0 ]); <nl> gdk_pixmap_unref ( axis -> pixmap [ 1 ]); <nl> - g_free ( axis -> label ); <nl> + g_free ( ( gpointer ) ( axis -> label ) ); <nl> } <nl>  <nl> static void axis_display ( struct axis * axis ) <nl> display_simple_dialog ( gint type , gint btn_mask , char * message ) <nl> GdkBitmap * mask ; <nl> GtkStyle * style ; <nl> GdkColormap * cmap ; <nl> - gchar ** icon ; <nl> + const gchar ** icon ; <nl>  <nl> /* Main window */ <nl> switch ( type ) { <nl> display_simple_dialog ( gint type , gint btn_mask , char * message ) <nl> style = gtk_widget_get_style ( win ); <nl> cmap = gdk_colormap_get_system (); <nl> pixmap = gdk_pixmap_colormap_create_from_xpm_d ( NULL , cmap , & mask , <nl> - & style -> bg [ GTK_STATE_NORMAL ], icon ); <nl> + & style -> bg [ GTK_STATE_NORMAL ], ( gchar **) icon ); <nl> type_pm = gtk_pixmap_new ( pixmap , mask ); <nl> gtk_misc_set_alignment ( GTK_MISC ( type_pm ), 0 . 5 , 0 . 0 ); <nl> gtk_container_add ( GTK_CONTAINER ( top_hb ), type_pm ); <nl> extern GtkWidget * ctree_new ( gint columns , gint tree_column ); <nl> * @ return the newly created GtkCTree <nl> */ <nl> extern GtkWidget * ctree_new_with_titles ( gint columns , gint tree_column , <nl> - gchar * titles []); <nl> + const gchar * titles []); <nl> # else <nl> /** Create a GtkTreeView , give it the right styles , and remember it . <nl> *
mmm epan / dissectors / packet - xml . c <nl> ppp epan / dissectors / packet - xml . c <nl> next_attribute : <nl> g_ptr_array_free ( new -> element_names , TRUE ); <nl>  <nl> g_hash_table_insert ( root_element -> elements , new -> name , new ); <nl> - <nl> - g_free ( curr_name ); <nl> } <nl> } <nl> 
mmm ui / qt / wireless_frame . cpp <nl> ppp ui / qt / wireless_frame . cpp <nl> WirelessFrame :: WirelessFrame ( QWidget * parent ) : <nl>  <nl> WirelessFrame ::~ WirelessFrame () <nl> { <nl> + ws80211_free_interfaces ( interfaces_ ); <nl> delete ui ; <nl> } <nl> 
mmm epan / oids . c <nl> ppp epan / oids . c <nl> guint oid_string2subid ( wmem_allocator_t * scope , const char * str , guint32 ** subid <nl> subid += * r - ' 0 '; <nl>  <nl> if ( subids >= subids_overflow || subid > 0xffffffff ) { <nl> + wmem_free ( scope , * subids_p ); <nl> * subids_p = NULL ; <nl> return 0 ; <nl> }
mmm epan / dissectors / packet - qnet6 . c <nl> ppp epan / dissectors / packet - qnet6 . c <nl> dissect_qnet6 ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * dat <nl> /* <nl> * data after header <nl> */ <nl> - if ( cklen != 0 ) <nl> + if ( cklen > 0 ) <nl> { <nl> crc = crc32_mpeg2_seed ( tvb_get_ptr ( tvb , 36 + 2 , cklen ), cklen , ~ crc ); <nl> crc = ~ crc ;
mmm epan / dissectors / packet - radius . c <nl> ppp epan / dissectors / packet - radius . c <nl> dissect_attribute_value_pairs ( proto_tree * tree , packet_info * pinfo , tvbuff_t * tv <nl>  <nl> avp_vsa_len -= avp_vsa_header_len ; <nl>  <nl> + memset (& vendor_type , 0 , sizeof ( vendor_type )); <nl> if ( avp_is_extended ) { <nl> vendor_type . u8_code [ 0 ] = avp_type . u8_code [ 0 ]; <nl> vendor_type . u8_code [ 1 ] = avp_vsa_type ;
mmm tools / lemon / lemon . c <nl> ppp tools / lemon / lemon . c <nl> PRIVATE void tplt_xfer ( const char * name , FILE * in , FILE * out , int * lineno ) <nl> PRIVATE FILE * tplt_open ( struct lemon * lemp ) <nl> { <nl> static char templatename [] = " lempar . c "; <nl> - char * buf ; <nl> FILE * in ; <nl> char * tpltname = NULL ; <nl> char * cp ; <nl>  <nl> if ( lemp -> templatename ) { <nl> tpltname = strdup ( lemp -> templatename ); <nl> - } <nl> - else { <nl> + } else { <nl> + char * buf ; <nl> + <nl> cp = strrchr ( lemp -> filename ,'.'); <nl> buf = malloc ( 1000 ); <nl> if ( cp ){ <nl> PRIVATE FILE * tplt_open ( struct lemon * lemp ) <nl> sprintf ( buf ,"% s . lt ", lemp -> filename ); <nl> } <nl> if ( access ( buf , 004 )== 0 ){ <nl> - tpltname = buf ; <nl> + tpltname = strdup ( buf ); <nl> } else if ( access ( templatename , 004 )== 0 ){ <nl> tpltname = strdup ( templatename ); <nl> } else { <nl> tpltname = pathsearch ( lemp -> argv0 , templatename , 0 ); <nl> - free ( buf ); <nl> } <nl> + free ( buf ); <nl> } <nl> if ( tpltname == 0 ){ <nl> fprintf ( stderr ," Can ' t find the parser driver template file \"% s \".\ n ",
mmm epan / dissectors / packet - sip . c <nl> ppp epan / dissectors / packet - sip . c <nl> dissect_sip_common ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree * tr <nl> } <nl> } <nl>  <nl> - if ( sub_value_offset == linelen ) <nl> + if ( sub_value_offset == value_len ) <nl> { <nl> /* Didn ' t find method name */ <nl> THROW ( ReportedBoundsError ); <nl> dissect_sip_common ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree * tr <nl> } <nl>  <nl> /* Extract method name from value */ <nl> - strlen_to_copy = ( int ) linelen - sub_value_offset ; <nl> + strlen_to_copy = ( int ) value_len - sub_value_offset ; <nl> if ( strlen_to_copy > MAX_CSEQ_METHOD_SIZE ) { <nl> /* Note the error in the protocol tree */ <nl> if ( hdr_tree ) {
mmm epan / dissectors / packet - rtpproxy . c <nl> ppp epan / dissectors / packet - rtpproxy . c <nl> static int <nl> dissect_rtpproxy ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ ) <nl> { <nl> gboolean has_lf = FALSE ; <nl> - guint offset = 0 ; <nl> + gint offset = 0 ; <nl> gint new_offset = 0 ; <nl> guint tmp ; <nl> - guint realsize = 0 ; <nl> + gint realsize = 0 ; <nl> guint8 * rawstr ; <nl> proto_item * ti ; <nl> proto_tree * rtpproxy_tree ; <nl> dissect_rtpproxy ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data <nl>  <nl> /* Extract parameters */ <nl> /* Parameters should be right after the command and before EOL ( in case of Info command ) or before whitespace */ <nl> - new_offset = ( tmp == ' i ' ? ( gint )( realsize - 1 > offset ? offset + strlen (" Ib ") : offset + strlen (" I ")) : tvb_find_guint8 ( tvb , offset , - 1 , ' ')); <nl> + new_offset = ( tmp == ' i ' ? ( realsize - 1 > offset ? offset + ( gint ) strlen (" Ib ") : offset + ( gint ) strlen (" I ")) : tvb_find_guint8 ( tvb , offset , - 1 , ' ')); <nl>  <nl> - if ( new_offset != ( gint ) offset + 1 ){ <nl> + if ( new_offset != offset + 1 ){ <nl> rtpproxy_tree = proto_item_add_subtree ( ti , ett_rtpproxy_command ); <nl> proto_tree_add_item ( rtpproxy_tree , hf_rtpproxy_command_parameters , tvb , offset + 1 , new_offset - ( offset + 1 ), ENC_ASCII | ENC_NA ); <nl> rtpproxy_tree = proto_item_get_parent ( ti );
mmm ui / win32 / console_win32 . c <nl> ppp ui / win32 / console_win32 . c <nl> /* console_win32 . c <nl> * Console support for MSWindows <nl> * <nl> - * $ Id : console_win32 . c 45689 2012 - 10 - 21 15 : 04 : 50Z alagoutte $ <nl> + * $ Id $ <nl> * <nl> * Wireshark - Network traffic analyzer <nl> * By Gerald Combs < gerald @ wireshark . org > <nl> * <nl> */ <nl>  <nl> +# ifdef _WIN32 <nl> + <nl> # include < string . h > <nl> # include < stdio . h > <nl> # include < stdlib . h > <nl> # include " console_win32 . h " <nl> # include "../../ console_io . h " <nl>  <nl> -# ifdef _WIN32 /* Needed for console I / O */ <nl> # if _MSC_VER < 1500 <nl> /* AttachConsole () needs this # define ! */ <nl> # define _WIN32_WINNT 0x0501 <nl> # include < conio . h > <nl> # include < windows . h > <nl> # include < tchar . h > <nl> -# endif <nl>  <nl> -# ifdef _WIN32 <nl> static gboolean has_console ; /* TRUE if app has console */ <nl> static gboolean console_wait ; /* " Press any key ..." */ <nl> static gboolean stdin_capture = FALSE ; /* Don ' t grab stdin & stdout if TRUE */ <nl> -# endif <nl>  <nl> -# ifdef _WIN32 <nl> /* The code to create and desstroy console windows should not be necessary , <nl> at least as I read the GLib source code , as it looks as if GLib is , on <nl> Win32 , * supposed * to create a console window into which to display its <nl> set_console_wait ( gboolean set_console_wait ) <nl> { <nl> console_wait = set_console_wait ; <nl> } <nl> + <nl> gboolean <nl> get_console_wait ( void ) <nl> { <nl> get_stdin_capture ( void ) <nl> { <nl> return stdin_capture ; <nl> } <nl> + <nl> # endif /* _WIN32 */ <nl>  <nl> /*
mmm epan / dissectors / packet - smb . c <nl> ppp epan / dissectors / packet - smb . c <nl> dissect_smb_command ( tvbuff_t * tvb , packet_info * pinfo , int offset , proto_tree * s <nl> smb_dissector [ cmd ]. request : smb_dissector [ cmd ]. response ; <nl>  <nl> offset = (* dissector )( tvb , pinfo , cmd_tree , offset , smb_tree ); <nl> + <nl> + if (! tvb_offset_exists ( tvb , offset - 1 )) { <nl> + THROW ( ReportedBoundsError ); <nl> + } <nl> proto_item_set_end ( cmd_item , tvb , offset ); <nl> } <nl> return offset ;
mmm epan / dissectors / packet - ieee80211 . c <nl> ppp epan / dissectors / packet - ieee80211 . c <nl> dissect_extended_capabilities_ie ( packet_info * pinfo , proto_tree * tree , <nl> expert_add_info_format ( pinfo , ti_len , PI_MALFORMED , PI_ERROR , " Tag length % u too short , must be greater than 0 ", tag_len ); <nl> return offset ; <nl> } <nl> - proto_item_append_text ( ti , " (% d octets )", tag_len ); <nl> + proto_item_append_text ( ti , " (% u octet % s )", tag_len , plurality ( tag_len , "", " s ")); <nl>  <nl> /* Extended Capability octet 1 */ <nl> ti_ex_cap = proto_tree_add_item ( tree , hf_ieee80211_tag_extended_capabilities , tvb , offset , 1 , ENC_NA ); <nl> add_tagged_field ( packet_info * pinfo , proto_tree * tree , tvbuff_t * tvb , int offset <nl> " (% s ) code not implemented , Contact " <nl> " Wireshark developers if you want this supported ", val_to_str_ext ( tag_no , <nl> & tag_num_vals_ext , "(% d )")); <nl> - proto_item_append_text ( ti , ": Tag % u Len % u ", tag_no , tag_len ); <nl> + proto_item_append_text ( ti , ": Undecoded "); <nl> break ; <nl> } <nl> if ( offset < tag_end ) {
mmm epan / wslua / wslua_field . c <nl> ppp epan / wslua / wslua_field . c <nl> static int FieldInfo_get_range ( lua_State * L ) { <nl> r -> tvb = ep_new ( struct _wslua_tvb ); <nl>  <nl> r -> tvb -> ws_tvb = fi -> ds_tvb ; <nl> + r -> tvb -> expired = FALSE ; <nl> + r -> tvb -> need_free = FALSE ; <nl> r -> offset = fi -> start ; <nl> r -> len = fi -> length ; <nl> 
mmm epan / dissectors / packet - umts_mac . c <nl> ppp epan / dissectors / packet - umts_mac . c <nl> static void dissect_mac_fdd_dch ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * t <nl>  <nl> macinf = p_get_proto_data ( pinfo -> fd , proto_umts_mac ); <nl> fpinf = p_get_proto_data ( pinfo -> fd , proto_fp ); <nl> - pos = fpinf -> cur_tb ; <nl> if (! macinf || ! fpinf ) { <nl> proto_tree_add_text ( dch_tree , tvb , 0 , - 1 , <nl> " Cannot dissect MAC frame because per - frame info is missing "); <nl> return ; <nl> } <nl> + pos = fpinf -> cur_tb ; <nl> if ( macinf -> ctmux [ pos ]) { <nl> proto_tree_add_bits_item ( dch_tree , hf_mac_ct , tvb , 0 , 4 , FALSE ); <nl> bitoffs = 4 ;
mmm capture . c <nl> ppp capture . c <nl> /* capture . c <nl> * Routines for packet capture windows <nl> * <nl> - * $ Id : capture . c , v 1 . 197 2002 / 12 / 18 06 : 44 : 50 guy Exp $ <nl> + * $ Id : capture . c , v 1 . 198 2002 / 12 / 29 01 : 19 : 08 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> pipe_open_live ( char * pipename , struct pcap_hdr * hdr , loop_data * ld , <nl> " Unexpected error from select : % s ", strerror ( errno )); <nl> goto error ; <nl> } else if ( sel_ret > 0 ) { <nl> - b = read ( fd , & magic + bytes_read , sizeof magic - bytes_read ); <nl> + b = read ( fd , (( char *)& magic )+ bytes_read , sizeof magic - bytes_read ); <nl> if ( b <= 0 ) { <nl> if ( b == 0 ) <nl> snprintf ( errmsg , errmsgl , " End of file on pipe during open ");
mmm epan / dissectors / packet - cops . c <nl> ppp epan / dissectors / packet - cops . c <nl> * Based on PKT - SP - DQOS - I09 - 040402 ( April 2 , 2004 ) <nl> * <nl> * PacketCable Multimedia Specification <nl> - * Based on PKT - SP - MM - I02 - 040930 <nl> + * Based on PKT - SP - MM - I04 - 080522 <nl> * <nl> * www . packetcable . com <nl> * <nl> cops_classifier ( tvbuff_t * tvb , proto_tree * st , guint n , guint32 offset , gboolean <nl> offset += 2 ; <nl> } <nl>  <nl> - /* Priority */ <nl> - info_to_display ( tvb , stt , offset , 1 ," Priority ", NULL , FMT_HEX ,& hf_cops_pcmm_classifier_priority ); <nl> - offset += 1 ; <nl> - <nl> if ( extended ) { <nl> /* ClassifierID */ <nl> info_to_display ( tvb , stt , offset , 2 ," ClassifierID ", NULL , FMT_HEX ,& hf_cops_pcmm_classifier_classifier_id ); <nl> offset += 2 ; <nl> + } <nl> + <nl> + /* Priority */ <nl> + info_to_display ( tvb , stt , offset , 1 ," Priority ", NULL , FMT_HEX ,& hf_cops_pcmm_classifier_priority ); <nl> + offset += 1 ; <nl>  <nl> + if ( extended ) { <nl> /* Activation State */ <nl> info_to_display ( tvb , stt , offset , 1 ," Activation State ", NULL , FMT_HEX ,& hf_cops_pcmm_classifier_activation_state ); <nl> offset += 1 ;
mmm wsutil / ws_pipe . c <nl> ppp wsutil / ws_pipe . c <nl> ws_pipe_wait_for_pipe ( HANDLE * pipe_handles , int num_pipe_handles , HANDLE pid ) <nl> int num_waiting_to_connect = 0 ; <nl> int num_handles = num_pipe_handles + 1 ; // PID handle is also added to list of handles . <nl>  <nl> + SecureZeroMemory ( pipeinsts , sizeof ( pipeinsts )); <nl> + <nl> if ( num_pipe_handles == 0 || num_pipe_handles > 3 ) <nl> { <nl> g_log ( LOG_DOMAIN_CAPTURE , G_LOG_LEVEL_DEBUG , " Invalid number of pipes given as argument .");
mmm examples / client / client . c <nl> ppp examples / client / client . c <nl> static int ClientBenchmarkThroughput ( WOLFSSL_CTX * ctx , char * host , word16 port , <nl>  <nl> /* Compare TX and RX buffers */ <nl> if ( XMEMCMP ( tx_buffer , rx_buffer , len ) != 0 ) { <nl> + free ( tx_buffer ); <nl> + tx_buffer = NULL ; <nl> + free ( rx_buffer ); <nl> + rx_buffer = NULL ; <nl> err_sys (" Compare TX and RX buffers failed "); <nl> } <nl> mmm wolfcrypt / test / test . c <nl> ppp wolfcrypt / test / test . c <nl> static int ClientBenchmarkThroughput ( WOLFSSL_CTX * ctx , char * host , word16 port , <nl>  <nl> /* Compare TX and RX buffers */ <nl> if ( XMEMCMP ( tx_buffer , rx_buffer , len ) != 0 ) { <nl> + free ( tx_buffer ); <nl> + tx_buffer = NULL ; <nl> + free ( rx_buffer ); <nl> + rx_buffer = NULL ; <nl> err_sys (" Compare TX and RX buffers failed "); <nl> } <nl>  <nl> static int ecc_test_curve ( WC_RNG * rng , int keySize ) <nl>  <nl> # if ! defined ( WOLFSSL_ATECC508A ) && defined ( HAVE_ECC_KEY_IMPORT ) && \ <nl> defined ( HAVE_ECC_KEY_EXPORT ) <nl> - static int ecc_point_test () <nl> + static int ecc_point_test ( void ) <nl> { <nl> int ret ; <nl> ecc_point * point ;
mmm wolfssl / error - ssl . h <nl> ppp wolfssl / error - ssl . h <nl> enum wolfSSL_ErrorCodes { <nl> SANITY_MSG_E = - 394 , /* Sanity check on msg order error */ <nl> DUPLICATE_MSG_E = - 395 , /* Duplicate message error */ <nl> SNI_UNSUPPORTED = - 396 , /* SSL 3 . 0 does not support SNI */ <nl> + SOCKET_PEER_CLOSED_E = - 397 , /* Underlying transport closed */ <nl>  <nl> /* add strings to SetErrorString !!!!! */ <nl> mmm src / internal . c <nl> ppp src / internal . c <nl> enum wolfSSL_ErrorCodes { <nl> SANITY_MSG_E = - 394 , /* Sanity check on msg order error */ <nl> DUPLICATE_MSG_E = - 395 , /* Duplicate message error */ <nl> SNI_UNSUPPORTED = - 396 , /* SSL 3 . 0 does not support SNI */ <nl> + SOCKET_PEER_CLOSED_E = - 397 , /* Underlying transport closed */ <nl>  <nl> /* add strings to SetErrorString !!!!! */ <nl>  <nl> startScr : <nl> if ( ssl -> error == SOCKET_ERROR_E ) { <nl> if ( ssl -> options . connReset || ssl -> options . isClosed ) { <nl> WOLFSSL_MSG (" Peer reset or closed , connection done "); <nl> + ssl -> error = SOCKET_PEER_CLOSED_E ; <nl> + WOLFSSL_ERROR ( ssl -> error ); <nl> return 0 ; /* peer reset or closed */ <nl> } <nl> } <nl> const char * wolfSSL_ERR_reason_error_string ( unsigned long e ) <nl> case DUPLICATE_MSG_E : <nl> return " Duplicate HandShake message Error "; <nl>  <nl> + case SNI_UNSUPPORTED : <nl> + return " Protocol version does not support SNI Error "; <nl> + <nl> + case SOCKET_PEER_CLOSED_E : <nl> + return " Peer closed underlying transport Error "; <nl> + <nl> default : <nl> return " unknown error number "; <nl> }
mmm ctaocrypt / src / aes . c <nl> ppp ctaocrypt / src / aes . c <nl> void AesCtrEncrypt ( Aes * aes , byte * out , const byte * in , word32 sz ) <nl> word32 blocks = sz / AES_BLOCK_SIZE ; <nl>  <nl> while ( blocks --) { <nl> - AesEncrypt ( aes , aes -> reg , out ); <nl> + AesEncrypt ( aes , ( byte *) aes -> reg , out ); <nl> IncrementAesCounter (( byte *) aes -> reg ); <nl> xorbuf ( out , in , AES_BLOCK_SIZE ); <nl> 
mmm src / tls . c <nl> ppp src / tls . c <nl> static int TLSX_KeyShare_Parse ( WOLFSSL * ssl , byte * input , word16 length , <nl> if ( TLSX_KeyShare_Find ( ssl , group )) <nl> return BAD_KEY_SHARE_DATA ; <nl>  <nl> + /* Clear out unusable key shares . */ <nl> + ret = TLSX_KeyShare_Empty ( ssl ); <nl> + if ( ret != 0 ) <nl> + return ret ; <nl> + <nl> /* Try to use the server ' s group . */ <nl> ret = TLSX_KeyShare_Use ( ssl , group , 0 , NULL , NULL ); <nl> }
mmm wolfcrypt / src / logging . c <nl> ppp wolfcrypt / src / logging . c <nl> int wc_AddErrorNode ( int error , int line , char * buf , char * file ) <nl> if ( wc_errors != NULL ) { <nl> /* check for unexpected case before over writing wc_errors */ <nl> WOLFSSL_MSG (" ERROR in adding new node to logging queue !!\ n "); <nl> + /* In the event both wc_last_node and wc_errors are NULL , err <nl> + * goes unassigned to external wc_errors , wc_last_node . Free <nl> + * err in this instance since wc_ClearErrorNodes will not <nl> + */ <nl> + XFREE ( err , wc_error_heap , DYNAMIC_TYPE_LOG ); <nl> } <nl> else { <nl> wc_errors = err ;
mmm src / ssl . c <nl> ppp src / ssl . c <nl> void wolfSSL_X509_STORE_CTX_set_time ( WOLFSSL_X509_STORE_CTX * ctx , <nl> { <nl> ( void ) flags ; <nl>  <nl> + if ( ctx == NULL ) <nl> + return ; <nl> + <nl> ctx -> param -> check_time = t ; <nl> ctx -> param -> flags |= WOLFSSL_USE_CHECK_TIME ; <nl> }
mmm src / internal . c <nl> ppp src / internal . c <nl> int DoSessionTicket ( WOLFSSL * ssl , <nl> # ifdef WOLFSSL_DTLS <nl> Hmac cookieHmac ; <nl> byte peerCookie [ MAX_COOKIE_LEN ]; <nl> - byte peerCookieSz ; <nl> + byte peerCookieSz = 0 ; <nl> byte cookieType ; <nl> byte cookieSz ; <nl> # endif /* WOLFSSL_DTLS */
mmm src / internal . c <nl> ppp src / internal . c <nl> static int BuildMessage ( CYASSL * ssl , byte * output , int outSz , <nl> ivSz = blockSz ; <nl> sz += ivSz ; <nl>  <nl> + if ( ivSz > ( word32 ) sizeof ( iv )) <nl> + return BUFFER_E ; <nl> + <nl> ret = RNG_GenerateBlock ( ssl -> rng , iv , ivSz ); <nl> if ( ret != 0 ) <nl> return ret ;
mmm src / ssl . c <nl> ppp src / ssl . c <nl> int AddCA ( WOLFSSL_CERT_MANAGER * cm , DerBuffer ** pDer , int type , int verify ) <nl> ret = MEMORY_ERROR ; <nl> else { <nl> signer -> keyOID = cert -> keyOID ; <nl> - signer -> publicKey = cert -> publicKey ; <nl> - signer -> pubKeySize = cert -> pubKeySize ; <nl> - signer -> nameLen = cert -> subjectCNLen ; <nl> - signer -> name = cert -> subjectCN ; <nl> + if ( cert -> pubKeyStored ) { <nl> + signer -> publicKey = cert -> publicKey ; <nl> + signer -> pubKeySize = cert -> pubKeySize ; <nl> + } <nl> + if ( cert -> subjectCNStored ) { <nl> + signer -> nameLen = cert -> subjectCNLen ; <nl> + signer -> name = cert -> subjectCN ; <nl> + } <nl> signer -> pathLength = cert -> pathLength ; <nl> signer -> pathLengthSet = cert -> pathLengthSet ; <nl> # ifndef IGNORE_NAME_CONSTRAINTS
mmm src / internal . c <nl> ppp src / internal . c <nl> void InitX509Name ( WOLFSSL_X509_NAME * name , int dynamicFlag ) <nl> # ifdef OPENSSL_EXTRA <nl> XMEMSET (& name -> fullName , 0 , sizeof ( DecodedName )); <nl> XMEMSET (& name -> cnEntry , 0 , sizeof ( WOLFSSL_X509_NAME_ENTRY )); <nl> + XMEMSET (& name -> extra , 0 , sizeof ( name -> extra )); <nl> name -> cnEntry . value = &( name -> cnEntry . data ); /* point to internal data */ <nl> name -> cnEntry . nid = ASN_COMMON_NAME ; <nl> name -> x509 = NULL ;
mmm src / internal . c <nl> ppp src / internal . c <nl> int SendCertificateRequest ( WOLFSSL * ssl ) <nl> /* write to output */ <nl> output [ i ++] = ( byte ) typeTotal ; /* # of types */ <nl> # ifdef HAVE_ECC <nl> - if ( ssl -> options . cipherSuite0 == ECC_BYTE && <nl> + if (( ssl -> options . cipherSuite0 == ECC_BYTE || <nl> + ssl -> options . cipherSuite0 == CHACHA_BYTE ) && <nl> ssl -> specs . sig_algo == ecc_dsa_sa_algo ) { <nl> output [ i ++] = ecdsa_sign ; <nl> } else
mmm wolfcrypt / src / integer . c <nl> ppp wolfcrypt / src / integer . c <nl> int mp_init ( mp_int * a ) <nl> { <nl> int i ; <nl>  <nl> + /* Safeguard against passing in a null pointer */ <nl> + if ( a == NULL ) <nl> + return MP_VAL ; <nl> + <nl> /* allocate memory required and clear it */ <nl> a -> dp = OPT_CAST ( mp_digit ) XMALLOC ( sizeof ( mp_digit ) * MP_PREC , 0 , <nl> DYNAMIC_TYPE_BIGINT ); <nl> mp_copy ( mp_int * a , mp_int * b ) <nl> { <nl> int res , n ; <nl>  <nl> + /* Safeguard against passing in a null pointer */ <nl> + if ( a == NULL || b == NULL ) <nl> + return MP_VAL ; <nl> + <nl> /* if dst == src do nothing */ <nl> if ( a == b ) { <nl> return MP_OKAY ;
mmm cyassl / ctaocrypt / settings . h <nl> ppp cyassl / ctaocrypt / settings . h <nl> # include " mutex . h " <nl> # endif <nl>  <nl> - # define XMALLOC ( s , h , type ) ( void *) _mem_alloc_system (( s )) <nl> - # define XFREE ( p , h , type ) _mem_free ( p ) <nl> + # define XMALLOC ( s , h , t ) ( void *) _mem_alloc_system (( s )) <nl> + # define XFREE ( p , h , t ) { void * xp = ( p ); if (( xp )) _mem_free (( xp ));} <nl> /* Note : MQX has no realloc , using fastmath above */ <nl> # endif <nl> 
mmm src / internal . c <nl> ppp src / internal . c <nl> int SetCipherList ( WOLFSSL_CTX * ctx , Suites * suites , const char * list ) <nl> } <nl> # endif /* WOLFSSL_DTLS */ <nl>  <nl> + if ( idx + 1 >= WOLFSSL_MAX_SUITE_SZ ) { <nl> + WOLFSSL_MSG (" WOLFSSL_MAX_SUITE_SZ set too low "); <nl> + return 0 ; /* suites buffer not large enough , error out */ <nl> + } <nl> + <nl> suites -> suites [ idx ++] = ( XSTRSTR ( name , " TLS13 ")) ? TLS13_BYTE <nl> : ( XSTRSTR ( name , " CHACHA ")) ? CHACHA_BYTE <nl> : ( XSTRSTR ( name , " QSH ")) ? QSH_BYTE
mmm examples / echoclient / echoclient . c <nl> ppp examples / echoclient / echoclient . c <nl> void echoclient_test ( void * args ) <nl> # if defined ( CYASSL_DTLS ) <nl> method = DTLSv1_client_method (); <nl> # elif ! defined ( NO_TLS ) <nl> - method = TLSv1_2_client_method (); <nl> + method = CyaSSLv23_client_method (); <nl> # else <nl> method = SSLv3_client_method (); <nl> # endif
mmm src / ssl . c <nl> ppp src / ssl . c <nl> long wolfSSL_set_options ( WOLFSSL * ssl , long op ) <nl> long wolfSSL_get_options ( const WOLFSSL * ssl ) <nl> { <nl> WOLFSSL_ENTER (" wolfSSL_get_options "); <nl> - if ( ssl == NULL ) return WOLFSSL_FAILURE ; <nl> + if ( ssl == NULL ) <nl> + return WOLFSSL_FAILURE ; <nl> return ssl -> options . mask ; <nl> } <nl>  <nl> long wolfSSL_clear_options ( WOLFSSL * ssl , long opt ) <nl> { <nl> WOLFSSL_ENTER (" SSL_clear_options "); <nl> + if ( ssl == NULL ) <nl> + return WOLFSSL_FAILURE ; <nl> ssl -> options . mask &= ~ opt ; <nl> return ssl -> options . mask ; <nl> }
mmm src / tls . c <nl> ppp src / tls . c <nl> int TLSX_ValidateEllipticCurves ( CYASSL * ssl , byte first , byte second ) { <nl> int sig = 0 ; /* valitade signature */ <nl> int key = 0 ; /* validate key */ <nl>  <nl> + ( void ) oid ; <nl> + ( void ) octets ; <nl> + <nl> if (! extension ) <nl> return 1 ; /* no suite restriction */ <nl> 
mmm src / tls . c <nl> ppp src / tls . c <nl> static int TLSX_SNI_Parse ( WOLFSSL * ssl , byte * input , word16 length , <nl> return BUFFER_ERROR ; <nl>  <nl> for ( size = 0 ; offset < length ; offset += size ) { <nl> - SNI * sni ; <nl> + SNI * sni = NULL ; <nl> byte type = input [ offset ++]; <nl>  <nl> if ( offset + OPAQUE16_LEN > length )
mmm src / internal . c <nl> ppp src / internal . c <nl> static int DoCertificate ( CYASSL * ssl , byte * input , word32 * inOutIdx , <nl> ret = KEYUSE_ENCIPHER_E ; <nl> } <nl> if (( ssl -> specs . sig_algo == rsa_sa_algo || <nl> - ssl -> specs . sig_algo == ecc_dsa_sa_algo ) && <nl> + ( ssl -> specs . sig_algo == ecc_dsa_sa_algo && <nl> + ! ssl -> specs . static_ecdh )) && <nl> ( dCert . extKeyUsage & KEYUSE_DIGITAL_SIG ) == 0 ) { <nl> CYASSL_MSG (" KeyUse Digital Sig not set "); <nl> ret = KEYUSE_SIGNATURE_E ;
mmm src / internal . c <nl> ppp src / internal . c <nl> static int DoHandShakeMsgType ( CYASSL * ssl , byte * input , word32 * inOutIdx , <nl> return OUT_OF_ORDER_E ; <nl> } <nl>  <nl> + if ( ssl -> options . side == CLIENT_END && ssl -> options . dtls == 0 && <nl> + ssl -> options . serverState == NULL_STATE && type != server_hello ) { <nl> + CYASSL_MSG (" First server message not server hello "); <nl> + return OUT_OF_ORDER_E ; <nl> + } <nl> + <nl> + if ( ssl -> options . side == SERVER_END && <nl> + ssl -> options . clientState == NULL_STATE && type != client_hello ) { <nl> + CYASSL_MSG (" First client message not client hello "); <nl> + return OUT_OF_ORDER_E ; <nl> + } <nl> + <nl> + <nl> switch ( type ) { <nl>  <nl> case hello_request :
mmm src / internal . c <nl> ppp src / internal . c <nl> int DoSessionTicket ( WOLFSSL * ssl , const byte * input , word32 * inOutIdx , <nl> { <nl> int i ; <nl>  <nl> - if ( suites == NULL ) { <nl> - WOLFSSL_MSG (" Suites pointer error "); <nl> + if ( suites == NULL || suites -> suiteSz == 0 ) { <nl> + WOLFSSL_MSG (" Suites pointer error or suiteSz 0 "); <nl> return SUITES_ERROR ; <nl> } <nl>  <nl> - for ( i = 0 ; i < suites -> suiteSz ; i += 2 ) { <nl> + for ( i = 0 ; i < suites -> suiteSz - 1 ; i += SUITE_LEN ) { <nl> if ( suites -> suites [ i ] == first && <nl> suites -> suites [ i + 1 ] == second ) <nl> return i ;
mmm wolfssl / error - ssl . h <nl> ppp wolfssl / error - ssl . h <nl> enum wolfSSL_ErrorCodes { <nl>  <nl> /* begin negotiation parameter errors */ <nl> UNSUPPORTED_SUITE = - 500 , /* unsupported cipher suite */ <nl> - MATCH_SUITE_ERROR = - 501 /* can ' t match cipher suite */ <nl> + MATCH_SUITE_ERROR = - 501 , /* can ' t match cipher suite */ <nl> + COMPRESSION_ERROR = - 502 /* compression mismatch */ <nl> /* end negotiation parameter errors only 10 for now */ <nl> /* add strings to wolfSSL_ERR_reason_error_string in internal . c !!!!! */ <nl> mmm src / internal . c <nl> ppp src / internal . c <nl> enum wolfSSL_ErrorCodes { <nl>  <nl> /* begin negotiation parameter errors */ <nl> UNSUPPORTED_SUITE = - 500 , /* unsupported cipher suite */ <nl> - MATCH_SUITE_ERROR = - 501 /* can ' t match cipher suite */ <nl> + MATCH_SUITE_ERROR = - 501 , /* can ' t match cipher suite */ <nl> + COMPRESSION_ERROR = - 502 /* compression mismatch */ <nl> /* end negotiation parameter errors only 10 for now */ <nl> /* add strings to wolfSSL_ERR_reason_error_string in internal . c !!!!! */ <nl>  <nl> const char * wolfSSL_ERR_reason_error_string ( unsigned long e ) <nl> case MATCH_SUITE_ERROR : <nl> return " can ' t match cipher suite "; <nl>  <nl> + case COMPRESSION_ERROR : <nl> + return " compression mismatch error "; <nl> + <nl> case BUILD_MSG_ERROR : <nl> return " build message failure "; <nl>  <nl> static void PickHashSigAlgo ( WOLFSSL * ssl , <nl> ssl -> options . cipherSuite = cs1 ; <nl> compression = input [ i ++]; <nl>  <nl> + if ( compression != NO_COMPRESSION && ! ssl -> options . usingCompression ) { <nl> + WOLFSSL_MSG (" Server forcing compression w / o support "); <nl> + return COMPRESSION_ERROR ; <nl> + } <nl> + <nl> if ( compression != ZLIB_COMPRESSION && ssl -> options . usingCompression ) { <nl> WOLFSSL_MSG (" Server refused compression , turning off "); <nl> ssl -> options . usingCompression = 0 ; /* turn off if server refused */
mmm src / ssl . c <nl> ppp src / ssl . c <nl> int wolfSSL_EVP_MD_type ( const WOLFSSL_EVP_MD * md ) <nl> return WOLFSSL_FAILURE ; <nl> # endif <nl> } <nl> - <nl> +# ifdef SESSION_CERTS <nl> + ssl -> session . chain . count = 0 ; <nl> +# endif <nl> # ifdef KEEP_PEER_CERT <nl> FreeX509 (& ssl -> peerCert ); <nl> InitX509 (& ssl -> peerCert , 0 , ssl -> heap );
mmm wolfcrypt / benchmark / benchmark . c <nl> ppp wolfcrypt / benchmark / benchmark . c <nl> void bench_chacha ( void ) <nl> void bench_chacha20_poly1305_aead ( void ) <nl> { <nl> double start ; <nl> - int ret , i , count ; <nl> + int ret = 0 , i , count ; <nl>  <nl> byte authTag [ CHACHA20_POLY1305_AEAD_AUTHTAG_SIZE ]; <nl> XMEMSET ( authTag , 0 , sizeof ( authTag ));
mmm wolfcrypt / src / asn . c <nl> ppp wolfcrypt / src / asn . c <nl> static int DecodePolicyOID ( char * out , word32 outSz , byte * in , word32 inSz ) <nl> # endif <nl> } <nl> idx += policy_length ; <nl> - } while (( int ) idx < total_length && cert -> extCertPoliciesNb < MAX_CERTPOL_NB ); <nl> + } while (( int ) idx < total_length <nl> + # if defined ( WOLFSSL_CERT_EXT ) <nl> + && cert -> extCertPoliciesNb < MAX_CERTPOL_NB <nl> + # endif <nl> + ); <nl>  <nl> WOLFSSL_LEAVE (" DecodeCertPolicy ", 0 ); <nl> return 0 ;
mmm src / sniffer . c <nl> ppp src / sniffer . c <nl> static int ProcessServerHello ( const byte * input , int * sslBytes , <nl> XMEMCPY ( session -> sslServer -> arrays . sessionID , input , ID_LEN ); <nl> input += b ; <nl> * sslBytes -= b ; <nl> + if ( b ) <nl> + session -> sslServer -> options . haveSessionId = 1 ; <nl>  <nl> ( void )* input ++; /* eat first byte , always 0 */ <nl> b = * input ++; <nl> static int ProcessServerHello ( const byte * input , int * sslBytes , <nl> session -> sslClient -> options . cipherSuite = b ; <nl> * sslBytes -= SUITE_LEN ; <nl>  <nl> - if ( XMEMCMP ( session -> sslServer -> arrays . sessionID , <nl> - session -> sslClient -> arrays . sessionID , ID_LEN ) == 0 ) { <nl> + if ( session -> sslServer -> options . haveSessionId && <nl> + XMEMCMP ( session -> sslServer -> arrays . sessionID , <nl> + session -> sslClient -> arrays . sessionID , ID_LEN ) == 0 ) { <nl> /* resuming */ <nl> SSL_SESSION * resume = GetSession ( session -> sslServer , <nl> session -> sslServer -> arrays . masterSecret ); <nl> static int DoHandShake ( const byte * input , int * sslBytes , <nl> ret = DoFinished ( ssl , input , & inOutIdx , SNIFF ); <nl>  <nl> if ( ret == 0 && session -> flags . cached == 0 ) { <nl> + session -> sslServer -> options . haveSessionId = 1 ; <nl> AddSession ( session -> sslServer ); <nl> session -> flags . cached = 1 ; <nl> }
mmm src / internal . c <nl> ppp src / internal . c <nl> int SetCipherList ( Suites * s , const char * list ) <nl> byte b ; <nl> byte compression ; <nl> ProtocolVersion pv ; <nl> - word16 extSz ; <nl> word32 i = * inOutIdx ; <nl> word32 begin = i ; <nl> 
mmm ctaocrypt / src / asn . c <nl> ppp ctaocrypt / src / asn . c <nl> static int SetMyVersion ( word32 version , byte * output , int header ) <nl> } <nl>  <nl>  <nl> +/* convert der buffer to pem into output , can ' t do inplace , der and output <nl> + need to be different */ <nl> int DerToPem ( const byte * der , word32 derSz , byte * output , word32 outSz , <nl> int type ) <nl> { <nl> int DerToPem ( const byte * der , word32 derSz , byte * output , word32 outSz , <nl> int err ; <nl> int outLen ; /* return length or error */ <nl>  <nl> + if ( der == output ) /* no in place conversion */ <nl> + return BAD_FUNC_ARG ; <nl> + <nl> if ( type == CERT_TYPE ) { <nl> XSTRNCPY ( header , "----- BEGIN CERTIFICATE -----\ n ", sizeof ( header )); <nl> XSTRNCPY ( footer , "----- END CERTIFICATE -----\ n ", sizeof ( footer ));
mmm wolfcrypt / user - crypto / include / user_rsa . h <nl> ppp wolfcrypt / user - crypto / include / user_rsa . h <nl> WOLFSSL_API int wc_RsaPublicKeyDecodeRaw ( const byte * n , word32 nSz , <nl> # endif <nl> WOLFSSL_API int wc_RsaFlattenPublicKey ( RsaKey *, byte *, word32 *, byte *, <nl> word32 *); <nl> + WOLFSSL_API int wc_RsaSetRNG ( RsaKey * key , WC_RNG * rng ); <nl>  <nl>  <nl> # if defined ( WOLFSSL_CERT_GEN ) || defined ( WOLFSSL_KEY_GEN )mmm wolfcrypt / user - crypto / src / rsa . c <nl> ppp wolfcrypt / user - crypto / src / rsa . c <nl> WOLFSSL_API int wc_RsaPublicKeyDecodeRaw ( const byte * n , word32 nSz , <nl> # endif <nl> WOLFSSL_API int wc_RsaFlattenPublicKey ( RsaKey *, byte *, word32 *, byte *, <nl> word32 *); <nl> + WOLFSSL_API int wc_RsaSetRNG ( RsaKey * key , WC_RNG * rng ); <nl>  <nl>  <nl> # if defined ( WOLFSSL_CERT_GEN ) || defined ( WOLFSSL_KEY_GEN ) <nl> int wc_RsaKeyToPublicDer ( RsaKey * key , byte * output , word32 inLen ) <nl>  <nl> # endif /* WOLFSSL_KEY_GEN */ <nl>  <nl> +# ifdef WC_RSA_BLINDING <nl> + <nl> + int wc_RsaSetRNG ( RsaKey * key , WC_RNG * rng ) <nl> +{ <nl> + if ( key == NULL ) <nl> + return BAD_FUNC_ARG ; <nl> + <nl> + ( void ) rng ; <nl> + <nl> + return 0 ; <nl> +} <nl> + <nl> +# endif /* WC_RSA_BLINDING */ <nl> + <nl> # endif /* NO_RSA */ <nl> 
mmm src / ssl . c <nl> ppp src / ssl . c <nl> int wolfSSL_BN_hex2bn ( WOLFSSL_BIGNUM ** bn , const char * str ) <nl> # else <nl> byte decoded [ 1024 ]; <nl> # endif <nl> + int weOwn = 0 ; <nl>  <nl> WOLFSSL_MSG (" wolfSSL_BN_hex2bn "); <nl>  <nl> int wolfSSL_BN_hex2bn ( WOLFSSL_BIGNUM ** bn , const char * str ) <nl> else if ( bn == NULL ) <nl> ret = decSz ; <nl> else { <nl> - if (* bn == NULL ) <nl> + if (* bn == NULL ) { <nl> * bn = wolfSSL_BN_new (); <nl> + if (* bn != NULL ) { <nl> + weOwn = 1 ; <nl> + } <nl> + } <nl>  <nl> if (* bn == NULL ) <nl> WOLFSSL_MSG (" BN new failed "); <nl> else if ( wolfSSL_BN_bin2bn ( decoded , decSz , * bn ) == NULL ) { <nl> WOLFSSL_MSG (" Bad bin2bn error "); <nl> - wolfSSL_BN_free (* bn ); /* Free new BN */ <nl> + if ( weOwn == 1 ) { <nl> + wolfSSL_BN_free (* bn ); /* Free new BN */ <nl> + } <nl> } <nl> else <nl> ret = WOLFSSL_SUCCESS ;
mmm wolfcrypt / src / rsa . c <nl> ppp wolfcrypt / src / rsa . c <nl> static int mp_rand ( mp_int * a , int digits , WC_RNG * rng ) <nl> int ret ; <nl> mp_digit d ; <nl>  <nl> - if ( a == NULL || rng == NULL ) <nl> + if ( rng == NULL ) <nl> + return MISSING_RNG_E ; <nl> + <nl> + if ( a == NULL ) <nl> return BAD_FUNC_ARG ; <nl>  <nl> mp_zero ( a );mmm wolfssl / wolfcrypt / error - crypt . h <nl> ppp wolfssl / wolfcrypt / error - crypt . h <nl> static int mp_rand ( mp_int * a , int digits , WC_RNG * rng ) <nl> int ret ; <nl> mp_digit d ; <nl>  <nl> - if ( a == NULL || rng == NULL ) <nl> + if ( rng == NULL ) <nl> + return MISSING_RNG_E ; <nl> + <nl> + if ( a == NULL ) <nl> return BAD_FUNC_ARG ; <nl>  <nl> mp_zero ( a ); <nl> enum { <nl>  <nl> WC_KEY_SIZE_E = - 234 , /* Key size error , either too small or large */ <nl> ASN_COUNTRY_SIZE_E = - 235 , /* ASN Cert Gen , invalid country code size */ <nl> + MISSING_RNG_E = - 236 , /* RNG required but not provided */ <nl>  <nl> MIN_CODE_E = - 300 /* errors - 101 - - 299 */ <nl> mmm wolfcrypt / src / error . c <nl> ppp wolfcrypt / src / error . c <nl> static int mp_rand ( mp_int * a , int digits , WC_RNG * rng ) <nl> int ret ; <nl> mp_digit d ; <nl>  <nl> - if ( a == NULL || rng == NULL ) <nl> + if ( rng == NULL ) <nl> + return MISSING_RNG_E ; <nl> + <nl> + if ( a == NULL ) <nl> return BAD_FUNC_ARG ; <nl>  <nl> mp_zero ( a ); <nl> enum { <nl>  <nl> WC_KEY_SIZE_E = - 234 , /* Key size error , either too small or large */ <nl> ASN_COUNTRY_SIZE_E = - 235 , /* ASN Cert Gen , invalid country code size */ <nl> + MISSING_RNG_E = - 236 , /* RNG required but not provided */ <nl>  <nl> MIN_CODE_E = - 300 /* errors - 101 - - 299 */ <nl>  <nl> const char * wc_GetErrorString ( int error ) <nl> case ASN_COUNTRY_SIZE_E : <nl> return " Country code size error , either too small or large "; <nl>  <nl> + case MISSING_RNG_E : <nl> + return " RNG required but not provided "; <nl> + <nl> default : <nl> return " unknown error number "; <nl> 
mmm wolfssl / wolfcrypt / asn . h <nl> ppp wolfssl / wolfcrypt / asn . h <nl> enum VerifyType { <nl> VERIFY_OCSP = 3 , <nl> VERIFY_NAME = 4 , <nl> VERIFY_SKIP_DATE = 5 , <nl> + VERIFY_OCSP_CERT = 6 , <nl> }; <nl>  <nl> # ifdef WOLFSSL_CERT_EXTmmm wolfcrypt / src / asn . c <nl> ppp wolfcrypt / src / asn . c <nl> enum VerifyType { <nl> VERIFY_OCSP = 3 , <nl> VERIFY_NAME = 4 , <nl> VERIFY_SKIP_DATE = 5 , <nl> + VERIFY_OCSP_CERT = 6 , <nl> }; <nl>  <nl> # ifdef WOLFSSL_CERT_EXT <nl> int ParseCertRelative ( DecodedCert * cert , int type , int verify , void * cm ) <nl> } <nl>  <nl> # ifdef HAVE_OCSP <nl> - /* trust for the lifetime of the responder ' s cert */ <nl> - if ( cert -> ocspNoCheckSet && verify == VERIFY_OCSP ) <nl> - verify = NO_VERIFY ; <nl> + if ( verify == VERIFY_OCSP_CERT ) { <nl> + /* trust for the lifetime of the responder ' s cert */ <nl> + if ( cert -> ocspNoCheckSet ) <nl> + verify = VERIFY ; <nl> + else <nl> + verify = VERIFY_OCSP ; <nl> + } <nl> # endif <nl> /* advance past extensions */ <nl> cert -> srcIdx = cert -> sigIndex ; <nl> static int DecodeBasicOcspResponse ( byte * source , word32 * ioIndex , <nl>  <nl> /* Don ' t verify if we don ' t have access to Cert Manager . */ <nl> ret = ParseCertRelative (& cert , CERT_TYPE , <nl> - noVerify ? NO_VERIFY : VERIFY_OCSP , cm ); <nl> + noVerify ? NO_VERIFY : VERIFY_OCSP_CERT , cm ); <nl> if ( ret < 0 ) { <nl> WOLFSSL_MSG ("\ tOCSP Responder certificate parsing failed "); <nl> FreeDecodedCert (& cert );
mmm src / tls13 . c <nl> ppp src / tls13 . c <nl> int SendTls13CertificateVerify ( WOLFSSL * ssl ) <nl> /* Add signature algorithm . */ <nl> if ( ssl -> hsType == DYNAMIC_TYPE_RSA ) { <nl> # ifdef WC_RSA_PSS <nl> - if ( ssl -> pssAlgo | ( 1 << ssl -> suites -> hashAlgo )) <nl> + if ( ssl -> pssAlgo & ( 1 << ssl -> suites -> hashAlgo )) <nl> args -> sigAlgo = rsa_pss_sa_algo ; <nl> else <nl> # endifmmm src / internal . c <nl> ppp src / internal . c <nl> int SendTls13CertificateVerify ( WOLFSSL * ssl ) <nl> /* Add signature algorithm . */ <nl> if ( ssl -> hsType == DYNAMIC_TYPE_RSA ) { <nl> # ifdef WC_RSA_PSS <nl> - if ( ssl -> pssAlgo | ( 1 << ssl -> suites -> hashAlgo )) <nl> + if ( ssl -> pssAlgo & ( 1 << ssl -> suites -> hashAlgo )) <nl> args -> sigAlgo = rsa_pss_sa_algo ; <nl> else <nl> # endif <nl> void PickHashSigAlgo ( WOLFSSL * ssl , const byte * hashSigAlgo , <nl>  <nl> PickHashSigAlgo ( ssl , input + * inOutIdx , len ); <nl> * inOutIdx += len ; <nl> + # ifdef WC_RSA_PSS <nl> + ssl -> pssAlgo = 0 ; <nl> + if ( ssl -> suites -> sigAlgo == rsa_pss_sa_algo ) <nl> + ssl -> pssAlgo |= 1 << ssl -> suites -> hashAlgo ; <nl> + # endif <nl> } <nl>  <nl> /* authorities */ <nl> int SendCertificateVerify ( WOLFSSL * ssl ) <nl> if ( ssl -> hsType == DYNAMIC_TYPE_RSA ) { <nl> # ifdef WC_RSA_PSS <nl> if ( IsAtLeastTLSv1_2 ( ssl ) && <nl> - ( ssl -> pssAlgo | ( 1 << ssl -> suites -> hashAlgo ))) { <nl> + ( ssl -> pssAlgo & ( 1 << ssl -> suites -> hashAlgo ))) { <nl> args -> sigAlgo = rsa_pss_sa_algo ; <nl> } <nl> else
mmm xbmc / cores / paplayer / VideoPlayerCodec . cpp <nl> ppp xbmc / cores / paplayer / VideoPlayerCodec . cpp <nl> bool VideoPlayerCodec :: Init ( const CFileItem & file , unsigned int filecache ) <nl> // we have to decode initial data in order to get channels / samplerate <nl> // for sanity - we read no more than 10 packets <nl> int nErrors = 0 ; <nl> - for ( int nPacket = 0 ; nPacket < 10 && ( m_channels == 0 || m_format . m_sampleRate == 0 ); nPacket ++) <nl> + for ( int nPacket = 0 ; <nl> + nPacket < 10 && ( m_channels == 0 || m_format . m_sampleRate == 0 || m_format . m_frameSize == 0 ); <nl> + nPacket ++) <nl> { <nl> uint8_t dummy [ 256 ]; <nl> size_t nSize = 256 ; <nl> bool VideoPlayerCodec :: Init ( const CFileItem & file , unsigned int filecache ) <nl> if ( NeedConvert ( m_srcFormat . m_dataFormat )) <nl> { <nl> m_needConvert = true ; <nl> + // if we don ' t know the framesize yet , we will fail when converting <nl> + if ( m_srcFormat . m_frameSize == 0 ) <nl> + return false ; <nl> + <nl> m_pResampler = ActiveAE :: CAEResampleFactory :: Create (); <nl>  <nl> SampleConfig dstConfig , srcConfig ;
mmm thunar / thunar - transfer - job . c <nl> ppp thunar / thunar - transfer - job . c <nl> thunar_transfer_job_copy_node ( ThunarTransferJob * job , <nl> } <nl>  <nl> /* update progress information */ <nl> - exo_job_info_message ( EXO_JOB ( job ), g_file_info_get_display_name ( info )); <nl> + exo_job_info_message ( EXO_JOB ( job ), "% s ", g_file_info_get_display_name ( info )); <nl>  <nl> retry_copy : <nl> /* copy the item specified by this node ( not recursively ) */
mmm src / opusfile . c <nl> ppp src / opusfile . c <nl> static int op_get_data ( OggOpusFile * _of , int _nbytes ){ <nl> int nbytes ; <nl> OP_ASSERT ( _nbytes > 0 ); <nl> buffer =( unsigned char *) ogg_sync_buffer (& _of -> oy , _nbytes ); <nl> + if ( OP_UNLIKELY ( buffer == NULL )) return OP_EFAULT ; <nl> nbytes =( int )(* _of -> callbacks . read )( _of -> stream , buffer , _nbytes ); <nl> OP_ASSERT ( nbytes <= _nbytes ); <nl> if ( OP_LIKELY ( nbytes > 0 )) ogg_sync_wrote (& _of -> oy , nbytes ); <nl> static int op_open1 ( OggOpusFile * _of , <nl> if ( _initial_bytes > 0 ){ <nl> char * buffer ; <nl> buffer = ogg_sync_buffer (& _of -> oy ,( long ) _initial_bytes ); <nl> + if ( OP_UNLIKELY ( buffer == NULL )) return OP_EFAULT ; <nl> memcpy ( buffer , _initial_data , _initial_bytes * sizeof (* buffer )); <nl> ogg_sync_wrote (& _of -> oy ,( long ) _initial_bytes ); <nl> }
mmm src / maprules . c <nl> ppp src / maprules . c <nl> XkbRF_SubstituteVars ( char * name , XkbRF_MultiDefsPtr mdefs ) <nl> int len , ndx ; <nl>  <nl> orig = name ; <nl> - str = index ( name ,'%'); <nl> + str = strchr ( name ,'%'); <nl> if ( str == NULL ) <nl> return name ; <nl> len = strlen ( name ); <nl> XkbRF_SubstituteVars ( char * name , XkbRF_MultiDefsPtr mdefs ) <nl> var = str + 1 ; <nl> str = get_index ( var + 1 , & ndx ); <nl> if ( ndx == - 1 ) { <nl> - str = index ( str ,'%'); <nl> + str = strchr ( str ,'%'); <nl> continue ; <nl> } <nl> if ((* var ==' l ') && mdefs -> layout [ ndx ] && * mdefs -> layout [ ndx ]) <nl> XkbRF_SubstituteVars ( char * name , XkbRF_MultiDefsPtr mdefs ) <nl> if (( pfx =='(')&&(* str ==')')) { <nl> str ++; <nl> } <nl> - str = index (& str [ 0 ],'%'); <nl> + str = strchr (& str [ 0 ],'%'); <nl> } <nl> name = ( char *) malloc ( len + 1 ); <nl> str = orig ;
mmm src / xkbcomp / expr . c <nl> ppp src / xkbcomp / expr . c <nl> ExprResolveBoolean ( struct xkb_context * ctx , const ExprDef * expr , <nl>  <nl> case EXPR_INVERT : <nl> case EXPR_NOT : <nl> - ok = ExprResolveBoolean ( ctx , expr , set_rtrn ); <nl> + ok = ExprResolveBoolean ( ctx , expr -> unary . child , set_rtrn ); <nl> if ( ok ) <nl> * set_rtrn = !* set_rtrn ; <nl> return ok ;
mmm src / xkbcomp / expr . c <nl> ppp src / xkbcomp / expr . c <nl> ExprResolveLhs ( struct xkb_context * ctx , const ExprDef * expr , <nl> * elem_rtrn = NULL ; <nl> * field_rtrn = xkb_atom_text ( ctx , expr -> ident . ident ); <nl> * index_rtrn = NULL ; <nl> - return true ; <nl> + return (* field_rtrn != NULL ); <nl> case EXPR_FIELD_REF : <nl> * elem_rtrn = xkb_atom_text ( ctx , expr -> field_ref . element ); <nl> * field_rtrn = xkb_atom_text ( ctx , expr -> field_ref . field );
mmm src / xkbcomp / expr . c <nl> ppp src / xkbcomp / expr . c <nl> LookupModMask ( struct xkb_context * ctx , const void * priv , xkb_atom_t field , <nl> return false ; <nl>  <nl> str = xkb_atom_text ( ctx , field ); <nl> + if (! str ) <nl> + return false ; <nl>  <nl> if ( istreq ( str , " all ")) { <nl> * val_rtrn = MOD_REAL_MASK_ALL ;
mmm src / utils . c <nl> ppp src / utils . c <nl> bool <nl> map_file ( FILE * file , char ** string_out , size_t * size_out ) <nl> { <nl> struct stat stat_buf ; <nl> - const int fd = fileno ( file ); <nl> + int fd ; <nl> char * string ; <nl>  <nl> /* Make sure to keep the errno on failure ! */ <nl> + fd = fileno ( file ); <nl> + if ( fd < 0 ) <nl> + return false ; <nl>  <nl> if ( fstat ( fd , & stat_buf ) != 0 ) <nl> return false ;
mmm src / compose / parser . c <nl> ppp src / compose / parser . c <nl> skip_more_whitespace_and_comments : <nl>  <nl> /* LHS Keysym . */ <nl> if ( chr ( s , '<')) { <nl> - while ( peek ( s ) != '>' && ! eol ( s )) <nl> + while ( peek ( s ) != '>' && ! eol ( s ) && ! eof ( s )) <nl> buf_append ( s , next ( s )); <nl> if (! chr ( s , '>')) { <nl> scanner_err ( s , " unterminated keysym literal ");
mmm src / xkbcomp / keymap . c <nl> ppp src / xkbcomp / keymap . c <nl> CompileKeymap ( XkbFile * file , struct xkb_keymap * keymap , enum merge_mode merge ) <nl> file = ( XkbFile *) file -> common . next ) { <nl> if ( file -> file_type < FIRST_KEYMAP_FILE_TYPE || <nl> file -> file_type > LAST_KEYMAP_FILE_TYPE ) { <nl> - log_err ( ctx , " Cannot define % s in a keymap file \ n ", <nl> - xkb_file_type_to_string ( file -> file_type )); <nl> + if ( file -> file_type == FILE_TYPE_GEOMETRY ) { <nl> + log_vrb ( ctx , 1 , <nl> + " Geometry sections are not supported ; ignoring \ n "); <nl> + } else { <nl> + log_err ( ctx , " Cannot define % s in a keymap file \ n ", <nl> + xkb_file_type_to_string ( file -> file_type )); <nl> + } <nl> continue ; <nl> } <nl> 
mmm src / xkbcomp / compat . c <nl> ppp src / xkbcomp / compat . c <nl> ResolveStateAndPredicate ( ExprDef * expr , enum xkb_match_operation * pred_rtrn , <nl> * pred_rtrn = MATCH_EXACTLY ; <nl> if ( expr -> expr . op == EXPR_ACTION_DECL ) { <nl> const char * pred_txt = xkb_atom_text ( info -> ctx , expr -> action . name ); <nl> - if (! LookupString ( symInterpretMatchMaskNames , pred_txt , pred_rtrn )) { <nl> + if (! LookupString ( symInterpretMatchMaskNames , pred_txt , pred_rtrn ) || <nl> + ! expr -> action . args ) { <nl> log_err ( info -> ctx , <nl> " Illegal modifier predicate \"% s \"; Ignored \ n ", pred_txt ); <nl> return false ;
mmm src / xkbcomp / keycodes . c <nl> ppp src / xkbcomp / keycodes . c <nl> CopyKeyAliasesToKeymap ( struct xkb_keymap * keymap , KeyNamesInfo * info ) <nl> key_aliases = calloc ( num_key_aliases , sizeof (* key_aliases )); <nl> if (! key_aliases ) <nl> return false ; <nl> - } <nl>  <nl> - i = 0 ; <nl> - darray_foreach ( alias , info -> aliases ) { <nl> - if ( alias -> real != XKB_ATOM_NONE ) { <nl> - key_aliases [ i ]. alias = alias -> alias ; <nl> - key_aliases [ i ]. real = alias -> real ; <nl> - i ++; <nl> + i = 0 ; <nl> + darray_foreach ( alias , info -> aliases ) { <nl> + if ( alias -> real != XKB_ATOM_NONE ) { <nl> + key_aliases [ i ]. alias = alias -> alias ; <nl> + key_aliases [ i ]. real = alias -> real ; <nl> + i ++; <nl> + } <nl> } <nl> } <nl> 
mmm src / xkbcomp / expr . c <nl> ppp src / xkbcomp / expr . c <nl> ExprResolveLhs ( struct xkb_context * ctx , const ExprDef * expr , <nl> * elem_rtrn = xkb_atom_text ( ctx , expr -> field_ref . element ); <nl> * field_rtrn = xkb_atom_text ( ctx , expr -> field_ref . field ); <nl> * index_rtrn = NULL ; <nl> - return true ; <nl> + return (* elem_rtrn != NULL && * field_rtrn != NULL ); <nl> case EXPR_ARRAY_REF : <nl> * elem_rtrn = xkb_atom_text ( ctx , expr -> array_ref . element ); <nl> * field_rtrn = xkb_atom_text ( ctx , expr -> array_ref . field ); <nl> * index_rtrn = expr -> array_ref . entry ; <nl> + if ( expr -> array_ref . element != XKB_ATOM_NONE && * elem_rtrn == NULL ) <nl> + return false ; <nl> + if (* field_rtrn == NULL ) <nl> + return false ; <nl> return true ; <nl> default : <nl> break ;
mmm src / xkbcomp / ast - build . c <nl> ppp src / xkbcomp / ast - build . c <nl> ExprAppendMultiKeysymList ( ExprDef * expr , ExprDef * append ) <nl> darray_append ( expr -> keysym_list . symsNumEntries , numEntries ); <nl> darray_concat ( expr -> keysym_list . syms , append -> keysym_list . syms ); <nl>  <nl> - FreeStmt (( ParseCommon *) & append ); <nl> + FreeStmt (( ParseCommon *) append ); <nl>  <nl> return expr ; <nl> }
mmm src / x11 / keymap . c <nl> ppp src / x11 / keymap . c <nl> get_controls ( struct xkb_keymap * keymap , xcb_connection_t * conn , <nl> xcb_xkb_get_controls_reply ( conn , cookie , NULL ); <nl>  <nl> FAIL_IF_BAD_REPLY ( reply , " XkbGetControls "); <nl> + FAIL_UNLESS ( reply -> numGroups > 0 && reply -> numGroups <= 4 ); <nl>  <nl> keymap -> enabled_ctrls = translate_controls_mask ( reply -> enabledControls ); <nl> keymap -> num_groups = reply -> numGroups ;
mmm src / xkbcomp / compat . c <nl> ppp src / xkbcomp / compat . c <nl> typedef struct _GroupCompatInfo <nl> { <nl> unsigned char fileID ; <nl> unsigned char merge ; <nl> + Bool defined ; <nl> unsigned char real_mods ; <nl> xkb_atom_t vmods ; <nl> } GroupCompatInfo ; <nl> AddGroupCompat ( CompatInfo * info , unsigned group , GroupCompatInfo * newGC ) <nl> ACTION (" Using % s definition \ n ", <nl> ( merge == MergeAugment ? " old " : " new ")); <nl> } <nl> - if ( merge != MergeAugment ) <nl> + if ( newGC -> defined && ( merge != MergeAugment || ! gc -> defined )) <nl> * gc = * newGC ; <nl> return True ; <nl> } <nl> HandleGroupCompatDef ( GroupCompatDef * def , <nl> } <nl> tmp . real_mods = val . uval & 0xff ; <nl> tmp . vmods = ( val . uval >> 8 ) & 0xffff ; <nl> + tmp . defined = True ; <nl> return AddGroupCompat ( info , def -> group - 1 , & tmp ); <nl> } <nl> 
mmm src / Xrd / XrdConfig . cc <nl> ppp src / Xrd / XrdConfig . cc <nl> int XrdConfig :: Configure ( int argc , char ** argv ) <nl> if (* dfltProt != '.' ) <nl> { char * p = dfltProt ; <nl> while (* p && * p != '.') p ++; <nl> - if (* p == '.') {* p = '\ 0 '; dfltProt = strdup ( dfltProt ); * p = ',';} <nl> + if (* p == '.') {* p = '\ 0 '; dfltProt = strdup ( dfltProt ); * p = '.';} <nl> } <nl>  <nl> // Process the options
mmm src / XrdCl / XrdClPlugInManager . cc <nl> ppp src / XrdCl / XrdClPlugInManager . cc <nl> namespace XrdCl <nl>  <nl> XrdSysPwd pwdHandler ; <nl> passwd * pwd = pwdHandler . Get ( getuid () ); <nl> + if ( ! pwd ) return ; <nl> std :: string userPlugIns = pwd -> pw_dir ; <nl> userPlugIns += "/. xrootd / client . plugins . d "; <nl> ProcessConfigDir ( userPlugIns );
mmm src / XrdOdc / XrdOdcFinder . cc <nl> ppp src / XrdOdc / XrdOdcFinder . cc <nl> int XrdOdcFinderRMT :: Locate ( XrdOucErrInfo & Resp , const char * path , int flags , <nl> { xmsg [ 1 ]. iov_base = ( char *)" select " ; xmsg [ 1 ]. iov_len = 7 ;} <nl> xmsg [ 2 ]. iov_base = ( char *) ptype ; xmsg [ 2 ]. iov_len = 2 ; <nl> if ( Avoid ) <nl> - { xmsg [ 3 ]. iov_base = ( char *)" -"; xmsg [ 3 ]. iov_len = 2 ; <nl> + { xmsg [ 3 ]. iov_base = ( char *)"-"; xmsg [ 3 ]. iov_len = 1 ; <nl> xmsg [ 4 ]. iov_base = Avoid ; xmsg [ 4 ]. iov_len = strlen ( Avoid ); <nl> xmsg [ 5 ]. iov_base = ( char *)" "; xmsg [ 5 ]. iov_len = 1 ; <nl> ioveol = 6 ;
mmm src / XrdCl / XrdClXRootDMsgHandler . cc <nl> ppp src / XrdCl / XrdClXRootDMsgHandler . cc <nl> namespace XrdCl <nl> XRDCL_SMART_PTR_T < Message > msgPtr ( pResponse ); <nl> pResponse = 0 ; <nl>  <nl> - if ( rsp -> hdr . dlen < 4 ) <nl> + if ( rsp -> hdr . dlen <= 4 ) <nl> { <nl> log -> Error ( XRootDMsg , "[% s ] Got invalid redirect response .", <nl> pUrl . GetHostId (). c_str () );
mmm src / XrdClient / XrdClientUrlSet . cc <nl> ppp src / XrdClient / XrdClientUrlSet . cc <nl> void XrdClientUrlSet :: ConvertDNSAlias ( UrlArray & urls , XrdClientString proto , <nl> // Notify <nl> Info ( XrdClientDebug :: kHIDEBUG , " ConvertDNSAlias ", <nl> " found host " << newurl -> Host << " with addr " << newurl -> HostAddr ); <nl> + <nl> + // Get a copy , if we need to store another <nl> + if ( i < ( naddr - 1 )) <nl> + newurl = new XrdClientUrlInfo (* newurl ); <nl> + <nl> } <nl> }
mmm src / XrdSut / XrdSutAux . cc <nl> ppp src / XrdSut / XrdSutAux . cc <nl> int XrdSutGetPass ( const char * prompt , XrdOucString & passwd ) <nl>  <nl> char * pw = getpass ( prompt ); <nl> if ( pw ) { <nl> - if ( pw [ strlen ( pw )- 1 ] == '\ n ') <nl> - pw [ strlen ( pw ) - 1 ] = 0 ; // get rid of \ n <nl> + // Get rid of special chars , if any <nl> + int k = 0 , i = 0 , len = strlen ( pw ); <nl> + for (; i < len ; i ++) <nl> + if ( pw [ i ] > 0x20 ) pw [ k ++] = pw [ i ]; <nl> + pw [ k ] = 0 ; <nl> passwd = pw ; <nl> - XrdSutMemSet (( volatile void *) pw , 0 , strlen ( pw )); <nl> + XrdSutMemSet (( volatile void *) pw , 0 , len ); <nl> } else { <nl> DEBUG (" error from getpass "); <nl> return - 1 ;
mmm src / XrdHttp / XrdHttpReq . cc <nl> ppp src / XrdHttp / XrdHttpReq . cc <nl> int XrdHttpReq :: ProcessHTTPReq () { <nl> } else { <nl>  <nl> // We lookup the requested path in a hash containing the preread files <nl> - XrdHttpProtocol :: StaticPreloadInfo * mydata = prot -> staticpreload -> Find ( resource . c_str ()); <nl> - if ( mydata ) { <nl> + if ( prot -> staticpreload ) { <nl> + XrdHttpProtocol :: StaticPreloadInfo * mydata = prot -> staticpreload -> Find ( resource . c_str ()); <nl> + if ( mydata ) { <nl> prot -> SendSimpleResp ( 200 , NULL , NULL , ( char *) mydata -> data , mydata -> len ); <nl> reset (); <nl> return 1 ; <nl> } <nl> + } <nl> + <nl> } <nl>  <nl> 
mmm src / XrdApps / XrdCpConfig . cc <nl> ppp src / XrdApps / XrdCpConfig . cc <nl> do { while ( optind < Argc && Legacy ( optind )) {} <nl> switch ( opC ) <nl> { case OpCksum : defCks ( optarg ); <nl> break ; <nl> + case OpCoerce : OpSpec |= DoCoerce ; <nl> + break ; <nl> case OpDebug : OpSpec |= DoDebug ; <nl> if (! a2i ( optarg , & Dlvl , 0 , 3 )) Usage ( 22 ); <nl> break ;
mmm src / XrdOuc / XrdOuca2x . cc <nl> ppp src / XrdOuc / XrdOuca2x . cc <nl> int XrdOuca2x :: a2sz ( XrdSysError & Eroute , const char * emsg , const char * item , <nl> else if (* fP == ' t ' || * fP == ' T ') qmult = 1024LL * 1024LL * 1024LL * 1024LL ; <nl> else { qmult = 1 ; fP ++;} <nl> errno = 0 ; <nl> - * val = strtoll ( item , & eP , 10 ) * qmult ; <nl> + double dval = strtod ( item , & eP ) * qmult ; <nl> if ( errno || eP != fP ) <nl> { Eroute . Emsg (" a2x ", emsg , item , " is not a number "); <nl> return - 1 ; <nl> } <nl> + * val = ( long long ) dval ; <nl> if (* val < minv ) <nl> return Emsg ( Eroute , emsg , item , " may not be less than % lld ", minv ); <nl> if ( maxv >= 0 && * val > maxv )
mmm src / XrdSsi / XrdSsiUtils . cc <nl> ppp src / XrdSsi / XrdSsiUtils . cc <nl> void DoIt () { myMutex . Lock (); <nl> virtual void Finished ( XrdSsiRequest & rqstR , <nl> const XrdSsiRespInfo & rInfo , <nl> bool cancel = false ) <nl> - { myMutex . Lock (); <nl> + { UnBindRequest (); <nl> + myMutex . Lock (); <nl> if (! isActive ) delete this ; <nl> else { isActive = false ; <nl> myMutex . UnLock ();
mmm src / configure . cpp <nl> ppp src / configure . cpp <nl> bool Handler :: xsecretkey ( XrdOucStream & config_obj , XrdSysError * log , std :: string <nl> return false ; <nl> } <nl>  <nl> - FILE * fp = fopen ( val , " r +"); <nl> + FILE * fp = fopen ( val , " rb "); <nl>  <nl> if ( fp == NULL ) { <nl> log -> Emsg (" Config ", " Cannot open shared secret key file '", val , "'");
mmm XrdClFileStateHandler . cc <nl> ppp XrdClFileStateHandler . cc <nl> namespace XrdCl <nl> pFileUrl ( 0 ), <nl> pDataServer ( 0 ), <nl> pLoadBalancer ( 0 ), <nl> + pStateRedirect ( 0 ), <nl> pFileHandle ( 0 ), <nl> pOpenMode ( 0 ), <nl> pOpenFlags ( 0 ),
mmm src / XrdClient / XrdClientConn . cc <nl> ppp src / XrdClient / XrdClientConn . cc <nl> XReqErrorType XrdClientConn :: GoBackToRedirector () { <nl> // redirections . Used typically for stat and similar functions <nl> Disconnect ( false ); <nl> if ( fGlobalRedirCnt ) fGlobalRedirCnt --; <nl> - return GoToAnotherServer (* fLBSUrl ); <nl> + return ( fLBSUrl ? GoToAnotherServer (* fLBSUrl ) : kOK ); <nl> } <nl>  <nl> // _____________________________________________________________________________
mmm src / XrdClient / XrdClient . cc <nl> ppp src / XrdClient / XrdClient . cc <nl> bool XrdClient :: TryOpen ( kXR_unt16 mode , kXR_unt16 options , bool doitparallel ) { <nl>  <nl> // If the open request failed for the error " file not found " proceed , <nl> // otherwise return FALSE <nl> - if ( fConnModule -> LastServerResp . status != kXR_NotFound ) { <nl> + if ( ( fConnModule -> LastServerResp . status != kXR_error ) || <nl> + (( fConnModule -> LastServerResp . status == kXR_error ) && <nl> + ( fConnModule -> LastServerError . errnum != kXR_NotFound )) ){ <nl> + <nl> TerminateOpenAttempt (); <nl>  <nl> return FALSE ; <nl> bool XrdClient :: TryOpen ( kXR_unt16 mode , kXR_unt16 options , bool doitparallel ) { <nl> // from the one we formerly connected , then we resend the request <nl> // specifyng the supposed failing server as opaque info <nl> if ( fConnModule -> GetLBSUrl () && <nl> - ( fConnModule -> GetCurrentUrl (). Host != fConnModule -> GetLBSUrl ()-> Host ) ) { <nl> + ( ( fConnModule -> GetCurrentUrl (). Host != fConnModule -> GetLBSUrl ()-> Host ) || <nl> + ( fConnModule -> GetCurrentUrl (). Port != fConnModule -> GetLBSUrl ()-> Port ) ) ) { <nl> XrdOucString opinfo ; <nl>  <nl> opinfo = "& tried =" + fConnModule -> GetCurrentUrl (). Host ;
mmm src / XrdClient / XrdClientReadV . cc <nl> ppp src / XrdClient / XrdClientReadV . cc <nl> kXR_int32 XrdClientReadV :: UnpackReadVResp ( char * destbuf , char * respdata , kXR_int <nl>  <nl> // I just rebuild the readahead_list element <nl> struct readahead_list header ; <nl> - kXR_int64 pos_from = 0 , pos_to = 0 ; <nl> + kXR_int32 pos_from = 0 , pos_to = 0 ; <nl> int i = 0 ; <nl> - <nl> - int cur_buf_len = 0 , cur_buf_offset = - 1 , cur_buf = 0 ; <nl> + kXR_int64 cur_buf_offset = - 1 ; <nl> + int cur_buf_len = 0 , cur_buf = 0 ; <nl>  <nl> while ( ( pos_from < respdatalen ) && ( i < nbuf ) ) { <nl> memcpy (& header , respdata + pos_from , sizeof ( struct readahead_list ));
mmm src / XrdCl / XrdClURL . cc <nl> ppp src / XrdCl / XrdClURL . cc <nl> namespace XrdCl <nl> // Check if we ' re IPv6 encoded IPv4 <nl> //---------------------------------------------------------------------- <nl> pos = pHostName . find ( "." ); <nl> - if ( pos != std :: string :: npos ) <nl> + size_t pos2 = pHostName . find ( "[:: ffff " ); <nl> + if ( pos != std :: string :: npos && pos2 == std :: string :: npos ) <nl> { <nl> pHostName . erase ( 0 , 3 ); <nl> pHostName . erase ( pHostName . length ()- 1 , 1 );
mmm src / XrdOlb / XrdOlbConfig . cc <nl> ppp src / XrdOlb / XrdOlbConfig . cc <nl> int XrdOlbConfig :: Configure2 () <nl> // <nl> Say . Say ( 0 , myInstance , " phase 2 initialization started ."); <nl>  <nl> +// Readjust the thread parameters as we know how many we will actually need <nl> +// <nl> + Sched -> setParms ( 16 , 256 , 8 , 0 ); <nl> + <nl> // Determine who we are . If we are a manager or supervisor start the file <nl> // location cache scrubber . <nl> //
mmm src / XrdFileCache / XrdFileCacheFactory . cc <nl> ppp src / XrdFileCache / XrdFileCacheFactory . cc <nl> bool Factory :: ConfigParameters ( std :: string part , XrdOucStream & config ) <nl> } <nl> else if ( part == " prefetch " ) <nl> { <nl> - printf (" prefetch enabled !!!!\ n "); <nl> - m_configuration . m_prefetch = true ; <nl> - config . GetWord (); <nl> + int p = :: atoi ( config . GetWord ()); <nl> + if ( p != 0 ) { <nl> + printf (" prefetch enabled !!!!\ n "); <nl> + m_configuration . m_prefetch = true ; <nl> + } <nl> + else { <nl> + m_configuration . m_prefetch = false ; <nl> + } <nl> } <nl> else if ( part == " nram " ) <nl> {
mmm src / XrdCl / XrdClCopyProcess . cc <nl> ppp src / XrdCl / XrdClCopyProcess . cc <nl> namespace XrdCl <nl>  <nl> props . Get ( " source ", tmp ); <nl> URL source = tmp ; <nl> + if ( ! source . IsValid () ) <nl> + return XRootDStatus ( stError , errInvalidArgs , 0 , " invalid source " ); <nl> + <nl> props . Get ( " target ", tmp ); <nl> URL target = tmp ; <nl> + if ( ! target . IsValid () ) <nl> + return XRootDStatus ( stError , errInvalidArgs , 0 , " invalid target " ); <nl>  <nl> bool tpc = false ; <nl> bool tpcFallBack = false ;
mmm src / XrdNet / XrdNet . cc <nl> ppp src / XrdNet / XrdNet . cc <nl> int XrdNet :: do_Accept_UDP ( XrdNetPeer & myPeer , int opts ) <nl>  <nl> // Read the message and get the host address <nl> // <nl> - do { dlen = recvfrom ( iofd , ( Sokdata_t ) bp -> data , BuffSize , 0 , & addr ,& addrlen ); <nl> + do { dlen = recvfrom ( iofd ,( Sokdata_t ) bp -> data , BuffSize - 1 , 0 ,& addr ,& addrlen ); <nl> } while ( dlen < 0 && errno == EINTR ); <nl>  <nl> if ( dlen < 0 ) <nl> { eDest -> Emsg (" Receive ", errno , " perform UDP recvfrom ()"); <nl> BuffQ -> Recycle ( bp ); <nl> return 0 ; <nl> - } <nl> + } else bp -> data [ dlen ] = '\ 0 '; <nl>  <nl> // Authorize this connection . We don ' t accept messages that set the <nl> // loopback address since this can be trivially spoofed in UDP packets .
mmm src / XrdClient / Xrdcp . cc <nl> ppp src / XrdClient / Xrdcp . cc <nl> int doCp_xrd2xrd ( XrdClient ** xrddest , const char * src , const char * dst ) { <nl> cout << endl ; <nl> } <nl>  <nl> - if (( unsigned ) cpnfo . len != bytesread ) retvalue = 13 ; <nl> + if ( cpnfo . len != bytesread ) retvalue = 13 ; <nl>  <nl> # ifdef HAVE_XRDCRYPTO <nl> if ( md5 ) MD_5 -> Final (); <nl> int doCp_xrd2loc ( const char * src , const char * dst ) { <nl> cout << endl ; <nl> } <nl>  <nl> - if (( unsigned ) cpnfo . len != bytesread ) retvalue = 13 ; <nl> + if ( cpnfo . len != bytesread ) retvalue = 13 ; <nl>  <nl> # ifdef HAVE_XRDCRYPTO <nl> if ( md5 ) MD_5 -> Final ();
mmm src / XrdXrootd / XrdXrootdMonitor . cc <nl> ppp src / XrdXrootd / XrdXrootdMonitor . cc <nl> XrdXrootdMonitor ::~ XrdXrootdMonitor () <nl>  <nl> void XrdXrootdMonitor :: appID ( char * id ) <nl> { <nl> + static const int apInfoSize = sizeof ( XrdXrootdMonTrace )- 4 ; <nl>  <nl> // Application ID ' s are only meaningful for io event recording <nl> // <nl> void XrdXrootdMonitor :: appID ( char * id ) <nl> if ( lastWindow != currWindow ) Mark (); <nl> else if ( nextEnt == lastEnt ) Flush (); <nl> monBuff -> info [ nextEnt ]. arg0 . id [ 0 ] = XROOTD_MON_APPID ; <nl> - strncpy (( char *)& monBuff -> info [ nextEnt ]. arg0 . id [ 4 ], id , <nl> - sizeof ( XrdXrootdMonTrace )- 4 ); <nl> + strncpy (( char *)(&( monBuff -> info [ nextEnt ])+ 4 ), id , apInfoSize ); <nl> } <nl>  <nl> /******************************************************************************/
mmm src / XrdOuc / XrdOuca2x . cc <nl> ppp src / XrdOuc / XrdOuca2x . cc <nl> int XrdOuca2x :: a2sp ( XrdSysError & Eroute , const char * emsg , const char * item , <nl> if ( maxv < 0 ) maxv = 100 ; <nl>  <nl> if (* val > maxv ) <nl> - { sprintf ( buff , " may not be greater than % d %%", maxv ); <nl> + { sprintf ( buff , " may not be greater than % lld %%", maxv ); <nl> Eroute . Emsg (" a2x ", emsg , item , buff ); <nl> return - 1 ; <nl> } <nl> int XrdOuca2x :: a2sp ( XrdSysError & Eroute , const char * emsg , const char * item , <nl> if ( minv < 0 ) minv = 0 ; <nl>  <nl> if (* val > maxv ) <nl> - { sprintf ( buff , " may not be less than % d %%", minv ); <nl> + { sprintf ( buff , " may not be less than % lld %%", minv ); <nl> Eroute . Emsg (" a2x ", emsg , item , buff ); <nl> return - 1 ; <nl> }mmm src / XrdOuc / XrdOucUtils . cc <nl> ppp src / XrdOuc / XrdOucUtils . cc <nl> int XrdOuca2x :: a2sp ( XrdSysError & Eroute , const char * emsg , const char * item , <nl> if ( maxv < 0 ) maxv = 100 ; <nl>  <nl> if (* val > maxv ) <nl> - { sprintf ( buff , " may not be greater than % d %%", maxv ); <nl> + { sprintf ( buff , " may not be greater than % lld %%", maxv ); <nl> Eroute . Emsg (" a2x ", emsg , item , buff ); <nl> return - 1 ; <nl> } <nl> int XrdOuca2x :: a2sp ( XrdSysError & Eroute , const char * emsg , const char * item , <nl> if ( minv < 0 ) minv = 0 ; <nl>  <nl> if (* val > maxv ) <nl> - { sprintf ( buff , " may not be less than % d %%", minv ); <nl> + { sprintf ( buff , " may not be less than % lld %%", minv ); <nl> Eroute . Emsg (" a2x ", emsg , item , buff ); <nl> return - 1 ; <nl> } <nl> int XrdOucUtils :: fmtBytes ( long long val , char * buff , int bsz ) <nl> static const long long Gval = 1024LL * 1024LL * 1024LL ; <nl> static const long long Tval = 1024LL * 1024LL * 1024LL * 1024LL ; <nl> char sName = ' '; <nl> - int n , resid ; <nl> + int resid ; <nl>  <nl> // Get correct scaling <nl> //
mmm src / XrdHttp / XrdHttpReq . cc <nl> ppp src / XrdHttp / XrdHttpReq . cc <nl> int XrdHttpReq :: PostProcessHTTPReq ( bool final_ ) { <nl>  <nl> } else <nl> for ( int i = 0 ; i < iovN ; i ++) { <nl> - prot -> SendData (( char *) iovP [ i ]. iov_base , iovP [ i ]. iov_len ); <nl> + if ( prot -> SendData (( char *) iovP [ i ]. iov_base , iovP [ i ]. iov_len )) return 1 ; <nl> writtenbytes += iovP [ i ]. iov_len ; <nl> } <nl> 
mmm src / XrdClient / XrdCommandLine . cc <nl> ppp src / XrdClient / XrdCommandLine . cc <nl> int main ( int argc , char ** argv ) { <nl>  <nl> if (! path . length ()) { <nl> cout << " The current path is empty ." << endl ; <nl> - retval = 1 ; <nl> + path = '/'; <nl> } <nl>  <nl> // Now try to issue the request
mmm src / XrdNet / XrdNet . cc <nl> ppp src / XrdNet / XrdNet . cc <nl> int XrdNet :: do_Accept_TCP ( XrdNetAddr & hAddr , int opts ) <nl>  <nl> // Initialize the address of the new connection <nl> // <nl> - hAddr . Set (& IP . Addr , newfd ); <nl> + const char * eMsg = hAddr . Set (& IP . Addr , newfd ); <nl> + if ( eMsg ) <nl> + { char buff [ 256 ]; <nl> + snprintf ( buff , sizeof ( buff ), "% d ;", newfd ); <nl> + eDest -> Emsg (" Accept ", " Failed to identify FD ", buff , eMsg ); <nl> + close ( newfd ); <nl> + return 0 ; <nl> + } <nl>  <nl> // Remove TCP_NODELAY option for unix domain sockets to avoid error message <nl> //
mmm src / XrdSecgsi / XrdSecProtocolgsi . cc <nl> ppp src / XrdSecgsi / XrdSecProtocolgsi . cc <nl> int XrdSecProtocolgsi :: Encrypt ( const char * inbuf , // Data to be encrypted <nl> return - EINVAL ; <nl>  <nl> // Get output buffer <nl> - char * buf = ( char *) malloc ( sessionKey -> EncOutLength ( inlen )); <nl> - if (! buf ) <nl> - return - ENOMEM ; <nl> + int sz = sessionKey -> EncOutLength ( inlen ); <nl> + char * buf = ( char *) malloc ( sz ); <nl> + if (! buf ) return - ENOMEM ; <nl> + memset ( buf , 0 , sz ); <nl>  <nl> // Encrypt <nl> int len = sessionKey -> Encrypt ( inbuf , inlen , buf ); <nl> int XrdSecProtocolgsi :: Decrypt ( const char * inbuf , // Data to be decrypted <nl> return - EINVAL ; <nl>  <nl> // Get output buffer <nl> - char * buf = ( char *) malloc ( sessionKey -> DecOutLength ( inlen )); <nl> - if (! buf ) <nl> - return - ENOMEM ; <nl> + int sz = sessionKey -> DecOutLength ( inlen ); <nl> + char * buf = ( char *) malloc ( sz ); <nl> + if (! buf ) return - ENOMEM ; <nl> + memset ( buf , 0 , sz ); <nl>  <nl> // Decrypt <nl> int len = sessionKey -> Decrypt ( inbuf , inlen , buf );
mmm src / XrdFileCache / XrdFileCachePrefetch . cc <nl> ppp src / XrdFileCache / XrdFileCachePrefetch . cc <nl> ssize_t Prefetch :: ReadInBlocks ( char * buff , off_t off , size_t size ) <nl>  <nl> int Prefetch :: ReadV ( const XrdOucIOVec * readV , int n ) <nl> { <nl> + { <nl> + XrdSysCondVarHelper monitor ( m_stateCond ); <nl> + <nl> + // AMT check if this can be done once during initalization <nl> + if ( m_failed ) return m_input . ReadV ( readV , n ); <nl> + <nl> + if ( ! m_started ) <nl> + { <nl> + m_stateCond . Wait (); <nl> + if ( m_failed ) return 0 ; <nl> + } <nl> + } <nl> + <nl> // check if read sizes are big enough to cache <nl>  <nl> XrdCl :: XRootDStatus Status ;
mmm src / XrdCl / XrdClCopy . cc <nl> ppp src / XrdCl / XrdClCopy . cc <nl> class ProgressDisplay : public XrdCl :: CopyProgressHandler <nl> uint64_t speed = 0 ; <nl> if ( now - d . started ) <nl> speed = d . bytesProcessed /( now - d . started ); <nl> + else <nl> + speed = d . bytesProcessed ; <nl>  <nl> std :: string bar ; <nl> int prog = 0 ;
mmm src / XrdClient / XrdClientAdmin_c . cc <nl> ppp src / XrdClient / XrdClientAdmin_c . cc <nl> extern " C " { <nl> char tok1 [ 256 ], tok2 [ 256 ]; <nl> long v ; <nl>  <nl> - if ( sscanf ((* env )[ it ]. c_str (), "% 256s % d ", tok1 , & v ) == 2 ) { <nl> + if ( sscanf ((* env )[ it ]. c_str (), "% 256s % ld ", tok1 , & v ) == 2 ) { <nl> // It ' s an integer value <nl> EnvPutInt ( tok1 , v ); <nl> // cout << " Env : " << tok1 << " Val =" << EnvGetLong ( tok1 ) << endl ;
mmm src / XrdCl / XrdClDefaultEnv . cc <nl> ppp src / XrdCl / XrdClDefaultEnv . cc <nl> namespace XrdCl <nl> " libXrdSecgsi . so ", <nl> " libXrdSecgsiAuthzVO . so ", <nl> " libXrdSecgsiGMAPDN . so ", <nl> - " libXrdSecgsiGMAPLDAP . so ", <nl> " libXrdSecpwd . so ", <nl> " libXrdSecsss . so ", <nl> " libXrdSecunix . so ",mmm src / XrdSecgsi / XrdSecgsiGMAPFunLDAP . cc <nl> ppp src / XrdSecgsi / XrdSecgsiGMAPFunLDAP . cc <nl> namespace XrdCl <nl> " libXrdSecgsi . so ", <nl> " libXrdSecgsiAuthzVO . so ", <nl> " libXrdSecgsiGMAPDN . so ", <nl> - " libXrdSecgsiGMAPLDAP . so ", <nl> " libXrdSecpwd . so ", <nl> " libXrdSecsss . so ", <nl> " libXrdSecunix . so ", <nl> XrdVERSIONINFO ( XrdSecgsiGMAPFun , secgsigmap ); <nl> /* */ <nl> /* GMAP function implementation querying a LDAP database */ <nl> /* */ <nl> +/* Warning : this plug - in is not build any longer because the external */ <nl> +/* LDAP query via the popen () represents a potential security threat */ <nl> +/* and it is believed that functionality provided is not actually used . */ <nl> +/* If this believe happens to be uncorrect please report at */ <nl> +/* */ <nl> +/* https :// github . com / xrootd */ <nl> +/* */ <nl> +/* a sanitized version of the plug - in can be provided using a proper library . */ <nl> +/* */ <nl> /* ************************************************************************** */ <nl>  <nl> # include < stdio . h >
mmm src / XrdNet / XrdNetConnect . cc <nl> ppp src / XrdNet / XrdNetConnect . cc <nl> int XrdNetConnect :: Connect ( int fd , <nl> new_flags = old_flags | O_NDELAY | O_NONBLOCK ; <nl> fcntl ( fd , F_SETFL , new_flags ); <nl> if (! connect ( fd , name , namelen )) myRC = 0 ; <nl> - else if ( EINPROGRESS != errno ) myRC = errno ; <nl> + else if ( EINPROGRESS != net_errno ) myRC = net_errno ; <nl> else { struct pollfd polltab = { fd , POLLOUT | POLLWRNORM , 0 }; <nl> do { myRC = poll (& polltab , 1 , tsec * 1000 );} <nl> while ( myRC < 0 && errno == EINTR );
mmm src / XrdCeph / XrdCephPosix . cc <nl> ppp src / XrdCeph / XrdCephPosix . cc <nl> int ceph_posix_open ( XrdOucEnv * env , const char * pathname , int flags , mode_t mode <nl> // in case of O_TRUNC , we should truncate the file <nl> if ( flags & O_TRUNC ) { <nl> int rc = ceph_posix_internal_truncate ( fr , 0 ); <nl> - if ( rc < 0 ) return rc ; <nl> + // fail only if file exists and cannot be truncated <nl> + if ( rc < 0 && rc != - ENOENT ) return rc ; <nl> } <nl> return g_nextCephFd - 1 ; <nl> }
mmm src / XrdOfs / XrdOfsConfig . cc <nl> ppp src / XrdOfs / XrdOfsConfig . cc <nl> int XrdOfs :: xred ( XrdOucStream & Config , XrdOucError & Eroute ) <nl> if (! ropt ) ropt = XrdOfsREDIRRMT ; <nl> else if ( val ) val = Config . GetWord (); <nl>  <nl> - if ( val && ! strcmp (" if ", val )) <nl> - if (( rc = XrdOucUtils :: doIf (& Eroute , Config , " redirect directive ", <nl> + if ( val ) <nl> + { if ( strcmp (" if ", val )) <nl> + { Config . RetToken (); <nl> + Eroute . Emsg (" Config ", " Warning ! Implied ' if ' on redirect is now deprecated ."); <nl> + } <nl> + if (( rc = XrdOucUtils :: doIf (& Eroute , Config , " redirect directive ", <nl> getenv (" XRDHOST "), getenv (" XRDNAME "))) <= 0 ) <nl> - return ( rc < 0 ); <nl> - <nl> + return ( rc < 0 ); <nl> + } <nl> Options |= ropt ; <nl> return 0 ; <nl> }
mmm src / XrdSys / XrdSysTimer . cc <nl> ppp src / XrdSys / XrdSysTimer . cc <nl> unsigned long XrdSysTimer :: Report ( double & Total_Time ) <nl>  <nl> // Add up the time as a double <nl> // <nl> - Total_Time += ( double ) LastReport . tv_sec + <nl> - (( double )( LastReport . tv_usec / 1000 ))/ 1000 . 0 ; <nl> + Total_Time += static_cast < double >( LastReport . tv_sec ) + <nl> + static_cast < double >( LastReport . tv_usec / 1000 )/ 1000 . 0 ; <nl>  <nl> // Return time <nl> // <nl> unsigned long XrdSysTimer :: Report ( unsigned long & Total_Time ) <nl> { <nl> unsigned long report_time = Report (); <nl>  <nl> -// Add up the time as a 32 - bit value to nearest microsecond ( max = 24 days ) <nl> +// Add up the time as a 32 - bit value to nearest milliseconds ( max = 24 days ) <nl> // <nl> Total_Time += ( unsigned long ) LastReport . tv_sec * 1000 + <nl> ( unsigned long )( LastReport . tv_usec / 1000 ); <nl> unsigned long XrdSysTimer :: Report ( unsigned long long & Total_Time ) <nl> { <nl> unsigned long report_time = Report (); <nl>  <nl> -// Add up the time as a 64 - bit value to nearest microsecond <nl> +// Add up the time as a 64 - bit value to nearest milliseconds <nl> // <nl> Total_Time += ( unsigned long long ) LastReport . tv_sec * 1000 + <nl> ( unsigned long long )( LastReport . tv_usec / 1000 );
mmm src / XrdXrootd / XrdXrootdResponse . cc <nl> ppp src / XrdXrootd / XrdXrootdResponse . cc <nl> int XrdXrootdResponse :: Send ( XResponseType rcode , int info , const char * data ) <nl> kXR_int32 xbuf = static_cast < kXR_int32 >( htonl ( info )); <nl> int dlen ; <nl>  <nl> - TRACES ( RSP , " sending " << dlen <<" data bytes ; status =" << rcode ); <nl> - <nl> RespIO [ 1 ]. iov_base = ( caddr_t )(& xbuf ); <nl> RespIO [ 1 ]. iov_len = sizeof ( xbuf ); <nl> RespIO [ 2 ]. iov_base = ( caddr_t ) data ; <nl> RespIO [ 2 ]. iov_len = dlen = strlen ( data ); <nl>  <nl> + TRACES ( RSP ," sending " <<( sizeof ( xbuf )+ dlen ) <<" data bytes ; status =" << rcode ); <nl> + <nl> if ( Bridge ) <nl> { if ( Bridge -> Send ( rcode , & RespIO [ 1 ], 1 , dlen ) >= 0 ) return 0 ; <nl> return Link -> setEtext (" send failure ");
mmm src / XrdOuc / XrdOucPup . cc <nl> ppp src / XrdOuc / XrdOucPup . cc <nl> int XrdOucPup :: Pack ( struct iovec * iovP , struct iovec * iovE , XrdOucPupArgs * pup , <nl> break ; <nl>  <nl> case PT_int : <nl> - n32 = htons (* Base . B32 ); <nl> + n32 = htonl (* Base . B32 ); <nl> * wP = PT_int ; memcpy ( wP + 1 , & n32 , sizeof ( n32 )); <nl> vP -> iov_base = wP ; vP -> iov_len = Sz32 ; vP ++; <nl> wP += Sz32 ; TotLen += Sz32 ; dlen = sizeof ( n32 ); <nl> break ; <nl>  <nl> case PT_longlong : <nl> - n64 = htons (* Base . B64 ); <nl> + h2nll (* Base . B64 , n64 ); <nl> * wP = PT_longlong ; memcpy ( wP + 1 , & n64 , sizeof ( n64 )); <nl> vP -> iov_base = wP ; vP -> iov_len = Sz64 ; vP ++; <nl> wP += Sz64 ; TotLen += Sz64 ; dlen = sizeof ( n64 );
mmm src / XrdXrootd / XrdXrootdXeq . cc <nl> ppp src / XrdXrootd / XrdXrootdXeq . cc <nl> int XrdXrootdProtocol :: do_Qconf () <nl> // Now determine what the user wants to query <nl> // <nl> if (! strcmp (" readv_ior_max ", val )) <nl> - { n = sprintf ( bp , "% d \ n ", maxTransz - sizeof ( readahead_list )); <nl> + { n = sprintf ( bp , "% d \ n ", maxTransz - ( int ) sizeof ( readahead_list )); <nl> bp += n ; bleft -= n ; <nl> } <nl> else if (! strcmp (" readv_iov_max ", val ))
mmm viostor / virtio_stor_hw_helper . c <nl> ppp viostor / virtio_stor_hw_helper . c <nl> RhelShutDown ( <nl>  <nl> virtio_device_reset (& adaptExt -> vdev ); <nl> virtio_delete_queues (& adaptExt -> vdev ); <nl> + virtio_device_shutdown (& adaptExt -> vdev ); <nl> adaptExt -> vq = NULL ; <nl> } <nl> 
mmm VirtIO / VirtIOPCICommon . c <nl> ppp VirtIO / VirtIOPCICommon . c <nl> void virtio_delete_queues ( VirtIODevice * vdev ) <nl> struct virtqueue * vq ; <nl> unsigned i ; <nl>  <nl> + if ( vdev -> info == NULL ) <nl> + return ; <nl> + <nl> for ( i = 0 ; i < vdev -> maxQueues ; i ++) { <nl> vq = vdev -> info [ i ]. vq ; <nl> if ( vq != NULL ) {
mmm NetKVM / Common / ParaNdis - Common . cpp <nl> ppp NetKVM / Common / ParaNdis - Common . cpp <nl> static NDIS_STATUS ParaNdis_VirtIONetInit ( PARANDIS_ADAPTER * pContext ) <nl> for ( i = 0 ; i < pContext -> nPathBundles ; i ++) <nl> { <nl> new ( pContext -> pPathBundles + i , PLACEMENT_NEW ) CPUPathesBundle (); <nl> + } <nl>  <nl> + for ( i = 0 ; i < pContext -> nPathBundles ; i ++) <nl> + { <nl> if (! pContext -> pPathBundles [ i ]. rxPath . Create ( pContext , i * 2 )) <nl> { <nl> DPrintf ( 0 , ("% s : CParaNdisRX creation failed \ n ", __FUNCTION__ ));
mmm agent - ini / src / IniParser . cc <nl> ppp agent - ini / src / IniParser . cc <nl> std :: string format ( const char * format , ...) { <nl>  <nl> va_list ap ; <nl> va_start ( ap , format ); <nl> - <nl> int numprinted = vasprintf (& buf , format , ap ); <nl> + va_end ( ap ); <nl> + <nl> if ( numprinted >= 0 ) { <nl> val = buf ; <nl> free ( buf ); <nl> std :: string format ( const char * format , ...) { <nl> throw std :: runtime_error (" vasprintf failed in ag_ini . Out of memory ?"); <nl> } <nl>  <nl> - va_end ( ap ); <nl> return val ; <nl> } <nl> 
mmm libycp / src / YExpression . cc <nl> ppp libycp / src / YExpression . cc <nl> YEBuiltin :: toStream ( std :: ostream & str ) const <nl> std :: ostream & <nl> YEBuiltin :: toXml ( std :: ostream & str , int indent ) const <nl> { <nl> - str << "< builtin name =\"" << m_decl -> name << "\""; <nl> + str << "< builtin name =\"" << StaticDeclaration :: Decl2String ( m_decl ) << "\""; <nl>  <nl> if ( m_parameterblock != 0 ) <nl> {
mmm agent - probe / src / HwParse . cc <nl> ppp agent - probe / src / HwParse . cc <nl> HwProbe :: hd2value ( hd_t * hd ) <nl> out -> add ( YCPString (" sub_vendor "), YCPString ( s )); <nl> } <nl>  <nl> + // HAL udi <nl> + <nl> + s = hd -> udi ; <nl> + if ( s ) <nl> + { <nl> + out -> add ( YCPString (" udi "), YCPString ( s )); <nl> + } <nl> + <nl> // unique key <nl>  <nl> s = hd -> unique_id ;
mmm debugger / Debugger . cc <nl> ppp debugger / Debugger . cc <nl> void Debugger :: generateBacktrace () <nl> result += " with paramters : "; <nl> for ( int i = 0 ; i < paramcount ; i ++ ) <nl> { <nl> - result += (* it )-> params [ 0 ]-> toString () + " "; <nl> + string param = (* it )-> params [ 0 ]-> toString (); <nl> + if ( param . length () > 80 ) <nl> + { <nl> + param = "< too long >"; <nl> + } <nl> + result += param ; <nl> + if ( i < paramcount - 1 ) <nl> + { <nl> + result += ", "; <nl> + } <nl> } <nl> ++ it ; <nl> };
mmm lib / ytnef . c <nl> ppp lib / ytnef . c <nl> BYTE * DecompressRTF ( variableLength * p , int * size ) { <nl> ALLOCCHECK_CHAR ( dst ); <nl> memcpy ( dst , comp_Prebuf . data , comp_Prebuf . size ); <nl> out = comp_Prebuf . size ; <nl> - while ( out < ( comp_Prebuf . size + uncompressedSize )) { <nl> + while (( out < ( comp_Prebuf . size + uncompressedSize )) && ( in < p -> size )) { <nl> // each flag byte flags 8 literals / references , 1 per bit <nl> flags = ( flagCount ++ % 8 == 0 ) ? src [ in ++] : flags >> 1 ; <nl> if (( flags & 1 ) == 1 ) { // each flag bit is 1 for reference , 0 for literal
mmm lib / ytnef . c <nl> ppp lib / ytnef . c <nl> int TNEFParse ( TNEFStruct * TNEF ) { <nl> while ( TNEFGetHeader ( TNEF , & type , & size ) == 0 ) { <nl> DEBUG2 ( TNEF -> Debug , 2 , " Header says type = 0x % X , size =% u ", type , size ); <nl> DEBUG2 ( TNEF -> Debug , 2 , " Header says type =% u , size =% u ", type , size ); <nl> + if ( size == 0 ) { <nl> + printf (" ERROR : Field with size of 0 \ n "); <nl> + return YTNEF_ERROR_READING_DATA ; <nl> + } <nl> data = calloc ( size , sizeof ( BYTE )); <nl> ALLOCCHECK ( data ); <nl> if ( TNEFRawRead ( TNEF , data , size , & header_checksum ) < 0 ) {
mmm ytnef / src / ytnef / vcal . c <nl> ppp ytnef / src / ytnef / vcal . c <nl> void SaveVCalendar ( TNEFStruct TNEF , int isMtgReq ) { <nl> if ( isMtgReq ) { <nl> CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " MtgReq ", " ics ", filepath ); <nl> } else { <nl> - CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " calendar ", " vcf ", filepath ); <nl> + CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " calendar ", " ics ", filepath ); <nl> } <nl>  <nl> printf ("% s \ n ", ifilename );
mmm lib / ytnef . c <nl> ppp lib / ytnef . c <nl> void MAPIPrint ( MAPIProps * p ) { <nl> printf ("] (% llu )\ n ", ddword_tmp ); <nl> break ; <nl> case PT_LONG : <nl> - printf (" Value : % li \ n ", *(( long *) mapidata -> data )); <nl> + printf (" Value : % i \ n ", *(( int *) mapidata -> data )); <nl> break ; <nl> case PT_I2 : <nl> printf (" Value : % hi \ n ", *(( short int *) mapidata -> data ));
mmm probe . c <nl> ppp probe . c <nl> void hexdump ( msg_info msg_info , const char * mem , unsigned int len ) <nl> } <nl> str [ c ++] = '\ n '; <nl> str [ c ++] = 0 ; <nl> - print_message ( msg_info , str ); <nl> + print_message ( msg_info , "% s ", str ); <nl> c = 0 ; <nl> } <nl> }
mmm pam_yubico . c <nl> ppp pam_yubico . c <nl> display_error ( pam_handle_t * pamh , const char * message ) { <nl> } <nl>  <nl> D ((" conv returned : '% s '", resp -> resp )); <nl> + free ( resp ); <nl> return retval ; <nl> } <nl> # endif /* HAVE_CR */ <nl> pam_sm_authenticate ( pam_handle_t * pamh , <nl> struct pam_conv * conv ; <nl> const struct pam_message * pmsg [ 1 ]; <nl> struct pam_message msg [ 1 ]; <nl> - struct pam_response * resp ; <nl> + struct pam_response * resp = NULL ; <nl> int nargs = 1 ; <nl> ykclient_t * ykc = NULL ; <nl> struct cfg cfg_st ; <nl> pam_sm_authenticate ( pam_handle_t * pamh , <nl> } <nl> } <nl> msg [ 0 ]. msg_style = cfg -> verbose_otp ? PAM_PROMPT_ECHO_ON : PAM_PROMPT_ECHO_OFF ; <nl> - resp = NULL ; <nl>  <nl> retval = conv -> conv ( nargs , pmsg , & resp , conv -> appdata_ptr ); <nl>  <nl> done : <nl> DBG ((" done . [% s ]", pam_strerror ( pamh , retval ))); <nl> pam_set_data ( pamh , " yubico_setcred_return ", ( void *) ( intptr_t ) retval , NULL ); <nl>  <nl> + if ( resp ) <nl> + free ( resp ); <nl> + <nl> return retval ; <nl> } <nl> 
mmm util . c <nl> ppp util . c <nl> check_user_token ( const char * authfile , <nl> { <nl> if ( verbose ) <nl> D ( debug_file , " Match user / token as % s /% s ", username , otp_id ); <nl> + <nl> + fclose ( opwfile ); <nl> return AUTH_FOUND ; <nl> } <nl> }
mmm CoinSpend . cpp <nl> ppp CoinSpend . cpp <nl> CoinSpend :: CoinSpend ( const Params * p , const PrivateCoin & coin , <nl> throw ZerocoinException (" Accumulator witness does not verify "); <nl> } <nl>  <nl> + // The serial # needs to be within the specified range our else it can be incremented by the modulus and create another valid proof <nl> + if (! HasValidSerial ()) { <nl> + throw ZerocoinException (" Invalid serial # range "); <nl> + } <nl> + <nl> // 1 : Generate two separate commitments to the public coin ( C ), each under <nl> // a different set of public parameters . We do this because the RSA accumulator <nl> // has specific requirements for the commitment parameters that are not <nl> const uint256 CoinSpend :: signatureHash ( const SpendMetaData & m ) const { <nl> return h . GetHash (); <nl> } <nl>  <nl> + bool CoinSpend :: HasValidSerial () const <nl> +{ <nl> + return coinSerialNumber > 0 && coinSerialNumber < params -> coinCommitmentGroup . groupOrder ; <nl> +} <nl> + <nl> } /* namespace libzerocoin */mmm CoinSpend . h <nl> ppp CoinSpend . h <nl> CoinSpend :: CoinSpend ( const Params * p , const PrivateCoin & coin , <nl> throw ZerocoinException (" Accumulator witness does not verify "); <nl> } <nl>  <nl> + // The serial # needs to be within the specified range our else it can be incremented by the modulus and create another valid proof <nl> + if (! HasValidSerial ()) { <nl> + throw ZerocoinException (" Invalid serial # range "); <nl> + } <nl> + <nl> // 1 : Generate two separate commitments to the public coin ( C ), each under <nl> // a different set of public parameters . We do this because the RSA accumulator <nl> // has specific requirements for the commitment parameters that are not <nl> const uint256 CoinSpend :: signatureHash ( const SpendMetaData & m ) const { <nl> return h . GetHash (); <nl> } <nl>  <nl> + bool CoinSpend :: HasValidSerial () const <nl> +{ <nl> + return coinSerialNumber > 0 && coinSerialNumber < params -> coinCommitmentGroup . groupOrder ; <nl> +} <nl> + <nl> } /* namespace libzerocoin */ <nl> public : <nl> */ <nl> const CoinDenomination getDenomination (); <nl>  <nl> + bool HasValidSerial () const ; <nl> bool Verify ( const Accumulator & a , const SpendMetaData & metaData ) const ; <nl>  <nl> IMPLEMENT_SERIALIZE
mmm jerry - core / vm / opcodes - ecma - relational . c <nl> ppp jerry - core / vm / opcodes - ecma - relational . c <nl> opfunc_instanceof ( ecma_value_t left_value , /**< left value */ <nl>  <nl> if (! ecma_is_value_object ( right_value )) <nl> { <nl> - ret_value = ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + ret_value = ecma_raise_type_error ( ECMA_ERR_MSG (" Expected an object in ' instanceof ' check .")); <nl> } <nl> else <nl> { <nl> opfunc_in ( ecma_value_t left_value , /**< left value */ <nl>  <nl> if (! ecma_is_value_object ( right_value )) <nl> { <nl> - ret_value = ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + ret_value = ecma_raise_type_error ( ECMA_ERR_MSG (" Expected an object in ' in ' check .")); <nl> } <nl> else <nl> {mmm jerry - core / vm / vm . c <nl> ppp jerry - core / vm / vm . c <nl> opfunc_instanceof ( ecma_value_t left_value , /**< left value */ <nl>  <nl> if (! ecma_is_value_object ( right_value )) <nl> { <nl> - ret_value = ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + ret_value = ecma_raise_type_error ( ECMA_ERR_MSG (" Expected an object in ' instanceof ' check .")); <nl> } <nl> else <nl> { <nl> opfunc_in ( ecma_value_t left_value , /**< left value */ <nl>  <nl> if (! ecma_is_value_object ( right_value )) <nl> { <nl> - ret_value = ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + ret_value = ecma_raise_type_error ( ECMA_ERR_MSG (" Expected an object in ' in ' check .")); <nl> } <nl> else <nl> { <nl> vm_op_get_value ( ecma_value_t object , /**< base object */ <nl>  <nl> if ( unlikely ( ecma_is_value_undefined ( object ) || ecma_is_value_null ( object ))) <nl> { <nl> - return ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + return ecma_raise_type_error ( ECMA_ERR_MSG (" Base object cannot be null or undefined .")); <nl> } <nl>  <nl> ecma_value_t prop_to_string_result = ecma_op_to_string ( property ); <nl> opfunc_call ( vm_frame_ctx_t * frame_ctx_p ) /**< frame context */ <nl>  <nl> if (! ecma_op_is_callable ( func_value )) <nl> { <nl> - completion_value = ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + completion_value = ecma_raise_type_error ( ECMA_ERR_MSG (" Expected a function .")); <nl> } <nl> else <nl> { <nl> opfunc_construct ( vm_frame_ctx_t * frame_ctx_p ) /**< frame context */ <nl>  <nl> if (! ecma_is_constructor ( constructor_value )) <nl> { <nl> - completion_value = ecma_raise_type_error ( ECMA_ERR_MSG ("")); <nl> + completion_value = ecma_raise_type_error ( ECMA_ERR_MSG (" Expected a constructor .")); <nl> } <nl> else <nl> { <nl> vm_loop ( vm_frame_ctx_t * frame_ctx_p ) /**< frame context */ <nl> } <nl> else <nl> { <nl> - result = ecma_raise_reference_error ( ECMA_ERR_MSG ("")); <nl> + result = ecma_raise_reference_error ( ECMA_ERR_MSG (" Cannot resolve reference .")); <nl> } <nl>  <nl> if ( ECMA_IS_VALUE_ERROR ( result )) <nl> vm_loop ( vm_frame_ctx_t * frame_ctx_p ) /**< frame context */ <nl> } <nl> case VM_OC_THROW_REFERENCE_ERROR : <nl> { <nl> - result = ecma_raise_reference_error ( ECMA_ERR_MSG ("")); <nl> + result = ecma_raise_reference_error ( ECMA_ERR_MSG (" Undefined reference .")); <nl> goto error ; <nl> } <nl> case VM_OC_EVAL :
mmm src / libcoreint / opcodes - ecma - relational . c <nl> ppp src / libcoreint / opcodes - ecma - relational . c <nl> opfunc_in ( opcode_t opdata __unused , /**< operation data */ <nl> const idx_t left_var_idx = opdata . data . in . var_left ; <nl> const idx_t right_var_idx = opdata . data . in . var_right ; <nl>  <nl> + int_data -> pos ++; <nl> + <nl> ecma_completion_value_t ret_value ; <nl>  <nl> ECMA_TRY_CATCH ( left_value , get_variable_value ( int_data , left_var_idx , false ), ret_value );
mmm jerry - main / main - unix . c <nl> ppp jerry - main / main - unix . c <nl> main ( int argc , <nl> { <nl> break ; <nl> } <nl> + <nl> + jerry_release_value ( ret_value ); <nl> + ret_value = jerry_create_undefined (); <nl> } <nl> } <nl> mmm jerry - main / main - unix - minimal . c <nl> ppp jerry - main / main - unix - minimal . c <nl> main ( int argc , <nl> { <nl> break ; <nl> } <nl> + <nl> + jerry_release_value ( ret_value ); <nl> + ret_value = jerry_create_undefined (); <nl> } <nl> } <nl>  <nl> main ( int argc , <nl> { <nl> break ; <nl> } <nl> + <nl> + jerry_release_value ( ret_value ); <nl> + ret_value = jerry_create_undefined (); <nl> } <nl>  <nl> int ret_code = JERRY_STANDALONE_EXIT_CODE_OK ;
mmm src / mod_auth_openidc . c <nl> ppp src / mod_auth_openidc . c <nl> static int oidc_request_post_preserved_restore ( request_rec * r , <nl> " input . type = \" hidden \";\ n " <nl> " document . forms [ 0 ]. appendChild ( input );\ n " <nl> " }\ n " <nl> - " document . forms [ 0 ]. action = '% s ';\ n " <nl> + " document . forms [ 0 ]. action = \"% s \";\ n " <nl> " document . forms [ 0 ]. submit ();\ n " <nl> " }\ n " <nl> " </ script >\ n ", method , original_url );
mmm src / mod_auth_openidc . c <nl> ppp src / mod_auth_openidc . c <nl> static int oidc_handle_session_management_iframe_rp ( request_rec * r , oidc_cfg * c , <nl> "\ n " <nl> " function setTimer () {\ n " <nl> " checkSession ();\ n " <nl> - " timerID = setInterval (' checkSession ()', % s );\ n " <nl> + " timerID = setInterval (' checkSession ()', % d );\ n " <nl> " }\ n " <nl> "\ n " <nl> " function receiveMessage ( e ) {\ n " <nl> static int oidc_handle_session_management_iframe_rp ( request_rec * r , oidc_cfg * c , <nl>  <nl> char * s_poll_interval = NULL ; <nl> oidc_util_get_request_parameter ( r , " poll ", & s_poll_interval ); <nl> - if ( s_poll_interval == NULL ) <nl> - s_poll_interval = " 3000 "; <nl> + int poll_interval = s_poll_interval ? strtol ( s_poll_interval , NULL , 10 ) : 0 ; <nl> + if (( poll_interval <= 0 ) || ( poll_interval > 3600 * 24 )) <nl> + poll_interval = 3000 ; <nl>  <nl> const char * redirect_uri = oidc_get_redirect_uri ( r , c ); <nl> java_script = apr_psprintf ( r -> pool , java_script , origin , client_id , <nl> - session_state , op_iframe_id , s_poll_interval , redirect_uri , <nl> + session_state , op_iframe_id , poll_interval , redirect_uri , <nl> redirect_uri ); <nl>  <nl> return oidc_util_html_send ( r , NULL , java_script , " setTimer ", NULL , DONE );
mmm src / Client . cpp <nl> ppp src / Client . cpp <nl> void CClient :: EchoMessage ( const CMessage & Message ) { <nl> CMessage EchoedMessage = Message ; <nl> for ( CClient * pClient : GetClients ()) { <nl> if ( pClient -> HasEchoMessage () || <nl> - ( pClient != this && ( m_pNetwork -> IsChan ( Message . GetParam ( 0 )) || <nl> + ( pClient != this && (( m_pNetwork && m_pNetwork -> IsChan ( Message . GetParam ( 0 ))) || <nl> pClient -> HasSelfMessage ()))) { <nl> EchoedMessage . SetNick ( GetNickMask ()); <nl> pClient -> PutClient ( EchoedMessage );mmm test / integration / tests / core . cpp <nl> ppp test / integration / tests / core . cpp <nl> void CClient :: EchoMessage ( const CMessage & Message ) { <nl> CMessage EchoedMessage = Message ; <nl> for ( CClient * pClient : GetClients ()) { <nl> if ( pClient -> HasEchoMessage () || <nl> - ( pClient != this && ( m_pNetwork -> IsChan ( Message . GetParam ( 0 )) || <nl> + ( pClient != this && (( m_pNetwork && m_pNetwork -> IsChan ( Message . GetParam ( 0 ))) || <nl> pClient -> HasSelfMessage ()))) { <nl> EchoedMessage . SetNick ( GetNickMask ()); <nl> pClient -> PutClient ( EchoedMessage ); <nl> TEST_F ( ZNCTest , StatusEchoMessage ) { <nl> client . Write (" PRIVMSG * status : blah "); <nl> client . ReadUntil (": nick ! user @ irc . znc . in PRIVMSG * status : blah "); <nl> client . ReadUntil (":* status ! znc @ znc . in PRIVMSG nick : Unknown command "); <nl> + client . Write (" znc delnetwork test "); <nl> + client . ReadUntil (" Network deleted "); <nl> + auto client2 = LoginClient (); <nl> + client2 . Write (" PRIVMSG * status : blah2 "); <nl> + client2 . ReadUntil (":* status ! znc @ znc . in PRIVMSG nick : Unknown command "); <nl> + auto client3 = LoginClient (); <nl> + client3 . Write (" PRIVMSG * status : blah3 "); <nl> + client3 . ReadUntil (":* status ! znc @ znc . in PRIVMSG nick : Unknown command "); <nl> } <nl>  <nl> } // namespace
mmm test / MessageTest . cpp <nl> ppp test / MessageTest . cpp <nl> TEST ( MessageTest , Topic ) { <nl> EXPECT_EQ (": nick TOPIC # chan test ", topic . ToString ()); <nl> } <nl>  <nl> + TEST ( MessageTest , Parse ) { <nl> + CMessage msg ; <nl> + <nl> + // # 1037 <nl> + msg . Parse (": irc . znc . in PRIVMSG ::)"); <nl> + EXPECT_EQ (":)", msg . GetParam ( 0 )); <nl> +} <nl> + <nl> // The test data for MessageTest . Parse originates from https :// github . com / SaberUK / ircparser <nl> // <nl> // IRCParser - Internet Relay Chat Message Parsermmm src / Message . cpp <nl> ppp src / Message . cpp <nl> TEST ( MessageTest , Topic ) { <nl> EXPECT_EQ (": nick TOPIC # chan test ", topic . ToString ()); <nl> } <nl>  <nl> + TEST ( MessageTest , Parse ) { <nl> + CMessage msg ; <nl> + <nl> + // # 1037 <nl> + msg . Parse (": irc . znc . in PRIVMSG ::)"); <nl> + EXPECT_EQ (":)", msg . GetParam ( 0 )); <nl> +} <nl> + <nl> // The test data for MessageTest . Parse originates from https :// github . com / SaberUK / ircparser <nl> // <nl> // IRCParser - Internet Relay Chat Message Parser <nl> void CMessage :: Parse ( CString sMessage ) <nl> // NUL or CR or LF > <nl>  <nl> // < prefix > <nl> - if ( sMessage . TrimLeft (":")) { <nl> + if ( sMessage . TrimPrefix (":")) { <nl> m_Nick . Parse ( sMessage . Token ( 0 )); <nl> sMessage = sMessage . Token ( 1 , true ); <nl> } <nl> void CMessage :: Parse ( CString sMessage ) <nl> // < params > <nl> m_vsParams . clear (); <nl> while (! sMessage . empty ()) { <nl> - if ( sMessage . TrimLeft (":")) { <nl> + if ( sMessage . TrimPrefix (":")) { <nl> m_vsParams . push_back ( sMessage ); <nl> sMessage . clear (); <nl> } else {
mmm modules / webadmin . cpp <nl> ppp modules / webadmin . cpp <nl> public : <nl> CIRCNetwork * pNetwork = SafeGetNetworkFromParam ( WebSock ); <nl>  <nl> // Admin || Self Check <nl> - if (! spSession -> IsAdmin () && (! spSession -> GetUser () || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> + if (! spSession -> IsAdmin () && (! spSession -> GetUser () || ! pNetwork || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> return false ; <nl> } <nl>  <nl> public : <nl> CIRCNetwork * pNetwork = SafeGetNetworkFromParam ( WebSock ); <nl>  <nl> // Admin || Self Check <nl> - if (! spSession -> IsAdmin () && (! spSession -> GetUser () || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> + if (! spSession -> IsAdmin () && (! spSession -> GetUser () || ! pNetwork || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> return false ; <nl> } <nl>  <nl> public : <nl> CIRCNetwork * pNetwork = SafeGetNetworkFromParam ( WebSock ); <nl>  <nl> // Admin || Self Check <nl> - if (! spSession -> IsAdmin () && (! spSession -> GetUser () || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> + if (! spSession -> IsAdmin () && (! spSession -> GetUser () || ! pNetwork || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> return false ; <nl> } <nl>  <nl> public : <nl> CIRCNetwork * pNetwork = SafeGetNetworkFromParam ( WebSock ); <nl>  <nl> // Admin || Self Check <nl> - if (! spSession -> IsAdmin () && (! spSession -> GetUser () || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> + if (! spSession -> IsAdmin () && (! spSession -> GetUser () || ! pNetwork || spSession -> GetUser () != pNetwork -> GetUser ())) { <nl> return false ; <nl> } <nl> 
mmm modules / modpython / compiler . cpp <nl> ppp modules / modpython / compiler . cpp <nl> */ <nl>  <nl> # include < Python . h > <nl> +# include < string > <nl>  <nl> void fail ( PyObject * py , int n ) { <nl> // Doesn ' t clear any variables , but meh , finalize anyway ... <nl> int main ( int argc , char ** argv ) { <nl> PyObject * pyFunc = PyObject_GetAttrString ( pyModule , " compile "); <nl> fail ( pyFunc , 2 ); <nl>  <nl> - PyObject * pyKW = Py_BuildValue ("{ sssN }", " cfile ", argv [ 2 ], " doraise ", Py_True ); <nl> + std :: string cfile = argv [ 2 ]; <nl> + if ( cfile . find ('/') == std :: string :: npos ) { <nl> + cfile = "./" + cfile ; <nl> + } <nl> + PyObject * pyKW = Py_BuildValue ("{ sssN }", " cfile ", cfile . c_str (), " doraise ", Py_True ); <nl> fail ( pyKW , 3 ); <nl>  <nl> PyObject * pyArg = Py_BuildValue ("( s )", argv [ 1 ]);
mmm modules / watch . cpp <nl> ppp modules / watch . cpp <nl> private : <nl> if ( m_pUser -> IsUserAttached ()) { <nl> m_pUser -> PutUser (":" + WatchEntry . GetTarget () + "! watch @ znc . in PRIVMSG " + m_pUser -> GetCurNick () + " :" + sMessage ); <nl> } else { <nl> - m_Buffer . AddLine (":" + WatchEntry . GetTarget () + "! watch @ znc . in PRIVMSG ", " :" + sMessage ); <nl> + m_Buffer . AddLine (":" + WatchEntry . GetTarget () + "! watch @ znc . in PRIVMSG ", <nl> + " :" + m_pUser -> AddTimestamp ( sMessage )); <nl> } <nl> } <nl> }
mmm modules / shell . cpp <nl> ppp modules / shell . cpp <nl> public : <nl> } <nl> } <nl>  <nl> + virtual bool OnLoad ( const CString & sArgs , CString & sMessage ) <nl> + { <nl> +# ifndef MOD_SHELL_ALLOW_EVERYONE <nl> + if (! m_pUser -> IsAdmin ()) { <nl> + sMessage = " You must be admin to use the shell module "; <nl> + return false ; <nl> + } <nl> +# endif <nl> + <nl> + return true ; <nl> + } <nl> + <nl> virtual void OnModCommand ( const CString & sCommand ) { <nl> if (( strcasecmp ( sCommand . c_str (), " cd ") == 0 ) || ( strncasecmp ( sCommand . c_str (), " cd ", 3 ) == 0 )) { <nl> CString sPath = CUtils :: ChangeDir ( m_sPath , (( sCommand . length () == 2 ) ? CString ( CZNC :: Get (). GetHomePath ()) : CString ( sCommand . substr ( 3 ))), CZNC :: Get (). GetHomePath ());
mmm modules / controlpanel . cpp <nl> ppp modules / controlpanel . cpp <nl> class CAdminMod : public CModule { <nl> } <nl>  <nl> PutModule ( t_p (" Channel { 1 } is deleted from network { 2 } of user { 3 }", <nl> - " Channels { 2 } are deleted from network { 2 } of user { 3 }", <nl> + " Channels { 1 } are deleted from network { 2 } of user { 3 }", <nl> vsNames . size ())( <nl> CString (", "). Join ( vsNames . begin (), vsNames . end ()), <nl> pNetwork -> GetName (), sUsername ));
mmm znc . cpp <nl> ppp znc . cpp <nl> bool CZNC :: ParseConfig ( const CString & sConfig ) { <nl> m_sListenHost = sValue . Token ( 0 , false , ":"); <nl> sPort = sValue . Token ( 1 , true , ":"); <nl> } else { <nl> + m_sListenHost = ""; <nl> sPort = sValue ; <nl> } <nl> 
mmm main . cpp <nl> ppp main . cpp <nl> int main ( int argc , char ** argv ) { <nl> delete pZNC ; <nl> return 0 ; <nl> } <nl> + <nl> if ( bEncPem && ! bMakePem ) { <nl> CUtils :: PrintError ("-- encrypt - pem should be used along with -- makepem ."); <nl> + delete pZNC ; <nl> return 1 ; <nl> } <nl> - <nl> # endif /* HAVE_LIBSSL */ <nl> + <nl> if ( bMakePass ) { <nl> CString sSalt ; <nl> CString sHash = CUtils :: GetSaltedHashPass ( sSalt ); <nl> CUtils :: PrintMessage (" Use this in the < User > section of your config :"); <nl> CUtils :: PrintMessage (" Pass = md5 #" + sHash + "#" + sSalt + "#"); <nl>  <nl> + delete pZNC ; <nl> return 0 ; <nl> } <nl>  <nl> int main ( int argc , char ** argv ) { <nl> CUtils :: PrintError (" You are running ZNC as root ! Don ' t do that ! There are not many valid "); <nl> CUtils :: PrintError (" reasons for this and it can , in theory , cause great damage !"); <nl> if (! bAllowRoot ) { <nl> - exit ( 1 ); <nl> + delete pZNC ; <nl> + return 1 ; <nl> } <nl> CUtils :: PrintError (" You have been warned ."); <nl> CUtils :: PrintError (" Hit CTRL + C now if you don ' t want to run ZNC as root ."); <nl> int main ( int argc , char ** argv ) { <nl> if ( iPid == - 1 ) { <nl> CUtils :: PrintStatus ( false , strerror ( errno )); <nl> delete pZNC ; <nl> - exit ( 1 ); <nl> + return 1 ; <nl> } <nl>  <nl> if ( iPid > 0 ) { <nl> int main ( int argc , char ** argv ) { <nl>  <nl> pZNC -> WritePidFile ( iPid ); <nl> CUtils :: PrintMessage ( CZNC :: GetTag ()); <nl> - exit ( 0 ); <nl> + /* Don ' t destroy pZNC here or it will delete the pid file . */ <nl> + return 0 ; <nl> } <nl>  <nl> // Redirect std in / out / err to / dev / null
mmm src / main . cpp <nl> ppp src / main . cpp <nl> int main ( int argc , char ** argv ) { <nl>  <nl> { <nl> set < CModInfo > ssGlobalMods ; <nl> + set < CModInfo > ssUserMods ; <nl> + set < CModInfo > ssNetworkMods ; <nl> CUtils :: PrintAction (" Checking for list of available modules "); <nl> pZNC -> GetModules (). GetAvailableMods ( ssGlobalMods , CModInfo :: GlobalModule ); <nl> - if ( ssGlobalMods . empty ()) { <nl> + pZNC -> GetModules (). GetAvailableMods ( ssUserMods , CModInfo :: UserModule ); <nl> + pZNC -> GetModules (). GetAvailableMods ( ssNetworkMods , CModInfo :: NetworkModule ); <nl> + if ( ssGlobalMods . empty () && ssUserMods . empty () && ssNetworkMods . empty ()) { <nl> CUtils :: PrintStatus ( false , ""); <nl> CUtils :: PrintError (" No modules found . Perhaps you didn ' t install ZNC properly ?"); <nl> CUtils :: PrintError (" Read http :// wiki . znc . in / Installation for instructions .");
mmm src / WebModules . cpp <nl> ppp src / WebModules . cpp <nl> CWebSock :: EPageReqResult CWebSock :: PrintTemplate ( const CString & sPageName , <nl> } <nl>  <nl> CString CWebSock :: GetSkinPath ( const CString & sSkinName ) { <nl> - CString sRet = CZNC :: Get (). GetZNCPath () + "/ webskins /" + sSkinName ; <nl> + const CString sSkin = sSkinName . Replace_n ("/", " _ "). Replace_n (".", " _ "); <nl> + <nl> + CString sRet = CZNC :: Get (). GetZNCPath () + "/ webskins /" + sSkin ; <nl>  <nl> if (! CFile :: IsDir ( sRet )) { <nl> - sRet = CZNC :: Get (). GetCurPath () + "/ webskins /" + sSkinName ; <nl> + sRet = CZNC :: Get (). GetCurPath () + "/ webskins /" + sSkin ; <nl>  <nl> if (! CFile :: IsDir ( sRet )) { <nl> - sRet = CString ( _SKINDIR_ ) + "/" + sSkinName ; <nl> + sRet = CString ( _SKINDIR_ ) + "/" + sSkin ; <nl> } <nl> } <nl> 
mmm src / Config . cpp <nl> ppp src / Config . cpp <nl> bool CConfig :: Parse ( CFile & file , CString & sErrorMsg ) { <nl> void CConfig :: Write ( CFile & File , unsigned int iIndentation ) { <nl> CString sIndentation = CString ( iIndentation , '\ t '); <nl>  <nl> + auto SingleLine = []( const CString & s ) { <nl> + return s . Replace_n ("\ r ", ""). Replace_n ("\ n ", ""); <nl> + }; <nl> + <nl> for ( const auto & it : m_ConfigEntries ) { <nl> for ( const CString & sValue : it . second ) { <nl> - File . Write ( sIndentation + it . first + " = " + sValue + "\ n "); <nl> + File . Write ( SingleLine ( sIndentation + it . first + " = " + sValue ) + <nl> + "\ n "); <nl> } <nl> } <nl>  <nl> void CConfig :: Write ( CFile & File , unsigned int iIndentation ) { <nl> for ( const auto & it2 : it . second ) { <nl> File . Write ("\ n "); <nl>  <nl> - File . Write ( sIndentation + "<" + it . first + " " + it2 . first + ">\ n "); <nl> + File . Write ( SingleLine ( sIndentation + "<" + it . first + " " + <nl> + it2 . first + ">") + <nl> + "\ n "); <nl> it2 . second . m_pSubConfig -> Write ( File , iIndentation + 1 ); <nl> - File . Write ( sIndentation + "</" + it . first + ">\ n "); <nl> + File . Write ( SingleLine ( sIndentation + "</" + it . first + ">") + "\ n "); <nl> } <nl> } <nl> }
mmm modules / flooddetach . cpp <nl> ppp modules / flooddetach . cpp <nl> public : <nl> return CONTINUE ; <nl> } <nl>  <nl> + void OnNick ( const CNick & Nick , const CString & sNewNick , const std :: vector < CChan *>& vChans ) override { <nl> + for ( CChan * pChan : vChans ) { <nl> + Message (* pChan ); <nl> + } <nl> + } <nl> + <nl> void ShowCommand ( const CString & sLine ) { <nl> PutModule (" Current limit is " + CString ( m_iThresholdMsgs ) + " lines " <nl> " in " + CString ( m_iThresholdSecs ) + " secs .");
mmm HTTPSock . cpp <nl> ppp HTTPSock . cpp <nl> CString CHTTPSock :: GetParam ( const CString & sName , bool bPost , const CString & sFi <nl>  <nl> CString CHTTPSock :: GetParam ( const CString & sName , const map < CString , VCString >& msvsParams , const CString & sFilter ) { <nl> CString sRet = GetRawParam ( sName , msvsParams ); <nl> + sRet . Trim (); <nl>  <nl> for ( size_t i = 0 ; i < sFilter . length (); i ++) { <nl> sRet . Replace ( CString ( sFilter . at ( i )), ""); <nl> unsigned int CHTTPSock :: GetParamValues ( const CString & sName , set < CString >& ssRet <nl> if ( it != msvsParams . end ()) { <nl> for ( unsigned int a = 0 ; a < it -> second . size (); a ++) { <nl> CString sParam = it -> second [ a ]; <nl> + sParam . Trim (); <nl>  <nl> for ( size_t i = 0 ; i < sFilter . length (); i ++) { <nl> sParam . Replace ( CString ( sFilter . at ( i )), ""); <nl> unsigned int CHTTPSock :: GetParamValues ( const CString & sName , VCString & vsRet , co <nl> if ( it != msvsParams . end ()) { <nl> for ( unsigned int a = 0 ; a < it -> second . size (); a ++) { <nl> CString sParam = it -> second [ a ]; <nl> + sParam . Trim (); <nl>  <nl> for ( size_t i = 0 ; i < sFilter . length (); i ++) { <nl> sParam . Replace ( CString ( sFilter . at ( i )), "");
mmm src / main . cpp <nl> ppp src / main . cpp <nl> int main ( int argc , char ** argv ) { <nl> } <nl>  <nl> if ( optind < argc ) { <nl> - CUtils :: PrintError (" Specifying a config file as an argument isn ' t supported anymore ."); <nl> - CUtils :: PrintError (" Use -- datadir instead ."); <nl> + CUtils :: PrintError (" Unrecognized command line arguments ."); <nl> + CUtils :: PrintError (" Did you mean to run `/ znc " + CString ( argv [ optind ]) + "' in IRC client instead ?"); <nl> + CUtils :: PrintError (" Hint : `/ znc " + CString ( argv [ optind ]) + "' is an alias for `/ msg * status " + CString ( argv [ optind ]) + "'"); <nl> return 1 ; <nl> } <nl> 
mmm src / Client . cpp <nl> ppp src / Client . cpp <nl> void CClient :: ReadLine ( const CString & sData ) { <nl> CLanguageScope user_lang ( GetUser () ? GetUser ()-> GetLanguage () : ""); <nl> CString sLine = sData ; <nl>  <nl> - sLine . TrimRight ("\ n \ r "); <nl> + sLine . Replace ("\ n ", ""); <nl> + sLine . Replace ("\ r ", ""); <nl>  <nl> DEBUG ("(" << GetFullName () << ") CLI -> ZNC [" <nl> << CDebug :: Filter ( sLine ) << "]");mmm src / IRCSock . cpp <nl> ppp src / IRCSock . cpp <nl> void CClient :: ReadLine ( const CString & sData ) { <nl> CLanguageScope user_lang ( GetUser () ? GetUser ()-> GetLanguage () : ""); <nl> CString sLine = sData ; <nl>  <nl> - sLine . TrimRight ("\ n \ r "); <nl> + sLine . Replace ("\ n ", ""); <nl> + sLine . Replace ("\ r ", ""); <nl>  <nl> DEBUG ("(" << GetFullName () << ") CLI -> ZNC [" <nl> << CDebug :: Filter ( sLine ) << "]"); <nl> void CIRCSock :: Quit ( const CString & sQuitMsg ) { <nl> void CIRCSock :: ReadLine ( const CString & sData ) { <nl> CString sLine = sData ; <nl>  <nl> - sLine . TrimRight ("\ n \ r "); <nl> + sLine . Replace ("\ n ", ""); <nl> + sLine . Replace ("\ r ", ""); <nl>  <nl> DEBUG ("(" << m_pNetwork -> GetUser ()-> GetUserName () << "/" <nl> << m_pNetwork -> GetName () << ") IRC -> ZNC [" << sLine << "]");
mmm modules / charset . cpp <nl> ppp modules / charset . cpp <nl> private : <nl> do <nl> { <nl> char * pOut = tmpbuf ; <nl> - size_t uBufSize = 1024 ; <nl> + size_t uBufSize = sizeof ( tmpbuf ); <nl> bBreak = ( uInLen < 1 ); <nl>  <nl> if ( iconv ( ic , // this is ugly , but keeps the code short : <nl> private : <nl> } <nl> } <nl>  <nl> - uLength += ( pOut - tmpbuf ); <nl> + uLength += sizeof ( tmpbuf ) - uBufSize ; <nl> } while (! bBreak ); <nl>  <nl> return uLength ; <nl> private : <nl>  <nl> if ( bResult ) <nl> { <nl> - sData . assign ( pResult , uLength ); <nl> + sData . assign ( pResult , ( uLength + 1 ) - uResultBufSize ); <nl>  <nl> DEBUG (" charset : Converted : [" + sData . Escape_n ( CString :: EURL ) + "] from [" + sFrom + "] to [" + sTo + "]!"); <nl> }
mmm znc . h <nl> ppp znc . h <nl> public : <nl> if ( IsSSL ()) { <nl> bSSL = true ; <nl> m_pListener -> SetPemLocation ( CZNC :: Get (). GetPemLocation ()); <nl> + <nl> + // Ask the client for a cert , if it got none , nothing bad happens <nl> + m_pListener -> SetRequireClientCertFlags ( SSL_VERIFY_PEER ); <nl> } <nl> # endif <nl> 
mmm src / FileUtils . cpp <nl> ppp src / FileUtils . cpp <nl> bool CFile :: Copy ( const CString & sOldFileName , const CString & sNewFileName , bool <nl> OldFile . Close (); <nl> NewFile . Close (); <nl>  <nl> + struct stat st ; <nl> + GetInfo ( sOldFileName , st ); <nl> + Chmod ( sNewFileName , st . st_mode ); <nl> + <nl> return true ; <nl> } <nl> 
mmm User . cpp <nl> ppp User . cpp <nl> void CUser :: SetIRCNick ( const CNick & n ) { <nl> } <nl>  <nl> bool CUser :: AddCTCPReply ( const CString & sCTCP , const CString & sReply ) { <nl> + // Reject CTCP requests containing spaces <nl> + if ( sCTCP . find_first_of (' ') != CString :: npos ) { <nl> + return false ; <nl> + } <nl> + // Reject empty CTCP requests <nl> if ( sCTCP . empty ()) { <nl> return false ; <nl> } <nl> - <nl> m_mssCTCPReplies [ sCTCP . AsUpper ()] = sReply ; <nl> return true ; <nl> }
mmm String . cpp <nl> ppp String . cpp <nl> CString CString :: Format ( const CString & sFormatStr , ...) { <nl> return ""; <nl> } <nl>  <nl> + CString CString :: ToString ( char c ) { stringstream s ; s << c ; return s . str (); } <nl> + CString CString :: ToString ( unsigned char c ) { stringstream s ; s << c ; return s . str (); } <nl> CString CString :: ToString ( short i ) { stringstream s ; s << i ; return s . str (); } <nl> CString CString :: ToString ( unsigned short i ) { stringstream s ; s << i ; return s . str (); } <nl> CString CString :: ToString ( int i ) { stringstream s ; s << i ; return s . str (); }mmm String . h <nl> ppp String . h <nl> CString CString :: Format ( const CString & sFormatStr , ...) { <nl> return ""; <nl> } <nl>  <nl> + CString CString :: ToString ( char c ) { stringstream s ; s << c ; return s . str (); } <nl> + CString CString :: ToString ( unsigned char c ) { stringstream s ; s << c ; return s . str (); } <nl> CString CString :: ToString ( short i ) { stringstream s ; s << i ; return s . str (); } <nl> CString CString :: ToString ( unsigned short i ) { stringstream s ; s << i ; return s . str (); } <nl> CString CString :: ToString ( int i ) { stringstream s ; s << i ; return s . str (); } <nl> public : <nl>  <nl> static CString Format ( const CString & sFormatStr , ...); <nl>  <nl> + static CString ToString ( char c ); <nl> + static CString ToString ( unsigned char c ); <nl> static CString ToString ( short i ); <nl> static CString ToString ( unsigned short i ); <nl> static CString ToString ( int i );